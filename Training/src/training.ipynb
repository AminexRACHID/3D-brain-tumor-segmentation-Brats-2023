{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be51a2aa-5ca9-463d-9051-1df693ac23dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 629\n",
      "Number of validation images: 109\n",
      "Using device: cuda:0\n",
      "model created\n",
      "Number of parameters in the model: 174453080\n",
      "num_classes : 4, class_weights : tensor([ 0.2600, 33.1800,  8.5700, 23.4500])\n",
      "Model Training Step\n",
      "Batch: 0 , Combined Loss: tensor(1.1436, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7675749063491821\n",
      "Batch: 1 , Combined Loss: tensor(1.1587, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8575944900512695\n",
      "Batch: 2 , Combined Loss: tensor(1.1493, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8829892873764038\n",
      "Batch: 3 , Combined Loss: tensor(1.1655, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8664044141769409\n",
      "Batch: 4 , Combined Loss: tensor(1.1586, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8782557249069214\n",
      "Batch: 5 , Combined Loss: tensor(1.1477, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.872433066368103\n",
      "Batch: 6 , Combined Loss: tensor(1.1365, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8901104927062988\n",
      "Batch: 7 , Combined Loss: tensor(1.1513, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9338408708572388\n",
      "Batch: 8 , Combined Loss: tensor(1.1451, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9270455837249756\n",
      "Batch: 9 , Combined Loss: tensor(1.1345, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.744927167892456\n",
      "Batch: 10 , Combined Loss: tensor(1.1136, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8702529668807983\n",
      "Batch: 11 , Combined Loss: tensor(1.1154, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7878962755203247\n",
      "Batch: 12 , Combined Loss: tensor(1.1443, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9060108065605164\n",
      "Batch: 13 , Combined Loss: tensor(1.1239, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8905877470970154\n",
      "Batch: 14 , Combined Loss: tensor(1.1133, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.812996506690979\n",
      "Batch: 15 , Combined Loss: tensor(1.1522, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9071260094642639\n",
      "Batch: 16 , Combined Loss: tensor(1.1258, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8965239524841309\n",
      "Batch: 17 , Combined Loss: tensor(1.1612, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9465239644050598\n",
      "Batch: 18 , Combined Loss: tensor(1.1647, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9326597452163696\n",
      "Batch: 19 , Combined Loss: tensor(1.1179, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.791622519493103\n",
      "Batch: 20 , Combined Loss: tensor(1.1754, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9035579562187195\n",
      "Batch: 21 , Combined Loss: tensor(1.1553, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8887500762939453\n",
      "Batch: 22 , Combined Loss: tensor(1.1622, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9331039786338806\n",
      "Batch: 23 , Combined Loss: tensor(1.1360, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8636958003044128\n",
      "Batch: 24 , Combined Loss: tensor(1.1196, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6886334419250488\n",
      "Batch: 25 , Combined Loss: tensor(1.1009, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7351789474487305\n",
      "Batch: 26 , Combined Loss: tensor(1.1401, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8832212090492249\n",
      "Batch: 27 , Combined Loss: tensor(1.1361, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9287086725234985\n",
      "Batch: 28 , Combined Loss: tensor(1.1398, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9005500078201294\n",
      "Batch: 29 , Combined Loss: tensor(1.1444, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.945835530757904\n",
      "Batch: 30 , Combined Loss: tensor(1.1103, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8175353407859802\n",
      "Batch: 31 , Combined Loss: tensor(1.1600, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.968482494354248\n",
      "Batch: 32 , Combined Loss: tensor(1.0985, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8873972296714783\n",
      "Batch: 33 , Combined Loss: tensor(1.0931, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.660744845867157\n",
      "Batch: 34 , Combined Loss: tensor(1.1148, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8527315855026245\n",
      "Batch: 35 , Combined Loss: tensor(1.1025, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8143882155418396\n",
      "Batch: 36 , Combined Loss: tensor(1.1332, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9346928596496582\n",
      "Batch: 37 , Combined Loss: tensor(1.1196, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9257182478904724\n",
      "Batch: 38 , Combined Loss: tensor(1.1290, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7874500751495361\n",
      "Batch: 39 , Combined Loss: tensor(1.1244, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8039693832397461\n",
      "Batch: 40 , Combined Loss: tensor(1.1274, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.800345242023468\n",
      "Batch: 41 , Combined Loss: tensor(1.1030, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8811542987823486\n",
      "Batch: 42 , Combined Loss: tensor(1.1085, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7139883637428284\n",
      "Batch: 43 , Combined Loss: tensor(1.1086, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6251291036605835\n",
      "Batch: 44 , Combined Loss: tensor(1.1029, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6672201752662659\n",
      "Batch: 45 , Combined Loss: tensor(1.1153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7660195231437683\n",
      "Batch: 46 , Combined Loss: tensor(1.1496, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.657863974571228\n",
      "Batch: 47 , Combined Loss: tensor(1.1402, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.820000410079956\n",
      "Batch: 48 , Combined Loss: tensor(1.1323, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8173166513442993\n",
      "Batch: 49 , Combined Loss: tensor(1.1479, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8896608948707581\n",
      "Batch: 50 , Combined Loss: tensor(1.0888, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6629538536071777\n",
      "Batch: 51 , Combined Loss: tensor(1.1078, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7314674854278564\n",
      "Batch: 52 , Combined Loss: tensor(1.0851, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8661150336265564\n",
      "Batch: 53 , Combined Loss: tensor(1.1199, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.887463390827179\n",
      "Batch: 54 , Combined Loss: tensor(1.1222, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6587294340133667\n",
      "Batch: 55 , Combined Loss: tensor(1.0921, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7704641819000244\n",
      "Batch: 56 , Combined Loss: tensor(1.1048, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8911769986152649\n",
      "Batch: 57 , Combined Loss: tensor(1.0975, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5756783485412598\n",
      "Batch: 58 , Combined Loss: tensor(1.0780, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6209348440170288\n",
      "Batch: 59 , Combined Loss: tensor(1.0955, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7485449910163879\n",
      "Batch: 60 , Combined Loss: tensor(1.0880, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6832908391952515\n",
      "Batch: 61 , Combined Loss: tensor(1.0865, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5898658037185669\n",
      "Batch: 62 , Combined Loss: tensor(1.0836, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6183518171310425\n",
      "Batch: 63 , Combined Loss: tensor(1.0882, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8408832550048828\n",
      "Batch: 64 , Combined Loss: tensor(1.1034, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9198271632194519\n",
      "Batch: 65 , Combined Loss: tensor(1.1098, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7360097169876099\n",
      "Batch: 66 , Combined Loss: tensor(1.0715, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5926060676574707\n",
      "Batch: 67 , Combined Loss: tensor(1.1029, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7473932504653931\n",
      "Batch: 68 , Combined Loss: tensor(1.0988, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9295520782470703\n",
      "Batch: 69 , Combined Loss: tensor(1.0982, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8792776465415955\n",
      "Batch: 70 , Combined Loss: tensor(1.0844, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8053534626960754\n",
      "Batch: 71 , Combined Loss: tensor(1.0896, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7033130526542664\n",
      "Batch: 72 , Combined Loss: tensor(1.0768, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6356596946716309\n",
      "Batch: 73 , Combined Loss: tensor(1.0740, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5558018088340759\n",
      "Batch: 74 , Combined Loss: tensor(1.0930, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8523727655410767\n",
      "Batch: 75 , Combined Loss: tensor(1.0699, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9374079704284668\n",
      "Batch: 76 , Combined Loss: tensor(1.0871, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6706132888793945\n",
      "Batch: 77 , Combined Loss: tensor(1.0860, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8665049076080322\n",
      "Batch: 78 , Combined Loss: tensor(1.0846, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9214409589767456\n",
      "Batch: 79 , Combined Loss: tensor(1.0706, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.848505973815918\n",
      "Batch: 80 , Combined Loss: tensor(1.0780, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.798235297203064\n",
      "Batch: 81 , Combined Loss: tensor(1.0808, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9139687418937683\n",
      "Batch: 82 , Combined Loss: tensor(1.1302, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7077138423919678\n",
      "Batch: 83 , Combined Loss: tensor(1.0730, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8670016527175903\n",
      "Batch: 84 , Combined Loss: tensor(1.1159, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8716137409210205\n",
      "Batch: 85 , Combined Loss: tensor(1.1399, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7029361724853516\n",
      "Batch: 86 , Combined Loss: tensor(1.1309, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7777617573738098\n",
      "Batch: 87 , Combined Loss: tensor(1.1395, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5527504682540894\n",
      "Batch: 88 , Combined Loss: tensor(1.1542, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7058594226837158\n",
      "Batch: 89 , Combined Loss: tensor(1.0475, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8365679979324341\n",
      "Batch: 90 , Combined Loss: tensor(1.1099, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.625525951385498\n",
      "Batch: 91 , Combined Loss: tensor(1.0371, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9418731331825256\n",
      "Batch: 92 , Combined Loss: tensor(1.1095, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4701523184776306\n",
      "Batch: 93 , Combined Loss: tensor(1.0426, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8709070682525635\n",
      "Batch: 94 , Combined Loss: tensor(1.0871, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8990781307220459\n",
      "Batch: 95 , Combined Loss: tensor(1.0508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7019681930541992\n",
      "Batch: 96 , Combined Loss: tensor(1.0909, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5298534631729126\n",
      "Batch: 97 , Combined Loss: tensor(1.0428, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.743228554725647\n",
      "Batch: 98 , Combined Loss: tensor(1.1482, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5155459046363831\n",
      "Batch: 99 , Combined Loss: tensor(1.0628, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7448087930679321\n",
      "Batch: 100 , Combined Loss: tensor(1.0930, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7988581657409668\n",
      "Batch: 101 , Combined Loss: tensor(1.0288, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8865890502929688\n",
      "Batch: 102 , Combined Loss: tensor(1.0481, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8984060287475586\n",
      "Batch: 103 , Combined Loss: tensor(1.1108, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6099870204925537\n",
      "Batch: 104 , Combined Loss: tensor(1.0919, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6023814678192139\n",
      "Batch: 105 , Combined Loss: tensor(1.0891, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7177013754844666\n",
      "Batch: 106 , Combined Loss: tensor(1.0758, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7095922231674194\n",
      "Batch: 107 , Combined Loss: tensor(1.1403, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5480912327766418\n",
      "Batch: 108 , Combined Loss: tensor(1.0478, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9011046886444092\n",
      "Batch: 109 , Combined Loss: tensor(1.0316, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7787919044494629\n",
      "Batch: 110 , Combined Loss: tensor(1.0366, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7435760498046875\n",
      "Batch: 111 , Combined Loss: tensor(1.0512, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9136276245117188\n",
      "Batch: 112 , Combined Loss: tensor(1.0358, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8754570484161377\n",
      "Batch: 113 , Combined Loss: tensor(1.0771, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6900806427001953\n",
      "Batch: 114 , Combined Loss: tensor(1.0307, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9050093293190002\n",
      "Batch: 115 , Combined Loss: tensor(1.0941, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5817093253135681\n",
      "Batch: 116 , Combined Loss: tensor(1.0330, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5751364231109619\n",
      "Batch: 117 , Combined Loss: tensor(1.0206, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5658186674118042\n",
      "Batch: 118 , Combined Loss: tensor(1.0602, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8112473487854004\n",
      "Batch: 119 , Combined Loss: tensor(1.0131, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6433038711547852\n",
      "Batch: 120 , Combined Loss: tensor(1.0388, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8891084790229797\n",
      "Batch: 121 , Combined Loss: tensor(1.0241, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7927980422973633\n",
      "Batch: 122 , Combined Loss: tensor(1.0018, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5157012939453125\n",
      "Batch: 123 , Combined Loss: tensor(1.0239, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8602898716926575\n",
      "Batch: 124 , Combined Loss: tensor(1.0169, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6965922117233276\n",
      "Batch: 125 , Combined Loss: tensor(1.0318, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7692744731903076\n",
      "Batch: 126 , Combined Loss: tensor(1.0503, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8979095220565796\n",
      "Batch: 127 , Combined Loss: tensor(1.0604, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7295857071876526\n",
      "Batch: 128 , Combined Loss: tensor(1.0678, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8704957962036133\n",
      "Batch: 129 , Combined Loss: tensor(1.0502, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.54318767786026\n",
      "Batch: 130 , Combined Loss: tensor(1.0331, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7996006011962891\n",
      "Batch: 131 , Combined Loss: tensor(1.0122, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7701555490493774\n",
      "Batch: 132 , Combined Loss: tensor(1.0370, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3745940923690796\n",
      "Batch: 133 , Combined Loss: tensor(1.0434, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8226167559623718\n",
      "Batch: 134 , Combined Loss: tensor(1.0075, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8042372465133667\n",
      "Batch: 135 , Combined Loss: tensor(1.0383, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6086330413818359\n",
      "Batch: 136 , Combined Loss: tensor(1.0675, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9434059262275696\n",
      "Batch: 137 , Combined Loss: tensor(1.0839, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6965133547782898\n",
      "Batch: 138 , Combined Loss: tensor(1.0093, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6062359809875488\n",
      "Batch: 139 , Combined Loss: tensor(1.0298, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5848731994628906\n",
      "Batch: 140 , Combined Loss: tensor(1.0909, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7854627966880798\n",
      "Batch: 141 , Combined Loss: tensor(1.0672, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6651893854141235\n",
      "Batch: 142 , Combined Loss: tensor(1.0451, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.713114321231842\n",
      "Batch: 143 , Combined Loss: tensor(0.9537, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9145376086235046\n",
      "Batch: 144 , Combined Loss: tensor(1.1522, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7516964077949524\n",
      "Batch: 145 , Combined Loss: tensor(1.0342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6698766946792603\n",
      "Batch: 146 , Combined Loss: tensor(0.9916, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6171637177467346\n",
      "Batch: 147 , Combined Loss: tensor(1.0140, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9088342189788818\n",
      "Batch: 148 , Combined Loss: tensor(1.0906, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.821896493434906\n",
      "Batch: 149 , Combined Loss: tensor(0.9743, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.878391683101654\n",
      "Batch: 150 , Combined Loss: tensor(0.9944, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7363990545272827\n",
      "Batch: 151 , Combined Loss: tensor(1.0301, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5315905213356018\n",
      "Batch: 152 , Combined Loss: tensor(1.0006, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4007684588432312\n",
      "Batch: 153 , Combined Loss: tensor(1.0086, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8166921138763428\n",
      "Batch: 154 , Combined Loss: tensor(0.9869, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8062639832496643\n",
      "Batch: 155 , Combined Loss: tensor(0.9831, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9137578010559082\n",
      "Batch: 156 , Combined Loss: tensor(1.0288, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4516947865486145\n",
      "Batch: 157 , Combined Loss: tensor(0.9647, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9019513726234436\n",
      "Batch: 158 , Combined Loss: tensor(1.0774, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8011772632598877\n",
      "Batch: 159 , Combined Loss: tensor(1.0227, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5866928100585938\n",
      "Batch: 160 , Combined Loss: tensor(1.0135, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8943505883216858\n",
      "Batch: 161 , Combined Loss: tensor(0.9510, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6614033579826355\n",
      "Batch: 162 , Combined Loss: tensor(1.0925, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7923717498779297\n",
      "Batch: 163 , Combined Loss: tensor(1.0483, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5888298749923706\n",
      "Batch: 164 , Combined Loss: tensor(1.0384, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7923365831375122\n",
      "Batch: 165 , Combined Loss: tensor(0.9752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7347373366355896\n",
      "Batch: 166 , Combined Loss: tensor(1.1051, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7940986752510071\n",
      "Batch: 167 , Combined Loss: tensor(1.0384, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9091773629188538\n",
      "Batch: 168 , Combined Loss: tensor(1.0009, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7615516185760498\n",
      "Batch: 169 , Combined Loss: tensor(0.9800, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8858961462974548\n",
      "Batch: 170 , Combined Loss: tensor(1.0001, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9003356695175171\n",
      "Batch: 171 , Combined Loss: tensor(1.0032, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7932155132293701\n",
      "Batch: 172 , Combined Loss: tensor(0.9856, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7118667960166931\n",
      "Batch: 173 , Combined Loss: tensor(1.0608, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7465832233428955\n",
      "Batch: 174 , Combined Loss: tensor(0.9953, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4896565079689026\n",
      "Batch: 175 , Combined Loss: tensor(0.9773, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7353957295417786\n",
      "Batch: 176 , Combined Loss: tensor(1.0804, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9130200147628784\n",
      "Batch: 177 , Combined Loss: tensor(1.0365, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9319888353347778\n",
      "Batch: 178 , Combined Loss: tensor(1.0173, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6275970935821533\n",
      "Batch: 179 , Combined Loss: tensor(1.0476, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6198843717575073\n",
      "Batch: 180 , Combined Loss: tensor(1.0272, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8320762515068054\n",
      "Batch: 181 , Combined Loss: tensor(1.0791, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9118446111679077\n",
      "Batch: 182 , Combined Loss: tensor(1.0158, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9325162172317505\n",
      "Batch: 183 , Combined Loss: tensor(1.0402, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7338599562644958\n",
      "Batch: 184 , Combined Loss: tensor(1.0941, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8257770538330078\n",
      "Batch: 185 , Combined Loss: tensor(0.9988, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5415409803390503\n",
      "Batch: 186 , Combined Loss: tensor(0.9947, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9061625003814697\n",
      "Batch: 187 , Combined Loss: tensor(0.9597, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.755351185798645\n",
      "Batch: 188 , Combined Loss: tensor(1.0324, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8989484906196594\n",
      "Batch: 189 , Combined Loss: tensor(0.9946, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.548322319984436\n",
      "Batch: 190 , Combined Loss: tensor(0.9873, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.40869230031967163\n",
      "Batch: 191 , Combined Loss: tensor(1.0169, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8670058250427246\n",
      "Batch: 192 , Combined Loss: tensor(1.0011, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5248774290084839\n",
      "Batch: 193 , Combined Loss: tensor(0.9842, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7247717380523682\n",
      "Batch: 194 , Combined Loss: tensor(1.1062, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8987661600112915\n",
      "Batch: 195 , Combined Loss: tensor(0.9599, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.352014422416687\n",
      "Batch: 196 , Combined Loss: tensor(1.0099, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7339422702789307\n",
      "Batch: 197 , Combined Loss: tensor(1.0727, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.46976137161254883\n",
      "Batch: 198 , Combined Loss: tensor(1.0271, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6857448816299438\n",
      "Batch: 199 , Combined Loss: tensor(1.0444, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8660155534744263\n",
      "Batch: 200 , Combined Loss: tensor(1.0226, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6847450733184814\n",
      "Batch: 201 , Combined Loss: tensor(1.0220, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9159246683120728\n",
      "Batch: 202 , Combined Loss: tensor(0.9698, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.741965651512146\n",
      "Batch: 203 , Combined Loss: tensor(0.9893, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6227725744247437\n",
      "Batch: 204 , Combined Loss: tensor(0.9974, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.32481807470321655\n",
      "Batch: 205 , Combined Loss: tensor(1.0847, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7096329927444458\n",
      "Batch: 206 , Combined Loss: tensor(1.0117, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7836378812789917\n",
      "Batch: 207 , Combined Loss: tensor(1.0407, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6886007189750671\n",
      "Batch: 208 , Combined Loss: tensor(1.0065, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9212156534194946\n",
      "Batch: 209 , Combined Loss: tensor(0.9923, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6925200819969177\n",
      "Batch: 210 , Combined Loss: tensor(1.0073, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5680426359176636\n",
      "Batch: 211 , Combined Loss: tensor(1.0011, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7591410279273987\n",
      "Batch: 212 , Combined Loss: tensor(1.0106, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.681567370891571\n",
      "Batch: 213 , Combined Loss: tensor(0.9960, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.46311867237091064\n",
      "Batch: 214 , Combined Loss: tensor(1.0301, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6790387630462646\n",
      "Batch: 215 , Combined Loss: tensor(1.0003, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6320902109146118\n",
      "Batch: 216 , Combined Loss: tensor(0.9525, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6724491715431213\n",
      "Batch: 217 , Combined Loss: tensor(0.9706, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8606053590774536\n",
      "Batch: 218 , Combined Loss: tensor(0.9980, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5752896070480347\n",
      "Batch: 219 , Combined Loss: tensor(0.9783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.47208189964294434\n",
      "Batch: 220 , Combined Loss: tensor(1.0624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7732665538787842\n",
      "Batch: 221 , Combined Loss: tensor(1.0271, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.890075147151947\n",
      "Batch: 222 , Combined Loss: tensor(1.0095, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7947544455528259\n",
      "Batch: 223 , Combined Loss: tensor(1.0126, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7459622621536255\n",
      "Batch: 224 , Combined Loss: tensor(0.9848, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8280234932899475\n",
      "Batch: 225 , Combined Loss: tensor(1.0186, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7536349296569824\n",
      "Batch: 226 , Combined Loss: tensor(0.9625, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.44464975595474243\n",
      "Batch: 227 , Combined Loss: tensor(0.9813, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6070507168769836\n",
      "Batch: 228 , Combined Loss: tensor(1.0781, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.775745689868927\n",
      "Batch: 229 , Combined Loss: tensor(1.0075, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.641004204750061\n",
      "Batch: 230 , Combined Loss: tensor(1.0038, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6428730487823486\n",
      "Batch: 231 , Combined Loss: tensor(0.9829, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.38253843784332275\n",
      "Batch: 232 , Combined Loss: tensor(0.9461, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7882375717163086\n",
      "Batch: 233 , Combined Loss: tensor(0.9783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6761007308959961\n",
      "Batch: 234 , Combined Loss: tensor(1.1003, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6770956516265869\n",
      "Batch: 235 , Combined Loss: tensor(0.9721, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5126983523368835\n",
      "Batch: 236 , Combined Loss: tensor(0.9756, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8835150003433228\n",
      "Batch: 237 , Combined Loss: tensor(1.0130, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.781552791595459\n",
      "Batch: 238 , Combined Loss: tensor(0.9928, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7878657579421997\n",
      "Batch: 239 , Combined Loss: tensor(1.0071, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6247444152832031\n",
      "Batch: 240 , Combined Loss: tensor(1.0339, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6988626718521118\n",
      "Batch: 241 , Combined Loss: tensor(0.9898, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7511770725250244\n",
      "Batch: 242 , Combined Loss: tensor(1.0271, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8595366477966309\n",
      "Batch: 243 , Combined Loss: tensor(0.9886, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6136010885238647\n",
      "Batch: 244 , Combined Loss: tensor(0.9954, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7510096430778503\n",
      "Batch: 245 , Combined Loss: tensor(1.0611, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.567550778388977\n",
      "Batch: 246 , Combined Loss: tensor(1.0126, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.890292763710022\n",
      "Batch: 247 , Combined Loss: tensor(0.9853, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7297502756118774\n",
      "Batch: 248 , Combined Loss: tensor(0.9926, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7855758666992188\n",
      "Batch: 249 , Combined Loss: tensor(1.0455, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6936779022216797\n",
      "Batch: 250 , Combined Loss: tensor(1.0359, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8203042149543762\n",
      "Batch: 251 , Combined Loss: tensor(1.0025, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7602227926254272\n",
      "Batch: 252 , Combined Loss: tensor(0.9822, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5874567031860352\n",
      "Batch: 253 , Combined Loss: tensor(0.9790, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5290849208831787\n",
      "Batch: 254 , Combined Loss: tensor(0.9979, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7054299116134644\n",
      "Batch: 255 , Combined Loss: tensor(0.9833, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8332197070121765\n",
      "Batch: 256 , Combined Loss: tensor(0.9898, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.840819776058197\n",
      "Batch: 257 , Combined Loss: tensor(0.9954, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2989655137062073\n",
      "Batch: 258 , Combined Loss: tensor(1.0481, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7725710272789001\n",
      "Batch: 259 , Combined Loss: tensor(1.0198, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7083998918533325\n",
      "Batch: 260 , Combined Loss: tensor(0.9842, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.871787965297699\n",
      "Batch: 261 , Combined Loss: tensor(1.0398, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8691505789756775\n",
      "Batch: 262 , Combined Loss: tensor(1.0447, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4220407009124756\n",
      "Batch: 263 , Combined Loss: tensor(0.9909, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.45098572969436646\n",
      "Batch: 264 , Combined Loss: tensor(0.9888, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5951422452926636\n",
      "Batch: 265 , Combined Loss: tensor(0.9706, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7455611228942871\n",
      "Batch: 266 , Combined Loss: tensor(0.9754, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8054115772247314\n",
      "Batch: 267 , Combined Loss: tensor(0.9551, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7790669202804565\n",
      "Batch: 268 , Combined Loss: tensor(0.9662, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6703104376792908\n",
      "Batch: 269 , Combined Loss: tensor(0.9625, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9208929538726807\n",
      "Batch: 270 , Combined Loss: tensor(0.9969, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6046597957611084\n",
      "Batch: 271 , Combined Loss: tensor(1.0229, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.860830545425415\n",
      "Batch: 272 , Combined Loss: tensor(1.0272, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.48275071382522583\n",
      "Batch: 273 , Combined Loss: tensor(1.0355, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5651274919509888\n",
      "Batch: 274 , Combined Loss: tensor(0.9828, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9260604977607727\n",
      "Batch: 275 , Combined Loss: tensor(1.0022, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5658771991729736\n",
      "Batch: 276 , Combined Loss: tensor(0.9868, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7153745889663696\n",
      "Batch: 277 , Combined Loss: tensor(0.9679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8691867589950562\n",
      "Batch: 278 , Combined Loss: tensor(1.0403, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5520480275154114\n",
      "Batch: 279 , Combined Loss: tensor(0.9877, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8396676778793335\n",
      "Batch: 280 , Combined Loss: tensor(1.0202, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.498309850692749\n",
      "Batch: 281 , Combined Loss: tensor(1.0521, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8750842809677124\n",
      "Batch: 282 , Combined Loss: tensor(0.9911, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8075857758522034\n",
      "Batch: 283 , Combined Loss: tensor(0.9581, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9186843633651733\n",
      "Batch: 284 , Combined Loss: tensor(0.9673, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7142389416694641\n",
      "Batch: 285 , Combined Loss: tensor(0.9990, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6922298669815063\n",
      "Batch: 286 , Combined Loss: tensor(1.0114, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3600904941558838\n",
      "Batch: 287 , Combined Loss: tensor(0.9740, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7251891493797302\n",
      "Batch: 288 , Combined Loss: tensor(1.0165, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6583496332168579\n",
      "Batch: 289 , Combined Loss: tensor(0.9788, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5309046506881714\n",
      "Batch: 290 , Combined Loss: tensor(0.9730, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8699729442596436\n",
      "Batch: 291 , Combined Loss: tensor(0.9211, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9401329159736633\n",
      "Batch: 292 , Combined Loss: tensor(1.0125, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8888871669769287\n",
      "Batch: 293 , Combined Loss: tensor(0.9440, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.836986780166626\n",
      "Batch: 294 , Combined Loss: tensor(1.0144, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7541825175285339\n",
      "Batch: 295 , Combined Loss: tensor(0.9605, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5298922657966614\n",
      "Batch: 296 , Combined Loss: tensor(1.0401, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8158682584762573\n",
      "Batch: 297 , Combined Loss: tensor(0.9981, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7677034735679626\n",
      "Batch: 298 , Combined Loss: tensor(0.9798, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5949908494949341\n",
      "Batch: 299 , Combined Loss: tensor(0.8922, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8705065250396729\n",
      "Batch: 300 , Combined Loss: tensor(0.9612, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6798141002655029\n",
      "Batch: 301 , Combined Loss: tensor(1.0086, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7041572332382202\n",
      "Batch: 302 , Combined Loss: tensor(0.9650, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6181508302688599\n",
      "Batch: 303 , Combined Loss: tensor(1.0871, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.68436199426651\n",
      "Batch: 304 , Combined Loss: tensor(0.9360, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5006910562515259\n",
      "Batch: 305 , Combined Loss: tensor(0.9715, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5255526900291443\n",
      "Batch: 306 , Combined Loss: tensor(0.9449, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7363901138305664\n",
      "Batch: 307 , Combined Loss: tensor(1.0724, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7310634851455688\n",
      "Batch: 308 , Combined Loss: tensor(0.9923, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.350017786026001\n",
      "Batch: 309 , Combined Loss: tensor(0.9938, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9104535579681396\n",
      "Batch: 310 , Combined Loss: tensor(0.9981, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7893915772438049\n",
      "Batch: 311 , Combined Loss: tensor(1.0026, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5494914054870605\n",
      "Batch: 312 , Combined Loss: tensor(0.9299, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6645654439926147\n",
      "Batch: 313 , Combined Loss: tensor(0.9689, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5635679960250854\n",
      "Batch: 314 , Combined Loss: tensor(1.0201, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6618188619613647\n",
      "Batch: 315 , Combined Loss: tensor(1.0165, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9023742079734802\n",
      "Batch: 316 , Combined Loss: tensor(1.0323, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7555567622184753\n",
      "Batch: 317 , Combined Loss: tensor(1.0330, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6070702075958252\n",
      "Batch: 318 , Combined Loss: tensor(0.9978, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.36140143871307373\n",
      "Batch: 319 , Combined Loss: tensor(0.9472, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3684106469154358\n",
      "Batch: 320 , Combined Loss: tensor(0.9523, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6545143723487854\n",
      "Batch: 321 , Combined Loss: tensor(0.8960, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8665570616722107\n",
      "Batch: 322 , Combined Loss: tensor(0.9209, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6219395399093628\n",
      "Batch: 323 , Combined Loss: tensor(0.9525, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6595209836959839\n",
      "Batch: 324 , Combined Loss: tensor(0.9855, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6903742551803589\n",
      "Batch: 325 , Combined Loss: tensor(0.9425, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.34623777866363525\n",
      "Batch: 326 , Combined Loss: tensor(0.9403, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7639659643173218\n",
      "Batch: 327 , Combined Loss: tensor(0.9826, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6098151206970215\n",
      "Batch: 328 , Combined Loss: tensor(0.9795, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7354397773742676\n",
      "Batch: 329 , Combined Loss: tensor(0.9455, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.901999294757843\n",
      "Batch: 330 , Combined Loss: tensor(0.9343, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7774515151977539\n",
      "Batch: 331 , Combined Loss: tensor(0.9909, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.665777325630188\n",
      "Batch: 332 , Combined Loss: tensor(0.9703, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7046017646789551\n",
      "Batch: 333 , Combined Loss: tensor(0.9171, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8253989815711975\n",
      "Batch: 334 , Combined Loss: tensor(0.9967, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8181494474411011\n",
      "Batch: 335 , Combined Loss: tensor(0.9442, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.36252033710479736\n",
      "Batch: 336 , Combined Loss: tensor(0.9955, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.866407573223114\n",
      "Batch: 337 , Combined Loss: tensor(1.0002, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39778101444244385\n",
      "Batch: 338 , Combined Loss: tensor(0.9504, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6651858687400818\n",
      "Batch: 339 , Combined Loss: tensor(0.9802, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7333787083625793\n",
      "Batch: 340 , Combined Loss: tensor(1.0226, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5122736692428589\n",
      "Batch: 341 , Combined Loss: tensor(0.9793, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5110774636268616\n",
      "Batch: 342 , Combined Loss: tensor(0.9176, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7805936932563782\n",
      "Batch: 343 , Combined Loss: tensor(1.0350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8821226358413696\n",
      "Batch: 344 , Combined Loss: tensor(0.9995, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5204914808273315\n",
      "Batch: 345 , Combined Loss: tensor(1.0560, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6633674502372742\n",
      "Batch: 346 , Combined Loss: tensor(0.9306, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.45769333839416504\n",
      "Batch: 347 , Combined Loss: tensor(0.9505, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7210976481437683\n",
      "Batch: 348 , Combined Loss: tensor(0.8754, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7894364595413208\n",
      "Batch: 349 , Combined Loss: tensor(0.9755, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7624501585960388\n",
      "Batch: 350 , Combined Loss: tensor(0.9996, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5177361369132996\n",
      "Batch: 351 , Combined Loss: tensor(0.9597, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5822561383247375\n",
      "Batch: 352 , Combined Loss: tensor(0.9966, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8597851991653442\n",
      "Batch: 353 , Combined Loss: tensor(0.9600, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7618973851203918\n",
      "Batch: 354 , Combined Loss: tensor(0.9448, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6565874218940735\n",
      "Batch: 355 , Combined Loss: tensor(0.8978, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8203111290931702\n",
      "Batch: 356 , Combined Loss: tensor(0.9670, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4294261932373047\n",
      "Batch: 357 , Combined Loss: tensor(0.9914, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6676353216171265\n",
      "Batch: 358 , Combined Loss: tensor(1.0678, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7209222316741943\n",
      "Batch: 359 , Combined Loss: tensor(0.9736, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8408463597297668\n",
      "Batch: 360 , Combined Loss: tensor(0.9265, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8095996379852295\n",
      "Batch: 361 , Combined Loss: tensor(0.9610, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8132567405700684\n",
      "Batch: 362 , Combined Loss: tensor(1.0058, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6901659965515137\n",
      "Batch: 363 , Combined Loss: tensor(0.9537, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7949140071868896\n",
      "Batch: 364 , Combined Loss: tensor(0.9326, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4079321026802063\n",
      "Batch: 365 , Combined Loss: tensor(0.9410, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.877051830291748\n",
      "Batch: 366 , Combined Loss: tensor(1.0356, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8613303303718567\n",
      "Batch: 367 , Combined Loss: tensor(0.9833, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7190219163894653\n",
      "Batch: 368 , Combined Loss: tensor(0.9290, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5969427824020386\n",
      "Batch: 369 , Combined Loss: tensor(0.9803, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7018852233886719\n",
      "Batch: 370 , Combined Loss: tensor(1.0199, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.759880006313324\n",
      "Batch: 371 , Combined Loss: tensor(0.9077, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9099990725517273\n",
      "Batch: 372 , Combined Loss: tensor(1.0009, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5089209079742432\n",
      "Batch: 373 , Combined Loss: tensor(0.9567, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.446466326713562\n",
      "Batch: 374 , Combined Loss: tensor(0.9694, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6760474443435669\n",
      "Batch: 375 , Combined Loss: tensor(1.0456, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7800177931785583\n",
      "Batch: 376 , Combined Loss: tensor(0.9929, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7238037586212158\n",
      "Batch: 377 , Combined Loss: tensor(0.9789, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7483454942703247\n",
      "Batch: 378 , Combined Loss: tensor(0.9250, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6633801460266113\n",
      "Batch: 379 , Combined Loss: tensor(0.9958, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9064359664916992\n",
      "Batch: 380 , Combined Loss: tensor(1.0178, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5576425790786743\n",
      "Batch: 381 , Combined Loss: tensor(1.0516, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4667583107948303\n",
      "Batch: 382 , Combined Loss: tensor(1.0257, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.753618597984314\n",
      "Batch: 383 , Combined Loss: tensor(0.9312, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5974566340446472\n",
      "Batch: 384 , Combined Loss: tensor(0.9527, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5975374579429626\n",
      "Batch: 385 , Combined Loss: tensor(1.0438, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7047679424285889\n",
      "Batch: 386 , Combined Loss: tensor(0.9548, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.47320491075515747\n",
      "Batch: 387 , Combined Loss: tensor(1.0385, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5808641910552979\n",
      "Batch: 388 , Combined Loss: tensor(0.9542, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8372151851654053\n",
      "Batch: 389 , Combined Loss: tensor(0.9796, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3563762307167053\n",
      "Batch: 390 , Combined Loss: tensor(0.9583, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8089988231658936\n",
      "Batch: 391 , Combined Loss: tensor(0.9892, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7625004649162292\n",
      "Batch: 392 , Combined Loss: tensor(1.1487, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6763968467712402\n",
      "Batch: 393 , Combined Loss: tensor(0.9629, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5670064091682434\n",
      "Batch: 394 , Combined Loss: tensor(0.9762, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7662973403930664\n",
      "Batch: 395 , Combined Loss: tensor(1.0618, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8132264614105225\n",
      "Batch: 396 , Combined Loss: tensor(0.9521, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6324144601821899\n",
      "Batch: 397 , Combined Loss: tensor(0.9486, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6607568264007568\n",
      "Batch: 398 , Combined Loss: tensor(0.9490, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5643482208251953\n",
      "Batch: 399 , Combined Loss: tensor(0.9556, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.47903090715408325\n",
      "Batch: 400 , Combined Loss: tensor(1.0035, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7966809272766113\n",
      "Batch: 401 , Combined Loss: tensor(0.9359, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.55929034948349\n",
      "Batch: 402 , Combined Loss: tensor(0.9262, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7205086946487427\n",
      "Batch: 403 , Combined Loss: tensor(0.9857, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8388563990592957\n",
      "Batch: 404 , Combined Loss: tensor(0.9774, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.33086341619491577\n",
      "Batch: 405 , Combined Loss: tensor(0.9891, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7653834819793701\n",
      "Batch: 406 , Combined Loss: tensor(1.0520, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9169979095458984\n",
      "Batch: 407 , Combined Loss: tensor(1.0236, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7430040240287781\n",
      "Batch: 408 , Combined Loss: tensor(0.9204, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6228556632995605\n",
      "Batch: 409 , Combined Loss: tensor(0.9303, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4851430058479309\n",
      "Batch: 410 , Combined Loss: tensor(0.9579, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6966043710708618\n",
      "Batch: 411 , Combined Loss: tensor(0.9466, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8469130992889404\n",
      "Batch: 412 , Combined Loss: tensor(0.9460, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8611772060394287\n",
      "Batch: 413 , Combined Loss: tensor(0.9679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4668344259262085\n",
      "Batch: 414 , Combined Loss: tensor(0.9909, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7740219235420227\n",
      "Batch: 415 , Combined Loss: tensor(0.9209, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6221262812614441\n",
      "Batch: 416 , Combined Loss: tensor(0.9678, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5871291160583496\n",
      "Batch: 417 , Combined Loss: tensor(0.9768, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8978795409202576\n",
      "Batch: 418 , Combined Loss: tensor(0.9716, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7981606721878052\n",
      "Batch: 419 , Combined Loss: tensor(0.9870, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6245132088661194\n",
      "Batch: 420 , Combined Loss: tensor(0.9649, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7272524833679199\n",
      "Batch: 421 , Combined Loss: tensor(0.9208, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4231513738632202\n",
      "Batch: 422 , Combined Loss: tensor(0.9249, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7298836708068848\n",
      "Batch: 423 , Combined Loss: tensor(0.9659, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8950076103210449\n",
      "Batch: 424 , Combined Loss: tensor(0.9818, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8433019518852234\n",
      "Batch: 425 , Combined Loss: tensor(0.9499, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6842090487480164\n",
      "Batch: 426 , Combined Loss: tensor(0.9963, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.48228538036346436\n",
      "Batch: 427 , Combined Loss: tensor(0.9920, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.79673171043396\n",
      "Batch: 428 , Combined Loss: tensor(1.0350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4933719038963318\n",
      "Batch: 429 , Combined Loss: tensor(0.9383, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7179850339889526\n",
      "Batch: 430 , Combined Loss: tensor(0.9148, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.41130775213241577\n",
      "Batch: 431 , Combined Loss: tensor(0.9067, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.726891815662384\n",
      "Batch: 432 , Combined Loss: tensor(0.9096, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3525211215019226\n",
      "Batch: 433 , Combined Loss: tensor(1.0749, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7634955644607544\n",
      "Batch: 434 , Combined Loss: tensor(1.1271, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.521663248538971\n",
      "Batch: 435 , Combined Loss: tensor(1.0128, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6935787796974182\n",
      "Batch: 436 , Combined Loss: tensor(0.9583, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9238736033439636\n",
      "Batch: 437 , Combined Loss: tensor(0.9107, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6233222484588623\n",
      "Batch: 438 , Combined Loss: tensor(1.0479, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4659549593925476\n",
      "Batch: 439 , Combined Loss: tensor(1.0104, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8357855081558228\n",
      "Batch: 440 , Combined Loss: tensor(0.9607, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5978559255599976\n",
      "Batch: 441 , Combined Loss: tensor(0.9097, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6119533777236938\n",
      "Batch: 442 , Combined Loss: tensor(0.9247, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.33235085010528564\n",
      "Batch: 443 , Combined Loss: tensor(0.9530, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7589572668075562\n",
      "Batch: 444 , Combined Loss: tensor(1.0270, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7422970533370972\n",
      "Batch: 445 , Combined Loss: tensor(0.9646, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.608177900314331\n",
      "Batch: 446 , Combined Loss: tensor(0.9195, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7908692359924316\n",
      "Batch: 447 , Combined Loss: tensor(0.9297, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.914817214012146\n",
      "Batch: 448 , Combined Loss: tensor(0.9475, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7438734769821167\n",
      "Batch: 449 , Combined Loss: tensor(0.9973, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7005951404571533\n",
      "Batch: 450 , Combined Loss: tensor(0.9765, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8719663023948669\n",
      "Batch: 451 , Combined Loss: tensor(0.9182, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7119442820549011\n",
      "Batch: 452 , Combined Loss: tensor(0.9657, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5512818098068237\n",
      "Batch: 453 , Combined Loss: tensor(0.9176, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7210993766784668\n",
      "Batch: 454 , Combined Loss: tensor(0.9887, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3527832627296448\n",
      "Batch: 455 , Combined Loss: tensor(0.9456, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.896379292011261\n",
      "Batch: 456 , Combined Loss: tensor(0.9559, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6741161346435547\n",
      "Batch: 457 , Combined Loss: tensor(0.9907, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7351230978965759\n",
      "Batch: 458 , Combined Loss: tensor(1.0042, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6525585651397705\n",
      "Batch: 459 , Combined Loss: tensor(0.9441, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.80848628282547\n",
      "Batch: 460 , Combined Loss: tensor(1.0155, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8132319450378418\n",
      "Batch: 461 , Combined Loss: tensor(1.0456, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6230710744857788\n",
      "Batch: 462 , Combined Loss: tensor(0.9261, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5201980471611023\n",
      "Batch: 463 , Combined Loss: tensor(0.9549, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7043416500091553\n",
      "Batch: 464 , Combined Loss: tensor(0.9253, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.46651124954223633\n",
      "Batch: 465 , Combined Loss: tensor(0.9195, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5216058492660522\n",
      "Batch: 466 , Combined Loss: tensor(0.9292, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8837789297103882\n",
      "Batch: 467 , Combined Loss: tensor(0.9502, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8546606302261353\n",
      "Batch: 468 , Combined Loss: tensor(0.9967, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8346875905990601\n",
      "Batch: 469 , Combined Loss: tensor(0.9481, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7474051713943481\n",
      "Batch: 470 , Combined Loss: tensor(0.9313, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4734857678413391\n",
      "Batch: 471 , Combined Loss: tensor(0.9752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5538309216499329\n",
      "Batch: 472 , Combined Loss: tensor(1.0494, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.47853928804397583\n",
      "Batch: 473 , Combined Loss: tensor(0.9157, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39091914892196655\n",
      "Batch: 474 , Combined Loss: tensor(0.9306, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6867531538009644\n",
      "Batch: 475 , Combined Loss: tensor(1.0227, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8050251007080078\n",
      "Batch: 476 , Combined Loss: tensor(0.9874, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5331199169158936\n",
      "Batch: 477 , Combined Loss: tensor(1.0066, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8946019411087036\n",
      "Batch: 478 , Combined Loss: tensor(0.9997, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8092684745788574\n",
      "Batch: 479 , Combined Loss: tensor(0.9506, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7287393808364868\n",
      "Batch: 480 , Combined Loss: tensor(0.9386, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.42357391119003296\n",
      "Batch: 481 , Combined Loss: tensor(0.9830, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7518177628517151\n",
      "Batch: 482 , Combined Loss: tensor(0.9491, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8903980255126953\n",
      "Batch: 483 , Combined Loss: tensor(0.9753, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7820178270339966\n",
      "Batch: 484 , Combined Loss: tensor(0.9699, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7319210767745972\n",
      "Batch: 485 , Combined Loss: tensor(0.9057, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.45262855291366577\n",
      "Batch: 486 , Combined Loss: tensor(0.9771, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8479481935501099\n",
      "Batch: 487 , Combined Loss: tensor(0.9067, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5875542759895325\n",
      "Batch: 488 , Combined Loss: tensor(0.9438, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8137375116348267\n",
      "Batch: 489 , Combined Loss: tensor(0.9651, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4918631911277771\n",
      "Batch: 490 , Combined Loss: tensor(0.9131, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5708409547805786\n",
      "Batch: 491 , Combined Loss: tensor(0.9465, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5821207761764526\n",
      "Batch: 492 , Combined Loss: tensor(0.9664, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.36853140592575073\n",
      "Batch: 493 , Combined Loss: tensor(1.0206, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8164916038513184\n",
      "Batch: 494 , Combined Loss: tensor(0.9153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8755569458007812\n",
      "Batch: 495 , Combined Loss: tensor(0.9935, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6064131259918213\n",
      "Batch: 496 , Combined Loss: tensor(0.9851, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6187301874160767\n",
      "Batch: 497 , Combined Loss: tensor(0.9809, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5906793475151062\n",
      "Batch: 498 , Combined Loss: tensor(1.0141, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5726330280303955\n",
      "Batch: 499 , Combined Loss: tensor(0.9870, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6576876640319824\n",
      "Batch: 500 , Combined Loss: tensor(0.9222, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.689232587814331\n",
      "Batch: 501 , Combined Loss: tensor(1.0042, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.539422869682312\n",
      "Batch: 502 , Combined Loss: tensor(0.9879, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7117167711257935\n",
      "Batch: 503 , Combined Loss: tensor(0.9886, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6425381898880005\n",
      "Batch: 504 , Combined Loss: tensor(0.9112, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5992459058761597\n",
      "Batch: 505 , Combined Loss: tensor(0.9290, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5953138470649719\n",
      "Batch: 506 , Combined Loss: tensor(1.0369, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6865333318710327\n",
      "Batch: 507 , Combined Loss: tensor(0.9418, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.31077343225479126\n",
      "Batch: 508 , Combined Loss: tensor(0.8481, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.575096845626831\n",
      "Batch: 509 , Combined Loss: tensor(0.9071, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3935593366622925\n",
      "Batch: 510 , Combined Loss: tensor(0.9986, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8459848165512085\n",
      "Batch: 511 , Combined Loss: tensor(1.0408, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7881320714950562\n",
      "Batch: 512 , Combined Loss: tensor(0.9830, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4698164463043213\n",
      "Batch: 513 , Combined Loss: tensor(0.9650, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4979513883590698\n",
      "Batch: 514 , Combined Loss: tensor(0.9121, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.539788007736206\n",
      "Batch: 515 , Combined Loss: tensor(1.0502, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5966349244117737\n",
      "Batch: 516 , Combined Loss: tensor(1.0106, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5765731334686279\n",
      "Batch: 517 , Combined Loss: tensor(0.8600, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6019303798675537\n",
      "Batch: 518 , Combined Loss: tensor(0.8801, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5536987781524658\n",
      "Batch: 519 , Combined Loss: tensor(0.9794, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6397351026535034\n",
      "Batch: 520 , Combined Loss: tensor(1.0285, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9209372997283936\n",
      "Batch: 521 , Combined Loss: tensor(0.9593, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5455704927444458\n",
      "Batch: 522 , Combined Loss: tensor(0.9605, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5680708885192871\n",
      "Batch: 523 , Combined Loss: tensor(1.1187, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7272624969482422\n",
      "Batch: 524 , Combined Loss: tensor(0.9085, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8054172396659851\n",
      "Batch: 525 , Combined Loss: tensor(0.9820, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7330767512321472\n",
      "Batch: 526 , Combined Loss: tensor(1.0103, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8835367560386658\n",
      "Batch: 527 , Combined Loss: tensor(0.8964, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.37532806396484375\n",
      "Batch: 528 , Combined Loss: tensor(0.9644, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8377575874328613\n",
      "Batch: 529 , Combined Loss: tensor(1.1563, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6037867069244385\n",
      "Batch: 530 , Combined Loss: tensor(0.9520, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.783261775970459\n",
      "Batch: 531 , Combined Loss: tensor(0.9174, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6014261841773987\n",
      "Batch: 532 , Combined Loss: tensor(1.0273, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7898980379104614\n",
      "Batch: 533 , Combined Loss: tensor(0.9227, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.766521692276001\n",
      "Batch: 534 , Combined Loss: tensor(0.9425, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6079448461532593\n",
      "Batch: 535 , Combined Loss: tensor(0.9376, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6966521739959717\n",
      "Batch: 536 , Combined Loss: tensor(0.9071, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.827096164226532\n",
      "Batch: 537 , Combined Loss: tensor(0.9569, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7731038928031921\n",
      "Batch: 538 , Combined Loss: tensor(0.9063, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5765542387962341\n",
      "Batch: 539 , Combined Loss: tensor(1.0387, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7160602807998657\n",
      "Batch: 540 , Combined Loss: tensor(0.9626, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8871877193450928\n",
      "Batch: 541 , Combined Loss: tensor(0.9463, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7037184238433838\n",
      "Batch: 542 , Combined Loss: tensor(0.9595, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8066672682762146\n",
      "Batch: 543 , Combined Loss: tensor(0.9003, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.75492262840271\n",
      "Batch: 544 , Combined Loss: tensor(0.9554, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5209265947341919\n",
      "Batch: 545 , Combined Loss: tensor(0.9320, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7470592260360718\n",
      "Batch: 546 , Combined Loss: tensor(0.9866, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9261206984519958\n",
      "Batch: 547 , Combined Loss: tensor(1.0279, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.757704496383667\n",
      "Batch: 548 , Combined Loss: tensor(0.9415, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6626673340797424\n",
      "Batch: 549 , Combined Loss: tensor(0.9421, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.826823890209198\n",
      "Batch: 550 , Combined Loss: tensor(0.9207, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6649523973464966\n",
      "Batch: 551 , Combined Loss: tensor(0.9891, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6629128456115723\n",
      "Batch: 552 , Combined Loss: tensor(0.9521, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8886288404464722\n",
      "Batch: 553 , Combined Loss: tensor(0.9287, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7620877027511597\n",
      "Batch: 554 , Combined Loss: tensor(0.9500, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6723471879959106\n",
      "Batch: 555 , Combined Loss: tensor(0.9426, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6890496015548706\n",
      "Batch: 556 , Combined Loss: tensor(0.8835, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8600767254829407\n",
      "Batch: 557 , Combined Loss: tensor(0.9099, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7575543522834778\n",
      "Batch: 558 , Combined Loss: tensor(1.0121, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4319002628326416\n",
      "Batch: 559 , Combined Loss: tensor(0.9981, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6033164262771606\n",
      "Batch: 560 , Combined Loss: tensor(0.9265, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5715528130531311\n",
      "Batch: 561 , Combined Loss: tensor(0.9800, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2852453589439392\n",
      "Batch: 562 , Combined Loss: tensor(0.9464, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5905230045318604\n",
      "Batch: 563 , Combined Loss: tensor(0.9749, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6608654260635376\n",
      "Batch: 564 , Combined Loss: tensor(0.9954, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6839250326156616\n",
      "Batch: 565 , Combined Loss: tensor(0.9960, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6868581771850586\n",
      "Batch: 566 , Combined Loss: tensor(0.9531, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4733753204345703\n",
      "Batch: 567 , Combined Loss: tensor(0.9974, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7808984518051147\n",
      "Batch: 568 , Combined Loss: tensor(0.9090, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7213230133056641\n",
      "Batch: 569 , Combined Loss: tensor(0.9309, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7559375762939453\n",
      "Batch: 570 , Combined Loss: tensor(0.9193, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.425648033618927\n",
      "Batch: 571 , Combined Loss: tensor(0.9341, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8405542373657227\n",
      "Batch: 572 , Combined Loss: tensor(0.9506, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5879778265953064\n",
      "Batch: 573 , Combined Loss: tensor(0.9145, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.36771243810653687\n",
      "Batch: 574 , Combined Loss: tensor(0.9629, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8609407544136047\n",
      "Batch: 575 , Combined Loss: tensor(0.9396, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5380347967147827\n",
      "Batch: 576 , Combined Loss: tensor(0.9847, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6646007299423218\n",
      "Batch: 577 , Combined Loss: tensor(1.0118, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.618452787399292\n",
      "Batch: 578 , Combined Loss: tensor(0.9463, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39342033863067627\n",
      "Batch: 579 , Combined Loss: tensor(0.9241, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5696285963058472\n",
      "Batch: 580 , Combined Loss: tensor(0.9594, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7255179286003113\n",
      "Batch: 581 , Combined Loss: tensor(0.8815, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6460119485855103\n",
      "Batch: 582 , Combined Loss: tensor(1.0152, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7765868902206421\n",
      "Batch: 583 , Combined Loss: tensor(0.9395, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6061758995056152\n",
      "Batch: 584 , Combined Loss: tensor(0.9293, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6453948020935059\n",
      "Batch: 585 , Combined Loss: tensor(0.9295, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6860842108726501\n",
      "Batch: 586 , Combined Loss: tensor(0.8765, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5755008459091187\n",
      "Batch: 587 , Combined Loss: tensor(0.9522, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6119669675827026\n",
      "Batch: 588 , Combined Loss: tensor(0.9362, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8328490257263184\n",
      "Batch: 589 , Combined Loss: tensor(0.9668, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6443806886672974\n",
      "Batch: 590 , Combined Loss: tensor(0.9698, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.503690242767334\n",
      "Batch: 591 , Combined Loss: tensor(1.0174, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7317702174186707\n",
      "Batch: 592 , Combined Loss: tensor(0.9335, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7452949285507202\n",
      "Batch: 593 , Combined Loss: tensor(0.8747, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.46972835063934326\n",
      "Batch: 594 , Combined Loss: tensor(0.9793, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7429407835006714\n",
      "Batch: 595 , Combined Loss: tensor(1.0143, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8353971838951111\n",
      "Batch: 596 , Combined Loss: tensor(0.9530, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7340465784072876\n",
      "Batch: 597 , Combined Loss: tensor(0.9672, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6320260763168335\n",
      "Batch: 598 , Combined Loss: tensor(0.8884, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6045650839805603\n",
      "Batch: 599 , Combined Loss: tensor(0.9542, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6868996024131775\n",
      "Batch: 600 , Combined Loss: tensor(0.9277, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.46310991048812866\n",
      "Batch: 601 , Combined Loss: tensor(0.9666, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4893614649772644\n",
      "Batch: 602 , Combined Loss: tensor(0.9951, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7560175657272339\n",
      "Batch: 603 , Combined Loss: tensor(0.8956, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6446132659912109\n",
      "Batch: 604 , Combined Loss: tensor(0.9385, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.45052534341812134\n",
      "Batch: 605 , Combined Loss: tensor(0.9154, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7286673784255981\n",
      "Batch: 606 , Combined Loss: tensor(1.1078, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4453968405723572\n",
      "Batch: 607 , Combined Loss: tensor(0.9292, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6085390448570251\n",
      "Batch: 608 , Combined Loss: tensor(0.9682, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5168675184249878\n",
      "Batch: 609 , Combined Loss: tensor(0.9416, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8729072213172913\n",
      "Batch: 610 , Combined Loss: tensor(1.0634, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2638047933578491\n",
      "Batch: 611 , Combined Loss: tensor(0.9196, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9007681012153625\n",
      "Batch: 612 , Combined Loss: tensor(0.9240, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8625853061676025\n",
      "Batch: 613 , Combined Loss: tensor(0.9311, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7446595430374146\n",
      "Batch: 614 , Combined Loss: tensor(0.9815, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8764476776123047\n",
      "Batch: 615 , Combined Loss: tensor(0.8836, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5546377897262573\n",
      "Batch: 616 , Combined Loss: tensor(0.9562, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.414050817489624\n",
      "Batch: 617 , Combined Loss: tensor(0.9617, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7522974610328674\n",
      "Batch: 618 , Combined Loss: tensor(0.9179, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6736067533493042\n",
      "Batch: 619 , Combined Loss: tensor(0.9117, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7962070107460022\n",
      "Batch: 620 , Combined Loss: tensor(0.9367, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4568479061126709\n",
      "Batch: 621 , Combined Loss: tensor(1.0077, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7047064304351807\n",
      "Batch: 622 , Combined Loss: tensor(0.9905, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8932268023490906\n",
      "Batch: 623 , Combined Loss: tensor(0.9455, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4250869154930115\n",
      "Batch: 624 , Combined Loss: tensor(1.0096, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4630833864212036\n",
      "Batch: 625 , Combined Loss: tensor(0.9123, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.43134695291519165\n",
      "Batch: 626 , Combined Loss: tensor(0.9361, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6564270853996277\n",
      "Batch: 627 , Combined Loss: tensor(0.9626, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.696031928062439\n",
      "Batch: 628 , Combined Loss: tensor(0.9423, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6013399362564087\n",
      "----------Epoch 1, Loss: 1.0056256162911796, Accuracy: 0.45082534326089396, Dice Coef: [0.5961543498930946, 0.0886784225108354, 0.1791825536875405, 0.05809666988818214], Dice Coef Necrotic: 0.1336513240517151, Dice Coef Edema: 0.14763974862092358, Dice Coef Enhancing: 0.1552824460456646, Sensitivity: [0.43942760173024076, 0.3947079967467509, 0.64750975261432, 0.8199435884648846], Specificity: [0.9922557548043838, 0.9499784774355744, 0.8259466787021377, 0.6662107056246653], Precision: [0.9989900696069144, 0.05730658358525771, 0.11058930783100722, 0.030724074976888366]\n",
      "/teamspace/studios/this_studio/main.py:326: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, pd.DataFrame(new_row, index=[0])], ignore_index=True)\n",
      "Saving without nn.DataParallel\n",
      "Batch: 0 , Combined Loss: tensor(0.9219, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.29232168197631836\n",
      "Batch: 1 , Combined Loss: tensor(0.9496, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6195776462554932\n",
      "Batch: 2 , Combined Loss: tensor(1.0172, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7381250858306885\n",
      "Batch: 3 , Combined Loss: tensor(0.9319, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4199131727218628\n",
      "Batch: 4 , Combined Loss: tensor(0.9482, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6928908824920654\n",
      "Batch: 5 , Combined Loss: tensor(0.9526, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5097289085388184\n",
      "Batch: 6 , Combined Loss: tensor(0.9643, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1947057843208313\n",
      "Batch: 7 , Combined Loss: tensor(0.9695, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8295446038246155\n",
      "Batch: 8 , Combined Loss: tensor(0.9525, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3615409731864929\n",
      "Batch: 9 , Combined Loss: tensor(0.9199, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.701008141040802\n",
      "Batch: 10 , Combined Loss: tensor(0.9125, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7657326459884644\n",
      "Batch: 11 , Combined Loss: tensor(0.8988, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.579532265663147\n",
      "Batch: 12 , Combined Loss: tensor(0.9059, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9065572619438171\n",
      "Batch: 13 , Combined Loss: tensor(0.8985, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7594561576843262\n",
      "Batch: 14 , Combined Loss: tensor(0.9092, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.653979480266571\n",
      "Batch: 15 , Combined Loss: tensor(0.9422, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5163171291351318\n",
      "Batch: 16 , Combined Loss: tensor(0.9325, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.31258392333984375\n",
      "Batch: 17 , Combined Loss: tensor(0.9469, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6450521945953369\n",
      "Batch: 18 , Combined Loss: tensor(0.9477, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4482719302177429\n",
      "Batch: 19 , Combined Loss: tensor(0.9275, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7568126916885376\n",
      "Batch: 20 , Combined Loss: tensor(0.9210, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5462748408317566\n",
      "Batch: 21 , Combined Loss: tensor(0.9584, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5754613876342773\n",
      "Batch: 22 , Combined Loss: tensor(0.9748, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5216391682624817\n",
      "Batch: 23 , Combined Loss: tensor(0.9022, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6308369636535645\n",
      "Batch: 24 , Combined Loss: tensor(0.9873, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9187561869621277\n",
      "Batch: 25 , Combined Loss: tensor(0.9202, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9013429880142212\n",
      "Batch: 26 , Combined Loss: tensor(0.9329, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2951297163963318\n",
      "Batch: 27 , Combined Loss: tensor(0.9380, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.41956233978271484\n",
      "Batch: 28 , Combined Loss: tensor(0.8952, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.35525429248809814\n",
      "Batch: 29 , Combined Loss: tensor(0.9109, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7888971567153931\n",
      "Batch: 30 , Combined Loss: tensor(0.8555, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8008522391319275\n",
      "Batch: 31 , Combined Loss: tensor(0.9189, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39994585514068604\n",
      "Batch: 32 , Combined Loss: tensor(0.9042, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6680792570114136\n",
      "Batch: 33 , Combined Loss: tensor(0.9170, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5620303750038147\n",
      "Batch: 34 , Combined Loss: tensor(0.9584, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6750251054763794\n",
      "Batch: 35 , Combined Loss: tensor(0.9394, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22134160995483398\n",
      "Batch: 36 , Combined Loss: tensor(0.9679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8067654371261597\n",
      "Batch: 37 , Combined Loss: tensor(0.8918, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.42312633991241455\n",
      "Batch: 38 , Combined Loss: tensor(1.0012, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6424878835678101\n",
      "Batch: 39 , Combined Loss: tensor(0.8960, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8567853569984436\n",
      "Batch: 40 , Combined Loss: tensor(0.9411, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5546013712882996\n",
      "Batch: 41 , Combined Loss: tensor(0.9432, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2488364577293396\n",
      "Batch: 42 , Combined Loss: tensor(1.0147, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.43016916513442993\n",
      "Batch: 43 , Combined Loss: tensor(1.0049, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4930528402328491\n",
      "Batch: 44 , Combined Loss: tensor(0.9242, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7456973791122437\n",
      "Batch: 45 , Combined Loss: tensor(0.9433, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4026092290878296\n",
      "Batch: 46 , Combined Loss: tensor(0.9773, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5342962145805359\n",
      "Batch: 47 , Combined Loss: tensor(0.9368, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6251223087310791\n",
      "Batch: 48 , Combined Loss: tensor(0.9216, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8284509181976318\n",
      "Batch: 49 , Combined Loss: tensor(0.9279, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.040003061294555664\n",
      "Batch: 50 , Combined Loss: tensor(0.9125, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7480671405792236\n",
      "Batch: 51 , Combined Loss: tensor(0.9135, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.18594986200332642\n",
      "Batch: 52 , Combined Loss: tensor(0.9363, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14799857139587402\n",
      "Batch: 53 , Combined Loss: tensor(1.0192, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4759301543235779\n",
      "Batch: 54 , Combined Loss: tensor(0.9586, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.709653913974762\n",
      "Batch: 55 , Combined Loss: tensor(0.9515, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.369665265083313\n",
      "Batch: 56 , Combined Loss: tensor(0.9935, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.46118491888046265\n",
      "Batch: 57 , Combined Loss: tensor(0.9941, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3399313688278198\n",
      "Batch: 58 , Combined Loss: tensor(0.8976, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6201434135437012\n",
      "Batch: 59 , Combined Loss: tensor(0.8961, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21171551942825317\n",
      "Batch: 60 , Combined Loss: tensor(0.9646, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5806867480278015\n",
      "Batch: 61 , Combined Loss: tensor(0.9558, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15097224712371826\n",
      "Batch: 62 , Combined Loss: tensor(0.9446, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5866133570671082\n",
      "Batch: 63 , Combined Loss: tensor(0.8763, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7726818919181824\n",
      "Batch: 64 , Combined Loss: tensor(0.9106, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7054961919784546\n",
      "Batch: 65 , Combined Loss: tensor(1.0287, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6319383382797241\n",
      "Batch: 66 , Combined Loss: tensor(0.9202, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7799856662750244\n",
      "Batch: 67 , Combined Loss: tensor(0.8786, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8012025356292725\n",
      "Batch: 68 , Combined Loss: tensor(0.9240, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6255203485488892\n",
      "Batch: 69 , Combined Loss: tensor(1.0130, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.48766690492630005\n",
      "Batch: 70 , Combined Loss: tensor(0.9552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5819441676139832\n",
      "Batch: 71 , Combined Loss: tensor(0.9819, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7495920658111572\n",
      "Batch: 72 , Combined Loss: tensor(0.9616, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6859396696090698\n",
      "Batch: 73 , Combined Loss: tensor(0.9249, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.38788944482803345\n",
      "Batch: 74 , Combined Loss: tensor(0.9571, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.801998496055603\n",
      "Batch: 75 , Combined Loss: tensor(0.9021, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5564723014831543\n",
      "Batch: 76 , Combined Loss: tensor(0.8737, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.40474987030029297\n",
      "Batch: 77 , Combined Loss: tensor(0.9315, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8424156308174133\n",
      "Batch: 78 , Combined Loss: tensor(0.9310, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.44613587856292725\n",
      "Batch: 79 , Combined Loss: tensor(0.9769, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6368750333786011\n",
      "Batch: 80 , Combined Loss: tensor(0.8884, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7774392366409302\n",
      "Batch: 81 , Combined Loss: tensor(0.8742, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23446416854858398\n",
      "Batch: 82 , Combined Loss: tensor(0.9418, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39881110191345215\n",
      "Batch: 83 , Combined Loss: tensor(0.9364, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.42009609937667847\n",
      "Batch: 84 , Combined Loss: tensor(0.9260, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8284279108047485\n",
      "Batch: 85 , Combined Loss: tensor(0.8969, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.738295316696167\n",
      "Batch: 86 , Combined Loss: tensor(0.9246, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5786137580871582\n",
      "Batch: 87 , Combined Loss: tensor(0.9456, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8309604525566101\n",
      "Batch: 88 , Combined Loss: tensor(0.8785, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15461772680282593\n",
      "Batch: 89 , Combined Loss: tensor(0.9633, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.36607152223587036\n",
      "Batch: 90 , Combined Loss: tensor(0.9381, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3644988536834717\n",
      "Batch: 91 , Combined Loss: tensor(0.9389, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6337770223617554\n",
      "Batch: 92 , Combined Loss: tensor(0.8904, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12496042251586914\n",
      "Batch: 93 , Combined Loss: tensor(0.8962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5201851725578308\n",
      "Batch: 94 , Combined Loss: tensor(0.9559, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5100990533828735\n",
      "Batch: 95 , Combined Loss: tensor(0.9473, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.35419076681137085\n",
      "Batch: 96 , Combined Loss: tensor(0.8862, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.725820004940033\n",
      "Batch: 97 , Combined Loss: tensor(0.9070, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4453389048576355\n",
      "Batch: 98 , Combined Loss: tensor(0.9147, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8397533297538757\n",
      "Batch: 99 , Combined Loss: tensor(0.9086, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.561834454536438\n",
      "Batch: 100 , Combined Loss: tensor(0.9782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6347991824150085\n",
      "Batch: 101 , Combined Loss: tensor(0.9646, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6177685260772705\n",
      "Batch: 102 , Combined Loss: tensor(0.9461, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.38934576511383057\n",
      "Batch: 103 , Combined Loss: tensor(0.9622, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21274012327194214\n",
      "Batch: 104 , Combined Loss: tensor(0.9398, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.582022488117218\n",
      "Batch: 105 , Combined Loss: tensor(0.8902, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8327884674072266\n",
      "Batch: 106 , Combined Loss: tensor(0.9590, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6663057804107666\n",
      "Batch: 107 , Combined Loss: tensor(0.9175, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6234869956970215\n",
      "Batch: 108 , Combined Loss: tensor(0.9802, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6569391489028931\n",
      "Batch: 109 , Combined Loss: tensor(0.9686, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6880888342857361\n",
      "Batch: 110 , Combined Loss: tensor(0.9248, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7897908091545105\n",
      "Batch: 111 , Combined Loss: tensor(0.9140, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14762002229690552\n",
      "Batch: 112 , Combined Loss: tensor(0.9902, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7339251041412354\n",
      "Batch: 113 , Combined Loss: tensor(0.9401, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6713308095932007\n",
      "Batch: 114 , Combined Loss: tensor(0.9128, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.45557278394699097\n",
      "Batch: 115 , Combined Loss: tensor(0.9158, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6217694282531738\n",
      "Batch: 116 , Combined Loss: tensor(0.9623, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2861701250076294\n",
      "Batch: 117 , Combined Loss: tensor(0.9007, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8554390668869019\n",
      "Batch: 118 , Combined Loss: tensor(0.9293, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6762034296989441\n",
      "Batch: 119 , Combined Loss: tensor(1.0043, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5075435042381287\n",
      "Batch: 120 , Combined Loss: tensor(1.0236, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5968296527862549\n",
      "Batch: 121 , Combined Loss: tensor(0.9005, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3771875500679016\n",
      "Batch: 122 , Combined Loss: tensor(0.8898, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4645044803619385\n",
      "Batch: 123 , Combined Loss: tensor(0.9476, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8509989380836487\n",
      "Batch: 124 , Combined Loss: tensor(0.9364, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5963003039360046\n",
      "Batch: 125 , Combined Loss: tensor(0.9283, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7296509146690369\n",
      "Batch: 126 , Combined Loss: tensor(1.0486, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5201261639595032\n",
      "Batch: 127 , Combined Loss: tensor(0.9974, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6183536052703857\n",
      "Batch: 128 , Combined Loss: tensor(1.0095, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8452743291854858\n",
      "Batch: 129 , Combined Loss: tensor(0.8866, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7884019613265991\n",
      "Batch: 130 , Combined Loss: tensor(1.0065, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8395451903343201\n",
      "Batch: 131 , Combined Loss: tensor(0.9516, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.32745420932769775\n",
      "Batch: 132 , Combined Loss: tensor(1.0007, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7076090574264526\n",
      "Batch: 133 , Combined Loss: tensor(0.9576, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7276999950408936\n",
      "Batch: 134 , Combined Loss: tensor(1.0107, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.29056018590927124\n",
      "Batch: 135 , Combined Loss: tensor(0.8552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4823150038719177\n",
      "Batch: 136 , Combined Loss: tensor(0.9984, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8786600828170776\n",
      "Batch: 137 , Combined Loss: tensor(0.8803, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22039180994033813\n",
      "Batch: 138 , Combined Loss: tensor(0.9116, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.636254072189331\n",
      "Batch: 139 , Combined Loss: tensor(1.0074, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6310747265815735\n",
      "Batch: 140 , Combined Loss: tensor(0.9381, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3041635751724243\n",
      "Batch: 141 , Combined Loss: tensor(1.0076, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6179496049880981\n",
      "Batch: 142 , Combined Loss: tensor(0.9196, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8185204267501831\n",
      "Batch: 143 , Combined Loss: tensor(0.9784, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8665899634361267\n",
      "Batch: 144 , Combined Loss: tensor(0.8787, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5496297478675842\n",
      "Batch: 145 , Combined Loss: tensor(0.9644, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7893059849739075\n",
      "Batch: 146 , Combined Loss: tensor(0.9504, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7279263138771057\n",
      "Batch: 147 , Combined Loss: tensor(0.9123, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10445201396942139\n",
      "Batch: 148 , Combined Loss: tensor(0.9914, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7893937826156616\n",
      "Batch: 149 , Combined Loss: tensor(0.8445, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17863458395004272\n",
      "Batch: 150 , Combined Loss: tensor(0.9298, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5129525065422058\n",
      "Batch: 151 , Combined Loss: tensor(0.9108, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7920802235603333\n",
      "Batch: 152 , Combined Loss: tensor(0.8977, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8041111826896667\n",
      "Batch: 153 , Combined Loss: tensor(0.9423, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6000604629516602\n",
      "Batch: 154 , Combined Loss: tensor(1.0285, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7546672224998474\n",
      "Batch: 155 , Combined Loss: tensor(0.9051, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3477173447608948\n",
      "Batch: 156 , Combined Loss: tensor(1.0082, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8952924013137817\n",
      "Batch: 157 , Combined Loss: tensor(0.9428, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7636240720748901\n",
      "Batch: 158 , Combined Loss: tensor(0.8724, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12217319011688232\n",
      "Batch: 159 , Combined Loss: tensor(0.9056, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8427972197532654\n",
      "Batch: 160 , Combined Loss: tensor(0.9144, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7750599384307861\n",
      "Batch: 161 , Combined Loss: tensor(1.0142, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8639333248138428\n",
      "Batch: 162 , Combined Loss: tensor(1.0347, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7609468102455139\n",
      "Batch: 163 , Combined Loss: tensor(0.8645, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5903489589691162\n",
      "Batch: 164 , Combined Loss: tensor(0.9558, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8518807888031006\n",
      "Batch: 165 , Combined Loss: tensor(0.9864, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2997531294822693\n",
      "Batch: 166 , Combined Loss: tensor(0.9020, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8723224997520447\n",
      "Batch: 167 , Combined Loss: tensor(0.8863, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.36973458528518677\n",
      "Batch: 168 , Combined Loss: tensor(0.8819, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3686479926109314\n",
      "Batch: 169 , Combined Loss: tensor(0.9364, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7928309440612793\n",
      "Batch: 170 , Combined Loss: tensor(0.9096, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.47095823287963867\n",
      "Batch: 171 , Combined Loss: tensor(0.9401, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12001669406890869\n",
      "Batch: 172 , Combined Loss: tensor(0.8787, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4851304888725281\n",
      "Batch: 173 , Combined Loss: tensor(1.0017, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.32575154304504395\n",
      "Batch: 174 , Combined Loss: tensor(0.9654, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5758206248283386\n",
      "Batch: 175 , Combined Loss: tensor(0.8981, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6146013736724854\n",
      "Batch: 176 , Combined Loss: tensor(0.8267, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8911415338516235\n",
      "Batch: 177 , Combined Loss: tensor(0.9365, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.40222710371017456\n",
      "Batch: 178 , Combined Loss: tensor(0.8873, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7629525065422058\n",
      "Batch: 179 , Combined Loss: tensor(1.0053, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7428218722343445\n",
      "Batch: 180 , Combined Loss: tensor(0.9474, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6740632653236389\n",
      "Batch: 181 , Combined Loss: tensor(0.8754, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.340721070766449\n",
      "Batch: 182 , Combined Loss: tensor(0.8764, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5772808790206909\n",
      "Batch: 183 , Combined Loss: tensor(0.9499, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8930610418319702\n",
      "Batch: 184 , Combined Loss: tensor(0.9298, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4871840476989746\n",
      "Batch: 185 , Combined Loss: tensor(1.0474, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6636868715286255\n",
      "Batch: 186 , Combined Loss: tensor(0.8695, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6152235269546509\n",
      "Batch: 187 , Combined Loss: tensor(0.9127, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4751855731010437\n",
      "Batch: 188 , Combined Loss: tensor(0.8793, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8565180897712708\n",
      "Batch: 189 , Combined Loss: tensor(0.9107, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8003746271133423\n",
      "Batch: 190 , Combined Loss: tensor(0.9095, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22280913591384888\n",
      "Batch: 191 , Combined Loss: tensor(0.8675, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5576176643371582\n",
      "Batch: 192 , Combined Loss: tensor(0.9205, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2221813201904297\n",
      "Batch: 193 , Combined Loss: tensor(0.8530, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6019781231880188\n",
      "Batch: 194 , Combined Loss: tensor(1.0857, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9104323387145996\n",
      "Batch: 195 , Combined Loss: tensor(0.8708, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08633387088775635\n",
      "Batch: 196 , Combined Loss: tensor(0.8923, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6190952062606812\n",
      "Batch: 197 , Combined Loss: tensor(0.8854, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17503511905670166\n",
      "Batch: 198 , Combined Loss: tensor(0.9564, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15960752964019775\n",
      "Batch: 199 , Combined Loss: tensor(0.9332, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5295525789260864\n",
      "Batch: 200 , Combined Loss: tensor(0.8786, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20741760730743408\n",
      "Batch: 201 , Combined Loss: tensor(0.9513, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4847548007965088\n",
      "Batch: 202 , Combined Loss: tensor(0.9244, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.41817939281463623\n",
      "Batch: 203 , Combined Loss: tensor(0.8844, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5925681591033936\n",
      "Batch: 204 , Combined Loss: tensor(0.9368, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2624572515487671\n",
      "Batch: 205 , Combined Loss: tensor(0.9122, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8116919994354248\n",
      "Batch: 206 , Combined Loss: tensor(0.8999, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.823634684085846\n",
      "Batch: 207 , Combined Loss: tensor(0.9042, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4099084138870239\n",
      "Batch: 208 , Combined Loss: tensor(0.9208, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5473113059997559\n",
      "Batch: 209 , Combined Loss: tensor(0.9088, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8341468572616577\n",
      "Batch: 210 , Combined Loss: tensor(0.8946, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8525192737579346\n",
      "Batch: 211 , Combined Loss: tensor(0.9349, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6490330696105957\n",
      "Batch: 212 , Combined Loss: tensor(0.9778, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.40587228536605835\n",
      "Batch: 213 , Combined Loss: tensor(0.8899, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17574942111968994\n",
      "Batch: 214 , Combined Loss: tensor(0.8810, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.553990364074707\n",
      "Batch: 215 , Combined Loss: tensor(0.9224, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8680237531661987\n",
      "Batch: 216 , Combined Loss: tensor(0.9385, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7187943458557129\n",
      "Batch: 217 , Combined Loss: tensor(0.8750, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5073897838592529\n",
      "Batch: 218 , Combined Loss: tensor(0.9263, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.016244351863861084\n",
      "Batch: 219 , Combined Loss: tensor(0.9062, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4216158390045166\n",
      "Batch: 220 , Combined Loss: tensor(0.8894, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8911754488945007\n",
      "Batch: 221 , Combined Loss: tensor(1.0945, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4071323275566101\n",
      "Batch: 222 , Combined Loss: tensor(0.9158, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7227423191070557\n",
      "Batch: 223 , Combined Loss: tensor(0.9078, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7619515061378479\n",
      "Batch: 224 , Combined Loss: tensor(0.9933, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5810675621032715\n",
      "Batch: 225 , Combined Loss: tensor(0.9532, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.16993248462677002\n",
      "Batch: 226 , Combined Loss: tensor(0.9704, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3111916184425354\n",
      "Batch: 227 , Combined Loss: tensor(1.0271, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.44514524936676025\n",
      "Batch: 228 , Combined Loss: tensor(1.0530, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4238966107368469\n",
      "Batch: 229 , Combined Loss: tensor(0.9081, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7835197448730469\n",
      "Batch: 230 , Combined Loss: tensor(0.9553, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8583191633224487\n",
      "Batch: 231 , Combined Loss: tensor(0.8563, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5035560131072998\n",
      "Batch: 232 , Combined Loss: tensor(0.9408, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8295502662658691\n",
      "Batch: 233 , Combined Loss: tensor(0.9263, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5352034568786621\n",
      "Batch: 234 , Combined Loss: tensor(0.9479, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08749270439147949\n",
      "Batch: 235 , Combined Loss: tensor(0.8908, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.47052085399627686\n",
      "Batch: 236 , Combined Loss: tensor(0.8862, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23722201585769653\n",
      "Batch: 237 , Combined Loss: tensor(0.9385, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5069003105163574\n",
      "Batch: 238 , Combined Loss: tensor(0.9013, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7430559396743774\n",
      "Batch: 239 , Combined Loss: tensor(0.8820, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08557623624801636\n",
      "Batch: 240 , Combined Loss: tensor(0.9149, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23730111122131348\n",
      "Batch: 241 , Combined Loss: tensor(0.8798, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.784923791885376\n",
      "Batch: 242 , Combined Loss: tensor(0.9494, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4225362539291382\n",
      "Batch: 243 , Combined Loss: tensor(0.9238, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6422649025917053\n",
      "Batch: 244 , Combined Loss: tensor(0.9353, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5550463199615479\n",
      "Batch: 245 , Combined Loss: tensor(0.8456, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7834461331367493\n",
      "Batch: 246 , Combined Loss: tensor(0.9633, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5968451499938965\n",
      "Batch: 247 , Combined Loss: tensor(0.9340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2949622869491577\n",
      "Batch: 248 , Combined Loss: tensor(0.8827, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.004511654376983643\n",
      "Batch: 249 , Combined Loss: tensor(0.8859, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24272501468658447\n",
      "Batch: 250 , Combined Loss: tensor(0.9063, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3105847239494324\n",
      "Batch: 251 , Combined Loss: tensor(0.9363, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6647546291351318\n",
      "Batch: 252 , Combined Loss: tensor(0.8814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5873549580574036\n",
      "Batch: 253 , Combined Loss: tensor(0.9384, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6199329495429993\n",
      "Batch: 254 , Combined Loss: tensor(0.8915, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5143707990646362\n",
      "Batch: 255 , Combined Loss: tensor(0.8739, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5152769684791565\n",
      "Batch: 256 , Combined Loss: tensor(0.9538, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6047085523605347\n",
      "Batch: 257 , Combined Loss: tensor(0.8754, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.358928918838501\n",
      "Batch: 258 , Combined Loss: tensor(0.8788, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8584570288658142\n",
      "Batch: 259 , Combined Loss: tensor(0.8854, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.36431998014450073\n",
      "Batch: 260 , Combined Loss: tensor(0.9712, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5765423774719238\n",
      "Batch: 261 , Combined Loss: tensor(0.9870, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6118253469467163\n",
      "Batch: 262 , Combined Loss: tensor(0.9931, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.16512984037399292\n",
      "Batch: 263 , Combined Loss: tensor(0.9195, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24723052978515625\n",
      "Batch: 264 , Combined Loss: tensor(0.9294, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3184637427330017\n",
      "Batch: 265 , Combined Loss: tensor(0.9012, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5037482380867004\n",
      "Batch: 266 , Combined Loss: tensor(0.8643, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8449004888534546\n",
      "Batch: 267 , Combined Loss: tensor(1.0887, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.42025458812713623\n",
      "Batch: 268 , Combined Loss: tensor(0.9599, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.37061113119125366\n",
      "Batch: 269 , Combined Loss: tensor(0.9330, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6571921110153198\n",
      "Batch: 270 , Combined Loss: tensor(0.9254, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2080904245376587\n",
      "Batch: 271 , Combined Loss: tensor(0.9110, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7566123008728027\n",
      "Batch: 272 , Combined Loss: tensor(0.8378, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6272733211517334\n",
      "Batch: 273 , Combined Loss: tensor(0.8648, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3419058918952942\n",
      "Batch: 274 , Combined Loss: tensor(0.8986, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.49247056245803833\n",
      "Batch: 275 , Combined Loss: tensor(0.8986, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5245815515518188\n",
      "Batch: 276 , Combined Loss: tensor(0.9819, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7211761474609375\n",
      "Batch: 277 , Combined Loss: tensor(0.8751, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2732159495353699\n",
      "Batch: 278 , Combined Loss: tensor(0.9589, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39854896068573\n",
      "Batch: 279 , Combined Loss: tensor(0.9449, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7577094435691833\n",
      "Batch: 280 , Combined Loss: tensor(0.9881, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7481732368469238\n",
      "Batch: 281 , Combined Loss: tensor(0.9333, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5825401544570923\n",
      "Batch: 282 , Combined Loss: tensor(0.8783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07574164867401123\n",
      "Batch: 283 , Combined Loss: tensor(0.9148, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.41649478673934937\n",
      "Batch: 284 , Combined Loss: tensor(0.8713, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6031502485275269\n",
      "Batch: 285 , Combined Loss: tensor(0.8254, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03648620843887329\n",
      "Batch: 286 , Combined Loss: tensor(0.8633, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2837486267089844\n",
      "Batch: 287 , Combined Loss: tensor(0.8429, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2549670934677124\n",
      "Batch: 288 , Combined Loss: tensor(0.9278, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8683508634567261\n",
      "Batch: 289 , Combined Loss: tensor(0.8311, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39972442388534546\n",
      "Batch: 290 , Combined Loss: tensor(0.8203, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3278006911277771\n",
      "Batch: 291 , Combined Loss: tensor(0.8352, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2088257074356079\n",
      "Batch: 292 , Combined Loss: tensor(0.8651, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.33416998386383057\n",
      "Batch: 293 , Combined Loss: tensor(0.8676, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2701435089111328\n",
      "Batch: 294 , Combined Loss: tensor(0.9299, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7272969484329224\n",
      "Batch: 295 , Combined Loss: tensor(0.8415, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19498151540756226\n",
      "Batch: 296 , Combined Loss: tensor(0.8876, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5390588045120239\n",
      "Batch: 297 , Combined Loss: tensor(0.9833, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6302144527435303\n",
      "Batch: 298 , Combined Loss: tensor(0.8499, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6289833784103394\n",
      "Batch: 299 , Combined Loss: tensor(0.8362, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4304350018501282\n",
      "Batch: 300 , Combined Loss: tensor(0.8644, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8163317441940308\n",
      "Batch: 301 , Combined Loss: tensor(0.8870, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.460670530796051\n",
      "Batch: 302 , Combined Loss: tensor(0.8775, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7286853790283203\n",
      "Batch: 303 , Combined Loss: tensor(0.7981, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7408605813980103\n",
      "Batch: 304 , Combined Loss: tensor(0.9308, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.589600682258606\n",
      "Batch: 305 , Combined Loss: tensor(0.8852, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39658457040786743\n",
      "Batch: 306 , Combined Loss: tensor(0.7627, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6520253419876099\n",
      "Batch: 307 , Combined Loss: tensor(0.8744, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6217612028121948\n",
      "Batch: 308 , Combined Loss: tensor(0.9537, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.9134940505027771\n",
      "Batch: 309 , Combined Loss: tensor(0.9488, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3040463924407959\n",
      "Batch: 310 , Combined Loss: tensor(0.8314, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6106587648391724\n",
      "Batch: 311 , Combined Loss: tensor(0.9439, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.58835768699646\n",
      "Batch: 312 , Combined Loss: tensor(0.8899, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32206273078918457\n",
      "Batch: 313 , Combined Loss: tensor(0.8606, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.60622239112854\n",
      "Batch: 314 , Combined Loss: tensor(0.8644, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7594801187515259\n",
      "Batch: 315 , Combined Loss: tensor(0.8414, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.61568683385849\n",
      "Batch: 316 , Combined Loss: tensor(0.9555, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5389708280563354\n",
      "Batch: 317 , Combined Loss: tensor(0.8855, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.43356984853744507\n",
      "Batch: 318 , Combined Loss: tensor(0.8868, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.38363510370254517\n",
      "Batch: 319 , Combined Loss: tensor(0.9096, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6553380489349365\n",
      "Batch: 320 , Combined Loss: tensor(0.9156, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04081028699874878\n",
      "Batch: 321 , Combined Loss: tensor(0.9624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6806451082229614\n",
      "Batch: 322 , Combined Loss: tensor(0.9186, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.41002964973449707\n",
      "Batch: 323 , Combined Loss: tensor(0.9370, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.30414605140686035\n",
      "Batch: 324 , Combined Loss: tensor(0.9055, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7978318333625793\n",
      "Batch: 325 , Combined Loss: tensor(0.8826, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7809733152389526\n",
      "Batch: 326 , Combined Loss: tensor(0.9817, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8390789031982422\n",
      "Batch: 327 , Combined Loss: tensor(0.9019, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8796591758728027\n",
      "Batch: 328 , Combined Loss: tensor(0.8787, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.33593493700027466\n",
      "Batch: 329 , Combined Loss: tensor(0.9138, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5474059581756592\n",
      "Batch: 330 , Combined Loss: tensor(0.8667, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4253283143043518\n",
      "Batch: 331 , Combined Loss: tensor(0.9766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.628041684627533\n",
      "Batch: 332 , Combined Loss: tensor(0.8251, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8488535284996033\n",
      "Batch: 333 , Combined Loss: tensor(0.9054, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5335167646408081\n",
      "Batch: 334 , Combined Loss: tensor(0.9191, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5960131287574768\n",
      "Batch: 335 , Combined Loss: tensor(0.9152, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5818554162979126\n",
      "Batch: 336 , Combined Loss: tensor(0.8902, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4701148271560669\n",
      "Batch: 337 , Combined Loss: tensor(0.8686, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7439628839492798\n",
      "Batch: 338 , Combined Loss: tensor(0.9189, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4117938280105591\n",
      "Batch: 339 , Combined Loss: tensor(0.9365, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39596647024154663\n",
      "Batch: 340 , Combined Loss: tensor(0.8397, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4079154133796692\n",
      "Batch: 341 , Combined Loss: tensor(0.8287, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.32334333658218384\n",
      "Batch: 342 , Combined Loss: tensor(0.8502, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6139490604400635\n",
      "Batch: 343 , Combined Loss: tensor(0.8353, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7508325576782227\n",
      "Batch: 344 , Combined Loss: tensor(0.8218, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4614616632461548\n",
      "Batch: 345 , Combined Loss: tensor(0.9193, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.30478185415267944\n",
      "Batch: 346 , Combined Loss: tensor(1.0294, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.037681519985198975\n",
      "Batch: 347 , Combined Loss: tensor(0.8570, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1380900740623474\n",
      "Batch: 348 , Combined Loss: tensor(0.8503, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1400701403617859\n",
      "Batch: 349 , Combined Loss: tensor(0.8619, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3525393009185791\n",
      "Batch: 350 , Combined Loss: tensor(0.9398, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8197793960571289\n",
      "Batch: 351 , Combined Loss: tensor(0.9421, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5176857709884644\n",
      "Batch: 352 , Combined Loss: tensor(0.9961, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2141907811164856\n",
      "Batch: 353 , Combined Loss: tensor(0.9762, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5711872577667236\n",
      "Batch: 354 , Combined Loss: tensor(1.0664, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5869958400726318\n",
      "Batch: 355 , Combined Loss: tensor(1.0470, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4847179651260376\n",
      "Batch: 356 , Combined Loss: tensor(1.0247, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5146886110305786\n",
      "Batch: 357 , Combined Loss: tensor(0.8134, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11036264896392822\n",
      "Batch: 358 , Combined Loss: tensor(0.9802, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4197235107421875\n",
      "Batch: 359 , Combined Loss: tensor(0.9314, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7759950757026672\n",
      "Batch: 360 , Combined Loss: tensor(0.8904, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6202889084815979\n",
      "Batch: 361 , Combined Loss: tensor(0.8855, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6072653532028198\n",
      "Batch: 362 , Combined Loss: tensor(0.8366, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5827600955963135\n",
      "Batch: 363 , Combined Loss: tensor(1.1094, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.399091899394989\n",
      "Batch: 364 , Combined Loss: tensor(1.0226, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3065977692604065\n",
      "Batch: 365 , Combined Loss: tensor(0.8484, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.49823760986328125\n",
      "Batch: 366 , Combined Loss: tensor(0.9561, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24731570482254028\n",
      "Batch: 367 , Combined Loss: tensor(0.8884, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5558584928512573\n",
      "Batch: 368 , Combined Loss: tensor(0.8044, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5814831256866455\n",
      "Batch: 369 , Combined Loss: tensor(0.9138, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.008301496505737305\n",
      "Batch: 370 , Combined Loss: tensor(0.9899, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3805466294288635\n",
      "Batch: 371 , Combined Loss: tensor(0.8919, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23891735076904297\n",
      "Batch: 372 , Combined Loss: tensor(0.8845, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.30301862955093384\n",
      "Batch: 373 , Combined Loss: tensor(0.8668, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4087699055671692\n",
      "Batch: 374 , Combined Loss: tensor(0.8977, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.27716535329818726\n",
      "Batch: 375 , Combined Loss: tensor(0.8369, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24962496757507324\n",
      "Batch: 376 , Combined Loss: tensor(1.0478, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7968463897705078\n",
      "Batch: 377 , Combined Loss: tensor(0.9325, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5515629053115845\n",
      "Batch: 378 , Combined Loss: tensor(0.8551, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17279088497161865\n",
      "Batch: 379 , Combined Loss: tensor(0.8399, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6834414005279541\n",
      "Batch: 380 , Combined Loss: tensor(0.9353, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3024420142173767\n",
      "Batch: 381 , Combined Loss: tensor(0.9241, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4904252290725708\n",
      "Batch: 382 , Combined Loss: tensor(0.8891, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3608528971672058\n",
      "Batch: 383 , Combined Loss: tensor(0.8842, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20257413387298584\n",
      "Batch: 384 , Combined Loss: tensor(0.8878, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8216857314109802\n",
      "Batch: 385 , Combined Loss: tensor(0.7998, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7931675910949707\n",
      "Batch: 386 , Combined Loss: tensor(1.0764, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.36537325382232666\n",
      "Batch: 387 , Combined Loss: tensor(0.9212, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.13357317447662354\n",
      "Batch: 388 , Combined Loss: tensor(0.9171, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3087361454963684\n",
      "Batch: 389 , Combined Loss: tensor(0.9324, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4981344938278198\n",
      "Batch: 390 , Combined Loss: tensor(0.9588, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7487245798110962\n",
      "Batch: 391 , Combined Loss: tensor(1.0097, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8126800060272217\n",
      "Batch: 392 , Combined Loss: tensor(0.9054, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5650464296340942\n",
      "Batch: 393 , Combined Loss: tensor(0.8650, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6779395341873169\n",
      "Batch: 394 , Combined Loss: tensor(0.9912, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3890957236289978\n",
      "Batch: 395 , Combined Loss: tensor(0.9340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10220861434936523\n",
      "Batch: 396 , Combined Loss: tensor(0.8868, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17214292287826538\n",
      "Batch: 397 , Combined Loss: tensor(0.9818, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.38278812170028687\n",
      "Batch: 398 , Combined Loss: tensor(0.9072, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5446006655693054\n",
      "Batch: 399 , Combined Loss: tensor(0.9332, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.44787949323654175\n",
      "Batch: 400 , Combined Loss: tensor(0.8374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.40459680557250977\n",
      "Batch: 401 , Combined Loss: tensor(0.8886, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8948561549186707\n",
      "Batch: 402 , Combined Loss: tensor(0.8540, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3547462821006775\n",
      "Batch: 403 , Combined Loss: tensor(0.9039, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.489821195602417\n",
      "Batch: 404 , Combined Loss: tensor(0.8781, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3851781487464905\n",
      "Batch: 405 , Combined Loss: tensor(0.8261, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.561257004737854\n",
      "Batch: 406 , Combined Loss: tensor(0.9085, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7401481866836548\n",
      "Batch: 407 , Combined Loss: tensor(0.9723, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8879045844078064\n",
      "Batch: 408 , Combined Loss: tensor(0.9612, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4371280074119568\n",
      "Batch: 409 , Combined Loss: tensor(0.8952, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6149969100952148\n",
      "Batch: 410 , Combined Loss: tensor(0.9255, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08931505680084229\n",
      "Batch: 411 , Combined Loss: tensor(0.9060, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5931171178817749\n",
      "Batch: 412 , Combined Loss: tensor(0.8420, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.38924533128738403\n",
      "Batch: 413 , Combined Loss: tensor(0.8461, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2624695301055908\n",
      "Batch: 414 , Combined Loss: tensor(0.8746, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6201931238174438\n",
      "Batch: 415 , Combined Loss: tensor(0.8207, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08676981925964355\n",
      "Batch: 416 , Combined Loss: tensor(0.8575, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.649772047996521\n",
      "Batch: 417 , Combined Loss: tensor(0.9190, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6202493906021118\n",
      "Batch: 418 , Combined Loss: tensor(0.8452, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5197323560714722\n",
      "Batch: 419 , Combined Loss: tensor(0.9839, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5799265503883362\n",
      "Batch: 420 , Combined Loss: tensor(0.7442, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6701642274856567\n",
      "Batch: 421 , Combined Loss: tensor(0.8252, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6122740507125854\n",
      "Batch: 422 , Combined Loss: tensor(0.9291, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.28980666399002075\n",
      "Batch: 423 , Combined Loss: tensor(0.9329, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3084699511528015\n",
      "Batch: 424 , Combined Loss: tensor(0.8506, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7053948044776917\n",
      "Batch: 425 , Combined Loss: tensor(1.0120, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5001211166381836\n",
      "Batch: 426 , Combined Loss: tensor(0.8641, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6373683214187622\n",
      "Batch: 427 , Combined Loss: tensor(0.9359, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8683748841285706\n",
      "Batch: 428 , Combined Loss: tensor(0.8204, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6822599172592163\n",
      "Batch: 429 , Combined Loss: tensor(1.0003, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8088666796684265\n",
      "Batch: 430 , Combined Loss: tensor(1.0022, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.378059446811676\n",
      "Batch: 431 , Combined Loss: tensor(1.0967, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10910403728485107\n",
      "Batch: 432 , Combined Loss: tensor(0.8972, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.41168302297592163\n",
      "Batch: 433 , Combined Loss: tensor(0.9295, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19435465335845947\n",
      "Batch: 434 , Combined Loss: tensor(0.8529, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.36977219581604004\n",
      "Batch: 435 , Combined Loss: tensor(1.0558, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.47712695598602295\n",
      "Batch: 436 , Combined Loss: tensor(0.8622, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3853342533111572\n",
      "Batch: 437 , Combined Loss: tensor(0.8323, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.381547749042511\n",
      "Batch: 438 , Combined Loss: tensor(0.9352, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7953292727470398\n",
      "Batch: 439 , Combined Loss: tensor(0.8758, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2519086003303528\n",
      "Batch: 440 , Combined Loss: tensor(0.8572, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.47786033153533936\n",
      "Batch: 441 , Combined Loss: tensor(0.8531, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.47855716943740845\n",
      "Batch: 442 , Combined Loss: tensor(0.8784, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5417989492416382\n",
      "Batch: 443 , Combined Loss: tensor(0.9329, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5709900259971619\n",
      "Batch: 444 , Combined Loss: tensor(1.0389, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4653049111366272\n",
      "Batch: 445 , Combined Loss: tensor(0.9951, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0002894401550292969\n",
      "Batch: 446 , Combined Loss: tensor(0.8896, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6465018391609192\n",
      "Batch: 447 , Combined Loss: tensor(0.9817, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39119166135787964\n",
      "Batch: 448 , Combined Loss: tensor(0.8617, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5117670297622681\n",
      "Batch: 449 , Combined Loss: tensor(0.9456, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20358753204345703\n",
      "Batch: 450 , Combined Loss: tensor(0.9218, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7431342601776123\n",
      "Batch: 451 , Combined Loss: tensor(0.8291, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3420906662940979\n",
      "Batch: 452 , Combined Loss: tensor(0.8265, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6318248510360718\n",
      "Batch: 453 , Combined Loss: tensor(0.8509, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39349085092544556\n",
      "Batch: 454 , Combined Loss: tensor(0.9300, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.37362366914749146\n",
      "Batch: 455 , Combined Loss: tensor(0.9259, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3530071973800659\n",
      "Batch: 456 , Combined Loss: tensor(0.9674, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2594098448753357\n",
      "Batch: 457 , Combined Loss: tensor(0.8788, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7854259610176086\n",
      "Batch: 458 , Combined Loss: tensor(0.9504, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24061459302902222\n",
      "Batch: 459 , Combined Loss: tensor(0.9052, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.43697071075439453\n",
      "Batch: 460 , Combined Loss: tensor(0.9549, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7364556789398193\n",
      "Batch: 461 , Combined Loss: tensor(0.9561, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.41934967041015625\n",
      "Batch: 462 , Combined Loss: tensor(0.9220, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.020767509937286377\n",
      "Batch: 463 , Combined Loss: tensor(0.8823, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.47163742780685425\n",
      "Batch: 464 , Combined Loss: tensor(0.8907, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.241491436958313\n",
      "Batch: 465 , Combined Loss: tensor(0.8846, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.26506751775741577\n",
      "Batch: 466 , Combined Loss: tensor(0.8994, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6971766948699951\n",
      "Batch: 467 , Combined Loss: tensor(0.8805, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09272325038909912\n",
      "Batch: 468 , Combined Loss: tensor(0.9649, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.33040809631347656\n",
      "Batch: 469 , Combined Loss: tensor(0.8824, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.40789544582366943\n",
      "Batch: 470 , Combined Loss: tensor(0.9540, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7438063621520996\n",
      "Batch: 471 , Combined Loss: tensor(1.0252, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3793853521347046\n",
      "Batch: 472 , Combined Loss: tensor(0.9211, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5123135447502136\n",
      "Batch: 473 , Combined Loss: tensor(0.8812, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2947470545768738\n",
      "Batch: 474 , Combined Loss: tensor(0.9356, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7606673836708069\n",
      "Batch: 475 , Combined Loss: tensor(1.0745, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7099626064300537\n",
      "Batch: 476 , Combined Loss: tensor(0.8873, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.18367940187454224\n",
      "Batch: 477 , Combined Loss: tensor(0.9080, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6459949016571045\n",
      "Batch: 478 , Combined Loss: tensor(0.9906, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5063204765319824\n",
      "Batch: 479 , Combined Loss: tensor(0.9296, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6515873670578003\n",
      "Batch: 480 , Combined Loss: tensor(0.9339, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4592691659927368\n",
      "Batch: 481 , Combined Loss: tensor(0.8990, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.002428770065307617\n",
      "Batch: 482 , Combined Loss: tensor(0.9387, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.45889389514923096\n",
      "Batch: 483 , Combined Loss: tensor(0.9311, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7653312087059021\n",
      "Batch: 484 , Combined Loss: tensor(0.9086, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7209745049476624\n",
      "Batch: 485 , Combined Loss: tensor(0.8962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7308002710342407\n",
      "Batch: 486 , Combined Loss: tensor(0.9101, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8399988412857056\n",
      "Batch: 487 , Combined Loss: tensor(0.9365, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.66858971118927\n",
      "Batch: 488 , Combined Loss: tensor(1.0095, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6904491186141968\n",
      "Batch: 489 , Combined Loss: tensor(0.9220, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6518285870552063\n",
      "Batch: 490 , Combined Loss: tensor(0.9620, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5687224864959717\n",
      "Batch: 491 , Combined Loss: tensor(0.9357, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6238967180252075\n",
      "Batch: 492 , Combined Loss: tensor(0.9053, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8660874962806702\n",
      "Batch: 493 , Combined Loss: tensor(1.0691, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5522709488868713\n",
      "Batch: 494 , Combined Loss: tensor(0.9724, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5649409294128418\n",
      "Batch: 495 , Combined Loss: tensor(0.8883, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5863022804260254\n",
      "Batch: 496 , Combined Loss: tensor(0.9408, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7537993788719177\n",
      "Batch: 497 , Combined Loss: tensor(0.8741, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.36758214235305786\n",
      "Batch: 498 , Combined Loss: tensor(0.9609, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5973607301712036\n",
      "Batch: 499 , Combined Loss: tensor(0.9125, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7040250897407532\n",
      "Batch: 500 , Combined Loss: tensor(0.9342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5362182855606079\n",
      "Batch: 501 , Combined Loss: tensor(1.0716, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6693257093429565\n",
      "Batch: 502 , Combined Loss: tensor(0.8695, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2639632225036621\n",
      "Batch: 503 , Combined Loss: tensor(0.8758, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21795803308486938\n",
      "Batch: 504 , Combined Loss: tensor(0.9095, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4695606827735901\n",
      "Batch: 505 , Combined Loss: tensor(0.9119, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.44355469942092896\n",
      "Batch: 506 , Combined Loss: tensor(0.8963, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.42998194694519043\n",
      "Batch: 507 , Combined Loss: tensor(0.8221, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6641825437545776\n",
      "Batch: 508 , Combined Loss: tensor(0.8734, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7774233818054199\n",
      "Batch: 509 , Combined Loss: tensor(0.8905, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07703042030334473\n",
      "Batch: 510 , Combined Loss: tensor(0.9030, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3479960560798645\n",
      "Batch: 511 , Combined Loss: tensor(0.8230, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6870761513710022\n",
      "Batch: 512 , Combined Loss: tensor(0.9536, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07647502422332764\n",
      "Batch: 513 , Combined Loss: tensor(0.8831, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05330216884613037\n",
      "Batch: 514 , Combined Loss: tensor(0.9303, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5149991512298584\n",
      "Batch: 515 , Combined Loss: tensor(0.9401, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2806934118270874\n",
      "Batch: 516 , Combined Loss: tensor(0.9004, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26026952266693115\n",
      "Batch: 517 , Combined Loss: tensor(0.8688, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8053922653198242\n",
      "Batch: 518 , Combined Loss: tensor(0.8787, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2351670265197754\n",
      "Batch: 519 , Combined Loss: tensor(0.9099, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.010100960731506348\n",
      "Batch: 520 , Combined Loss: tensor(0.9471, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.41657525300979614\n",
      "Batch: 521 , Combined Loss: tensor(0.9713, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5229363441467285\n",
      "Batch: 522 , Combined Loss: tensor(0.8050, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.442049503326416\n",
      "Batch: 523 , Combined Loss: tensor(0.8752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4722214937210083\n",
      "Batch: 524 , Combined Loss: tensor(0.9026, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5524277091026306\n",
      "Batch: 525 , Combined Loss: tensor(0.9730, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7210434675216675\n",
      "Batch: 526 , Combined Loss: tensor(0.9233, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7847906351089478\n",
      "Batch: 527 , Combined Loss: tensor(0.9198, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7337648868560791\n",
      "Batch: 528 , Combined Loss: tensor(0.8630, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.436529278755188\n",
      "Batch: 529 , Combined Loss: tensor(0.9182, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.34052300453186035\n",
      "Batch: 530 , Combined Loss: tensor(1.0004, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6379748582839966\n",
      "Batch: 531 , Combined Loss: tensor(0.8802, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.02854698896408081\n",
      "Batch: 532 , Combined Loss: tensor(0.9183, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3391159176826477\n",
      "Batch: 533 , Combined Loss: tensor(0.8749, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.34916120767593384\n",
      "Batch: 534 , Combined Loss: tensor(0.8546, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6416592597961426\n",
      "Batch: 535 , Combined Loss: tensor(0.9296, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5812915563583374\n",
      "Batch: 536 , Combined Loss: tensor(0.8930, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5914509296417236\n",
      "Batch: 537 , Combined Loss: tensor(0.8314, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.732516884803772\n",
      "Batch: 538 , Combined Loss: tensor(0.8844, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.018000423908233643\n",
      "Batch: 539 , Combined Loss: tensor(0.9038, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3781343102455139\n",
      "Batch: 540 , Combined Loss: tensor(0.8340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6455638408660889\n",
      "Batch: 541 , Combined Loss: tensor(0.9433, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5751506090164185\n",
      "Batch: 542 , Combined Loss: tensor(0.9126, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6515112519264221\n",
      "Batch: 543 , Combined Loss: tensor(0.8374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.44576770067214966\n",
      "Batch: 544 , Combined Loss: tensor(0.8208, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20015519857406616\n",
      "Batch: 545 , Combined Loss: tensor(0.8591, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.126625657081604\n",
      "Batch: 546 , Combined Loss: tensor(0.9588, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5312967300415039\n",
      "Batch: 547 , Combined Loss: tensor(0.9217, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2561250925064087\n",
      "Batch: 548 , Combined Loss: tensor(1.0913, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4963496923446655\n",
      "Batch: 549 , Combined Loss: tensor(0.8374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.16630321741104126\n",
      "Batch: 550 , Combined Loss: tensor(0.8303, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7223573923110962\n",
      "Batch: 551 , Combined Loss: tensor(1.0121, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.32630717754364014\n",
      "Batch: 552 , Combined Loss: tensor(0.8803, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8701155185699463\n",
      "Batch: 553 , Combined Loss: tensor(0.8000, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.341169536113739\n",
      "Batch: 554 , Combined Loss: tensor(0.9112, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5964465141296387\n",
      "Batch: 555 , Combined Loss: tensor(0.8829, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2704247236251831\n",
      "Batch: 556 , Combined Loss: tensor(0.9602, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7024368047714233\n",
      "Batch: 557 , Combined Loss: tensor(0.8427, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8030319213867188\n",
      "Batch: 558 , Combined Loss: tensor(0.8887, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19789695739746094\n",
      "Batch: 559 , Combined Loss: tensor(1.0447, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6786587238311768\n",
      "Batch: 560 , Combined Loss: tensor(0.9518, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5352110862731934\n",
      "Batch: 561 , Combined Loss: tensor(0.8770, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.48950493335723877\n",
      "Batch: 562 , Combined Loss: tensor(0.8624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.49389129877090454\n",
      "Batch: 563 , Combined Loss: tensor(0.9047, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2382817268371582\n",
      "Batch: 564 , Combined Loss: tensor(0.9187, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.16197556257247925\n",
      "Batch: 565 , Combined Loss: tensor(0.9595, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.738499104976654\n",
      "Batch: 566 , Combined Loss: tensor(0.8409, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5332331657409668\n",
      "Batch: 567 , Combined Loss: tensor(0.8907, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5617281198501587\n",
      "Batch: 568 , Combined Loss: tensor(0.9124, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5026564598083496\n",
      "Batch: 569 , Combined Loss: tensor(0.8656, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23845088481903076\n",
      "Batch: 570 , Combined Loss: tensor(0.9055, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05435985326766968\n",
      "Batch: 571 , Combined Loss: tensor(0.8726, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24221080541610718\n",
      "Batch: 572 , Combined Loss: tensor(0.8267, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.292371928691864\n",
      "Batch: 573 , Combined Loss: tensor(0.9435, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5936059951782227\n",
      "Batch: 574 , Combined Loss: tensor(0.9258, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2634526491165161\n",
      "Batch: 575 , Combined Loss: tensor(0.8844, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2837601900100708\n",
      "Batch: 576 , Combined Loss: tensor(0.9845, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10047721862792969\n",
      "Batch: 577 , Combined Loss: tensor(1.0751, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7305653095245361\n",
      "Batch: 578 , Combined Loss: tensor(0.9139, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8370734453201294\n",
      "Batch: 579 , Combined Loss: tensor(1.0144, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7991060018539429\n",
      "Batch: 580 , Combined Loss: tensor(0.9406, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.594051718711853\n",
      "Batch: 581 , Combined Loss: tensor(0.8677, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5042825937271118\n",
      "Batch: 582 , Combined Loss: tensor(0.8572, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5384906530380249\n",
      "Batch: 583 , Combined Loss: tensor(0.8631, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6848777532577515\n",
      "Batch: 584 , Combined Loss: tensor(0.8436, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07930576801300049\n",
      "Batch: 585 , Combined Loss: tensor(0.8620, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06142628192901611\n",
      "Batch: 586 , Combined Loss: tensor(0.9974, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.30758416652679443\n",
      "Batch: 587 , Combined Loss: tensor(0.9547, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8747326731681824\n",
      "Batch: 588 , Combined Loss: tensor(0.8188, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7649282217025757\n",
      "Batch: 589 , Combined Loss: tensor(0.8517, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5298858880996704\n",
      "Batch: 590 , Combined Loss: tensor(0.8604, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7642183303833008\n",
      "Batch: 591 , Combined Loss: tensor(0.8785, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6005079746246338\n",
      "Batch: 592 , Combined Loss: tensor(0.7671, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.30341988801956177\n",
      "Batch: 593 , Combined Loss: tensor(0.8369, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.772597074508667\n",
      "Batch: 594 , Combined Loss: tensor(0.8928, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.609114408493042\n",
      "Batch: 595 , Combined Loss: tensor(0.8891, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8784642815589905\n",
      "Batch: 596 , Combined Loss: tensor(0.9436, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.37459951639175415\n",
      "Batch: 597 , Combined Loss: tensor(0.8424, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03096771240234375\n",
      "Batch: 598 , Combined Loss: tensor(0.8915, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5401410460472107\n",
      "Batch: 599 , Combined Loss: tensor(0.9711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1728506088256836\n",
      "Batch: 600 , Combined Loss: tensor(0.8504, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6008275151252747\n",
      "Batch: 601 , Combined Loss: tensor(1.1358, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1395941972732544\n",
      "Batch: 602 , Combined Loss: tensor(0.9276, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3288768529891968\n",
      "Batch: 603 , Combined Loss: tensor(0.9536, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.32341545820236206\n",
      "Batch: 604 , Combined Loss: tensor(0.9207, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7903182506561279\n",
      "Batch: 605 , Combined Loss: tensor(0.9053, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06425803899765015\n",
      "Batch: 606 , Combined Loss: tensor(0.8566, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.40009790658950806\n",
      "Batch: 607 , Combined Loss: tensor(0.8507, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2833676338195801\n",
      "Batch: 608 , Combined Loss: tensor(0.8704, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6373540163040161\n",
      "Batch: 609 , Combined Loss: tensor(0.8461, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3690580129623413\n",
      "Batch: 610 , Combined Loss: tensor(0.9162, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21295177936553955\n",
      "Batch: 611 , Combined Loss: tensor(0.8507, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3880571722984314\n",
      "Batch: 612 , Combined Loss: tensor(0.9459, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4579944610595703\n",
      "Batch: 613 , Combined Loss: tensor(0.9777, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15146923065185547\n",
      "Batch: 614 , Combined Loss: tensor(0.9615, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8532497882843018\n",
      "Batch: 615 , Combined Loss: tensor(0.7969, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6582772731781006\n",
      "Batch: 616 , Combined Loss: tensor(0.9875, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5408979654312134\n",
      "Batch: 617 , Combined Loss: tensor(0.8591, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5309669375419617\n",
      "Batch: 618 , Combined Loss: tensor(0.9855, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0731196403503418\n",
      "Batch: 619 , Combined Loss: tensor(0.8159, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7104872465133667\n",
      "Batch: 620 , Combined Loss: tensor(0.8683, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2500913143157959\n",
      "Batch: 621 , Combined Loss: tensor(1.0019, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8014371991157532\n",
      "Batch: 622 , Combined Loss: tensor(0.8104, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2611944079399109\n",
      "Batch: 623 , Combined Loss: tensor(0.8261, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7873051166534424\n",
      "Batch: 624 , Combined Loss: tensor(1.1078, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17001128196716309\n",
      "Batch: 625 , Combined Loss: tensor(0.8111, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7654412984848022\n",
      "Batch: 626 , Combined Loss: tensor(0.8970, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8677268028259277\n",
      "Batch: 627 , Combined Loss: tensor(0.8021, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7719868421554565\n",
      "Batch: 628 , Combined Loss: tensor(0.9936, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6614000797271729\n",
      "----------Epoch 2, Loss: 0.9186439108583241, Accuracy: 0.7069390559234376, Dice Coef: [0.8245516864787225, 0.17569253124792675, 0.25850933593760145, 0.11987190018218079], Dice Coef Necrotic: 0.2022483368714564, Dice Coef Edema: 0.21773938133971213, Dice Coef Enhancing: 0.2128890207680949, Sensitivity: [0.7054077281671411, 0.5478337248200522, 0.7226367753816381, 0.8399303594618663], Specificity: [0.9684189824307476, 0.9721047100277888, 0.8758288507241703, 0.8552599626997507], Precision: [0.9979352374903159, 0.12484782221945757, 0.17063032589279847, 0.06717571160914734]\n",
      "Saving without nn.DataParallel\n",
      "Batch: 0 , Combined Loss: tensor(0.8542, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8930615186691284\n",
      "Batch: 1 , Combined Loss: tensor(0.8740, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04444313049316406\n",
      "Batch: 2 , Combined Loss: tensor(0.8871, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14957422018051147\n",
      "Batch: 3 , Combined Loss: tensor(0.8287, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09869170188903809\n",
      "Batch: 4 , Combined Loss: tensor(1.2320, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03088533878326416\n",
      "Batch: 5 , Combined Loss: tensor(1.0252, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.31795209646224976\n",
      "Batch: 6 , Combined Loss: tensor(0.9608, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.860700786113739\n",
      "Batch: 7 , Combined Loss: tensor(0.9712, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7295030355453491\n",
      "Batch: 8 , Combined Loss: tensor(0.9424, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09612828493118286\n",
      "Batch: 9 , Combined Loss: tensor(0.9496, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6829242706298828\n",
      "Batch: 10 , Combined Loss: tensor(0.9452, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.43164652585983276\n",
      "Batch: 11 , Combined Loss: tensor(0.8966, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.29620254039764404\n",
      "Batch: 12 , Combined Loss: tensor(0.9376, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7536898255348206\n",
      "Batch: 13 , Combined Loss: tensor(0.9908, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.45383840799331665\n",
      "Batch: 14 , Combined Loss: tensor(0.8075, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.42416441440582275\n",
      "Batch: 15 , Combined Loss: tensor(0.9930, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5895960330963135\n",
      "Batch: 16 , Combined Loss: tensor(0.9386, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5996648669242859\n",
      "Batch: 17 , Combined Loss: tensor(1.1798, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.30819857120513916\n",
      "Batch: 18 , Combined Loss: tensor(0.9300, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8440807461738586\n",
      "Batch: 19 , Combined Loss: tensor(0.8241, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.002259492874145508\n",
      "Batch: 20 , Combined Loss: tensor(0.9671, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03483235836029053\n",
      "Batch: 21 , Combined Loss: tensor(0.8500, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19676637649536133\n",
      "Batch: 22 , Combined Loss: tensor(0.9475, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4821884036064148\n",
      "Batch: 23 , Combined Loss: tensor(0.8398, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3642233610153198\n",
      "Batch: 24 , Combined Loss: tensor(0.9751, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.017179787158966064\n",
      "Batch: 25 , Combined Loss: tensor(0.8602, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.271365761756897\n",
      "Batch: 26 , Combined Loss: tensor(1.1096, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.48378145694732666\n",
      "Batch: 27 , Combined Loss: tensor(0.8225, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21932560205459595\n",
      "Batch: 28 , Combined Loss: tensor(1.0550, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.35689496994018555\n",
      "Batch: 29 , Combined Loss: tensor(0.9200, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.48928695917129517\n",
      "Batch: 30 , Combined Loss: tensor(0.7840, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6843278408050537\n",
      "Batch: 31 , Combined Loss: tensor(0.8503, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5638660192489624\n",
      "Batch: 32 , Combined Loss: tensor(0.8530, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1356818675994873\n",
      "Batch: 33 , Combined Loss: tensor(0.8054, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3045777678489685\n",
      "Batch: 34 , Combined Loss: tensor(0.8521, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7816771268844604\n",
      "Batch: 35 , Combined Loss: tensor(0.8806, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8473132252693176\n",
      "Batch: 36 , Combined Loss: tensor(0.9157, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4339632987976074\n",
      "Batch: 37 , Combined Loss: tensor(0.8935, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5005238652229309\n",
      "Batch: 38 , Combined Loss: tensor(0.8701, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8258917331695557\n",
      "Batch: 39 , Combined Loss: tensor(0.8706, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12354105710983276\n",
      "Batch: 40 , Combined Loss: tensor(0.9342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.45625483989715576\n",
      "Batch: 41 , Combined Loss: tensor(0.8036, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6919180750846863\n",
      "Batch: 42 , Combined Loss: tensor(0.8864, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.48565196990966797\n",
      "Batch: 43 , Combined Loss: tensor(0.8928, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2655959725379944\n",
      "Batch: 44 , Combined Loss: tensor(0.9034, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22193199396133423\n",
      "Batch: 45 , Combined Loss: tensor(0.8893, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.45956647396087646\n",
      "Batch: 46 , Combined Loss: tensor(0.9514, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.38586902618408203\n",
      "Batch: 47 , Combined Loss: tensor(0.8494, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.49053502082824707\n",
      "Batch: 48 , Combined Loss: tensor(0.9407, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5889164805412292\n",
      "Batch: 49 , Combined Loss: tensor(0.8337, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.656673789024353\n",
      "Batch: 50 , Combined Loss: tensor(0.8006, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6485990285873413\n",
      "Batch: 51 , Combined Loss: tensor(0.9864, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17479181289672852\n",
      "Batch: 52 , Combined Loss: tensor(0.8997, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7865113615989685\n",
      "Batch: 53 , Combined Loss: tensor(0.8804, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20107144117355347\n",
      "Batch: 54 , Combined Loss: tensor(0.8563, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.49809783697128296\n",
      "Batch: 55 , Combined Loss: tensor(0.9353, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6666080951690674\n",
      "Batch: 56 , Combined Loss: tensor(0.9198, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12305402755737305\n",
      "Batch: 57 , Combined Loss: tensor(0.8290, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6883907318115234\n",
      "Batch: 58 , Combined Loss: tensor(0.8777, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3611295223236084\n",
      "Batch: 59 , Combined Loss: tensor(0.9205, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8690961599349976\n",
      "Batch: 60 , Combined Loss: tensor(0.9223, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.478379487991333\n",
      "Batch: 61 , Combined Loss: tensor(0.8857, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5604796409606934\n",
      "Batch: 62 , Combined Loss: tensor(0.8994, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8169393539428711\n",
      "Batch: 63 , Combined Loss: tensor(0.9167, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6779557466506958\n",
      "Batch: 64 , Combined Loss: tensor(0.9037, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5269210338592529\n",
      "Batch: 65 , Combined Loss: tensor(0.8375, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3451352119445801\n",
      "Batch: 66 , Combined Loss: tensor(0.9144, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5915572643280029\n",
      "Batch: 67 , Combined Loss: tensor(0.8766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.37956905364990234\n",
      "Batch: 68 , Combined Loss: tensor(0.8873, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09109753370285034\n",
      "Batch: 69 , Combined Loss: tensor(1.0015, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6923596858978271\n",
      "Batch: 70 , Combined Loss: tensor(0.8176, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8183325529098511\n",
      "Batch: 71 , Combined Loss: tensor(0.8425, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5631365776062012\n",
      "Batch: 72 , Combined Loss: tensor(0.8615, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.33724457025527954\n",
      "Batch: 73 , Combined Loss: tensor(0.9849, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6333673596382141\n",
      "Batch: 74 , Combined Loss: tensor(0.8666, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.49938666820526123\n",
      "Batch: 75 , Combined Loss: tensor(0.8154, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2873483896255493\n",
      "Batch: 76 , Combined Loss: tensor(0.8608, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.800143301486969\n",
      "Batch: 77 , Combined Loss: tensor(0.9275, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4211563467979431\n",
      "Batch: 78 , Combined Loss: tensor(0.9034, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46182048320770264\n",
      "Batch: 79 , Combined Loss: tensor(1.0173, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03343886137008667\n",
      "Batch: 80 , Combined Loss: tensor(0.9551, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.40114009380340576\n",
      "Batch: 81 , Combined Loss: tensor(0.9653, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7745300531387329\n",
      "Batch: 82 , Combined Loss: tensor(0.9654, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06835472583770752\n",
      "Batch: 83 , Combined Loss: tensor(0.8548, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.030747652053833008\n",
      "Batch: 84 , Combined Loss: tensor(0.8875, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8023306727409363\n",
      "Batch: 85 , Combined Loss: tensor(0.9997, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.011624574661254883\n",
      "Batch: 86 , Combined Loss: tensor(0.8776, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21068155765533447\n",
      "Batch: 87 , Combined Loss: tensor(0.8656, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09670782089233398\n",
      "Batch: 88 , Combined Loss: tensor(0.9118, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2237876057624817\n",
      "Batch: 89 , Combined Loss: tensor(0.9334, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.312417209148407\n",
      "Batch: 90 , Combined Loss: tensor(0.9051, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2890160083770752\n",
      "Batch: 91 , Combined Loss: tensor(0.8159, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.02281033992767334\n",
      "Batch: 92 , Combined Loss: tensor(0.8701, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7525794506072998\n",
      "Batch: 93 , Combined Loss: tensor(0.7909, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2185521125793457\n",
      "Batch: 94 , Combined Loss: tensor(0.8567, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.34231036901474\n",
      "Batch: 95 , Combined Loss: tensor(0.8783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.45697861909866333\n",
      "Batch: 96 , Combined Loss: tensor(1.0357, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4370023012161255\n",
      "Batch: 97 , Combined Loss: tensor(0.9002, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.31903159618377686\n",
      "Batch: 98 , Combined Loss: tensor(0.8488, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.024863004684448242\n",
      "Batch: 99 , Combined Loss: tensor(0.8689, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06497025489807129\n",
      "Batch: 100 , Combined Loss: tensor(0.8864, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19173288345336914\n",
      "Batch: 101 , Combined Loss: tensor(0.8477, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6386972069740295\n",
      "Batch: 102 , Combined Loss: tensor(0.9329, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5730692148208618\n",
      "Batch: 103 , Combined Loss: tensor(0.9846, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.402729868888855\n",
      "Batch: 104 , Combined Loss: tensor(0.8604, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.26673799753189087\n",
      "Batch: 105 , Combined Loss: tensor(0.9595, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7891280651092529\n",
      "Batch: 106 , Combined Loss: tensor(0.8853, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.755006730556488\n",
      "Batch: 107 , Combined Loss: tensor(0.8957, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2942202687263489\n",
      "Batch: 108 , Combined Loss: tensor(0.8686, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6895171403884888\n",
      "Batch: 109 , Combined Loss: tensor(0.9112, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6472581028938293\n",
      "Batch: 110 , Combined Loss: tensor(0.8715, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5434627532958984\n",
      "Batch: 111 , Combined Loss: tensor(0.9292, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8021221160888672\n",
      "Batch: 112 , Combined Loss: tensor(0.8439, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7079833745956421\n",
      "Batch: 113 , Combined Loss: tensor(0.8726, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.309238076210022\n",
      "Batch: 114 , Combined Loss: tensor(0.8877, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22225385904312134\n",
      "Batch: 115 , Combined Loss: tensor(0.8684, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6272482872009277\n",
      "Batch: 116 , Combined Loss: tensor(0.8361, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7841815948486328\n",
      "Batch: 117 , Combined Loss: tensor(0.9529, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2216712236404419\n",
      "Batch: 118 , Combined Loss: tensor(0.9727, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7062066793441772\n",
      "Batch: 119 , Combined Loss: tensor(0.8880, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.31783920526504517\n",
      "Batch: 120 , Combined Loss: tensor(0.9107, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.48563438653945923\n",
      "Batch: 121 , Combined Loss: tensor(0.9249, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.18797922134399414\n",
      "Batch: 122 , Combined Loss: tensor(0.9023, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6334024667739868\n",
      "Batch: 123 , Combined Loss: tensor(0.8521, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2982944846153259\n",
      "Batch: 124 , Combined Loss: tensor(0.8551, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.655156135559082\n",
      "Batch: 125 , Combined Loss: tensor(0.8528, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7845093011856079\n",
      "Batch: 126 , Combined Loss: tensor(0.8319, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6585277318954468\n",
      "Batch: 127 , Combined Loss: tensor(0.8599, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5124225616455078\n",
      "Batch: 128 , Combined Loss: tensor(0.8766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0857548713684082\n",
      "Batch: 129 , Combined Loss: tensor(0.8641, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.026109278202056885\n",
      "Batch: 130 , Combined Loss: tensor(0.8907, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26900017261505127\n",
      "Batch: 131 , Combined Loss: tensor(0.8478, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11888885498046875\n",
      "Batch: 132 , Combined Loss: tensor(0.9346, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5677995681762695\n",
      "Batch: 133 , Combined Loss: tensor(0.8250, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.27581489086151123\n",
      "Batch: 134 , Combined Loss: tensor(0.9130, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5333619117736816\n",
      "Batch: 135 , Combined Loss: tensor(0.9894, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22517889738082886\n",
      "Batch: 136 , Combined Loss: tensor(0.8557, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03428792953491211\n",
      "Batch: 137 , Combined Loss: tensor(0.8987, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7889140844345093\n",
      "Batch: 138 , Combined Loss: tensor(0.8761, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4878948926925659\n",
      "Batch: 139 , Combined Loss: tensor(0.8797, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20975977182388306\n",
      "Batch: 140 , Combined Loss: tensor(0.8964, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8520853519439697\n",
      "Batch: 141 , Combined Loss: tensor(0.8652, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03451883792877197\n",
      "Batch: 142 , Combined Loss: tensor(0.8717, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14203894138336182\n",
      "Batch: 143 , Combined Loss: tensor(0.8412, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.36757904291152954\n",
      "Batch: 144 , Combined Loss: tensor(0.8590, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.29685044288635254\n",
      "Batch: 145 , Combined Loss: tensor(0.8974, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2981261610984802\n",
      "Batch: 146 , Combined Loss: tensor(1.0060, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19368678331375122\n",
      "Batch: 147 , Combined Loss: tensor(0.9047, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7222638130187988\n",
      "Batch: 148 , Combined Loss: tensor(0.8545, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4596658945083618\n",
      "Batch: 149 , Combined Loss: tensor(0.8380, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4301718473434448\n",
      "Batch: 150 , Combined Loss: tensor(0.9223, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3132007122039795\n",
      "Batch: 151 , Combined Loss: tensor(0.8989, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7225953340530396\n",
      "Batch: 152 , Combined Loss: tensor(0.9171, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15104806423187256\n",
      "Batch: 153 , Combined Loss: tensor(0.8878, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14436763525009155\n",
      "Batch: 154 , Combined Loss: tensor(0.9827, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5145448446273804\n",
      "Batch: 155 , Combined Loss: tensor(0.8060, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10888248682022095\n",
      "Batch: 156 , Combined Loss: tensor(0.8981, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8801381587982178\n",
      "Batch: 157 , Combined Loss: tensor(0.8976, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4486275315284729\n",
      "Batch: 158 , Combined Loss: tensor(0.9080, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1069561243057251\n",
      "Batch: 159 , Combined Loss: tensor(0.9164, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3275375962257385\n",
      "Batch: 160 , Combined Loss: tensor(0.8380, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4171174168586731\n",
      "Batch: 161 , Combined Loss: tensor(0.8727, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3333261013031006\n",
      "Batch: 162 , Combined Loss: tensor(0.8293, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7224516868591309\n",
      "Batch: 163 , Combined Loss: tensor(0.8484, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.32360607385635376\n",
      "Batch: 164 , Combined Loss: tensor(0.9612, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8358619213104248\n",
      "Batch: 165 , Combined Loss: tensor(0.9737, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.849807858467102\n",
      "Batch: 166 , Combined Loss: tensor(0.8558, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.029045581817626953\n",
      "Batch: 167 , Combined Loss: tensor(0.9404, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5180394649505615\n",
      "Batch: 168 , Combined Loss: tensor(0.8735, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3685116767883301\n",
      "Batch: 169 , Combined Loss: tensor(0.8599, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21293824911117554\n",
      "Batch: 170 , Combined Loss: tensor(1.0822, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10584151744842529\n",
      "Batch: 171 , Combined Loss: tensor(0.8955, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.047382473945617676\n",
      "Batch: 172 , Combined Loss: tensor(0.8294, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5676261782646179\n",
      "Batch: 173 , Combined Loss: tensor(0.8909, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06558382511138916\n",
      "Batch: 174 , Combined Loss: tensor(0.8840, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06498384475708008\n",
      "Batch: 175 , Combined Loss: tensor(0.8502, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15931886434555054\n",
      "Batch: 176 , Combined Loss: tensor(0.8899, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6903284788131714\n",
      "Batch: 177 , Combined Loss: tensor(0.9090, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5432834625244141\n",
      "Batch: 178 , Combined Loss: tensor(0.9004, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3792896270751953\n",
      "Batch: 179 , Combined Loss: tensor(1.0106, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5000156760215759\n",
      "Batch: 180 , Combined Loss: tensor(0.8876, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21379125118255615\n",
      "Batch: 181 , Combined Loss: tensor(0.8686, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21224325895309448\n",
      "Batch: 182 , Combined Loss: tensor(0.8389, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21433711051940918\n",
      "Batch: 183 , Combined Loss: tensor(0.8830, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5345917344093323\n",
      "Batch: 184 , Combined Loss: tensor(0.8506, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21424031257629395\n",
      "Batch: 185 , Combined Loss: tensor(0.8040, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8353608250617981\n",
      "Batch: 186 , Combined Loss: tensor(0.8342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19659656286239624\n",
      "Batch: 187 , Combined Loss: tensor(0.8496, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4549846649169922\n",
      "Batch: 188 , Combined Loss: tensor(0.9220, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.49011915922164917\n",
      "Batch: 189 , Combined Loss: tensor(0.8825, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.35781943798065186\n",
      "Batch: 190 , Combined Loss: tensor(0.8847, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06986868381500244\n",
      "Batch: 191 , Combined Loss: tensor(1.0185, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21210694313049316\n",
      "Batch: 192 , Combined Loss: tensor(0.8478, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.41890037059783936\n",
      "Batch: 193 , Combined Loss: tensor(0.8522, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.754404604434967\n",
      "Batch: 194 , Combined Loss: tensor(0.9351, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06283348798751831\n",
      "Batch: 195 , Combined Loss: tensor(0.8122, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12770581245422363\n",
      "Batch: 196 , Combined Loss: tensor(0.8358, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.595015287399292\n",
      "Batch: 197 , Combined Loss: tensor(0.9084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3720613121986389\n",
      "Batch: 198 , Combined Loss: tensor(0.9611, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08655154705047607\n",
      "Batch: 199 , Combined Loss: tensor(0.8390, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.72154301404953\n",
      "Batch: 200 , Combined Loss: tensor(0.8520, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.014914274215698242\n",
      "Batch: 201 , Combined Loss: tensor(0.8592, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3247760534286499\n",
      "Batch: 202 , Combined Loss: tensor(0.8315, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07751482725143433\n",
      "Batch: 203 , Combined Loss: tensor(0.8825, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8366670608520508\n",
      "Batch: 204 , Combined Loss: tensor(0.7748, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2862793803215027\n",
      "Batch: 205 , Combined Loss: tensor(0.8339, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6891248226165771\n",
      "Batch: 206 , Combined Loss: tensor(0.7987, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15716278553009033\n",
      "Batch: 207 , Combined Loss: tensor(0.9834, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.700581431388855\n",
      "Batch: 208 , Combined Loss: tensor(0.9113, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.726988673210144\n",
      "Batch: 209 , Combined Loss: tensor(0.8646, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25760436058044434\n",
      "Batch: 210 , Combined Loss: tensor(0.9916, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8177822828292847\n",
      "Batch: 211 , Combined Loss: tensor(0.8981, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8422058820724487\n",
      "Batch: 212 , Combined Loss: tensor(0.9306, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.44861817359924316\n",
      "Batch: 213 , Combined Loss: tensor(0.8939, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6442791223526001\n",
      "Batch: 214 , Combined Loss: tensor(0.8607, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1576048731803894\n",
      "Batch: 215 , Combined Loss: tensor(0.8340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34981071949005127\n",
      "Batch: 216 , Combined Loss: tensor(0.8640, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2937636375427246\n",
      "Batch: 217 , Combined Loss: tensor(0.8490, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6511396765708923\n",
      "Batch: 218 , Combined Loss: tensor(0.9647, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6181422472000122\n",
      "Batch: 219 , Combined Loss: tensor(0.8690, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5464475154876709\n",
      "Batch: 220 , Combined Loss: tensor(0.9630, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7718473672866821\n",
      "Batch: 221 , Combined Loss: tensor(0.8148, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6661819219589233\n",
      "Batch: 222 , Combined Loss: tensor(0.8419, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3624976873397827\n",
      "Batch: 223 , Combined Loss: tensor(0.8643, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5671249628067017\n",
      "Batch: 224 , Combined Loss: tensor(0.8340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3594973087310791\n",
      "Batch: 225 , Combined Loss: tensor(0.7341, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5770769119262695\n",
      "Batch: 226 , Combined Loss: tensor(0.8631, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06745922565460205\n",
      "Batch: 227 , Combined Loss: tensor(0.8652, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.43153977394104004\n",
      "Batch: 228 , Combined Loss: tensor(0.8890, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5750401020050049\n",
      "Batch: 229 , Combined Loss: tensor(0.9052, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6132855415344238\n",
      "Batch: 230 , Combined Loss: tensor(0.8131, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31527841091156006\n",
      "Batch: 231 , Combined Loss: tensor(0.8716, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7087182998657227\n",
      "Batch: 232 , Combined Loss: tensor(0.9818, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3319823741912842\n",
      "Batch: 233 , Combined Loss: tensor(0.8087, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15968847274780273\n",
      "Batch: 234 , Combined Loss: tensor(0.8651, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20402878522872925\n",
      "Batch: 235 , Combined Loss: tensor(0.8821, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7268928289413452\n",
      "Batch: 236 , Combined Loss: tensor(0.8823, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39118480682373047\n",
      "Batch: 237 , Combined Loss: tensor(0.8214, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7432224750518799\n",
      "Batch: 238 , Combined Loss: tensor(0.8532, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.013006746768951416\n",
      "Batch: 239 , Combined Loss: tensor(0.8916, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6394790410995483\n",
      "Batch: 240 , Combined Loss: tensor(1.0097, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6331073045730591\n",
      "Batch: 241 , Combined Loss: tensor(0.7552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6454970836639404\n",
      "Batch: 242 , Combined Loss: tensor(0.8253, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4547607898712158\n",
      "Batch: 243 , Combined Loss: tensor(0.9257, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5468036532402039\n",
      "Batch: 244 , Combined Loss: tensor(1.0289, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3335108757019043\n",
      "Batch: 245 , Combined Loss: tensor(0.8851, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20238351821899414\n",
      "Batch: 246 , Combined Loss: tensor(0.8497, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3731728196144104\n",
      "Batch: 247 , Combined Loss: tensor(0.9208, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11472100019454956\n",
      "Batch: 248 , Combined Loss: tensor(0.9041, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.48739558458328247\n",
      "Batch: 249 , Combined Loss: tensor(0.9340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11558705568313599\n",
      "Batch: 250 , Combined Loss: tensor(0.9706, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.45650386810302734\n",
      "Batch: 251 , Combined Loss: tensor(0.9986, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6672332286834717\n",
      "Batch: 252 , Combined Loss: tensor(0.8615, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6517320871353149\n",
      "Batch: 253 , Combined Loss: tensor(0.8967, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6904228925704956\n",
      "Batch: 254 , Combined Loss: tensor(0.8691, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8312350511550903\n",
      "Batch: 255 , Combined Loss: tensor(0.8711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12479627132415771\n",
      "Batch: 256 , Combined Loss: tensor(0.8858, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17198973894119263\n",
      "Batch: 257 , Combined Loss: tensor(0.8307, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3606181740760803\n",
      "Batch: 258 , Combined Loss: tensor(0.8380, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07910645008087158\n",
      "Batch: 259 , Combined Loss: tensor(0.8803, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.447196364402771\n",
      "Batch: 260 , Combined Loss: tensor(0.8358, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5270751714706421\n",
      "Batch: 261 , Combined Loss: tensor(0.9480, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14472103118896484\n",
      "Batch: 262 , Combined Loss: tensor(0.8792, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.18857800960540771\n",
      "Batch: 263 , Combined Loss: tensor(0.9119, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07862341403961182\n",
      "Batch: 264 , Combined Loss: tensor(0.8232, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06274187564849854\n",
      "Batch: 265 , Combined Loss: tensor(0.8608, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5511351227760315\n",
      "Batch: 266 , Combined Loss: tensor(0.9409, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8893541097640991\n",
      "Batch: 267 , Combined Loss: tensor(0.8674, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4395352005958557\n",
      "Batch: 268 , Combined Loss: tensor(0.9795, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3788706064224243\n",
      "Batch: 269 , Combined Loss: tensor(0.8964, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21187961101531982\n",
      "Batch: 270 , Combined Loss: tensor(0.8313, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5003364086151123\n",
      "Batch: 271 , Combined Loss: tensor(0.8493, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11502182483673096\n",
      "Batch: 272 , Combined Loss: tensor(0.8980, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7872164845466614\n",
      "Batch: 273 , Combined Loss: tensor(0.7891, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6286101341247559\n",
      "Batch: 274 , Combined Loss: tensor(0.7942, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2710447907447815\n",
      "Batch: 275 , Combined Loss: tensor(1.0029, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3431071639060974\n",
      "Batch: 276 , Combined Loss: tensor(0.9768, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4081020951271057\n",
      "Batch: 277 , Combined Loss: tensor(0.8475, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5043470859527588\n",
      "Batch: 278 , Combined Loss: tensor(0.8476, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41677379608154297\n",
      "Batch: 279 , Combined Loss: tensor(1.0054, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.345284104347229\n",
      "Batch: 280 , Combined Loss: tensor(0.8238, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4348181486129761\n",
      "Batch: 281 , Combined Loss: tensor(1.0852, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12350320816040039\n",
      "Batch: 282 , Combined Loss: tensor(0.9349, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.13854211568832397\n",
      "Batch: 283 , Combined Loss: tensor(0.8211, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0959022045135498\n",
      "Batch: 284 , Combined Loss: tensor(0.8665, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.42541027069091797\n",
      "Batch: 285 , Combined Loss: tensor(0.8859, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21066147089004517\n",
      "Batch: 286 , Combined Loss: tensor(0.8742, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.36544525623321533\n",
      "Batch: 287 , Combined Loss: tensor(0.8396, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1639941930770874\n",
      "Batch: 288 , Combined Loss: tensor(0.8866, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17930102348327637\n",
      "Batch: 289 , Combined Loss: tensor(0.8790, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.16277778148651123\n",
      "Batch: 290 , Combined Loss: tensor(0.9308, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.45479631423950195\n",
      "Batch: 291 , Combined Loss: tensor(0.8180, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3804819583892822\n",
      "Batch: 292 , Combined Loss: tensor(0.9806, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5537995100021362\n",
      "Batch: 293 , Combined Loss: tensor(0.8236, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5076318979263306\n",
      "Batch: 294 , Combined Loss: tensor(0.8635, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8079336881637573\n",
      "Batch: 295 , Combined Loss: tensor(0.8575, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20558971166610718\n",
      "Batch: 296 , Combined Loss: tensor(0.8451, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3093618154525757\n",
      "Batch: 297 , Combined Loss: tensor(0.8233, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17235827445983887\n",
      "Batch: 298 , Combined Loss: tensor(0.8374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37153804302215576\n",
      "Batch: 299 , Combined Loss: tensor(0.7974, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6599957942962646\n",
      "Batch: 300 , Combined Loss: tensor(1.0038, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44327759742736816\n",
      "Batch: 301 , Combined Loss: tensor(0.8980, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07195520401000977\n",
      "Batch: 302 , Combined Loss: tensor(0.8446, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14745694398880005\n",
      "Batch: 303 , Combined Loss: tensor(0.9778, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39070069789886475\n",
      "Batch: 304 , Combined Loss: tensor(0.8718, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2638511657714844\n",
      "Batch: 305 , Combined Loss: tensor(0.8340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3075284957885742\n",
      "Batch: 306 , Combined Loss: tensor(0.9164, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.038465678691864014\n",
      "Batch: 307 , Combined Loss: tensor(0.7958, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5091214776039124\n",
      "Batch: 308 , Combined Loss: tensor(0.9364, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08391225337982178\n",
      "Batch: 309 , Combined Loss: tensor(0.9633, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3872964382171631\n",
      "Batch: 310 , Combined Loss: tensor(0.9001, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08707743883132935\n",
      "Batch: 311 , Combined Loss: tensor(0.8044, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6576327681541443\n",
      "Batch: 312 , Combined Loss: tensor(0.9495, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11018800735473633\n",
      "Batch: 313 , Combined Loss: tensor(0.8699, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6624970436096191\n",
      "Batch: 314 , Combined Loss: tensor(0.8922, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.008362889289855957\n",
      "Batch: 315 , Combined Loss: tensor(1.1348, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17711514234542847\n",
      "Batch: 316 , Combined Loss: tensor(0.8087, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.44952744245529175\n",
      "Batch: 317 , Combined Loss: tensor(0.8578, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.334619402885437\n",
      "Batch: 318 , Combined Loss: tensor(0.9528, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08508974313735962\n",
      "Batch: 319 , Combined Loss: tensor(0.9477, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6960580945014954\n",
      "Batch: 320 , Combined Loss: tensor(0.8274, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6133095026016235\n",
      "Batch: 321 , Combined Loss: tensor(0.8862, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.36713021993637085\n",
      "Batch: 322 , Combined Loss: tensor(0.8750, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6867964267730713\n",
      "Batch: 323 , Combined Loss: tensor(0.8809, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08310472965240479\n",
      "Batch: 324 , Combined Loss: tensor(0.9475, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.13700908422470093\n",
      "Batch: 325 , Combined Loss: tensor(0.8839, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5666258931159973\n",
      "Batch: 326 , Combined Loss: tensor(0.9923, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4057460427284241\n",
      "Batch: 327 , Combined Loss: tensor(0.7890, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19188916683197021\n",
      "Batch: 328 , Combined Loss: tensor(0.8025, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23304080963134766\n",
      "Batch: 329 , Combined Loss: tensor(0.8378, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7879986763000488\n",
      "Batch: 330 , Combined Loss: tensor(0.9389, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5201497077941895\n",
      "Batch: 331 , Combined Loss: tensor(1.0837, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4039023518562317\n",
      "Batch: 332 , Combined Loss: tensor(0.7918, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17298418283462524\n",
      "Batch: 333 , Combined Loss: tensor(0.9401, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8089504241943359\n",
      "Batch: 334 , Combined Loss: tensor(0.8333, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13829302787780762\n",
      "Batch: 335 , Combined Loss: tensor(0.9252, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.43631815910339355\n",
      "Batch: 336 , Combined Loss: tensor(0.8171, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6520528793334961\n",
      "Batch: 337 , Combined Loss: tensor(0.9437, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07869833707809448\n",
      "Batch: 338 , Combined Loss: tensor(0.9276, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.870574414730072\n",
      "Batch: 339 , Combined Loss: tensor(0.9247, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.30198031663894653\n",
      "Batch: 340 , Combined Loss: tensor(0.8840, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7036267518997192\n",
      "Batch: 341 , Combined Loss: tensor(0.8903, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6991277933120728\n",
      "Batch: 342 , Combined Loss: tensor(0.8011, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6314420700073242\n",
      "Batch: 343 , Combined Loss: tensor(0.8650, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5897613167762756\n",
      "Batch: 344 , Combined Loss: tensor(0.8934, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05428248643875122\n",
      "Batch: 345 , Combined Loss: tensor(0.7982, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3295731544494629\n",
      "Batch: 346 , Combined Loss: tensor(0.8512, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23636096715927124\n",
      "Batch: 347 , Combined Loss: tensor(0.8263, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1147506833076477\n",
      "Batch: 348 , Combined Loss: tensor(0.9465, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6805344820022583\n",
      "Batch: 349 , Combined Loss: tensor(0.8396, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7137013673782349\n",
      "Batch: 350 , Combined Loss: tensor(0.8807, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04378819465637207\n",
      "Batch: 351 , Combined Loss: tensor(0.8219, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5219172239303589\n",
      "Batch: 352 , Combined Loss: tensor(0.9441, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5341864824295044\n",
      "Batch: 353 , Combined Loss: tensor(0.9033, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03899317979812622\n",
      "Batch: 354 , Combined Loss: tensor(0.8303, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37733352184295654\n",
      "Batch: 355 , Combined Loss: tensor(0.8335, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5503377914428711\n",
      "Batch: 356 , Combined Loss: tensor(0.8426, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06907296180725098\n",
      "Batch: 357 , Combined Loss: tensor(0.8494, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06543254852294922\n",
      "Batch: 358 , Combined Loss: tensor(0.8736, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12468189001083374\n",
      "Batch: 359 , Combined Loss: tensor(0.8978, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29273319244384766\n",
      "Batch: 360 , Combined Loss: tensor(0.8967, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39525729417800903\n",
      "Batch: 361 , Combined Loss: tensor(0.9767, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09002131223678589\n",
      "Batch: 362 , Combined Loss: tensor(0.9538, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8302792906761169\n",
      "Batch: 363 , Combined Loss: tensor(0.8018, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30924320220947266\n",
      "Batch: 364 , Combined Loss: tensor(0.9353, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07531332969665527\n",
      "Batch: 365 , Combined Loss: tensor(0.8452, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3507973551750183\n",
      "Batch: 366 , Combined Loss: tensor(0.9856, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7208213806152344\n",
      "Batch: 367 , Combined Loss: tensor(0.8204, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1287703514099121\n",
      "Batch: 368 , Combined Loss: tensor(0.8844, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28255224227905273\n",
      "Batch: 369 , Combined Loss: tensor(0.9925, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17381179332733154\n",
      "Batch: 370 , Combined Loss: tensor(0.8848, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.46053963899612427\n",
      "Batch: 371 , Combined Loss: tensor(0.8338, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24140691757202148\n",
      "Batch: 372 , Combined Loss: tensor(0.9040, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.025721073150634766\n",
      "Batch: 373 , Combined Loss: tensor(0.8289, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09062683582305908\n",
      "Batch: 374 , Combined Loss: tensor(0.8210, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08938568830490112\n",
      "Batch: 375 , Combined Loss: tensor(0.8663, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12047886848449707\n",
      "Batch: 376 , Combined Loss: tensor(0.9707, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8543962240219116\n",
      "Batch: 377 , Combined Loss: tensor(0.8711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10129880905151367\n",
      "Batch: 378 , Combined Loss: tensor(0.8517, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5803674459457397\n",
      "Batch: 379 , Combined Loss: tensor(0.9175, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.011594533920288086\n",
      "Batch: 380 , Combined Loss: tensor(0.8259, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.41683143377304077\n",
      "Batch: 381 , Combined Loss: tensor(0.8573, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3233388662338257\n",
      "Batch: 382 , Combined Loss: tensor(0.8507, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6101897954940796\n",
      "Batch: 383 , Combined Loss: tensor(0.8040, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.16935515403747559\n",
      "Batch: 384 , Combined Loss: tensor(0.8822, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.43419355154037476\n",
      "Batch: 385 , Combined Loss: tensor(0.9054, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1381717324256897\n",
      "Batch: 386 , Combined Loss: tensor(0.9044, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07083553075790405\n",
      "Batch: 387 , Combined Loss: tensor(0.8427, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5977431535720825\n",
      "Batch: 388 , Combined Loss: tensor(1.0789, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08742278814315796\n",
      "Batch: 389 , Combined Loss: tensor(0.8131, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37133944034576416\n",
      "Batch: 390 , Combined Loss: tensor(0.8609, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.41591912508010864\n",
      "Batch: 391 , Combined Loss: tensor(0.8054, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12520837783813477\n",
      "Batch: 392 , Combined Loss: tensor(0.9017, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17840206623077393\n",
      "Batch: 393 , Combined Loss: tensor(0.9541, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5166938304901123\n",
      "Batch: 394 , Combined Loss: tensor(0.8830, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15810513496398926\n",
      "Batch: 395 , Combined Loss: tensor(0.8363, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30284202098846436\n",
      "Batch: 396 , Combined Loss: tensor(0.8494, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29025089740753174\n",
      "Batch: 397 , Combined Loss: tensor(0.8055, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24844229221343994\n",
      "Batch: 398 , Combined Loss: tensor(0.8839, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5751731991767883\n",
      "Batch: 399 , Combined Loss: tensor(0.8476, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2615377902984619\n",
      "Batch: 400 , Combined Loss: tensor(0.9740, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6509702205657959\n",
      "Batch: 401 , Combined Loss: tensor(0.8541, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23241335153579712\n",
      "Batch: 402 , Combined Loss: tensor(0.8479, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2578563094139099\n",
      "Batch: 403 , Combined Loss: tensor(1.0219, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15190327167510986\n",
      "Batch: 404 , Combined Loss: tensor(0.8101, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.548772931098938\n",
      "Batch: 405 , Combined Loss: tensor(0.8628, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3010876178741455\n",
      "Batch: 406 , Combined Loss: tensor(0.8148, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36398041248321533\n",
      "Batch: 407 , Combined Loss: tensor(1.0773, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04551541805267334\n",
      "Batch: 408 , Combined Loss: tensor(0.8916, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.02738189697265625\n",
      "Batch: 409 , Combined Loss: tensor(0.8324, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07050144672393799\n",
      "Batch: 410 , Combined Loss: tensor(0.8103, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2487991452217102\n",
      "Batch: 411 , Combined Loss: tensor(0.8720, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1857343316078186\n",
      "Batch: 412 , Combined Loss: tensor(1.0975, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.16649585962295532\n",
      "Batch: 413 , Combined Loss: tensor(0.7998, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2716362476348877\n",
      "Batch: 414 , Combined Loss: tensor(0.9998, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07794326543807983\n",
      "Batch: 415 , Combined Loss: tensor(0.8150, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23617905378341675\n",
      "Batch: 416 , Combined Loss: tensor(0.8420, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.628917932510376\n",
      "Batch: 417 , Combined Loss: tensor(0.8177, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07661151885986328\n",
      "Batch: 418 , Combined Loss: tensor(0.7657, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5932536721229553\n",
      "Batch: 419 , Combined Loss: tensor(0.7499, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.36118167638778687\n",
      "Batch: 420 , Combined Loss: tensor(0.8415, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17674028873443604\n",
      "Batch: 421 , Combined Loss: tensor(0.8911, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33972740173339844\n",
      "Batch: 422 , Combined Loss: tensor(0.8323, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5432429313659668\n",
      "Batch: 423 , Combined Loss: tensor(0.9586, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.61833256483078\n",
      "Batch: 424 , Combined Loss: tensor(0.8936, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.35817259550094604\n",
      "Batch: 425 , Combined Loss: tensor(0.8765, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6485309600830078\n",
      "Batch: 426 , Combined Loss: tensor(0.8702, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.00432974100112915\n",
      "Batch: 427 , Combined Loss: tensor(0.8125, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.752927303314209\n",
      "Batch: 428 , Combined Loss: tensor(0.8441, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.34840142726898193\n",
      "Batch: 429 , Combined Loss: tensor(0.9028, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7457675933837891\n",
      "Batch: 430 , Combined Loss: tensor(0.8549, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5981153845787048\n",
      "Batch: 431 , Combined Loss: tensor(0.7657, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03285372257232666\n",
      "Batch: 432 , Combined Loss: tensor(0.7520, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6214144229888916\n",
      "Batch: 433 , Combined Loss: tensor(0.8413, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0344548225402832\n",
      "Batch: 434 , Combined Loss: tensor(0.8896, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11683046817779541\n",
      "Batch: 435 , Combined Loss: tensor(0.7886, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.41433286666870117\n",
      "Batch: 436 , Combined Loss: tensor(0.8199, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4057573080062866\n",
      "Batch: 437 , Combined Loss: tensor(0.8742, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5179986953735352\n",
      "Batch: 438 , Combined Loss: tensor(1.0158, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.037857890129089355\n",
      "Batch: 439 , Combined Loss: tensor(0.8185, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19565987586975098\n",
      "Batch: 440 , Combined Loss: tensor(0.8612, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4348045587539673\n",
      "Batch: 441 , Combined Loss: tensor(0.8783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.199160635471344\n",
      "Batch: 442 , Combined Loss: tensor(0.8169, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20521342754364014\n",
      "Batch: 443 , Combined Loss: tensor(0.8429, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23587006330490112\n",
      "Batch: 444 , Combined Loss: tensor(0.8391, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09355771541595459\n",
      "Batch: 445 , Combined Loss: tensor(0.8724, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15777724981307983\n",
      "Batch: 446 , Combined Loss: tensor(0.9636, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5925806760787964\n",
      "Batch: 447 , Combined Loss: tensor(0.8916, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15926063060760498\n",
      "Batch: 448 , Combined Loss: tensor(0.8233, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.620302677154541\n",
      "Batch: 449 , Combined Loss: tensor(1.1816, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09028613567352295\n",
      "Batch: 450 , Combined Loss: tensor(0.8572, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.25111013650894165\n",
      "Batch: 451 , Combined Loss: tensor(0.9186, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4087029695510864\n",
      "Batch: 452 , Combined Loss: tensor(0.8896, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5944693088531494\n",
      "Batch: 453 , Combined Loss: tensor(0.8550, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20123863220214844\n",
      "Batch: 454 , Combined Loss: tensor(0.9047, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4005087614059448\n",
      "Batch: 455 , Combined Loss: tensor(0.8112, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.18912702798843384\n",
      "Batch: 456 , Combined Loss: tensor(0.8084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07030898332595825\n",
      "Batch: 457 , Combined Loss: tensor(0.8853, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.011500537395477295\n",
      "Batch: 458 , Combined Loss: tensor(0.9022, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.18525975942611694\n",
      "Batch: 459 , Combined Loss: tensor(0.8575, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3536107540130615\n",
      "Batch: 460 , Combined Loss: tensor(0.9128, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2956835627555847\n",
      "Batch: 461 , Combined Loss: tensor(0.9440, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.30905866622924805\n",
      "Batch: 462 , Combined Loss: tensor(0.8749, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3052288889884949\n",
      "Batch: 463 , Combined Loss: tensor(1.0779, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7799087166786194\n",
      "Batch: 464 , Combined Loss: tensor(0.9037, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.45650172233581543\n",
      "Batch: 465 , Combined Loss: tensor(0.7797, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0037817955017089844\n",
      "Batch: 466 , Combined Loss: tensor(0.8319, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04932129383087158\n",
      "Batch: 467 , Combined Loss: tensor(0.8190, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17174243927001953\n",
      "Batch: 468 , Combined Loss: tensor(0.8197, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0794568657875061\n",
      "Batch: 469 , Combined Loss: tensor(0.8599, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3254239559173584\n",
      "Batch: 470 , Combined Loss: tensor(0.9300, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4249078035354614\n",
      "Batch: 471 , Combined Loss: tensor(0.8649, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.048502564430236816\n",
      "Batch: 472 , Combined Loss: tensor(0.8624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3883473873138428\n",
      "Batch: 473 , Combined Loss: tensor(0.8262, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4965212345123291\n",
      "Batch: 474 , Combined Loss: tensor(0.8089, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.517478346824646\n",
      "Batch: 475 , Combined Loss: tensor(0.9041, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10742223262786865\n",
      "Batch: 476 , Combined Loss: tensor(0.8313, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06622540950775146\n",
      "Batch: 477 , Combined Loss: tensor(0.9513, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07062464952468872\n",
      "Batch: 478 , Combined Loss: tensor(0.8806, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0270116925239563\n",
      "Batch: 479 , Combined Loss: tensor(0.9247, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5137706995010376\n",
      "Batch: 480 , Combined Loss: tensor(1.0089, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5541951656341553\n",
      "Batch: 481 , Combined Loss: tensor(0.9792, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6806663274765015\n",
      "Batch: 482 , Combined Loss: tensor(0.8208, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39048105478286743\n",
      "Batch: 483 , Combined Loss: tensor(0.8551, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7155908346176147\n",
      "Batch: 484 , Combined Loss: tensor(0.9165, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04929709434509277\n",
      "Batch: 485 , Combined Loss: tensor(1.0030, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5547932386398315\n",
      "Batch: 486 , Combined Loss: tensor(0.8727, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3190675377845764\n",
      "Batch: 487 , Combined Loss: tensor(0.8180, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.422204852104187\n",
      "Batch: 488 , Combined Loss: tensor(0.8175, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15063828229904175\n",
      "Batch: 489 , Combined Loss: tensor(0.8955, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.47351622581481934\n",
      "Batch: 490 , Combined Loss: tensor(0.8471, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5519744157791138\n",
      "Batch: 491 , Combined Loss: tensor(0.8604, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.050634145736694336\n",
      "Batch: 492 , Combined Loss: tensor(0.8637, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22821152210235596\n",
      "Batch: 493 , Combined Loss: tensor(1.0194, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6131828427314758\n",
      "Batch: 494 , Combined Loss: tensor(0.8507, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24415379762649536\n",
      "Batch: 495 , Combined Loss: tensor(0.8384, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11851978302001953\n",
      "Batch: 496 , Combined Loss: tensor(0.8490, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1524273157119751\n",
      "Batch: 497 , Combined Loss: tensor(0.8856, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.38229209184646606\n",
      "Batch: 498 , Combined Loss: tensor(0.8604, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.744204044342041\n",
      "Batch: 499 , Combined Loss: tensor(1.0356, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6081386804580688\n",
      "Batch: 500 , Combined Loss: tensor(0.8377, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1458965539932251\n",
      "Batch: 501 , Combined Loss: tensor(0.8309, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6983486413955688\n",
      "Batch: 502 , Combined Loss: tensor(0.9783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16069495677947998\n",
      "Batch: 503 , Combined Loss: tensor(0.8103, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7495338916778564\n",
      "Batch: 504 , Combined Loss: tensor(0.8469, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23716020584106445\n",
      "Batch: 505 , Combined Loss: tensor(0.8718, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.49828779697418213\n",
      "Batch: 506 , Combined Loss: tensor(0.8903, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09813356399536133\n",
      "Batch: 507 , Combined Loss: tensor(0.9159, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.016842544078826904\n",
      "Batch: 508 , Combined Loss: tensor(0.9259, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38672399520874023\n",
      "Batch: 509 , Combined Loss: tensor(0.8320, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7112938761711121\n",
      "Batch: 510 , Combined Loss: tensor(1.0411, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14240199327468872\n",
      "Batch: 511 , Combined Loss: tensor(0.8666, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6934288740158081\n",
      "Batch: 512 , Combined Loss: tensor(0.8358, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6206812858581543\n",
      "Batch: 513 , Combined Loss: tensor(0.8425, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.040352702140808105\n",
      "Batch: 514 , Combined Loss: tensor(0.8830, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6530858278274536\n",
      "Batch: 515 , Combined Loss: tensor(0.7118, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5177599191665649\n",
      "Batch: 516 , Combined Loss: tensor(0.7887, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3938918113708496\n",
      "Batch: 517 , Combined Loss: tensor(0.9480, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.560491681098938\n",
      "Batch: 518 , Combined Loss: tensor(0.9497, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5628823041915894\n",
      "Batch: 519 , Combined Loss: tensor(0.8908, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.16105031967163086\n",
      "Batch: 520 , Combined Loss: tensor(0.9235, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.42547547817230225\n",
      "Batch: 521 , Combined Loss: tensor(0.8007, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22488069534301758\n",
      "Batch: 522 , Combined Loss: tensor(0.8079, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24442362785339355\n",
      "Batch: 523 , Combined Loss: tensor(0.9325, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17035621404647827\n",
      "Batch: 524 , Combined Loss: tensor(0.9225, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7038532495498657\n",
      "Batch: 525 , Combined Loss: tensor(0.9812, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3818293809890747\n",
      "Batch: 526 , Combined Loss: tensor(0.9620, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7653462290763855\n",
      "Batch: 527 , Combined Loss: tensor(0.7829, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8707032203674316\n",
      "Batch: 528 , Combined Loss: tensor(0.8705, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33927667140960693\n",
      "Batch: 529 , Combined Loss: tensor(0.8905, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8858951330184937\n",
      "Batch: 530 , Combined Loss: tensor(0.9861, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6809158325195312\n",
      "Batch: 531 , Combined Loss: tensor(0.8303, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7776290774345398\n",
      "Batch: 532 , Combined Loss: tensor(0.8806, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2994198203086853\n",
      "Batch: 533 , Combined Loss: tensor(0.9421, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04968219995498657\n",
      "Batch: 534 , Combined Loss: tensor(0.9556, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2588968276977539\n",
      "Batch: 535 , Combined Loss: tensor(0.8544, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.004933714866638184\n",
      "Batch: 536 , Combined Loss: tensor(0.9736, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.693551778793335\n",
      "Batch: 537 , Combined Loss: tensor(1.0125, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07487773895263672\n",
      "Batch: 538 , Combined Loss: tensor(1.0337, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4298174977302551\n",
      "Batch: 539 , Combined Loss: tensor(1.0911, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8581444025039673\n",
      "Batch: 540 , Combined Loss: tensor(0.8365, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19498920440673828\n",
      "Batch: 541 , Combined Loss: tensor(0.7592, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.40050315856933594\n",
      "Batch: 542 , Combined Loss: tensor(0.9042, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5355808734893799\n",
      "Batch: 543 , Combined Loss: tensor(0.8364, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09291815757751465\n",
      "Batch: 544 , Combined Loss: tensor(0.8160, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6398494243621826\n",
      "Batch: 545 , Combined Loss: tensor(0.8466, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7460337281227112\n",
      "Batch: 546 , Combined Loss: tensor(0.8355, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05029904842376709\n",
      "Batch: 547 , Combined Loss: tensor(0.9169, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.28366178274154663\n",
      "Batch: 548 , Combined Loss: tensor(1.1440, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.18515467643737793\n",
      "Batch: 549 , Combined Loss: tensor(0.8987, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7677674889564514\n",
      "Batch: 550 , Combined Loss: tensor(0.9403, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2111077904701233\n",
      "Batch: 551 , Combined Loss: tensor(1.0211, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7741098403930664\n",
      "Batch: 552 , Combined Loss: tensor(0.9006, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07136416435241699\n",
      "Batch: 553 , Combined Loss: tensor(1.1050, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2013188600540161\n",
      "Batch: 554 , Combined Loss: tensor(0.8870, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.45772451162338257\n",
      "Batch: 555 , Combined Loss: tensor(0.9232, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.36798644065856934\n",
      "Batch: 556 , Combined Loss: tensor(1.0294, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3070076107978821\n",
      "Batch: 557 , Combined Loss: tensor(1.0874, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4225064516067505\n",
      "Batch: 558 , Combined Loss: tensor(0.8801, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8086954355239868\n",
      "Batch: 559 , Combined Loss: tensor(0.8901, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3179473280906677\n",
      "Batch: 560 , Combined Loss: tensor(0.8542, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3580728769302368\n",
      "Batch: 561 , Combined Loss: tensor(0.8352, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2991560697555542\n",
      "Batch: 562 , Combined Loss: tensor(0.8840, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.13368302583694458\n",
      "Batch: 563 , Combined Loss: tensor(0.8406, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.30025094747543335\n",
      "Batch: 564 , Combined Loss: tensor(1.1167, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.027374267578125\n",
      "Batch: 565 , Combined Loss: tensor(1.0025, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.34627360105514526\n",
      "Batch: 566 , Combined Loss: tensor(0.9435, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.004385590553283691\n",
      "Batch: 567 , Combined Loss: tensor(0.8827, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.38366180658340454\n",
      "Batch: 568 , Combined Loss: tensor(0.8337, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1617295742034912\n",
      "Batch: 569 , Combined Loss: tensor(0.9053, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.31464576721191406\n",
      "Batch: 570 , Combined Loss: tensor(0.9753, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4664343595504761\n",
      "Batch: 571 , Combined Loss: tensor(0.9006, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.35190314054489136\n",
      "Batch: 572 , Combined Loss: tensor(0.8243, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.40497297048568726\n",
      "Batch: 573 , Combined Loss: tensor(0.9437, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10433018207550049\n",
      "Batch: 574 , Combined Loss: tensor(0.8605, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4304661154747009\n",
      "Batch: 575 , Combined Loss: tensor(0.8051, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1849716305732727\n",
      "Batch: 576 , Combined Loss: tensor(0.8334, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1122199296951294\n",
      "Batch: 577 , Combined Loss: tensor(0.8311, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7984035015106201\n",
      "Batch: 578 , Combined Loss: tensor(0.9586, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6260945796966553\n",
      "Batch: 579 , Combined Loss: tensor(0.9772, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.003935456275939941\n",
      "Batch: 580 , Combined Loss: tensor(0.8574, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7716019153594971\n",
      "Batch: 581 , Combined Loss: tensor(0.9054, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23694050312042236\n",
      "Batch: 582 , Combined Loss: tensor(0.7976, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5590240955352783\n",
      "Batch: 583 , Combined Loss: tensor(0.8257, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.027178287506103516\n",
      "Batch: 584 , Combined Loss: tensor(0.8290, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6116876602172852\n",
      "Batch: 585 , Combined Loss: tensor(0.8989, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.050284504890441895\n",
      "Batch: 586 , Combined Loss: tensor(0.8948, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11458301544189453\n",
      "Batch: 587 , Combined Loss: tensor(0.9502, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6238685846328735\n",
      "Batch: 588 , Combined Loss: tensor(0.8117, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.25328177213668823\n",
      "Batch: 589 , Combined Loss: tensor(0.8438, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.16492772102355957\n",
      "Batch: 590 , Combined Loss: tensor(0.7945, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.33559197187423706\n",
      "Batch: 591 , Combined Loss: tensor(0.9058, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33260536193847656\n",
      "Batch: 592 , Combined Loss: tensor(0.8993, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3399887681007385\n",
      "Batch: 593 , Combined Loss: tensor(0.8044, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.010596692562103271\n",
      "Batch: 594 , Combined Loss: tensor(0.8893, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4740651249885559\n",
      "Batch: 595 , Combined Loss: tensor(0.9363, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4648914337158203\n",
      "Batch: 596 , Combined Loss: tensor(0.8269, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.292331337928772\n",
      "Batch: 597 , Combined Loss: tensor(0.8176, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5246701240539551\n",
      "Batch: 598 , Combined Loss: tensor(0.8999, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.25749295949935913\n",
      "Batch: 599 , Combined Loss: tensor(0.8725, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.558150589466095\n",
      "Batch: 600 , Combined Loss: tensor(0.9410, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.36040085554122925\n",
      "Batch: 601 , Combined Loss: tensor(0.8013, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.01787489652633667\n",
      "Batch: 602 , Combined Loss: tensor(0.8192, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23713600635528564\n",
      "Batch: 603 , Combined Loss: tensor(0.7911, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7812459468841553\n",
      "Batch: 604 , Combined Loss: tensor(0.9001, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08087468147277832\n",
      "Batch: 605 , Combined Loss: tensor(0.8014, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.32816165685653687\n",
      "Batch: 606 , Combined Loss: tensor(0.7952, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12355053424835205\n",
      "Batch: 607 , Combined Loss: tensor(0.8809, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.49280065298080444\n",
      "Batch: 608 , Combined Loss: tensor(0.9418, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5504769086837769\n",
      "Batch: 609 , Combined Loss: tensor(0.8874, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09709584712982178\n",
      "Batch: 610 , Combined Loss: tensor(0.7962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41124963760375977\n",
      "Batch: 611 , Combined Loss: tensor(0.8257, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2981187105178833\n",
      "Batch: 612 , Combined Loss: tensor(0.8654, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20409250259399414\n",
      "Batch: 613 , Combined Loss: tensor(0.8397, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5614000558853149\n",
      "Batch: 614 , Combined Loss: tensor(0.9041, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41074299812316895\n",
      "Batch: 615 , Combined Loss: tensor(0.8295, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6071468591690063\n",
      "Batch: 616 , Combined Loss: tensor(0.8843, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1811293363571167\n",
      "Batch: 617 , Combined Loss: tensor(0.8279, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1820797324180603\n",
      "Batch: 618 , Combined Loss: tensor(0.9382, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05971944332122803\n",
      "Batch: 619 , Combined Loss: tensor(0.9535, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03569608926773071\n",
      "Batch: 620 , Combined Loss: tensor(0.8133, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4526975154876709\n",
      "Batch: 621 , Combined Loss: tensor(0.8219, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.34008580446243286\n",
      "Batch: 622 , Combined Loss: tensor(0.8571, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32444071769714355\n",
      "Batch: 623 , Combined Loss: tensor(0.8104, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.008867144584655762\n",
      "Batch: 624 , Combined Loss: tensor(0.8188, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15160566568374634\n",
      "Batch: 625 , Combined Loss: tensor(0.8562, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4095551371574402\n",
      "Batch: 626 , Combined Loss: tensor(0.8436, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11162835359573364\n",
      "Batch: 627 , Combined Loss: tensor(0.8756, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1089019775390625\n",
      "Batch: 628 , Combined Loss: tensor(0.8417, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2320946455001831\n",
      "----------Epoch 3, Loss: 0.8877330488734101, Accuracy: 0.8127533824720519, Dice Coef: [0.8964250368230483, 0.2676603025521975, 0.31252080346280037, 0.20523026805458694], Dice Coef Necrotic: 0.2334219404412069, Dice Coef Edema: 0.2604051209522759, Dice Coef Enhancing: 0.24445046046510197, Sensitivity: [0.8153451362740254, 0.5540732082543267, 0.7674528419710873, 0.8342115451361161], Specificity: [0.9699377672471379, 0.9866208857686417, 0.9013197880670641, 0.9226423027215966], Precision: [0.9982177226645769, 0.22090436756050172, 0.2142091156461014, 0.12540451630136826]\n",
      "Saving without nn.DataParallel\n",
      "Batch: 0 , Combined Loss: tensor(0.8381, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5765461921691895\n",
      "Batch: 1 , Combined Loss: tensor(0.9347, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.026889562606811523\n",
      "Batch: 2 , Combined Loss: tensor(0.9062, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.38688182830810547\n",
      "Batch: 3 , Combined Loss: tensor(0.9440, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7459137439727783\n",
      "Batch: 4 , Combined Loss: tensor(0.8017, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8169645071029663\n",
      "Batch: 5 , Combined Loss: tensor(0.9479, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.423725426197052\n",
      "Batch: 6 , Combined Loss: tensor(1.0802, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.634093165397644\n",
      "Batch: 7 , Combined Loss: tensor(0.9215, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03337377309799194\n",
      "Batch: 8 , Combined Loss: tensor(0.8436, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09881973266601562\n",
      "Batch: 9 , Combined Loss: tensor(0.9183, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8301167488098145\n",
      "Batch: 10 , Combined Loss: tensor(0.9437, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3472444415092468\n",
      "Batch: 11 , Combined Loss: tensor(0.8332, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5379035472869873\n",
      "Batch: 12 , Combined Loss: tensor(0.8531, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4408893585205078\n",
      "Batch: 13 , Combined Loss: tensor(0.9337, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32942497730255127\n",
      "Batch: 14 , Combined Loss: tensor(0.8839, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4088946580886841\n",
      "Batch: 15 , Combined Loss: tensor(1.1066, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8679432272911072\n",
      "Batch: 16 , Combined Loss: tensor(0.9117, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1461406946182251\n",
      "Batch: 17 , Combined Loss: tensor(0.8796, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12028801441192627\n",
      "Batch: 18 , Combined Loss: tensor(0.9019, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.622229814529419\n",
      "Batch: 19 , Combined Loss: tensor(0.8967, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3859730362892151\n",
      "Batch: 20 , Combined Loss: tensor(0.7932, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24524396657943726\n",
      "Batch: 21 , Combined Loss: tensor(0.8632, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.13556671142578125\n",
      "Batch: 22 , Combined Loss: tensor(0.8570, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7071910500526428\n",
      "Batch: 23 , Combined Loss: tensor(0.8885, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.45670193433761597\n",
      "Batch: 24 , Combined Loss: tensor(0.9427, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.38884878158569336\n",
      "Batch: 25 , Combined Loss: tensor(0.8547, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5393062829971313\n",
      "Batch: 26 , Combined Loss: tensor(0.9231, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.43525028228759766\n",
      "Batch: 27 , Combined Loss: tensor(0.8658, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.724380612373352\n",
      "Batch: 28 , Combined Loss: tensor(0.9039, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07764798402786255\n",
      "Batch: 29 , Combined Loss: tensor(0.8819, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3197828531265259\n",
      "Batch: 30 , Combined Loss: tensor(0.9161, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.01523447036743164\n",
      "Batch: 31 , Combined Loss: tensor(1.0482, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20645016431808472\n",
      "Batch: 32 , Combined Loss: tensor(0.9185, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3343890309333801\n",
      "Batch: 33 , Combined Loss: tensor(0.8291, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2599128484725952\n",
      "Batch: 34 , Combined Loss: tensor(0.8997, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37567901611328125\n",
      "Batch: 35 , Combined Loss: tensor(0.8774, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.25090140104293823\n",
      "Batch: 36 , Combined Loss: tensor(0.8422, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.42545872926712036\n",
      "Batch: 37 , Combined Loss: tensor(0.9143, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06840062141418457\n",
      "Batch: 38 , Combined Loss: tensor(0.8450, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.032672762870788574\n",
      "Batch: 39 , Combined Loss: tensor(0.7742, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2308502197265625\n",
      "Batch: 40 , Combined Loss: tensor(0.8064, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.044615745544433594\n",
      "Batch: 41 , Combined Loss: tensor(0.8477, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7914028167724609\n",
      "Batch: 42 , Combined Loss: tensor(0.9655, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8939871788024902\n",
      "Batch: 43 , Combined Loss: tensor(0.7846, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.706650972366333\n",
      "Batch: 44 , Combined Loss: tensor(0.8780, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5697888135910034\n",
      "Batch: 45 , Combined Loss: tensor(0.8436, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.016478896141052246\n",
      "Batch: 46 , Combined Loss: tensor(0.9340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.47548067569732666\n",
      "Batch: 47 , Combined Loss: tensor(0.8841, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19903141260147095\n",
      "Batch: 48 , Combined Loss: tensor(0.8842, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.32629621028900146\n",
      "Batch: 49 , Combined Loss: tensor(0.8637, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29564011096954346\n",
      "Batch: 50 , Combined Loss: tensor(0.8356, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03482872247695923\n",
      "Batch: 51 , Combined Loss: tensor(0.8325, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09618985652923584\n",
      "Batch: 52 , Combined Loss: tensor(0.7946, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34397614002227783\n",
      "Batch: 53 , Combined Loss: tensor(0.8212, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6835707426071167\n",
      "Batch: 54 , Combined Loss: tensor(1.0041, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05831336975097656\n",
      "Batch: 55 , Combined Loss: tensor(0.8506, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5787447690963745\n",
      "Batch: 56 , Combined Loss: tensor(0.9472, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0977938175201416\n",
      "Batch: 57 , Combined Loss: tensor(0.8054, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03194069862365723\n",
      "Batch: 58 , Combined Loss: tensor(0.9282, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1441224217414856\n",
      "Batch: 59 , Combined Loss: tensor(0.8267, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10804784297943115\n",
      "Batch: 60 , Combined Loss: tensor(0.8270, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03800511360168457\n",
      "Batch: 61 , Combined Loss: tensor(0.8543, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24232900142669678\n",
      "Batch: 62 , Combined Loss: tensor(0.8222, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05360180139541626\n",
      "Batch: 63 , Combined Loss: tensor(0.8389, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5336488485336304\n",
      "Batch: 64 , Combined Loss: tensor(0.8268, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2003476619720459\n",
      "Batch: 65 , Combined Loss: tensor(1.0073, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.45081621408462524\n",
      "Batch: 66 , Combined Loss: tensor(0.8040, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06010866165161133\n",
      "Batch: 67 , Combined Loss: tensor(0.9694, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3700414299964905\n",
      "Batch: 68 , Combined Loss: tensor(0.8097, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15318435430526733\n",
      "Batch: 69 , Combined Loss: tensor(0.8478, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21027779579162598\n",
      "Batch: 70 , Combined Loss: tensor(0.9744, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.793789267539978\n",
      "Batch: 71 , Combined Loss: tensor(0.8514, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6652379631996155\n",
      "Batch: 72 , Combined Loss: tensor(0.8634, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40556252002716064\n",
      "Batch: 73 , Combined Loss: tensor(0.8296, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5323858261108398\n",
      "Batch: 74 , Combined Loss: tensor(0.7979, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3186657428741455\n",
      "Batch: 75 , Combined Loss: tensor(0.8146, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.056962013244628906\n",
      "Batch: 76 , Combined Loss: tensor(0.9309, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2631346583366394\n",
      "Batch: 77 , Combined Loss: tensor(0.8789, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32379472255706787\n",
      "Batch: 78 , Combined Loss: tensor(0.8215, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17787015438079834\n",
      "Batch: 79 , Combined Loss: tensor(0.9055, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5214074850082397\n",
      "Batch: 80 , Combined Loss: tensor(0.8936, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.612851619720459\n",
      "Batch: 81 , Combined Loss: tensor(0.8649, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06506264209747314\n",
      "Batch: 82 , Combined Loss: tensor(0.8178, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19045686721801758\n",
      "Batch: 83 , Combined Loss: tensor(0.9591, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23364979028701782\n",
      "Batch: 84 , Combined Loss: tensor(0.8242, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08575278520584106\n",
      "Batch: 85 , Combined Loss: tensor(0.8000, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8720972537994385\n",
      "Batch: 86 , Combined Loss: tensor(0.7963, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37753140926361084\n",
      "Batch: 87 , Combined Loss: tensor(0.7911, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5457988977432251\n",
      "Batch: 88 , Combined Loss: tensor(0.8927, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6881784200668335\n",
      "Batch: 89 , Combined Loss: tensor(0.8318, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6417676210403442\n",
      "Batch: 90 , Combined Loss: tensor(0.8355, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.38876307010650635\n",
      "Batch: 91 , Combined Loss: tensor(0.9690, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6419055461883545\n",
      "Batch: 92 , Combined Loss: tensor(0.8975, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4651721119880676\n",
      "Batch: 93 , Combined Loss: tensor(0.8516, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.02938610315322876\n",
      "Batch: 94 , Combined Loss: tensor(0.7843, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5431480407714844\n",
      "Batch: 95 , Combined Loss: tensor(0.7605, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39407074451446533\n",
      "Batch: 96 , Combined Loss: tensor(0.7762, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7176809310913086\n",
      "Batch: 97 , Combined Loss: tensor(0.8301, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22498881816864014\n",
      "Batch: 98 , Combined Loss: tensor(0.8299, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5819370746612549\n",
      "Batch: 99 , Combined Loss: tensor(0.8619, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2621961832046509\n",
      "Batch: 100 , Combined Loss: tensor(0.8919, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1708042025566101\n",
      "Batch: 101 , Combined Loss: tensor(0.8201, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5135761499404907\n",
      "Batch: 102 , Combined Loss: tensor(0.9004, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7633498907089233\n",
      "Batch: 103 , Combined Loss: tensor(0.9077, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2666466236114502\n",
      "Batch: 104 , Combined Loss: tensor(0.8731, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07057428359985352\n",
      "Batch: 105 , Combined Loss: tensor(0.9628, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.40596163272857666\n",
      "Batch: 106 , Combined Loss: tensor(0.8728, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.46847838163375854\n",
      "Batch: 107 , Combined Loss: tensor(0.9489, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.00104522705078125\n",
      "Batch: 108 , Combined Loss: tensor(0.7692, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5004189014434814\n",
      "Batch: 109 , Combined Loss: tensor(0.8710, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11412262916564941\n",
      "Batch: 110 , Combined Loss: tensor(0.7749, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17287933826446533\n",
      "Batch: 111 , Combined Loss: tensor(0.8286, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.47878146171569824\n",
      "Batch: 112 , Combined Loss: tensor(0.8909, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09826517105102539\n",
      "Batch: 113 , Combined Loss: tensor(0.8169, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15416157245635986\n",
      "Batch: 114 , Combined Loss: tensor(0.9534, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6603251695632935\n",
      "Batch: 115 , Combined Loss: tensor(0.9367, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7251714468002319\n",
      "Batch: 116 , Combined Loss: tensor(0.7940, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5369833707809448\n",
      "Batch: 117 , Combined Loss: tensor(1.0374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26271963119506836\n",
      "Batch: 118 , Combined Loss: tensor(0.8125, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4580204486846924\n",
      "Batch: 119 , Combined Loss: tensor(1.0377, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04235464334487915\n",
      "Batch: 120 , Combined Loss: tensor(0.8079, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14955508708953857\n",
      "Batch: 121 , Combined Loss: tensor(0.8958, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.056021809577941895\n",
      "Batch: 122 , Combined Loss: tensor(0.8085, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06829500198364258\n",
      "Batch: 123 , Combined Loss: tensor(0.9407, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1599975824356079\n",
      "Batch: 124 , Combined Loss: tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08994543552398682\n",
      "Batch: 125 , Combined Loss: tensor(0.8834, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.009816169738769531\n",
      "Batch: 126 , Combined Loss: tensor(0.8420, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.040128231048583984\n",
      "Batch: 127 , Combined Loss: tensor(0.8584, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4445589780807495\n",
      "Batch: 128 , Combined Loss: tensor(0.8690, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17381370067596436\n",
      "Batch: 129 , Combined Loss: tensor(0.8939, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5505318641662598\n",
      "Batch: 130 , Combined Loss: tensor(0.9493, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2805866003036499\n",
      "Batch: 131 , Combined Loss: tensor(0.8829, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04852283000946045\n",
      "Batch: 132 , Combined Loss: tensor(0.9118, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7891042232513428\n",
      "Batch: 133 , Combined Loss: tensor(0.9598, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5508310794830322\n",
      "Batch: 134 , Combined Loss: tensor(0.8576, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4574950933456421\n",
      "Batch: 135 , Combined Loss: tensor(0.7618, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20172762870788574\n",
      "Batch: 136 , Combined Loss: tensor(1.1184, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.02939450740814209\n",
      "Batch: 137 , Combined Loss: tensor(0.7408, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23264682292938232\n",
      "Batch: 138 , Combined Loss: tensor(0.8162, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7030584812164307\n",
      "Batch: 139 , Combined Loss: tensor(0.8126, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.35190069675445557\n",
      "Batch: 140 , Combined Loss: tensor(0.8313, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2826712131500244\n",
      "Batch: 141 , Combined Loss: tensor(0.7819, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07994508743286133\n",
      "Batch: 142 , Combined Loss: tensor(0.8250, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1078568696975708\n",
      "Batch: 143 , Combined Loss: tensor(0.9938, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03771042823791504\n",
      "Batch: 144 , Combined Loss: tensor(0.8696, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07636851072311401\n",
      "Batch: 145 , Combined Loss: tensor(0.7965, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4331422448158264\n",
      "Batch: 146 , Combined Loss: tensor(0.8303, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6239509582519531\n",
      "Batch: 147 , Combined Loss: tensor(0.8710, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6951038837432861\n",
      "Batch: 148 , Combined Loss: tensor(0.8186, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46893489360809326\n",
      "Batch: 149 , Combined Loss: tensor(0.9685, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4113502502441406\n",
      "Batch: 150 , Combined Loss: tensor(0.9106, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5680863857269287\n",
      "Batch: 151 , Combined Loss: tensor(0.9033, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15661752223968506\n",
      "Batch: 152 , Combined Loss: tensor(0.8503, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40486466884613037\n",
      "Batch: 153 , Combined Loss: tensor(0.7280, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11412453651428223\n",
      "Batch: 154 , Combined Loss: tensor(0.9383, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7856470942497253\n",
      "Batch: 155 , Combined Loss: tensor(0.8631, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6292647123336792\n",
      "Batch: 156 , Combined Loss: tensor(0.8024, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1340566873550415\n",
      "Batch: 157 , Combined Loss: tensor(0.8244, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48525238037109375\n",
      "Batch: 158 , Combined Loss: tensor(0.8127, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3893073797225952\n",
      "Batch: 159 , Combined Loss: tensor(0.7863, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.029827237129211426\n",
      "Batch: 160 , Combined Loss: tensor(0.8001, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39254438877105713\n",
      "Batch: 161 , Combined Loss: tensor(0.8342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08284962177276611\n",
      "Batch: 162 , Combined Loss: tensor(0.9383, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.009025037288665771\n",
      "Batch: 163 , Combined Loss: tensor(0.8284, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14809751510620117\n",
      "Batch: 164 , Combined Loss: tensor(0.8814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6427544355392456\n",
      "Batch: 165 , Combined Loss: tensor(0.9898, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.26845961809158325\n",
      "Batch: 166 , Combined Loss: tensor(0.9963, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7738646268844604\n",
      "Batch: 167 , Combined Loss: tensor(0.9240, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.054417967796325684\n",
      "Batch: 168 , Combined Loss: tensor(0.9001, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.028755903244018555\n",
      "Batch: 169 , Combined Loss: tensor(0.8521, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13106584548950195\n",
      "Batch: 170 , Combined Loss: tensor(0.8258, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3902527093887329\n",
      "Batch: 171 , Combined Loss: tensor(0.8413, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5015416145324707\n",
      "Batch: 172 , Combined Loss: tensor(0.8907, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4584037661552429\n",
      "Batch: 173 , Combined Loss: tensor(0.9465, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45232176780700684\n",
      "Batch: 174 , Combined Loss: tensor(0.7981, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24891698360443115\n",
      "Batch: 175 , Combined Loss: tensor(0.8503, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03456377983093262\n",
      "Batch: 176 , Combined Loss: tensor(0.9893, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.38976365327835083\n",
      "Batch: 177 , Combined Loss: tensor(0.9071, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11276477575302124\n",
      "Batch: 178 , Combined Loss: tensor(0.9375, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.021805286407470703\n",
      "Batch: 179 , Combined Loss: tensor(0.8952, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23560643196105957\n",
      "Batch: 180 , Combined Loss: tensor(0.8387, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.31156933307647705\n",
      "Batch: 181 , Combined Loss: tensor(0.8428, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.020145833492279053\n",
      "Batch: 182 , Combined Loss: tensor(0.7593, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11433559656143188\n",
      "Batch: 183 , Combined Loss: tensor(0.9180, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5012702941894531\n",
      "Batch: 184 , Combined Loss: tensor(0.9141, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6777200698852539\n",
      "Batch: 185 , Combined Loss: tensor(0.8296, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19780182838439941\n",
      "Batch: 186 , Combined Loss: tensor(0.9968, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24976909160614014\n",
      "Batch: 187 , Combined Loss: tensor(0.8328, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2417449951171875\n",
      "Batch: 188 , Combined Loss: tensor(0.8345, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3519434928894043\n",
      "Batch: 189 , Combined Loss: tensor(0.9453, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.44815564155578613\n",
      "Batch: 190 , Combined Loss: tensor(0.8047, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15885871648788452\n",
      "Batch: 191 , Combined Loss: tensor(0.8665, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6970281600952148\n",
      "Batch: 192 , Combined Loss: tensor(0.7889, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3081434965133667\n",
      "Batch: 193 , Combined Loss: tensor(0.8185, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3172324299812317\n",
      "Batch: 194 , Combined Loss: tensor(0.7882, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5284838080406189\n",
      "Batch: 195 , Combined Loss: tensor(0.8322, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2819332480430603\n",
      "Batch: 196 , Combined Loss: tensor(0.8053, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.639358401298523\n",
      "Batch: 197 , Combined Loss: tensor(0.8276, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.566792368888855\n",
      "Batch: 198 , Combined Loss: tensor(0.9337, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8120702505111694\n",
      "Batch: 199 , Combined Loss: tensor(0.7921, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05310302972793579\n",
      "Batch: 200 , Combined Loss: tensor(0.9455, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.76920086145401\n",
      "Batch: 201 , Combined Loss: tensor(0.8441, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3752967119216919\n",
      "Batch: 202 , Combined Loss: tensor(0.8377, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15907776355743408\n",
      "Batch: 203 , Combined Loss: tensor(0.8245, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08891594409942627\n",
      "Batch: 204 , Combined Loss: tensor(0.8416, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5214444398880005\n",
      "Batch: 205 , Combined Loss: tensor(0.7930, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3871799111366272\n",
      "Batch: 206 , Combined Loss: tensor(1.0274, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21105968952178955\n",
      "Batch: 207 , Combined Loss: tensor(0.9495, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8021131157875061\n",
      "Batch: 208 , Combined Loss: tensor(0.8312, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5253891944885254\n",
      "Batch: 209 , Combined Loss: tensor(1.0167, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7217560410499573\n",
      "Batch: 210 , Combined Loss: tensor(0.7732, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2505866289138794\n",
      "Batch: 211 , Combined Loss: tensor(0.8219, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20267295837402344\n",
      "Batch: 212 , Combined Loss: tensor(0.9115, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5807965397834778\n",
      "Batch: 213 , Combined Loss: tensor(0.8675, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.004999399185180664\n",
      "Batch: 214 , Combined Loss: tensor(0.8451, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4428645372390747\n",
      "Batch: 215 , Combined Loss: tensor(0.9319, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.010175585746765137\n",
      "Batch: 216 , Combined Loss: tensor(0.8981, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39265966415405273\n",
      "Batch: 217 , Combined Loss: tensor(0.8816, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.40352094173431396\n",
      "Batch: 218 , Combined Loss: tensor(0.8376, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11594521999359131\n",
      "Batch: 219 , Combined Loss: tensor(0.8593, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.49845534563064575\n",
      "Batch: 220 , Combined Loss: tensor(0.8142, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6979082226753235\n",
      "Batch: 221 , Combined Loss: tensor(0.9193, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3291449546813965\n",
      "Batch: 222 , Combined Loss: tensor(0.8000, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12376159429550171\n",
      "Batch: 223 , Combined Loss: tensor(0.8523, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0040171146392822266\n",
      "Batch: 224 , Combined Loss: tensor(0.8677, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6642897725105286\n",
      "Batch: 225 , Combined Loss: tensor(0.8618, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5797944664955139\n",
      "Batch: 226 , Combined Loss: tensor(0.8856, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12239372730255127\n",
      "Batch: 227 , Combined Loss: tensor(0.8530, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.027820467948913574\n",
      "Batch: 228 , Combined Loss: tensor(0.9474, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3734254837036133\n",
      "Batch: 229 , Combined Loss: tensor(0.8530, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7915151715278625\n",
      "Batch: 230 , Combined Loss: tensor(0.8976, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31378400325775146\n",
      "Batch: 231 , Combined Loss: tensor(0.7838, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6480941772460938\n",
      "Batch: 232 , Combined Loss: tensor(0.8320, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43371593952178955\n",
      "Batch: 233 , Combined Loss: tensor(0.9048, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07518035173416138\n",
      "Batch: 234 , Combined Loss: tensor(0.9136, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.01888430118560791\n",
      "Batch: 235 , Combined Loss: tensor(1.0564, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4841269850730896\n",
      "Batch: 236 , Combined Loss: tensor(0.9525, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.050827860832214355\n",
      "Batch: 237 , Combined Loss: tensor(0.9123, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4218651056289673\n",
      "Batch: 238 , Combined Loss: tensor(1.0200, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.41091495752334595\n",
      "Batch: 239 , Combined Loss: tensor(0.8405, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6733208894729614\n",
      "Batch: 240 , Combined Loss: tensor(0.8016, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1641939878463745\n",
      "Batch: 241 , Combined Loss: tensor(0.9580, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3030813932418823\n",
      "Batch: 242 , Combined Loss: tensor(0.9001, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6279655694961548\n",
      "Batch: 243 , Combined Loss: tensor(0.7695, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09023582935333252\n",
      "Batch: 244 , Combined Loss: tensor(0.9140, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4448104500770569\n",
      "Batch: 245 , Combined Loss: tensor(0.8607, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.262784481048584\n",
      "Batch: 246 , Combined Loss: tensor(1.2521, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1358637809753418\n",
      "Batch: 247 , Combined Loss: tensor(0.8563, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3169567584991455\n",
      "Batch: 248 , Combined Loss: tensor(0.8699, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8196854591369629\n",
      "Batch: 249 , Combined Loss: tensor(1.0407, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4022495746612549\n",
      "Batch: 250 , Combined Loss: tensor(0.8535, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21053415536880493\n",
      "Batch: 251 , Combined Loss: tensor(0.8335, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7792357802391052\n",
      "Batch: 252 , Combined Loss: tensor(1.0148, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6958387494087219\n",
      "Batch: 253 , Combined Loss: tensor(0.8337, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13334619998931885\n",
      "Batch: 254 , Combined Loss: tensor(1.2746, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2718154788017273\n",
      "Batch: 255 , Combined Loss: tensor(0.8034, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12059175968170166\n",
      "Batch: 256 , Combined Loss: tensor(0.8037, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.29463720321655273\n",
      "Batch: 257 , Combined Loss: tensor(0.7569, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.014806747436523438\n",
      "Batch: 258 , Combined Loss: tensor(0.8368, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7260844707489014\n",
      "Batch: 259 , Combined Loss: tensor(0.8778, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2450297474861145\n",
      "Batch: 260 , Combined Loss: tensor(0.8978, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.057572364807128906\n",
      "Batch: 261 , Combined Loss: tensor(0.9041, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.049368858337402344\n",
      "Batch: 262 , Combined Loss: tensor(0.7814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.010533630847930908\n",
      "Batch: 263 , Combined Loss: tensor(0.8332, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04705911874771118\n",
      "Batch: 264 , Combined Loss: tensor(0.9294, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8592035174369812\n",
      "Batch: 265 , Combined Loss: tensor(0.8127, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8705835938453674\n",
      "Batch: 266 , Combined Loss: tensor(0.8312, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.003256678581237793\n",
      "Batch: 267 , Combined Loss: tensor(0.8843, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07754349708557129\n",
      "Batch: 268 , Combined Loss: tensor(0.8230, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4867086410522461\n",
      "Batch: 269 , Combined Loss: tensor(0.8492, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39886343479156494\n",
      "Batch: 270 , Combined Loss: tensor(0.9532, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7125327587127686\n",
      "Batch: 271 , Combined Loss: tensor(0.8659, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07479465007781982\n",
      "Batch: 272 , Combined Loss: tensor(0.9203, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4692246913909912\n",
      "Batch: 273 , Combined Loss: tensor(0.7825, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5048185586929321\n",
      "Batch: 274 , Combined Loss: tensor(0.7963, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7194024324417114\n",
      "Batch: 275 , Combined Loss: tensor(1.0676, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08659982681274414\n",
      "Batch: 276 , Combined Loss: tensor(0.8333, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20089375972747803\n",
      "Batch: 277 , Combined Loss: tensor(0.8142, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.533143937587738\n",
      "Batch: 278 , Combined Loss: tensor(0.8071, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2833278179168701\n",
      "Batch: 279 , Combined Loss: tensor(0.8941, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24342679977416992\n",
      "Batch: 280 , Combined Loss: tensor(1.0770, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15917718410491943\n",
      "Batch: 281 , Combined Loss: tensor(0.8765, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5685262680053711\n",
      "Batch: 282 , Combined Loss: tensor(0.8838, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7300211787223816\n",
      "Batch: 283 , Combined Loss: tensor(0.8123, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7140315771102905\n",
      "Batch: 284 , Combined Loss: tensor(0.9122, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.16362160444259644\n",
      "Batch: 285 , Combined Loss: tensor(0.8305, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3504561185836792\n",
      "Batch: 286 , Combined Loss: tensor(0.8179, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12018537521362305\n",
      "Batch: 287 , Combined Loss: tensor(0.7936, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5819869041442871\n",
      "Batch: 288 , Combined Loss: tensor(0.9142, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7430778741836548\n",
      "Batch: 289 , Combined Loss: tensor(0.8105, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6361614465713501\n",
      "Batch: 290 , Combined Loss: tensor(0.8411, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6653529405593872\n",
      "Batch: 291 , Combined Loss: tensor(0.8606, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1888042688369751\n",
      "Batch: 292 , Combined Loss: tensor(0.8915, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.13526582717895508\n",
      "Batch: 293 , Combined Loss: tensor(0.8907, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6523250341415405\n",
      "Batch: 294 , Combined Loss: tensor(0.8287, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.25821453332901\n",
      "Batch: 295 , Combined Loss: tensor(0.9713, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5206253528594971\n",
      "Batch: 296 , Combined Loss: tensor(0.8282, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4187473654747009\n",
      "Batch: 297 , Combined Loss: tensor(1.0324, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5265986919403076\n",
      "Batch: 298 , Combined Loss: tensor(0.8622, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04195380210876465\n",
      "Batch: 299 , Combined Loss: tensor(0.9213, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3934721350669861\n",
      "Batch: 300 , Combined Loss: tensor(0.8497, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6827542781829834\n",
      "Batch: 301 , Combined Loss: tensor(0.8522, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7317918539047241\n",
      "Batch: 302 , Combined Loss: tensor(0.8998, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1304810643196106\n",
      "Batch: 303 , Combined Loss: tensor(0.9080, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6043123006820679\n",
      "Batch: 304 , Combined Loss: tensor(0.8694, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22745037078857422\n",
      "Batch: 305 , Combined Loss: tensor(0.8223, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16557753086090088\n",
      "Batch: 306 , Combined Loss: tensor(0.9071, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5245095491409302\n",
      "Batch: 307 , Combined Loss: tensor(0.9102, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4266676902770996\n",
      "Batch: 308 , Combined Loss: tensor(0.8002, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.18775051832199097\n",
      "Batch: 309 , Combined Loss: tensor(0.8604, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1818433403968811\n",
      "Batch: 310 , Combined Loss: tensor(0.9273, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03326749801635742\n",
      "Batch: 311 , Combined Loss: tensor(0.8707, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7963764667510986\n",
      "Batch: 312 , Combined Loss: tensor(0.8356, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4464324712753296\n",
      "Batch: 313 , Combined Loss: tensor(0.8146, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.024885118007659912\n",
      "Batch: 314 , Combined Loss: tensor(0.9183, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1667490005493164\n",
      "Batch: 315 , Combined Loss: tensor(0.8720, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5824105739593506\n",
      "Batch: 316 , Combined Loss: tensor(0.7751, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4354015588760376\n",
      "Batch: 317 , Combined Loss: tensor(0.8758, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14124631881713867\n",
      "Batch: 318 , Combined Loss: tensor(0.8257, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.31343144178390503\n",
      "Batch: 319 , Combined Loss: tensor(0.8654, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29399001598358154\n",
      "Batch: 320 , Combined Loss: tensor(0.8219, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.008251667022705078\n",
      "Batch: 321 , Combined Loss: tensor(0.7855, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4212093949317932\n",
      "Batch: 322 , Combined Loss: tensor(0.9556, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24770039319992065\n",
      "Batch: 323 , Combined Loss: tensor(0.8406, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.13577884435653687\n",
      "Batch: 324 , Combined Loss: tensor(0.8350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22086727619171143\n",
      "Batch: 325 , Combined Loss: tensor(0.8115, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.273543119430542\n",
      "Batch: 326 , Combined Loss: tensor(0.8121, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6711419820785522\n",
      "Batch: 327 , Combined Loss: tensor(0.8867, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.599571704864502\n",
      "Batch: 328 , Combined Loss: tensor(0.9083, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.42840927839279175\n",
      "Batch: 329 , Combined Loss: tensor(0.9442, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.41496074199676514\n",
      "Batch: 330 , Combined Loss: tensor(0.8462, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6619853973388672\n",
      "Batch: 331 , Combined Loss: tensor(0.8810, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.18567204475402832\n",
      "Batch: 332 , Combined Loss: tensor(0.7902, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0014071464538574219\n",
      "Batch: 333 , Combined Loss: tensor(0.7807, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5266141295433044\n",
      "Batch: 334 , Combined Loss: tensor(0.8626, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4898383617401123\n",
      "Batch: 335 , Combined Loss: tensor(0.8427, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08654165267944336\n",
      "Batch: 336 , Combined Loss: tensor(0.9551, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2862768769264221\n",
      "Batch: 337 , Combined Loss: tensor(0.8865, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2905339002609253\n",
      "Batch: 338 , Combined Loss: tensor(0.8806, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1448802947998047\n",
      "Batch: 339 , Combined Loss: tensor(0.8555, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.061249613761901855\n",
      "Batch: 340 , Combined Loss: tensor(0.7991, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5391547679901123\n",
      "Batch: 341 , Combined Loss: tensor(0.8964, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.18857204914093018\n",
      "Batch: 342 , Combined Loss: tensor(0.8360, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22270327806472778\n",
      "Batch: 343 , Combined Loss: tensor(0.7996, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6790085434913635\n",
      "Batch: 344 , Combined Loss: tensor(0.8160, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48613250255584717\n",
      "Batch: 345 , Combined Loss: tensor(0.8182, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3804934620857239\n",
      "Batch: 346 , Combined Loss: tensor(0.7523, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5257810354232788\n",
      "Batch: 347 , Combined Loss: tensor(0.7720, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04353207349777222\n",
      "Batch: 348 , Combined Loss: tensor(0.8288, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.25180357694625854\n",
      "Batch: 349 , Combined Loss: tensor(0.8385, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.16409844160079956\n",
      "Batch: 350 , Combined Loss: tensor(0.8216, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.27049994468688965\n",
      "Batch: 351 , Combined Loss: tensor(0.8393, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18818128108978271\n",
      "Batch: 352 , Combined Loss: tensor(0.9448, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6369540691375732\n",
      "Batch: 353 , Combined Loss: tensor(0.8111, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09069395065307617\n",
      "Batch: 354 , Combined Loss: tensor(0.8254, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36947906017303467\n",
      "Batch: 355 , Combined Loss: tensor(0.9536, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5987428426742554\n",
      "Batch: 356 , Combined Loss: tensor(0.8343, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4605419635772705\n",
      "Batch: 357 , Combined Loss: tensor(0.8239, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6981226205825806\n",
      "Batch: 358 , Combined Loss: tensor(0.8710, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1077885627746582\n",
      "Batch: 359 , Combined Loss: tensor(0.8509, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.28735119104385376\n",
      "Batch: 360 , Combined Loss: tensor(0.8461, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3072492480278015\n",
      "Batch: 361 , Combined Loss: tensor(0.8956, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.350185751914978\n",
      "Batch: 362 , Combined Loss: tensor(0.7750, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2872964143753052\n",
      "Batch: 363 , Combined Loss: tensor(0.8749, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5049120783805847\n",
      "Batch: 364 , Combined Loss: tensor(0.7911, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7558883428573608\n",
      "Batch: 365 , Combined Loss: tensor(0.8054, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3459911346435547\n",
      "Batch: 366 , Combined Loss: tensor(0.8689, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2943546772003174\n",
      "Batch: 367 , Combined Loss: tensor(0.9078, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6311715841293335\n",
      "Batch: 368 , Combined Loss: tensor(0.7976, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1619473695755005\n",
      "Batch: 369 , Combined Loss: tensor(0.8728, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21035051345825195\n",
      "Batch: 370 , Combined Loss: tensor(0.7730, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6217392683029175\n",
      "Batch: 371 , Combined Loss: tensor(0.8274, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.37591010332107544\n",
      "Batch: 372 , Combined Loss: tensor(0.8605, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34755396842956543\n",
      "Batch: 373 , Combined Loss: tensor(0.8749, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3060761094093323\n",
      "Batch: 374 , Combined Loss: tensor(0.7882, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2703099250793457\n",
      "Batch: 375 , Combined Loss: tensor(0.8798, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.35393404960632324\n",
      "Batch: 376 , Combined Loss: tensor(0.8212, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3152236342430115\n",
      "Batch: 377 , Combined Loss: tensor(0.7962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20350933074951172\n",
      "Batch: 378 , Combined Loss: tensor(0.8325, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05406534671783447\n",
      "Batch: 379 , Combined Loss: tensor(0.8070, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14263063669204712\n",
      "Batch: 380 , Combined Loss: tensor(0.7363, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.48651665449142456\n",
      "Batch: 381 , Combined Loss: tensor(0.7726, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20397412776947021\n",
      "Batch: 382 , Combined Loss: tensor(0.8335, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30064690113067627\n",
      "Batch: 383 , Combined Loss: tensor(0.9982, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5271792411804199\n",
      "Batch: 384 , Combined Loss: tensor(0.8290, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6256322860717773\n",
      "Batch: 385 , Combined Loss: tensor(0.9191, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6142187118530273\n",
      "Batch: 386 , Combined Loss: tensor(0.7862, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.037122249603271484\n",
      "Batch: 387 , Combined Loss: tensor(0.8964, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19203484058380127\n",
      "Batch: 388 , Combined Loss: tensor(0.8286, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5350438356399536\n",
      "Batch: 389 , Combined Loss: tensor(0.7591, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03556656837463379\n",
      "Batch: 390 , Combined Loss: tensor(0.8629, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06670784950256348\n",
      "Batch: 391 , Combined Loss: tensor(0.8478, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2820136547088623\n",
      "Batch: 392 , Combined Loss: tensor(0.9989, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8031148910522461\n",
      "Batch: 393 , Combined Loss: tensor(1.0212, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1426263451576233\n",
      "Batch: 394 , Combined Loss: tensor(0.8294, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1609973907470703\n",
      "Batch: 395 , Combined Loss: tensor(0.8450, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5789667367935181\n",
      "Batch: 396 , Combined Loss: tensor(0.7769, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6304640769958496\n",
      "Batch: 397 , Combined Loss: tensor(1.1908, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2515770196914673\n",
      "Batch: 398 , Combined Loss: tensor(0.7968, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4871126413345337\n",
      "Batch: 399 , Combined Loss: tensor(0.8043, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.26450055837631226\n",
      "Batch: 400 , Combined Loss: tensor(1.0271, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24296963214874268\n",
      "Batch: 401 , Combined Loss: tensor(0.7660, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.680057942867279\n",
      "Batch: 402 , Combined Loss: tensor(0.8321, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5689469575881958\n",
      "Batch: 403 , Combined Loss: tensor(0.9915, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2527022361755371\n",
      "Batch: 404 , Combined Loss: tensor(0.8941, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2970333695411682\n",
      "Batch: 405 , Combined Loss: tensor(0.8226, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.25576382875442505\n",
      "Batch: 406 , Combined Loss: tensor(0.8580, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8052514791488647\n",
      "Batch: 407 , Combined Loss: tensor(0.9880, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.49518269300460815\n",
      "Batch: 408 , Combined Loss: tensor(0.8794, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09461891651153564\n",
      "Batch: 409 , Combined Loss: tensor(0.7568, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09518897533416748\n",
      "Batch: 410 , Combined Loss: tensor(0.7593, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5890160799026489\n",
      "Batch: 411 , Combined Loss: tensor(0.8459, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6190994381904602\n",
      "Batch: 412 , Combined Loss: tensor(0.7391, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2799435257911682\n",
      "Batch: 413 , Combined Loss: tensor(0.9790, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3555009365081787\n",
      "Batch: 414 , Combined Loss: tensor(0.8305, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2393437623977661\n",
      "Batch: 415 , Combined Loss: tensor(0.8093, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4425632357597351\n",
      "Batch: 416 , Combined Loss: tensor(0.7744, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3691849708557129\n",
      "Batch: 417 , Combined Loss: tensor(0.9049, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04055225849151611\n",
      "Batch: 418 , Combined Loss: tensor(0.7440, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4505493640899658\n",
      "Batch: 419 , Combined Loss: tensor(0.8871, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6068432927131653\n",
      "Batch: 420 , Combined Loss: tensor(0.7566, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08592456579208374\n",
      "Batch: 421 , Combined Loss: tensor(1.0618, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.053503334522247314\n",
      "Batch: 422 , Combined Loss: tensor(0.9097, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2071455717086792\n",
      "Batch: 423 , Combined Loss: tensor(0.8148, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2483842372894287\n",
      "Batch: 424 , Combined Loss: tensor(0.7863, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3609147071838379\n",
      "Batch: 425 , Combined Loss: tensor(0.7603, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.25741928815841675\n",
      "Batch: 426 , Combined Loss: tensor(0.9427, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24721717834472656\n",
      "Batch: 427 , Combined Loss: tensor(1.0330, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31326794624328613\n",
      "Batch: 428 , Combined Loss: tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20778405666351318\n",
      "Batch: 429 , Combined Loss: tensor(0.7979, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2844109535217285\n",
      "Batch: 430 , Combined Loss: tensor(0.9077, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4191242456436157\n",
      "Batch: 431 , Combined Loss: tensor(0.8395, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4764147996902466\n",
      "Batch: 432 , Combined Loss: tensor(0.6953, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.34323590993881226\n",
      "Batch: 433 , Combined Loss: tensor(0.8020, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26173996925354004\n",
      "Batch: 434 , Combined Loss: tensor(0.9682, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5947650671005249\n",
      "Batch: 435 , Combined Loss: tensor(0.7904, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5173760056495667\n",
      "Batch: 436 , Combined Loss: tensor(0.7667, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2901715040206909\n",
      "Batch: 437 , Combined Loss: tensor(0.8417, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.48585760593414307\n",
      "Batch: 438 , Combined Loss: tensor(0.8062, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.29379963874816895\n",
      "Batch: 439 , Combined Loss: tensor(0.8210, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19108426570892334\n",
      "Batch: 440 , Combined Loss: tensor(0.8254, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42719531059265137\n",
      "Batch: 441 , Combined Loss: tensor(1.0049, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11615943908691406\n",
      "Batch: 442 , Combined Loss: tensor(1.0205, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6048510074615479\n",
      "Batch: 443 , Combined Loss: tensor(0.7937, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1823430061340332\n",
      "Batch: 444 , Combined Loss: tensor(0.7293, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27446281909942627\n",
      "Batch: 445 , Combined Loss: tensor(0.8187, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04669630527496338\n",
      "Batch: 446 , Combined Loss: tensor(0.9639, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6380035877227783\n",
      "Batch: 447 , Combined Loss: tensor(0.7665, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3076983690261841\n",
      "Batch: 448 , Combined Loss: tensor(0.9003, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43070244789123535\n",
      "Batch: 449 , Combined Loss: tensor(0.9041, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.29964834451675415\n",
      "Batch: 450 , Combined Loss: tensor(0.9153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2615586519241333\n",
      "Batch: 451 , Combined Loss: tensor(0.8962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20403051376342773\n",
      "Batch: 452 , Combined Loss: tensor(0.9444, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.038994431495666504\n",
      "Batch: 453 , Combined Loss: tensor(0.8100, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.496482789516449\n",
      "Batch: 454 , Combined Loss: tensor(0.6596, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20672309398651123\n",
      "Batch: 455 , Combined Loss: tensor(0.7828, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6016358733177185\n",
      "Batch: 456 , Combined Loss: tensor(0.8606, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.537893533706665\n",
      "Batch: 457 , Combined Loss: tensor(1.0161, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9170306921005249\n",
      "Batch: 458 , Combined Loss: tensor(1.4284, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1844770908355713\n",
      "Batch: 459 , Combined Loss: tensor(0.8556, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7218760251998901\n",
      "Batch: 460 , Combined Loss: tensor(0.8977, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2632577419281006\n",
      "Batch: 461 , Combined Loss: tensor(0.9560, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12268942594528198\n",
      "Batch: 462 , Combined Loss: tensor(0.8735, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.053040146827697754\n",
      "Batch: 463 , Combined Loss: tensor(1.0593, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26665210723876953\n",
      "Batch: 464 , Combined Loss: tensor(0.8096, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2721233367919922\n",
      "Batch: 465 , Combined Loss: tensor(0.7636, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2185874581336975\n",
      "Batch: 466 , Combined Loss: tensor(0.8829, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48765087127685547\n",
      "Batch: 467 , Combined Loss: tensor(1.0484, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19996869564056396\n",
      "Batch: 468 , Combined Loss: tensor(0.7500, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.45137321949005127\n",
      "Batch: 469 , Combined Loss: tensor(0.7748, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4877220392227173\n",
      "Batch: 470 , Combined Loss: tensor(0.9721, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1322319507598877\n",
      "Batch: 471 , Combined Loss: tensor(0.7714, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33272814750671387\n",
      "Batch: 472 , Combined Loss: tensor(0.9753, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15955644845962524\n",
      "Batch: 473 , Combined Loss: tensor(0.7220, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20767372846603394\n",
      "Batch: 474 , Combined Loss: tensor(0.8614, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.40776658058166504\n",
      "Batch: 475 , Combined Loss: tensor(0.8496, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.13555514812469482\n",
      "Batch: 476 , Combined Loss: tensor(0.7660, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17312073707580566\n",
      "Batch: 477 , Combined Loss: tensor(0.8843, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4579862952232361\n",
      "Batch: 478 , Combined Loss: tensor(1.0549, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15239614248275757\n",
      "Batch: 479 , Combined Loss: tensor(0.8507, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04828536510467529\n",
      "Batch: 480 , Combined Loss: tensor(0.8350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2165459394454956\n",
      "Batch: 481 , Combined Loss: tensor(1.1372, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3862147927284241\n",
      "Batch: 482 , Combined Loss: tensor(0.8827, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26430022716522217\n",
      "Batch: 483 , Combined Loss: tensor(0.8094, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5791651010513306\n",
      "Batch: 484 , Combined Loss: tensor(0.7607, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5184401273727417\n",
      "Batch: 485 , Combined Loss: tensor(1.0649, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5762157440185547\n",
      "Batch: 486 , Combined Loss: tensor(0.9566, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9534481763839722\n",
      "Batch: 487 , Combined Loss: tensor(0.7819, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4536764621734619\n",
      "Batch: 488 , Combined Loss: tensor(0.7803, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6553757190704346\n",
      "Batch: 489 , Combined Loss: tensor(1.0233, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3140184283256531\n",
      "Batch: 490 , Combined Loss: tensor(0.8302, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6042786836624146\n",
      "Batch: 491 , Combined Loss: tensor(0.6737, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1533597707748413\n",
      "Batch: 492 , Combined Loss: tensor(0.7763, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7272729277610779\n",
      "Batch: 493 , Combined Loss: tensor(0.7673, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.633237361907959\n",
      "Batch: 494 , Combined Loss: tensor(0.9060, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03258579969406128\n",
      "Batch: 495 , Combined Loss: tensor(0.9518, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3862471580505371\n",
      "Batch: 496 , Combined Loss: tensor(0.9884, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.36194026470184326\n",
      "Batch: 497 , Combined Loss: tensor(0.8115, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5958923101425171\n",
      "Batch: 498 , Combined Loss: tensor(0.9703, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.022956371307373047\n",
      "Batch: 499 , Combined Loss: tensor(0.8449, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12633001804351807\n",
      "Batch: 500 , Combined Loss: tensor(0.8729, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.44068241119384766\n",
      "Batch: 501 , Combined Loss: tensor(0.9520, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1821049451828003\n",
      "Batch: 502 , Combined Loss: tensor(0.7566, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.539387583732605\n",
      "Batch: 503 , Combined Loss: tensor(0.8935, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2831113338470459\n",
      "Batch: 504 , Combined Loss: tensor(0.8430, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5941324234008789\n",
      "Batch: 505 , Combined Loss: tensor(0.7392, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23445618152618408\n",
      "Batch: 506 , Combined Loss: tensor(0.7983, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.27214884757995605\n",
      "Batch: 507 , Combined Loss: tensor(0.8204, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12650275230407715\n",
      "Batch: 508 , Combined Loss: tensor(1.0886, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4163576364517212\n",
      "Batch: 509 , Combined Loss: tensor(0.9001, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6266211271286011\n",
      "Batch: 510 , Combined Loss: tensor(0.7971, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.761015772819519\n",
      "Batch: 511 , Combined Loss: tensor(0.7729, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6790319681167603\n",
      "Batch: 512 , Combined Loss: tensor(0.9409, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3054620027542114\n",
      "Batch: 513 , Combined Loss: tensor(0.7958, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6805503368377686\n",
      "Batch: 514 , Combined Loss: tensor(0.8071, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8143079280853271\n",
      "Batch: 515 , Combined Loss: tensor(0.9516, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5349001884460449\n",
      "Batch: 516 , Combined Loss: tensor(0.8808, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32294273376464844\n",
      "Batch: 517 , Combined Loss: tensor(0.8898, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17582201957702637\n",
      "Batch: 518 , Combined Loss: tensor(0.7337, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.13935935497283936\n",
      "Batch: 519 , Combined Loss: tensor(0.8906, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.45292943716049194\n",
      "Batch: 520 , Combined Loss: tensor(0.8173, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7889293432235718\n",
      "Batch: 521 , Combined Loss: tensor(0.8043, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5985689759254456\n",
      "Batch: 522 , Combined Loss: tensor(1.0179, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30311155319213867\n",
      "Batch: 523 , Combined Loss: tensor(0.7912, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47477400302886963\n",
      "Batch: 524 , Combined Loss: tensor(0.8513, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3183711767196655\n",
      "Batch: 525 , Combined Loss: tensor(0.8505, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2934143543243408\n",
      "Batch: 526 , Combined Loss: tensor(0.8951, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05291247367858887\n",
      "Batch: 527 , Combined Loss: tensor(0.9113, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5129900574684143\n",
      "Batch: 528 , Combined Loss: tensor(0.7421, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.18946635723114014\n",
      "Batch: 529 , Combined Loss: tensor(0.8490, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7778270244598389\n",
      "Batch: 530 , Combined Loss: tensor(0.9453, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.31165146827697754\n",
      "Batch: 531 , Combined Loss: tensor(0.7744, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.013692140579223633\n",
      "Batch: 532 , Combined Loss: tensor(0.7527, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3846619129180908\n",
      "Batch: 533 , Combined Loss: tensor(0.6939, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5366116762161255\n",
      "Batch: 534 , Combined Loss: tensor(0.8447, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.27277815341949463\n",
      "Batch: 535 , Combined Loss: tensor(0.8657, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10723596811294556\n",
      "Batch: 536 , Combined Loss: tensor(0.7951, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15955930948257446\n",
      "Batch: 537 , Combined Loss: tensor(0.8923, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7788472175598145\n",
      "Batch: 538 , Combined Loss: tensor(0.8556, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04351985454559326\n",
      "Batch: 539 , Combined Loss: tensor(0.8131, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32307255268096924\n",
      "Batch: 540 , Combined Loss: tensor(0.7954, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11076676845550537\n",
      "Batch: 541 , Combined Loss: tensor(0.8689, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3099226951599121\n",
      "Batch: 542 , Combined Loss: tensor(0.7895, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19523948431015015\n",
      "Batch: 543 , Combined Loss: tensor(0.8654, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4930263161659241\n",
      "Batch: 544 , Combined Loss: tensor(0.8131, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13463842868804932\n",
      "Batch: 545 , Combined Loss: tensor(0.8080, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6372891664505005\n",
      "Batch: 546 , Combined Loss: tensor(0.8994, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0668485164642334\n",
      "Batch: 547 , Combined Loss: tensor(0.8563, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05947542190551758\n",
      "Batch: 548 , Combined Loss: tensor(0.8269, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4642717242240906\n",
      "Batch: 549 , Combined Loss: tensor(0.8686, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.024034500122070312\n",
      "Batch: 550 , Combined Loss: tensor(0.7823, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08095765113830566\n",
      "Batch: 551 , Combined Loss: tensor(0.8048, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4634263515472412\n",
      "Batch: 552 , Combined Loss: tensor(0.7901, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4896963834762573\n",
      "Batch: 553 , Combined Loss: tensor(0.7912, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6899406909942627\n",
      "Batch: 554 , Combined Loss: tensor(0.8373, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14191937446594238\n",
      "Batch: 555 , Combined Loss: tensor(0.9093, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34150540828704834\n",
      "Batch: 556 , Combined Loss: tensor(0.8636, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41058647632598877\n",
      "Batch: 557 , Combined Loss: tensor(0.8935, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2534235715866089\n",
      "Batch: 558 , Combined Loss: tensor(0.7681, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35831141471862793\n",
      "Batch: 559 , Combined Loss: tensor(0.8430, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6530929803848267\n",
      "Batch: 560 , Combined Loss: tensor(0.8879, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.13744020462036133\n",
      "Batch: 561 , Combined Loss: tensor(0.8870, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5228414535522461\n",
      "Batch: 562 , Combined Loss: tensor(0.9241, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5889458656311035\n",
      "Batch: 563 , Combined Loss: tensor(0.9312, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.29006558656692505\n",
      "Batch: 564 , Combined Loss: tensor(0.7664, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21529054641723633\n",
      "Batch: 565 , Combined Loss: tensor(0.9401, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5604599714279175\n",
      "Batch: 566 , Combined Loss: tensor(0.9035, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1136549711227417\n",
      "Batch: 567 , Combined Loss: tensor(0.9227, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.30757349729537964\n",
      "Batch: 568 , Combined Loss: tensor(0.8320, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0739821195602417\n",
      "Batch: 569 , Combined Loss: tensor(0.8111, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6998953819274902\n",
      "Batch: 570 , Combined Loss: tensor(0.8596, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0806494951248169\n",
      "Batch: 571 , Combined Loss: tensor(0.8342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0399777889251709\n",
      "Batch: 572 , Combined Loss: tensor(0.8111, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.056434035301208496\n",
      "Batch: 573 , Combined Loss: tensor(0.8696, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1592998504638672\n",
      "Batch: 574 , Combined Loss: tensor(0.9489, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6925971508026123\n",
      "Batch: 575 , Combined Loss: tensor(0.7962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40743136405944824\n",
      "Batch: 576 , Combined Loss: tensor(0.8250, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07852745056152344\n",
      "Batch: 577 , Combined Loss: tensor(0.7841, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1201401948928833\n",
      "Batch: 578 , Combined Loss: tensor(0.8622, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.13768094778060913\n",
      "Batch: 579 , Combined Loss: tensor(0.9652, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23321938514709473\n",
      "Batch: 580 , Combined Loss: tensor(0.8067, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6703716516494751\n",
      "Batch: 581 , Combined Loss: tensor(0.8762, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6803971529006958\n",
      "Batch: 582 , Combined Loss: tensor(0.9108, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.29821038246154785\n",
      "Batch: 583 , Combined Loss: tensor(0.8209, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28275394439697266\n",
      "Batch: 584 , Combined Loss: tensor(0.8365, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3961108326911926\n",
      "Batch: 585 , Combined Loss: tensor(0.8207, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.019598960876464844\n",
      "Batch: 586 , Combined Loss: tensor(0.9394, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4762159585952759\n",
      "Batch: 587 , Combined Loss: tensor(0.8553, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.40677428245544434\n",
      "Batch: 588 , Combined Loss: tensor(0.8503, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3163766860961914\n",
      "Batch: 589 , Combined Loss: tensor(0.8089, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3374752998352051\n",
      "Batch: 590 , Combined Loss: tensor(0.9848, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1810600757598877\n",
      "Batch: 591 , Combined Loss: tensor(0.7638, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5567190647125244\n",
      "Batch: 592 , Combined Loss: tensor(0.8343, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4473341703414917\n",
      "Batch: 593 , Combined Loss: tensor(0.8326, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3190734386444092\n",
      "Batch: 594 , Combined Loss: tensor(0.8084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6434805393218994\n",
      "Batch: 595 , Combined Loss: tensor(0.8366, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24784493446350098\n",
      "Batch: 596 , Combined Loss: tensor(0.9658, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1632310152053833\n",
      "Batch: 597 , Combined Loss: tensor(1.0671, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5040111541748047\n",
      "Batch: 598 , Combined Loss: tensor(0.7911, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20113015174865723\n",
      "Batch: 599 , Combined Loss: tensor(0.8509, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26742124557495117\n",
      "Batch: 600 , Combined Loss: tensor(0.7952, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17527073621749878\n",
      "Batch: 601 , Combined Loss: tensor(0.7301, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4727928042411804\n",
      "Batch: 602 , Combined Loss: tensor(0.7606, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.25114327669143677\n",
      "Batch: 603 , Combined Loss: tensor(0.8208, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.01772540807723999\n",
      "Batch: 604 , Combined Loss: tensor(0.8669, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15532195568084717\n",
      "Batch: 605 , Combined Loss: tensor(0.8357, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45892834663391113\n",
      "Batch: 606 , Combined Loss: tensor(0.8029, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.02982652187347412\n",
      "Batch: 607 , Combined Loss: tensor(0.8802, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14783728122711182\n",
      "Batch: 608 , Combined Loss: tensor(0.8917, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5264118909835815\n",
      "Batch: 609 , Combined Loss: tensor(0.8449, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5245945453643799\n",
      "Batch: 610 , Combined Loss: tensor(0.8641, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13646483421325684\n",
      "Batch: 611 , Combined Loss: tensor(0.9802, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6584305763244629\n",
      "Batch: 612 , Combined Loss: tensor(0.9239, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.001343846321105957\n",
      "Batch: 613 , Combined Loss: tensor(0.8423, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8766698837280273\n",
      "Batch: 614 , Combined Loss: tensor(0.8613, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22607499361038208\n",
      "Batch: 615 , Combined Loss: tensor(0.8861, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7630377411842346\n",
      "Batch: 616 , Combined Loss: tensor(0.7476, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24371743202209473\n",
      "Batch: 617 , Combined Loss: tensor(0.9362, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5766770839691162\n",
      "Batch: 618 , Combined Loss: tensor(0.8437, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7736096382141113\n",
      "Batch: 619 , Combined Loss: tensor(0.8144, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6687102317810059\n",
      "Batch: 620 , Combined Loss: tensor(0.8666, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4340081214904785\n",
      "Batch: 621 , Combined Loss: tensor(0.7993, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29740214347839355\n",
      "Batch: 622 , Combined Loss: tensor(0.7543, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5526520013809204\n",
      "Batch: 623 , Combined Loss: tensor(0.7833, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5226696133613586\n",
      "Batch: 624 , Combined Loss: tensor(0.8251, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5528834462165833\n",
      "Batch: 625 , Combined Loss: tensor(0.8346, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5754824876785278\n",
      "Batch: 626 , Combined Loss: tensor(0.8807, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.01367884874343872\n",
      "Batch: 627 , Combined Loss: tensor(0.7845, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5351427793502808\n",
      "Batch: 628 , Combined Loss: tensor(0.8539, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20048141479492188\n",
      "----------Epoch 4, Loss: 0.8651276559632609, Accuracy: 0.8611134444207948, Dice Coef: [0.9264673505375229, 0.3035887780091391, 0.35215539220304193, 0.2870866811845598], Dice Coef Necrotic: 0.26058375343049867, Dice Coef Edema: 0.285797039858681, Dice Coef Enhancing: 0.2591289523626221, Sensitivity: [0.8661503562487555, 0.5818405227850574, 0.765797013784085, 0.8345137190551976], Specificity: [0.9598227216253599, 0.9900712402143614, 0.9192424491403213, 0.9509117490536457], Precision: [0.9977603048702113, 0.2647598997509863, 0.2510031703841349, 0.18993952573560785]\n",
      "Saving without nn.DataParallel\n",
      "Batch: 0 , Combined Loss: tensor(0.9604, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7527480721473694\n",
      "Batch: 1 , Combined Loss: tensor(0.7546, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15993624925613403\n",
      "Batch: 2 , Combined Loss: tensor(0.7937, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1033245325088501\n",
      "Batch: 3 , Combined Loss: tensor(0.8849, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1365010142326355\n",
      "Batch: 4 , Combined Loss: tensor(0.9172, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6463190317153931\n",
      "Batch: 5 , Combined Loss: tensor(0.8007, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2582244873046875\n",
      "Batch: 6 , Combined Loss: tensor(0.8666, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5369985103607178\n",
      "Batch: 7 , Combined Loss: tensor(0.9866, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6336969137191772\n",
      "Batch: 8 , Combined Loss: tensor(0.8413, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.16399621963500977\n",
      "Batch: 9 , Combined Loss: tensor(0.8245, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.008815288543701172\n",
      "Batch: 10 , Combined Loss: tensor(0.7710, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08100622892379761\n",
      "Batch: 11 , Combined Loss: tensor(1.1505, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5552841424942017\n",
      "Batch: 12 , Combined Loss: tensor(0.8123, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2663724422454834\n",
      "Batch: 13 , Combined Loss: tensor(0.9571, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.33546262979507446\n",
      "Batch: 14 , Combined Loss: tensor(0.8350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.34684300422668457\n",
      "Batch: 15 , Combined Loss: tensor(0.7522, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2910505533218384\n",
      "Batch: 16 , Combined Loss: tensor(0.9061, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07950162887573242\n",
      "Batch: 17 , Combined Loss: tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4769192934036255\n",
      "Batch: 18 , Combined Loss: tensor(0.7679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.02279829978942871\n",
      "Batch: 19 , Combined Loss: tensor(0.9151, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10217368602752686\n",
      "Batch: 20 , Combined Loss: tensor(0.7936, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.41491955518722534\n",
      "Batch: 21 , Combined Loss: tensor(0.9361, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5509003400802612\n",
      "Batch: 22 , Combined Loss: tensor(0.7758, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20570850372314453\n",
      "Batch: 23 , Combined Loss: tensor(0.9419, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.014535188674926758\n",
      "Batch: 24 , Combined Loss: tensor(0.8789, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31942951679229736\n",
      "Batch: 25 , Combined Loss: tensor(0.8397, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.013928413391113281\n",
      "Batch: 26 , Combined Loss: tensor(0.7349, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5305479764938354\n",
      "Batch: 27 , Combined Loss: tensor(0.8719, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6429935693740845\n",
      "Batch: 28 , Combined Loss: tensor(0.8313, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07340562343597412\n",
      "Batch: 29 , Combined Loss: tensor(0.8624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6239805221557617\n",
      "Batch: 30 , Combined Loss: tensor(0.8173, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0016701221466064453\n",
      "Batch: 31 , Combined Loss: tensor(0.8671, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2821459174156189\n",
      "Batch: 32 , Combined Loss: tensor(0.7419, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30056238174438477\n",
      "Batch: 33 , Combined Loss: tensor(1.0152, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5290817022323608\n",
      "Batch: 34 , Combined Loss: tensor(0.8542, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40341949462890625\n",
      "Batch: 35 , Combined Loss: tensor(0.8103, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5892177820205688\n",
      "Batch: 36 , Combined Loss: tensor(0.9553, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17207670211791992\n",
      "Batch: 37 , Combined Loss: tensor(0.9316, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1705244779586792\n",
      "Batch: 38 , Combined Loss: tensor(0.7943, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.512853741645813\n",
      "Batch: 39 , Combined Loss: tensor(0.8457, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5757728815078735\n",
      "Batch: 40 , Combined Loss: tensor(0.8203, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5751709938049316\n",
      "Batch: 41 , Combined Loss: tensor(0.8620, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24831914901733398\n",
      "Batch: 42 , Combined Loss: tensor(0.8849, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07167482376098633\n",
      "Batch: 43 , Combined Loss: tensor(0.7992, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6616876125335693\n",
      "Batch: 44 , Combined Loss: tensor(0.8126, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3670542240142822\n",
      "Batch: 45 , Combined Loss: tensor(0.9249, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.043488383293151855\n",
      "Batch: 46 , Combined Loss: tensor(0.8441, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.41616684198379517\n",
      "Batch: 47 , Combined Loss: tensor(0.7956, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3550755977630615\n",
      "Batch: 48 , Combined Loss: tensor(0.8701, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36707866191864014\n",
      "Batch: 49 , Combined Loss: tensor(0.8049, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3445783853530884\n",
      "Batch: 50 , Combined Loss: tensor(0.8412, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.025946438312530518\n",
      "Batch: 51 , Combined Loss: tensor(0.9066, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2926459312438965\n",
      "Batch: 52 , Combined Loss: tensor(0.9898, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.021254301071166992\n",
      "Batch: 53 , Combined Loss: tensor(0.9758, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2442641258239746\n",
      "Batch: 54 , Combined Loss: tensor(0.7623, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.49394917488098145\n",
      "Batch: 55 , Combined Loss: tensor(0.8889, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.012620329856872559\n",
      "Batch: 56 , Combined Loss: tensor(0.7361, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3520592451095581\n",
      "Batch: 57 , Combined Loss: tensor(0.7655, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7748842239379883\n",
      "Batch: 58 , Combined Loss: tensor(0.7844, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6049443483352661\n",
      "Batch: 59 , Combined Loss: tensor(0.7020, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26463234424591064\n",
      "Batch: 60 , Combined Loss: tensor(0.7814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.018801212310791016\n",
      "Batch: 61 , Combined Loss: tensor(0.8078, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08862316608428955\n",
      "Batch: 62 , Combined Loss: tensor(0.8988, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1841367483139038\n",
      "Batch: 63 , Combined Loss: tensor(0.8737, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15363144874572754\n",
      "Batch: 64 , Combined Loss: tensor(0.8680, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5311020612716675\n",
      "Batch: 65 , Combined Loss: tensor(0.9821, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43220388889312744\n",
      "Batch: 66 , Combined Loss: tensor(0.8050, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22710072994232178\n",
      "Batch: 67 , Combined Loss: tensor(0.8274, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03074181079864502\n",
      "Batch: 68 , Combined Loss: tensor(0.8518, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4324972629547119\n",
      "Batch: 69 , Combined Loss: tensor(0.8188, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.003229379653930664\n",
      "Batch: 70 , Combined Loss: tensor(0.8832, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8343017101287842\n",
      "Batch: 71 , Combined Loss: tensor(0.7822, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5360454320907593\n",
      "Batch: 72 , Combined Loss: tensor(1.0428, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2215132713317871\n",
      "Batch: 73 , Combined Loss: tensor(0.8279, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.26931852102279663\n",
      "Batch: 74 , Combined Loss: tensor(0.8031, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34290969371795654\n",
      "Batch: 75 , Combined Loss: tensor(0.8208, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15462428331375122\n",
      "Batch: 76 , Combined Loss: tensor(1.2376, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08573657274246216\n",
      "Batch: 77 , Combined Loss: tensor(0.7625, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6511849761009216\n",
      "Batch: 78 , Combined Loss: tensor(0.8517, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6642115712165833\n",
      "Batch: 79 , Combined Loss: tensor(0.7818, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5322638750076294\n",
      "Batch: 80 , Combined Loss: tensor(0.8254, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5742555856704712\n",
      "Batch: 81 , Combined Loss: tensor(0.7721, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2675597667694092\n",
      "Batch: 82 , Combined Loss: tensor(0.9570, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3962358832359314\n",
      "Batch: 83 , Combined Loss: tensor(0.9561, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24338781833648682\n",
      "Batch: 84 , Combined Loss: tensor(0.8094, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7021717429161072\n",
      "Batch: 85 , Combined Loss: tensor(0.8171, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7340538501739502\n",
      "Batch: 86 , Combined Loss: tensor(0.7883, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5415500402450562\n",
      "Batch: 87 , Combined Loss: tensor(0.8481, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1808415651321411\n",
      "Batch: 88 , Combined Loss: tensor(0.8371, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26884400844573975\n",
      "Batch: 89 , Combined Loss: tensor(0.8868, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04071164131164551\n",
      "Batch: 90 , Combined Loss: tensor(0.7855, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11743634939193726\n",
      "Batch: 91 , Combined Loss: tensor(0.7016, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4222775101661682\n",
      "Batch: 92 , Combined Loss: tensor(0.9958, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.017880797386169434\n",
      "Batch: 93 , Combined Loss: tensor(0.8283, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36229658126831055\n",
      "Batch: 94 , Combined Loss: tensor(0.9436, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11685991287231445\n",
      "Batch: 95 , Combined Loss: tensor(0.9233, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2821391820907593\n",
      "Batch: 96 , Combined Loss: tensor(0.7379, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4837036728858948\n",
      "Batch: 97 , Combined Loss: tensor(0.7298, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11700397729873657\n",
      "Batch: 98 , Combined Loss: tensor(0.7531, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.43008893728256226\n",
      "Batch: 99 , Combined Loss: tensor(0.8776, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.512911856174469\n",
      "Batch: 100 , Combined Loss: tensor(0.9672, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36731433868408203\n",
      "Batch: 101 , Combined Loss: tensor(0.9350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5176042318344116\n",
      "Batch: 102 , Combined Loss: tensor(0.8520, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7613229751586914\n",
      "Batch: 103 , Combined Loss: tensor(0.8662, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5997592806816101\n",
      "Batch: 104 , Combined Loss: tensor(0.7694, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5790057182312012\n",
      "Batch: 105 , Combined Loss: tensor(0.7375, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5257734060287476\n",
      "Batch: 106 , Combined Loss: tensor(0.7932, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34218740463256836\n",
      "Batch: 107 , Combined Loss: tensor(0.7357, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15847474336624146\n",
      "Batch: 108 , Combined Loss: tensor(0.7352, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.006020843982696533\n",
      "Batch: 109 , Combined Loss: tensor(0.8479, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18673336505889893\n",
      "Batch: 110 , Combined Loss: tensor(0.8663, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9902148246765137\n",
      "Batch: 111 , Combined Loss: tensor(0.8682, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6750475168228149\n",
      "Batch: 112 , Combined Loss: tensor(0.8705, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04203122854232788\n",
      "Batch: 113 , Combined Loss: tensor(0.9948, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.26223450899124146\n",
      "Batch: 114 , Combined Loss: tensor(1.1868, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36725473403930664\n",
      "Batch: 115 , Combined Loss: tensor(0.7698, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06335651874542236\n",
      "Batch: 116 , Combined Loss: tensor(0.8471, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6516494750976562\n",
      "Batch: 117 , Combined Loss: tensor(0.8400, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08645528554916382\n",
      "Batch: 118 , Combined Loss: tensor(0.7357, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19517749547958374\n",
      "Batch: 119 , Combined Loss: tensor(0.7767, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3506924510002136\n",
      "Batch: 120 , Combined Loss: tensor(0.7810, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4928469657897949\n",
      "Batch: 121 , Combined Loss: tensor(0.8286, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4622182846069336\n",
      "Batch: 122 , Combined Loss: tensor(0.7694, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09602737426757812\n",
      "Batch: 123 , Combined Loss: tensor(0.9553, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.023246169090270996\n",
      "Batch: 124 , Combined Loss: tensor(0.9973, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5884960889816284\n",
      "Batch: 125 , Combined Loss: tensor(0.8135, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5756628513336182\n",
      "Batch: 126 , Combined Loss: tensor(0.7991, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10654431581497192\n",
      "Batch: 127 , Combined Loss: tensor(0.8505, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5243998765945435\n",
      "Batch: 128 , Combined Loss: tensor(0.8094, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20101594924926758\n",
      "Batch: 129 , Combined Loss: tensor(0.7646, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6059977412223816\n",
      "Batch: 130 , Combined Loss: tensor(0.8322, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6489359140396118\n",
      "Batch: 131 , Combined Loss: tensor(0.8176, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4383491277694702\n",
      "Batch: 132 , Combined Loss: tensor(0.7570, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09449565410614014\n",
      "Batch: 133 , Combined Loss: tensor(0.8581, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6658804416656494\n",
      "Batch: 134 , Combined Loss: tensor(0.8726, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3184797763824463\n",
      "Batch: 135 , Combined Loss: tensor(0.7219, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7249712944030762\n",
      "Batch: 136 , Combined Loss: tensor(0.7821, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.01586759090423584\n",
      "Batch: 137 , Combined Loss: tensor(0.8557, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6528542041778564\n",
      "Batch: 138 , Combined Loss: tensor(0.7905, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5535049438476562\n",
      "Batch: 139 , Combined Loss: tensor(0.7631, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3307833671569824\n",
      "Batch: 140 , Combined Loss: tensor(1.0780, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.43231356143951416\n",
      "Batch: 141 , Combined Loss: tensor(0.8552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5442123413085938\n",
      "Batch: 142 , Combined Loss: tensor(0.9637, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6178650259971619\n",
      "Batch: 143 , Combined Loss: tensor(0.8552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.474132776260376\n",
      "Batch: 144 , Combined Loss: tensor(0.8744, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41858553886413574\n",
      "Batch: 145 , Combined Loss: tensor(0.7895, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9205257892608643\n",
      "Batch: 146 , Combined Loss: tensor(0.8228, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.697456955909729\n",
      "Batch: 147 , Combined Loss: tensor(0.8199, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45205044746398926\n",
      "Batch: 148 , Combined Loss: tensor(0.9208, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16283249855041504\n",
      "Batch: 149 , Combined Loss: tensor(0.9619, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.003984928131103516\n",
      "Batch: 150 , Combined Loss: tensor(0.7748, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5130636692047119\n",
      "Batch: 151 , Combined Loss: tensor(0.9038, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08328795433044434\n",
      "Batch: 152 , Combined Loss: tensor(1.0298, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.022136986255645752\n",
      "Batch: 153 , Combined Loss: tensor(0.8398, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1678396463394165\n",
      "Batch: 154 , Combined Loss: tensor(0.8204, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10254740715026855\n",
      "Batch: 155 , Combined Loss: tensor(0.7719, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4559006690979004\n",
      "Batch: 156 , Combined Loss: tensor(0.8638, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24507766962051392\n",
      "Batch: 157 , Combined Loss: tensor(0.8965, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07573890686035156\n",
      "Batch: 158 , Combined Loss: tensor(0.7920, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5149058103561401\n",
      "Batch: 159 , Combined Loss: tensor(0.8313, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7335395812988281\n",
      "Batch: 160 , Combined Loss: tensor(0.8032, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.409257173538208\n",
      "Batch: 161 , Combined Loss: tensor(0.7770, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5361839532852173\n",
      "Batch: 162 , Combined Loss: tensor(0.8689, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7490824460983276\n",
      "Batch: 163 , Combined Loss: tensor(0.7351, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3145267367362976\n",
      "Batch: 164 , Combined Loss: tensor(0.8308, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22299611568450928\n",
      "Batch: 165 , Combined Loss: tensor(0.8777, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.367647647857666\n",
      "Batch: 166 , Combined Loss: tensor(0.8580, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.008905887603759766\n",
      "Batch: 167 , Combined Loss: tensor(0.7771, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9939819574356079\n",
      "Batch: 168 , Combined Loss: tensor(0.8316, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6382952928543091\n",
      "Batch: 169 , Combined Loss: tensor(0.8572, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49839282035827637\n",
      "Batch: 170 , Combined Loss: tensor(0.8451, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7414878606796265\n",
      "Batch: 171 , Combined Loss: tensor(0.7988, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4354466199874878\n",
      "Batch: 172 , Combined Loss: tensor(0.8011, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5897642374038696\n",
      "Batch: 173 , Combined Loss: tensor(0.8245, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39010703563690186\n",
      "Batch: 174 , Combined Loss: tensor(0.7646, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7185877561569214\n",
      "Batch: 175 , Combined Loss: tensor(0.8658, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.38269490003585815\n",
      "Batch: 176 , Combined Loss: tensor(0.9430, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35754168033599854\n",
      "Batch: 177 , Combined Loss: tensor(0.7738, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.614507794380188\n",
      "Batch: 178 , Combined Loss: tensor(0.8310, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4408372640609741\n",
      "Batch: 179 , Combined Loss: tensor(0.8259, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19711029529571533\n",
      "Batch: 180 , Combined Loss: tensor(0.9005, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06871610879898071\n",
      "Batch: 181 , Combined Loss: tensor(0.8540, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19666486978530884\n",
      "Batch: 182 , Combined Loss: tensor(0.7782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9185672998428345\n",
      "Batch: 183 , Combined Loss: tensor(0.7757, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.02145993709564209\n",
      "Batch: 184 , Combined Loss: tensor(0.9346, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6335124969482422\n",
      "Batch: 185 , Combined Loss: tensor(0.7020, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3458523154258728\n",
      "Batch: 186 , Combined Loss: tensor(0.8194, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4020538330078125\n",
      "Batch: 187 , Combined Loss: tensor(0.8028, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.459048330783844\n",
      "Batch: 188 , Combined Loss: tensor(0.7283, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4625198245048523\n",
      "Batch: 189 , Combined Loss: tensor(1.0058, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1705111265182495\n",
      "Batch: 190 , Combined Loss: tensor(0.7930, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7650752663612366\n",
      "Batch: 191 , Combined Loss: tensor(0.8055, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3145025968551636\n",
      "Batch: 192 , Combined Loss: tensor(0.8009, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.049167752265930176\n",
      "Batch: 193 , Combined Loss: tensor(0.8493, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22380661964416504\n",
      "Batch: 194 , Combined Loss: tensor(0.8172, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22796815633773804\n",
      "Batch: 195 , Combined Loss: tensor(0.7679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2897099256515503\n",
      "Batch: 196 , Combined Loss: tensor(0.7309, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42852187156677246\n",
      "Batch: 197 , Combined Loss: tensor(0.8393, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8687902688980103\n",
      "Batch: 198 , Combined Loss: tensor(0.7702, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5851978063583374\n",
      "Batch: 199 , Combined Loss: tensor(0.9201, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7654598355293274\n",
      "Batch: 200 , Combined Loss: tensor(0.8097, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5773100852966309\n",
      "Batch: 201 , Combined Loss: tensor(0.8626, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2993583679199219\n",
      "Batch: 202 , Combined Loss: tensor(0.7507, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40194177627563477\n",
      "Batch: 203 , Combined Loss: tensor(0.7373, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24793267250061035\n",
      "Batch: 204 , Combined Loss: tensor(0.8641, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45135271549224854\n",
      "Batch: 205 , Combined Loss: tensor(0.8522, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.551087498664856\n",
      "Batch: 206 , Combined Loss: tensor(0.7867, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4529961347579956\n",
      "Batch: 207 , Combined Loss: tensor(0.8958, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4852486848831177\n",
      "Batch: 208 , Combined Loss: tensor(0.7517, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5687302350997925\n",
      "Batch: 209 , Combined Loss: tensor(0.7557, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3188663721084595\n",
      "Batch: 210 , Combined Loss: tensor(0.8103, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24575388431549072\n",
      "Batch: 211 , Combined Loss: tensor(0.7882, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.30793142318725586\n",
      "Batch: 212 , Combined Loss: tensor(0.8176, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5094153881072998\n",
      "Batch: 213 , Combined Loss: tensor(0.8379, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5460569262504578\n",
      "Batch: 214 , Combined Loss: tensor(0.8382, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.33899128437042236\n",
      "Batch: 215 , Combined Loss: tensor(0.8854, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08345580101013184\n",
      "Batch: 216 , Combined Loss: tensor(0.7029, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22416949272155762\n",
      "Batch: 217 , Combined Loss: tensor(0.7774, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.57677161693573\n",
      "Batch: 218 , Combined Loss: tensor(0.7478, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7431353330612183\n",
      "Batch: 219 , Combined Loss: tensor(0.9423, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5879234075546265\n",
      "Batch: 220 , Combined Loss: tensor(0.8679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24121761322021484\n",
      "Batch: 221 , Combined Loss: tensor(0.9250, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08259737491607666\n",
      "Batch: 222 , Combined Loss: tensor(0.9021, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18058371543884277\n",
      "Batch: 223 , Combined Loss: tensor(0.8917, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43825244903564453\n",
      "Batch: 224 , Combined Loss: tensor(0.9348, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6430935859680176\n",
      "Batch: 225 , Combined Loss: tensor(0.9180, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36200010776519775\n",
      "Batch: 226 , Combined Loss: tensor(0.7501, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.191919207572937\n",
      "Batch: 227 , Combined Loss: tensor(0.8391, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4684908390045166\n",
      "Batch: 228 , Combined Loss: tensor(0.9240, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6261779069900513\n",
      "Batch: 229 , Combined Loss: tensor(0.8121, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10534685850143433\n",
      "Batch: 230 , Combined Loss: tensor(0.8626, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4982086420059204\n",
      "Batch: 231 , Combined Loss: tensor(0.8481, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19767224788665771\n",
      "Batch: 232 , Combined Loss: tensor(0.8280, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.00701904296875\n",
      "Batch: 233 , Combined Loss: tensor(0.7760, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4869039058685303\n",
      "Batch: 234 , Combined Loss: tensor(0.9609, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2948892116546631\n",
      "Batch: 235 , Combined Loss: tensor(0.8228, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7048956155776978\n",
      "Batch: 236 , Combined Loss: tensor(0.8272, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.02263188362121582\n",
      "Batch: 237 , Combined Loss: tensor(0.8092, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5966832637786865\n",
      "Batch: 238 , Combined Loss: tensor(0.7965, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25335419178009033\n",
      "Batch: 239 , Combined Loss: tensor(0.8468, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2297039031982422\n",
      "Batch: 240 , Combined Loss: tensor(0.7930, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3751842975616455\n",
      "Batch: 241 , Combined Loss: tensor(0.8150, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42584168910980225\n",
      "Batch: 242 , Combined Loss: tensor(0.7685, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5011672973632812\n",
      "Batch: 243 , Combined Loss: tensor(0.8892, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.135883629322052\n",
      "Batch: 244 , Combined Loss: tensor(0.8729, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7151497006416321\n",
      "Batch: 245 , Combined Loss: tensor(1.1281, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4789842367172241\n",
      "Batch: 246 , Combined Loss: tensor(0.8187, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4922601580619812\n",
      "Batch: 247 , Combined Loss: tensor(0.8048, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19277620315551758\n",
      "Batch: 248 , Combined Loss: tensor(0.8483, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9920735359191895\n",
      "Batch: 249 , Combined Loss: tensor(0.8260, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39530324935913086\n",
      "Batch: 250 , Combined Loss: tensor(0.9117, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.30512356758117676\n",
      "Batch: 251 , Combined Loss: tensor(0.8060, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6001601219177246\n",
      "Batch: 252 , Combined Loss: tensor(0.8150, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22511565685272217\n",
      "Batch: 253 , Combined Loss: tensor(0.8548, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05206453800201416\n",
      "Batch: 254 , Combined Loss: tensor(0.7982, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7013835906982422\n",
      "Batch: 255 , Combined Loss: tensor(0.7370, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.369026243686676\n",
      "Batch: 256 , Combined Loss: tensor(0.8092, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.33523231744766235\n",
      "Batch: 257 , Combined Loss: tensor(0.8615, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6054941415786743\n",
      "Batch: 258 , Combined Loss: tensor(0.8500, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5149020552635193\n",
      "Batch: 259 , Combined Loss: tensor(0.8601, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03948688507080078\n",
      "Batch: 260 , Combined Loss: tensor(0.7180, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.245438814163208\n",
      "Batch: 261 , Combined Loss: tensor(0.7041, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2168843150138855\n",
      "Batch: 262 , Combined Loss: tensor(0.7882, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8320956230163574\n",
      "Batch: 263 , Combined Loss: tensor(0.9221, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5027766227722168\n",
      "Batch: 264 , Combined Loss: tensor(0.8289, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4296422004699707\n",
      "Batch: 265 , Combined Loss: tensor(0.7824, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17021054029464722\n",
      "Batch: 266 , Combined Loss: tensor(0.8728, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.25854116678237915\n",
      "Batch: 267 , Combined Loss: tensor(0.8139, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07386386394500732\n",
      "Batch: 268 , Combined Loss: tensor(0.9234, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14391100406646729\n",
      "Batch: 269 , Combined Loss: tensor(0.8144, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07334649562835693\n",
      "Batch: 270 , Combined Loss: tensor(0.8340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.794399619102478\n",
      "Batch: 271 , Combined Loss: tensor(0.9171, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43532395362854004\n",
      "Batch: 272 , Combined Loss: tensor(0.8039, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7629461288452148\n",
      "Batch: 273 , Combined Loss: tensor(0.8774, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3889142870903015\n",
      "Batch: 274 , Combined Loss: tensor(0.7943, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28481578826904297\n",
      "Batch: 275 , Combined Loss: tensor(0.9061, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2223823070526123\n",
      "Batch: 276 , Combined Loss: tensor(0.8354, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2934533357620239\n",
      "Batch: 277 , Combined Loss: tensor(0.8950, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4263148307800293\n",
      "Batch: 278 , Combined Loss: tensor(0.8536, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36229193210601807\n",
      "Batch: 279 , Combined Loss: tensor(0.9535, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.41969698667526245\n",
      "Batch: 280 , Combined Loss: tensor(0.8504, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.33613264560699463\n",
      "Batch: 281 , Combined Loss: tensor(0.9128, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2906447649002075\n",
      "Batch: 282 , Combined Loss: tensor(0.8758, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.151411771774292\n",
      "Batch: 283 , Combined Loss: tensor(0.7920, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32227790355682373\n",
      "Batch: 284 , Combined Loss: tensor(0.8315, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12594687938690186\n",
      "Batch: 285 , Combined Loss: tensor(0.8540, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28676748275756836\n",
      "Batch: 286 , Combined Loss: tensor(0.7473, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22429311275482178\n",
      "Batch: 287 , Combined Loss: tensor(0.8208, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5961347818374634\n",
      "Batch: 288 , Combined Loss: tensor(0.7624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.512832760810852\n",
      "Batch: 289 , Combined Loss: tensor(0.8194, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3708885908126831\n",
      "Batch: 290 , Combined Loss: tensor(0.8721, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24218213558197021\n",
      "Batch: 291 , Combined Loss: tensor(0.7647, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3111070394515991\n",
      "Batch: 292 , Combined Loss: tensor(0.7987, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21244418621063232\n",
      "Batch: 293 , Combined Loss: tensor(0.8289, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.45205920934677124\n",
      "Batch: 294 , Combined Loss: tensor(0.8592, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3446957468986511\n",
      "Batch: 295 , Combined Loss: tensor(0.7861, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8469367027282715\n",
      "Batch: 296 , Combined Loss: tensor(0.8205, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48452603816986084\n",
      "Batch: 297 , Combined Loss: tensor(0.7741, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.043375492095947266\n",
      "Batch: 298 , Combined Loss: tensor(0.8359, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.535453200340271\n",
      "Batch: 299 , Combined Loss: tensor(0.7940, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5926483869552612\n",
      "Batch: 300 , Combined Loss: tensor(0.9267, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.02353048324584961\n",
      "Batch: 301 , Combined Loss: tensor(0.7730, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5003726482391357\n",
      "Batch: 302 , Combined Loss: tensor(0.7749, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6674011945724487\n",
      "Batch: 303 , Combined Loss: tensor(0.9177, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6375545263290405\n",
      "Batch: 304 , Combined Loss: tensor(0.8401, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7620025277137756\n",
      "Batch: 305 , Combined Loss: tensor(0.9123, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39649903774261475\n",
      "Batch: 306 , Combined Loss: tensor(0.7832, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14122986793518066\n",
      "Batch: 307 , Combined Loss: tensor(0.8291, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0010633468627929688\n",
      "Batch: 308 , Combined Loss: tensor(0.8452, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2625248432159424\n",
      "Batch: 309 , Combined Loss: tensor(0.9003, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11538147926330566\n",
      "Batch: 310 , Combined Loss: tensor(0.8403, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09939098358154297\n",
      "Batch: 311 , Combined Loss: tensor(0.7555, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07726585865020752\n",
      "Batch: 312 , Combined Loss: tensor(0.7575, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22425758838653564\n",
      "Batch: 313 , Combined Loss: tensor(0.9141, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12117958068847656\n",
      "Batch: 314 , Combined Loss: tensor(0.8667, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.40868133306503296\n",
      "Batch: 315 , Combined Loss: tensor(0.7749, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5398857593536377\n",
      "Batch: 316 , Combined Loss: tensor(0.7570, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5812180042266846\n",
      "Batch: 317 , Combined Loss: tensor(1.0777, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.8472951054573059\n",
      "Batch: 318 , Combined Loss: tensor(0.8509, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.36109960079193115\n",
      "Batch: 319 , Combined Loss: tensor(0.7556, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3228667378425598\n",
      "Batch: 320 , Combined Loss: tensor(0.9068, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19670504331588745\n",
      "Batch: 321 , Combined Loss: tensor(0.7257, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.71288001537323\n",
      "Batch: 322 , Combined Loss: tensor(0.9384, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.38441717624664307\n",
      "Batch: 323 , Combined Loss: tensor(0.8495, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03654313087463379\n",
      "Batch: 324 , Combined Loss: tensor(0.7578, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.015890002250671387\n",
      "Batch: 325 , Combined Loss: tensor(0.7718, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5763988494873047\n",
      "Batch: 326 , Combined Loss: tensor(0.8914, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1401437520980835\n",
      "Batch: 327 , Combined Loss: tensor(0.9497, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4552661180496216\n",
      "Batch: 328 , Combined Loss: tensor(0.7811, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.537076473236084\n",
      "Batch: 329 , Combined Loss: tensor(0.8074, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7487684488296509\n",
      "Batch: 330 , Combined Loss: tensor(0.8570, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3367575407028198\n",
      "Batch: 331 , Combined Loss: tensor(0.7487, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3081265091896057\n",
      "Batch: 332 , Combined Loss: tensor(0.8229, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14963722229003906\n",
      "Batch: 333 , Combined Loss: tensor(0.8958, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9830400943756104\n",
      "Batch: 334 , Combined Loss: tensor(0.8955, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.26871687173843384\n",
      "Batch: 335 , Combined Loss: tensor(1.0595, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8793294429779053\n",
      "Batch: 336 , Combined Loss: tensor(0.9693, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4893639087677002\n",
      "Batch: 337 , Combined Loss: tensor(0.8434, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6746494770050049\n",
      "Batch: 338 , Combined Loss: tensor(1.0166, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20898288488388062\n",
      "Batch: 339 , Combined Loss: tensor(0.7649, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29238080978393555\n",
      "Batch: 340 , Combined Loss: tensor(0.7790, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18864452838897705\n",
      "Batch: 341 , Combined Loss: tensor(0.9589, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1449446678161621\n",
      "Batch: 342 , Combined Loss: tensor(0.7699, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19328713417053223\n",
      "Batch: 343 , Combined Loss: tensor(1.0388, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3900718688964844\n",
      "Batch: 344 , Combined Loss: tensor(0.8880, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.760550320148468\n",
      "Batch: 345 , Combined Loss: tensor(0.7947, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17915916442871094\n",
      "Batch: 346 , Combined Loss: tensor(0.8412, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6653883457183838\n",
      "Batch: 347 , Combined Loss: tensor(0.7608, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5553809404373169\n",
      "Batch: 348 , Combined Loss: tensor(0.8760, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5429578423500061\n",
      "Batch: 349 , Combined Loss: tensor(0.8719, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0696477890014648\n",
      "Batch: 350 , Combined Loss: tensor(0.8711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2938516139984131\n",
      "Batch: 351 , Combined Loss: tensor(0.8416, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.419222354888916\n",
      "Batch: 352 , Combined Loss: tensor(0.8202, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7279287576675415\n",
      "Batch: 353 , Combined Loss: tensor(0.8615, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1615605354309082\n",
      "Batch: 354 , Combined Loss: tensor(0.9818, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3680437207221985\n",
      "Batch: 355 , Combined Loss: tensor(0.8837, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39693522453308105\n",
      "Batch: 356 , Combined Loss: tensor(0.8294, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2454913854598999\n",
      "Batch: 357 , Combined Loss: tensor(0.7648, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4585665464401245\n",
      "Batch: 358 , Combined Loss: tensor(0.7815, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2896217107772827\n",
      "Batch: 359 , Combined Loss: tensor(0.7795, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.43396085500717163\n",
      "Batch: 360 , Combined Loss: tensor(0.8671, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13290750980377197\n",
      "Batch: 361 , Combined Loss: tensor(0.7363, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8280136585235596\n",
      "Batch: 362 , Combined Loss: tensor(0.7185, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6650683879852295\n",
      "Batch: 363 , Combined Loss: tensor(0.8775, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23440968990325928\n",
      "Batch: 364 , Combined Loss: tensor(0.7513, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8279918432235718\n",
      "Batch: 365 , Combined Loss: tensor(0.9047, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7505397200584412\n",
      "Batch: 366 , Combined Loss: tensor(0.9033, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18908154964447021\n",
      "Batch: 367 , Combined Loss: tensor(0.9061, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6254717111587524\n",
      "Batch: 368 , Combined Loss: tensor(0.7529, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03265416622161865\n",
      "Batch: 369 , Combined Loss: tensor(1.0029, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03787410259246826\n",
      "Batch: 370 , Combined Loss: tensor(0.9674, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6262059211730957\n",
      "Batch: 371 , Combined Loss: tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46414685249328613\n",
      "Batch: 372 , Combined Loss: tensor(0.9655, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8054107427597046\n",
      "Batch: 373 , Combined Loss: tensor(0.9961, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7224211692810059\n",
      "Batch: 374 , Combined Loss: tensor(0.8269, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30380797386169434\n",
      "Batch: 375 , Combined Loss: tensor(0.7724, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.014755666255950928\n",
      "Batch: 376 , Combined Loss: tensor(0.7584, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4686039686203003\n",
      "Batch: 377 , Combined Loss: tensor(0.8011, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05275857448577881\n",
      "Batch: 378 , Combined Loss: tensor(0.9397, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.47965550422668457\n",
      "Batch: 379 , Combined Loss: tensor(0.8016, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6512497663497925\n",
      "Batch: 380 , Combined Loss: tensor(0.8162, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.581200122833252\n",
      "Batch: 381 , Combined Loss: tensor(0.8413, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5164922475814819\n",
      "Batch: 382 , Combined Loss: tensor(0.9274, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12878340482711792\n",
      "Batch: 383 , Combined Loss: tensor(0.8138, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5957586765289307\n",
      "Batch: 384 , Combined Loss: tensor(0.9028, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04141509532928467\n",
      "Batch: 385 , Combined Loss: tensor(0.7472, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9281628131866455\n",
      "Batch: 386 , Combined Loss: tensor(0.9168, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3365107774734497\n",
      "Batch: 387 , Combined Loss: tensor(0.8301, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21455049514770508\n",
      "Batch: 388 , Combined Loss: tensor(0.8375, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5853643417358398\n",
      "Batch: 389 , Combined Loss: tensor(0.7889, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28018176555633545\n",
      "Batch: 390 , Combined Loss: tensor(0.8747, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5793691873550415\n",
      "Batch: 391 , Combined Loss: tensor(0.8646, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06421983242034912\n",
      "Batch: 392 , Combined Loss: tensor(1.0090, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2708784341812134\n",
      "Batch: 393 , Combined Loss: tensor(0.8573, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.014970660209655762\n",
      "Batch: 394 , Combined Loss: tensor(0.7953, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6126583814620972\n",
      "Batch: 395 , Combined Loss: tensor(0.7487, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4104839563369751\n",
      "Batch: 396 , Combined Loss: tensor(1.0577, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5168416500091553\n",
      "Batch: 397 , Combined Loss: tensor(0.8292, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2970810532569885\n",
      "Batch: 398 , Combined Loss: tensor(0.7782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3226720094680786\n",
      "Batch: 399 , Combined Loss: tensor(1.0129, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11316156387329102\n",
      "Batch: 400 , Combined Loss: tensor(0.9236, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09850311279296875\n",
      "Batch: 401 , Combined Loss: tensor(0.8336, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06392085552215576\n",
      "Batch: 402 , Combined Loss: tensor(0.9496, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7050548791885376\n",
      "Batch: 403 , Combined Loss: tensor(0.7391, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20212960243225098\n",
      "Batch: 404 , Combined Loss: tensor(0.8527, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3295961022377014\n",
      "Batch: 405 , Combined Loss: tensor(0.9197, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.022044658660888672\n",
      "Batch: 406 , Combined Loss: tensor(0.7952, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3135230541229248\n",
      "Batch: 407 , Combined Loss: tensor(0.9791, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0964234471321106\n",
      "Batch: 408 , Combined Loss: tensor(0.7442, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.709653913974762\n",
      "Batch: 409 , Combined Loss: tensor(0.8487, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36430490016937256\n",
      "Batch: 410 , Combined Loss: tensor(0.8161, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.02071279287338257\n",
      "Batch: 411 , Combined Loss: tensor(0.8484, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3250936269760132\n",
      "Batch: 412 , Combined Loss: tensor(0.8506, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24252581596374512\n",
      "Batch: 413 , Combined Loss: tensor(0.7996, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.02948737144470215\n",
      "Batch: 414 , Combined Loss: tensor(0.8352, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.039204955101013184\n",
      "Batch: 415 , Combined Loss: tensor(0.9284, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1504209041595459\n",
      "Batch: 416 , Combined Loss: tensor(0.9133, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21732819080352783\n",
      "Batch: 417 , Combined Loss: tensor(0.8737, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2042437195777893\n",
      "Batch: 418 , Combined Loss: tensor(0.9789, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6570097804069519\n",
      "Batch: 419 , Combined Loss: tensor(0.7946, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5234255790710449\n",
      "Batch: 420 , Combined Loss: tensor(0.8826, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3795285224914551\n",
      "Batch: 421 , Combined Loss: tensor(0.7739, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8488196134567261\n",
      "Batch: 422 , Combined Loss: tensor(0.8054, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5867931842803955\n",
      "Batch: 423 , Combined Loss: tensor(0.8163, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5906789302825928\n",
      "Batch: 424 , Combined Loss: tensor(0.7505, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2943979501724243\n",
      "Batch: 425 , Combined Loss: tensor(0.9136, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3148000240325928\n",
      "Batch: 426 , Combined Loss: tensor(1.0144, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1893775463104248\n",
      "Batch: 427 , Combined Loss: tensor(0.8302, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21811723709106445\n",
      "Batch: 428 , Combined Loss: tensor(0.7752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3062692880630493\n",
      "Batch: 429 , Combined Loss: tensor(0.8453, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5844196081161499\n",
      "Batch: 430 , Combined Loss: tensor(0.8296, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2876623272895813\n",
      "Batch: 431 , Combined Loss: tensor(0.8122, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19996106624603271\n",
      "Batch: 432 , Combined Loss: tensor(0.7578, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10723042488098145\n",
      "Batch: 433 , Combined Loss: tensor(0.8884, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19018399715423584\n",
      "Batch: 434 , Combined Loss: tensor(0.9293, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0579187273979187\n",
      "Batch: 435 , Combined Loss: tensor(0.8364, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3394230604171753\n",
      "Batch: 436 , Combined Loss: tensor(0.8442, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.016179978847503662\n",
      "Batch: 437 , Combined Loss: tensor(0.8164, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.16226619482040405\n",
      "Batch: 438 , Combined Loss: tensor(0.8032, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.162045419216156\n",
      "Batch: 439 , Combined Loss: tensor(0.7767, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5637019276618958\n",
      "Batch: 440 , Combined Loss: tensor(0.9126, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20771199464797974\n",
      "Batch: 441 , Combined Loss: tensor(0.7460, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.38233059644699097\n",
      "Batch: 442 , Combined Loss: tensor(0.7796, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5589863061904907\n",
      "Batch: 443 , Combined Loss: tensor(1.0155, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.020813345909118652\n",
      "Batch: 444 , Combined Loss: tensor(0.9573, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7820752859115601\n",
      "Batch: 445 , Combined Loss: tensor(0.8237, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9065922498703003\n",
      "Batch: 446 , Combined Loss: tensor(0.8661, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23895883560180664\n",
      "Batch: 447 , Combined Loss: tensor(0.8708, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0915447473526001\n",
      "Batch: 448 , Combined Loss: tensor(0.9305, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15675556659698486\n",
      "Batch: 449 , Combined Loss: tensor(0.8092, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3446671962738037\n",
      "Batch: 450 , Combined Loss: tensor(0.9700, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17030441761016846\n",
      "Batch: 451 , Combined Loss: tensor(0.8923, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.057768940925598145\n",
      "Batch: 452 , Combined Loss: tensor(0.8320, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46827828884124756\n",
      "Batch: 453 , Combined Loss: tensor(1.0024, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3482877016067505\n",
      "Batch: 454 , Combined Loss: tensor(0.8431, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07557374238967896\n",
      "Batch: 455 , Combined Loss: tensor(0.7592, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6174468994140625\n",
      "Batch: 456 , Combined Loss: tensor(0.8356, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.38133174180984497\n",
      "Batch: 457 , Combined Loss: tensor(0.7277, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12154078483581543\n",
      "Batch: 458 , Combined Loss: tensor(0.8006, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6615076065063477\n",
      "Batch: 459 , Combined Loss: tensor(0.8397, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36552202701568604\n",
      "Batch: 460 , Combined Loss: tensor(0.8340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06387126445770264\n",
      "Batch: 461 , Combined Loss: tensor(0.7681, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7625018358230591\n",
      "Batch: 462 , Combined Loss: tensor(1.0217, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.303647518157959\n",
      "Batch: 463 , Combined Loss: tensor(0.8438, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.52485191822052\n",
      "Batch: 464 , Combined Loss: tensor(0.8029, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17091220617294312\n",
      "Batch: 465 , Combined Loss: tensor(0.7857, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15308982133865356\n",
      "Batch: 466 , Combined Loss: tensor(0.7699, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2858714461326599\n",
      "Batch: 467 , Combined Loss: tensor(0.8040, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6081527471542358\n",
      "Batch: 468 , Combined Loss: tensor(0.8519, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22429609298706055\n",
      "Batch: 469 , Combined Loss: tensor(0.8007, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4493117332458496\n",
      "Batch: 470 , Combined Loss: tensor(0.8901, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08937513828277588\n",
      "Batch: 471 , Combined Loss: tensor(0.7653, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08024215698242188\n",
      "Batch: 472 , Combined Loss: tensor(0.8077, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10286951065063477\n",
      "Batch: 473 , Combined Loss: tensor(0.7865, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3067467212677002\n",
      "Batch: 474 , Combined Loss: tensor(0.7189, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39265525341033936\n",
      "Batch: 475 , Combined Loss: tensor(0.7921, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43183422088623047\n",
      "Batch: 476 , Combined Loss: tensor(0.9279, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.34033137559890747\n",
      "Batch: 477 , Combined Loss: tensor(0.8403, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2806253433227539\n",
      "Batch: 478 , Combined Loss: tensor(0.9415, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1927272081375122\n",
      "Batch: 479 , Combined Loss: tensor(0.8637, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5704349279403687\n",
      "Batch: 480 , Combined Loss: tensor(0.7834, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6515023708343506\n",
      "Batch: 481 , Combined Loss: tensor(0.8440, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19049525260925293\n",
      "Batch: 482 , Combined Loss: tensor(0.7690, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5316404104232788\n",
      "Batch: 483 , Combined Loss: tensor(0.8052, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3933802843093872\n",
      "Batch: 484 , Combined Loss: tensor(0.7920, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09257841110229492\n",
      "Batch: 485 , Combined Loss: tensor(0.8228, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3014429807662964\n",
      "Batch: 486 , Combined Loss: tensor(0.8673, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07281935214996338\n",
      "Batch: 487 , Combined Loss: tensor(0.9290, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4736005663871765\n",
      "Batch: 488 , Combined Loss: tensor(0.7603, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09064626693725586\n",
      "Batch: 489 , Combined Loss: tensor(0.7885, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6034904718399048\n",
      "Batch: 490 , Combined Loss: tensor(0.7588, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2603762745857239\n",
      "Batch: 491 , Combined Loss: tensor(0.7989, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5152281522750854\n",
      "Batch: 492 , Combined Loss: tensor(0.8384, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4407937526702881\n",
      "Batch: 493 , Combined Loss: tensor(0.8013, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16630268096923828\n",
      "Batch: 494 , Combined Loss: tensor(0.8503, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41492903232574463\n",
      "Batch: 495 , Combined Loss: tensor(0.9913, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12227702140808105\n",
      "Batch: 496 , Combined Loss: tensor(0.8990, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.486336350440979\n",
      "Batch: 497 , Combined Loss: tensor(0.7448, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3438795208930969\n",
      "Batch: 498 , Combined Loss: tensor(0.9006, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4238549470901489\n",
      "Batch: 499 , Combined Loss: tensor(0.7683, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1138492226600647\n",
      "Batch: 500 , Combined Loss: tensor(0.7734, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12376236915588379\n",
      "Batch: 501 , Combined Loss: tensor(0.8721, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7269315719604492\n",
      "Batch: 502 , Combined Loss: tensor(0.7620, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3812819719314575\n",
      "Batch: 503 , Combined Loss: tensor(0.9474, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4130697250366211\n",
      "Batch: 504 , Combined Loss: tensor(0.7823, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.013765335083007812\n",
      "Batch: 505 , Combined Loss: tensor(0.7824, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1813119649887085\n",
      "Batch: 506 , Combined Loss: tensor(0.8182, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5826423168182373\n",
      "Batch: 507 , Combined Loss: tensor(0.8630, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3883482813835144\n",
      "Batch: 508 , Combined Loss: tensor(0.8183, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.028586983680725098\n",
      "Batch: 509 , Combined Loss: tensor(0.7880, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05721855163574219\n",
      "Batch: 510 , Combined Loss: tensor(0.7591, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18873298168182373\n",
      "Batch: 511 , Combined Loss: tensor(0.8112, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5732033848762512\n",
      "Batch: 512 , Combined Loss: tensor(0.8193, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5337555408477783\n",
      "Batch: 513 , Combined Loss: tensor(0.9010, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8185687065124512\n",
      "Batch: 514 , Combined Loss: tensor(0.7693, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5486670732498169\n",
      "Batch: 515 , Combined Loss: tensor(0.8161, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39265942573547363\n",
      "Batch: 516 , Combined Loss: tensor(0.7686, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3647216558456421\n",
      "Batch: 517 , Combined Loss: tensor(1.0050, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11021578311920166\n",
      "Batch: 518 , Combined Loss: tensor(0.8153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.697372317314148\n",
      "Batch: 519 , Combined Loss: tensor(0.7271, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14676380157470703\n",
      "Batch: 520 , Combined Loss: tensor(1.1434, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14258122444152832\n",
      "Batch: 521 , Combined Loss: tensor(0.8615, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48850560188293457\n",
      "Batch: 522 , Combined Loss: tensor(0.7740, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0651097297668457\n",
      "Batch: 523 , Combined Loss: tensor(0.7847, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5031989812850952\n",
      "Batch: 524 , Combined Loss: tensor(0.8788, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6108801364898682\n",
      "Batch: 525 , Combined Loss: tensor(0.7957, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5806567668914795\n",
      "Batch: 526 , Combined Loss: tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11096537113189697\n",
      "Batch: 527 , Combined Loss: tensor(1.1572, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11760973930358887\n",
      "Batch: 528 , Combined Loss: tensor(0.7882, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3312302827835083\n",
      "Batch: 529 , Combined Loss: tensor(0.8145, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21582210063934326\n",
      "Batch: 530 , Combined Loss: tensor(0.8540, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.051127731800079346\n",
      "Batch: 531 , Combined Loss: tensor(0.7775, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3459968566894531\n",
      "Batch: 532 , Combined Loss: tensor(0.8546, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2872201204299927\n",
      "Batch: 533 , Combined Loss: tensor(0.9071, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30581021308898926\n",
      "Batch: 534 , Combined Loss: tensor(0.8480, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4085872173309326\n",
      "Batch: 535 , Combined Loss: tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.029846668243408203\n",
      "Batch: 536 , Combined Loss: tensor(0.7246, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.27761727571487427\n",
      "Batch: 537 , Combined Loss: tensor(0.9069, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.34922826290130615\n",
      "Batch: 538 , Combined Loss: tensor(0.8240, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5347400903701782\n",
      "Batch: 539 , Combined Loss: tensor(0.8767, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32317960262298584\n",
      "Batch: 540 , Combined Loss: tensor(0.7965, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5639649629592896\n",
      "Batch: 541 , Combined Loss: tensor(0.8510, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4182562828063965\n",
      "Batch: 542 , Combined Loss: tensor(0.8207, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08475887775421143\n",
      "Batch: 543 , Combined Loss: tensor(0.7397, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2936856746673584\n",
      "Batch: 544 , Combined Loss: tensor(0.7613, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2984668016433716\n",
      "Batch: 545 , Combined Loss: tensor(0.7490, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5551513433456421\n",
      "Batch: 546 , Combined Loss: tensor(0.7802, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8305356502532959\n",
      "Batch: 547 , Combined Loss: tensor(1.0054, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5040701627731323\n",
      "Batch: 548 , Combined Loss: tensor(0.8628, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.006895840167999268\n",
      "Batch: 549 , Combined Loss: tensor(0.8281, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1390320062637329\n",
      "Batch: 550 , Combined Loss: tensor(0.8943, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5877735614776611\n",
      "Batch: 551 , Combined Loss: tensor(0.7800, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.022237062454223633\n",
      "Batch: 552 , Combined Loss: tensor(0.7594, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6056878566741943\n",
      "Batch: 553 , Combined Loss: tensor(0.8116, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.012883007526397705\n",
      "Batch: 554 , Combined Loss: tensor(0.8157, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.44264328479766846\n",
      "Batch: 555 , Combined Loss: tensor(0.7763, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34682393074035645\n",
      "Batch: 556 , Combined Loss: tensor(0.7098, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0469968318939209\n",
      "Batch: 557 , Combined Loss: tensor(0.8394, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4255990982055664\n",
      "Batch: 558 , Combined Loss: tensor(0.7824, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7666722536087036\n",
      "Batch: 559 , Combined Loss: tensor(0.9740, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5105471611022949\n",
      "Batch: 560 , Combined Loss: tensor(0.7673, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2335498332977295\n",
      "Batch: 561 , Combined Loss: tensor(0.6860, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30870795249938965\n",
      "Batch: 562 , Combined Loss: tensor(0.7995, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7412571907043457\n",
      "Batch: 563 , Combined Loss: tensor(0.7356, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6176755428314209\n",
      "Batch: 564 , Combined Loss: tensor(0.8034, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6206181049346924\n",
      "Batch: 565 , Combined Loss: tensor(0.8439, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1149970293045044\n",
      "Batch: 566 , Combined Loss: tensor(0.8657, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6320855617523193\n",
      "Batch: 567 , Combined Loss: tensor(0.8078, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7477920055389404\n",
      "Batch: 568 , Combined Loss: tensor(0.7839, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.499911904335022\n",
      "Batch: 569 , Combined Loss: tensor(0.8149, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.712145209312439\n",
      "Batch: 570 , Combined Loss: tensor(0.8453, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06950783729553223\n",
      "Batch: 571 , Combined Loss: tensor(0.7501, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8811907768249512\n",
      "Batch: 572 , Combined Loss: tensor(0.7518, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5129257440567017\n",
      "Batch: 573 , Combined Loss: tensor(0.8140, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.25922876596450806\n",
      "Batch: 574 , Combined Loss: tensor(0.7201, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9000093936920166\n",
      "Batch: 575 , Combined Loss: tensor(0.7403, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06027793884277344\n",
      "Batch: 576 , Combined Loss: tensor(0.8172, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3498215675354004\n",
      "Batch: 577 , Combined Loss: tensor(0.6563, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04266202449798584\n",
      "Batch: 578 , Combined Loss: tensor(1.1808, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10005789995193481\n",
      "Batch: 579 , Combined Loss: tensor(0.9465, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24971354007720947\n",
      "Batch: 580 , Combined Loss: tensor(0.7759, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9814881086349487\n",
      "Batch: 581 , Combined Loss: tensor(0.8061, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3555382490158081\n",
      "Batch: 582 , Combined Loss: tensor(0.7194, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.40068066120147705\n",
      "Batch: 583 , Combined Loss: tensor(0.7672, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9044312238693237\n",
      "Batch: 584 , Combined Loss: tensor(0.9296, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15008533000946045\n",
      "Batch: 585 , Combined Loss: tensor(0.7355, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0772026777267456\n",
      "Batch: 586 , Combined Loss: tensor(0.7364, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11922347545623779\n",
      "Batch: 587 , Combined Loss: tensor(1.2203, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.299633264541626\n",
      "Batch: 588 , Combined Loss: tensor(0.6954, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5425254106521606\n",
      "Batch: 589 , Combined Loss: tensor(0.7392, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7701667547225952\n",
      "Batch: 590 , Combined Loss: tensor(1.2773, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3910841941833496\n",
      "Batch: 591 , Combined Loss: tensor(0.7236, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1593613624572754\n",
      "Batch: 592 , Combined Loss: tensor(0.7549, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17541682720184326\n",
      "Batch: 593 , Combined Loss: tensor(0.8788, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7288661003112793\n",
      "Batch: 594 , Combined Loss: tensor(0.8508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3990187644958496\n",
      "Batch: 595 , Combined Loss: tensor(0.8108, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6144341230392456\n",
      "Batch: 596 , Combined Loss: tensor(0.9380, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1064378023147583\n",
      "Batch: 597 , Combined Loss: tensor(0.9795, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08700597286224365\n",
      "Batch: 598 , Combined Loss: tensor(0.7276, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6954658031463623\n",
      "Batch: 599 , Combined Loss: tensor(0.7361, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2662850618362427\n",
      "Batch: 600 , Combined Loss: tensor(0.7812, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6703923940658569\n",
      "Batch: 601 , Combined Loss: tensor(0.7442, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5237467288970947\n",
      "Batch: 602 , Combined Loss: tensor(0.9429, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3858489990234375\n",
      "Batch: 603 , Combined Loss: tensor(0.7515, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.742953896522522\n",
      "Batch: 604 , Combined Loss: tensor(0.6977, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1745823621749878\n",
      "Batch: 605 , Combined Loss: tensor(0.8619, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3574584126472473\n",
      "Batch: 606 , Combined Loss: tensor(0.9476, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3947632908821106\n",
      "Batch: 607 , Combined Loss: tensor(1.0244, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14020752906799316\n",
      "Batch: 608 , Combined Loss: tensor(0.7182, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5604827404022217\n",
      "Batch: 609 , Combined Loss: tensor(0.7544, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10740363597869873\n",
      "Batch: 610 , Combined Loss: tensor(0.8204, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20366311073303223\n",
      "Batch: 611 , Combined Loss: tensor(0.8466, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24394845962524414\n",
      "Batch: 612 , Combined Loss: tensor(0.9851, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6800482273101807\n",
      "Batch: 613 , Combined Loss: tensor(1.0037, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08641523122787476\n",
      "Batch: 614 , Combined Loss: tensor(0.8322, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09031295776367188\n",
      "Batch: 615 , Combined Loss: tensor(0.9177, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1355513334274292\n",
      "Batch: 616 , Combined Loss: tensor(0.8620, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.640558123588562\n",
      "Batch: 617 , Combined Loss: tensor(0.9551, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4894092082977295\n",
      "Batch: 618 , Combined Loss: tensor(0.9420, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.01638197898864746\n",
      "Batch: 619 , Combined Loss: tensor(0.8096, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.42288434505462646\n",
      "Batch: 620 , Combined Loss: tensor(0.7545, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7532254457473755\n",
      "Batch: 621 , Combined Loss: tensor(0.8928, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.771093487739563\n",
      "Batch: 622 , Combined Loss: tensor(0.7880, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5597418546676636\n",
      "Batch: 623 , Combined Loss: tensor(0.8079, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4835611581802368\n",
      "Batch: 624 , Combined Loss: tensor(1.0086, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16745567321777344\n",
      "Batch: 625 , Combined Loss: tensor(1.0053, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.017563462257385254\n",
      "Batch: 626 , Combined Loss: tensor(0.8513, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4572041630744934\n",
      "Batch: 627 , Combined Loss: tensor(0.6938, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3193475008010864\n",
      "Batch: 628 , Combined Loss: tensor(0.8312, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15246033668518066\n",
      "----------Epoch 5, Loss: 0.8417909831424586, Accuracy: 0.9043277314433232, Dice Coef: [0.9520515582519798, 0.3471914602569659, 0.41239101547299123, 0.37253904177102093], Dice Coef Necrotic: 0.36415724262534055, Dice Coef Edema: 0.388776135384474, Dice Coef Enhancing: 0.31752862001274257, Sensitivity: [0.9107544199461399, 0.5781025431335541, 0.7895904779730332, 0.8353829852968679], Specificity: [0.9668096778692237, 0.9926837069620578, 0.9408304747223665, 0.9705785385944506], Precision: [0.9980818856691139, 0.32144514683677583, 0.3062206648851236, 0.26417868902792213]\n",
      "Saving without nn.DataParallel\n",
      "Batch: 0 , Combined Loss: tensor(0.8060, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23334848880767822\n",
      "Batch: 1 , Combined Loss: tensor(0.8497, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7168192863464355\n",
      "Batch: 2 , Combined Loss: tensor(0.8433, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49368035793304443\n",
      "Batch: 3 , Combined Loss: tensor(0.7933, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7009278535842896\n",
      "Batch: 4 , Combined Loss: tensor(0.7920, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14252841472625732\n",
      "Batch: 5 , Combined Loss: tensor(0.8182, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37129080295562744\n",
      "Batch: 6 , Combined Loss: tensor(0.8219, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2544447183609009\n",
      "Batch: 7 , Combined Loss: tensor(0.8098, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.804497241973877\n",
      "Batch: 8 , Combined Loss: tensor(0.9800, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0936734676361084\n",
      "Batch: 9 , Combined Loss: tensor(0.9814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07161110639572144\n",
      "Batch: 10 , Combined Loss: tensor(0.7830, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7854024171829224\n",
      "Batch: 11 , Combined Loss: tensor(0.7281, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5736651420593262\n",
      "Batch: 12 , Combined Loss: tensor(0.7367, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4434815049171448\n",
      "Batch: 13 , Combined Loss: tensor(0.7826, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40466976165771484\n",
      "Batch: 14 , Combined Loss: tensor(0.8064, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05841749906539917\n",
      "Batch: 15 , Combined Loss: tensor(0.7520, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3013284206390381\n",
      "Batch: 16 , Combined Loss: tensor(0.9816, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7335491180419922\n",
      "Batch: 17 , Combined Loss: tensor(0.7739, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.023762166500091553\n",
      "Batch: 18 , Combined Loss: tensor(0.7894, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14859187602996826\n",
      "Batch: 19 , Combined Loss: tensor(0.9512, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.053071677684783936\n",
      "Batch: 20 , Combined Loss: tensor(0.7613, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.004055380821228027\n",
      "Batch: 21 , Combined Loss: tensor(0.8932, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1377115249633789\n",
      "Batch: 22 , Combined Loss: tensor(0.7997, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5228657722473145\n",
      "Batch: 23 , Combined Loss: tensor(0.7510, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.345470666885376\n",
      "Batch: 24 , Combined Loss: tensor(0.7272, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19176572561264038\n",
      "Batch: 25 , Combined Loss: tensor(0.9149, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20505666732788086\n",
      "Batch: 26 , Combined Loss: tensor(0.8316, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.49610090255737305\n",
      "Batch: 27 , Combined Loss: tensor(0.9210, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6145926713943481\n",
      "Batch: 28 , Combined Loss: tensor(0.8443, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6560841798782349\n",
      "Batch: 29 , Combined Loss: tensor(0.9404, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27548980712890625\n",
      "Batch: 30 , Combined Loss: tensor(0.7568, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3096201419830322\n",
      "Batch: 31 , Combined Loss: tensor(0.9212, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.37913745641708374\n",
      "Batch: 32 , Combined Loss: tensor(0.7947, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4723738431930542\n",
      "Batch: 33 , Combined Loss: tensor(0.7833, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.013139724731445312\n",
      "Batch: 34 , Combined Loss: tensor(0.8643, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0027621984481811523\n",
      "Batch: 35 , Combined Loss: tensor(1.0149, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6260628700256348\n",
      "Batch: 36 , Combined Loss: tensor(0.8702, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.35314035415649414\n",
      "Batch: 37 , Combined Loss: tensor(0.7435, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12644028663635254\n",
      "Batch: 38 , Combined Loss: tensor(0.7922, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3356221318244934\n",
      "Batch: 39 , Combined Loss: tensor(0.8495, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07261049747467041\n",
      "Batch: 40 , Combined Loss: tensor(0.7809, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7393585443496704\n",
      "Batch: 41 , Combined Loss: tensor(0.7896, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0706319808959961\n",
      "Batch: 42 , Combined Loss: tensor(0.7875, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3007615804672241\n",
      "Batch: 43 , Combined Loss: tensor(0.7885, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.30604517459869385\n",
      "Batch: 44 , Combined Loss: tensor(0.7815, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6155774593353271\n",
      "Batch: 45 , Combined Loss: tensor(0.8259, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6220061779022217\n",
      "Batch: 46 , Combined Loss: tensor(0.8443, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8124635219573975\n",
      "Batch: 47 , Combined Loss: tensor(0.8491, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.051533520221710205\n",
      "Batch: 48 , Combined Loss: tensor(0.8031, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06720268726348877\n",
      "Batch: 49 , Combined Loss: tensor(0.8048, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5102025270462036\n",
      "Batch: 50 , Combined Loss: tensor(0.7363, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34413087368011475\n",
      "Batch: 51 , Combined Loss: tensor(0.8632, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2542773485183716\n",
      "Batch: 52 , Combined Loss: tensor(0.8260, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26762211322784424\n",
      "Batch: 53 , Combined Loss: tensor(0.7692, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2329561710357666\n",
      "Batch: 54 , Combined Loss: tensor(0.9306, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5688049793243408\n",
      "Batch: 55 , Combined Loss: tensor(0.7763, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2129122018814087\n",
      "Batch: 56 , Combined Loss: tensor(0.7453, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19399428367614746\n",
      "Batch: 57 , Combined Loss: tensor(0.7251, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5301297903060913\n",
      "Batch: 58 , Combined Loss: tensor(0.8865, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6082626581192017\n",
      "Batch: 59 , Combined Loss: tensor(0.7675, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40465831756591797\n",
      "Batch: 60 , Combined Loss: tensor(0.8330, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1954646110534668\n",
      "Batch: 61 , Combined Loss: tensor(0.7384, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5754705667495728\n",
      "Batch: 62 , Combined Loss: tensor(0.7617, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6535261869430542\n",
      "Batch: 63 , Combined Loss: tensor(0.7919, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1642413139343262\n",
      "Batch: 64 , Combined Loss: tensor(0.8596, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4592595100402832\n",
      "Batch: 65 , Combined Loss: tensor(0.8184, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3360099792480469\n",
      "Batch: 66 , Combined Loss: tensor(0.9082, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5040023326873779\n",
      "Batch: 67 , Combined Loss: tensor(0.7589, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3076326847076416\n",
      "Batch: 68 , Combined Loss: tensor(0.8759, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24044924974441528\n",
      "Batch: 69 , Combined Loss: tensor(0.7986, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35190296173095703\n",
      "Batch: 70 , Combined Loss: tensor(0.8781, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44589507579803467\n",
      "Batch: 71 , Combined Loss: tensor(0.8071, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35979557037353516\n",
      "Batch: 72 , Combined Loss: tensor(0.8232, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8360368013381958\n",
      "Batch: 73 , Combined Loss: tensor(0.8161, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3012371063232422\n",
      "Batch: 74 , Combined Loss: tensor(0.8884, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9626662731170654\n",
      "Batch: 75 , Combined Loss: tensor(0.8547, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7146919965744019\n",
      "Batch: 76 , Combined Loss: tensor(0.7898, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09021294116973877\n",
      "Batch: 77 , Combined Loss: tensor(0.8257, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4170936346054077\n",
      "Batch: 78 , Combined Loss: tensor(0.8990, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06253039836883545\n",
      "Batch: 79 , Combined Loss: tensor(0.8498, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5160984992980957\n",
      "Batch: 80 , Combined Loss: tensor(0.7637, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4342308044433594\n",
      "Batch: 81 , Combined Loss: tensor(0.8338, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23361635208129883\n",
      "Batch: 82 , Combined Loss: tensor(0.7860, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0135575532913208\n",
      "Batch: 83 , Combined Loss: tensor(0.7411, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15292203426361084\n",
      "Batch: 84 , Combined Loss: tensor(0.8220, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11771154403686523\n",
      "Batch: 85 , Combined Loss: tensor(0.9440, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2570706605911255\n",
      "Batch: 86 , Combined Loss: tensor(0.7803, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07005894184112549\n",
      "Batch: 87 , Combined Loss: tensor(0.9004, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1582719087600708\n",
      "Batch: 88 , Combined Loss: tensor(0.8631, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4148155450820923\n",
      "Batch: 89 , Combined Loss: tensor(0.8132, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6571882963180542\n",
      "Batch: 90 , Combined Loss: tensor(0.7566, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4806262254714966\n",
      "Batch: 91 , Combined Loss: tensor(0.7094, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1956106424331665\n",
      "Batch: 92 , Combined Loss: tensor(0.8270, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.554221510887146\n",
      "Batch: 93 , Combined Loss: tensor(0.8650, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6205011606216431\n",
      "Batch: 94 , Combined Loss: tensor(0.8069, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10875332355499268\n",
      "Batch: 95 , Combined Loss: tensor(0.8520, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3572046756744385\n",
      "Batch: 96 , Combined Loss: tensor(0.8935, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6858731508255005\n",
      "Batch: 97 , Combined Loss: tensor(0.7782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4523897171020508\n",
      "Batch: 98 , Combined Loss: tensor(0.8679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6844120025634766\n",
      "Batch: 99 , Combined Loss: tensor(0.9715, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3495337963104248\n",
      "Batch: 100 , Combined Loss: tensor(0.8610, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4761470556259155\n",
      "Batch: 101 , Combined Loss: tensor(0.8350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29653728008270264\n",
      "Batch: 102 , Combined Loss: tensor(0.8236, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5879751443862915\n",
      "Batch: 103 , Combined Loss: tensor(0.8533, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32692766189575195\n",
      "Batch: 104 , Combined Loss: tensor(0.7641, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8004152774810791\n",
      "Batch: 105 , Combined Loss: tensor(0.9079, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.013597607612609863\n",
      "Batch: 106 , Combined Loss: tensor(0.7904, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9516127109527588\n",
      "Batch: 107 , Combined Loss: tensor(0.7986, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06137800216674805\n",
      "Batch: 108 , Combined Loss: tensor(0.8115, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2944626808166504\n",
      "Batch: 109 , Combined Loss: tensor(0.7661, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3795405626296997\n",
      "Batch: 110 , Combined Loss: tensor(0.9240, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19214165210723877\n",
      "Batch: 111 , Combined Loss: tensor(0.8186, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10441482067108154\n",
      "Batch: 112 , Combined Loss: tensor(0.8577, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6766786575317383\n",
      "Batch: 113 , Combined Loss: tensor(0.7896, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5452182292938232\n",
      "Batch: 114 , Combined Loss: tensor(0.9336, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2639821767807007\n",
      "Batch: 115 , Combined Loss: tensor(0.7659, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9174032211303711\n",
      "Batch: 116 , Combined Loss: tensor(0.9104, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29498291015625\n",
      "Batch: 117 , Combined Loss: tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9715557098388672\n",
      "Batch: 118 , Combined Loss: tensor(0.7671, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.600703239440918\n",
      "Batch: 119 , Combined Loss: tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5907696485519409\n",
      "Batch: 120 , Combined Loss: tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43705499172210693\n",
      "Batch: 121 , Combined Loss: tensor(0.7697, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4791683554649353\n",
      "Batch: 122 , Combined Loss: tensor(0.9238, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.42067283391952515\n",
      "Batch: 123 , Combined Loss: tensor(0.8844, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7503572702407837\n",
      "Batch: 124 , Combined Loss: tensor(0.8005, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18465924263000488\n",
      "Batch: 125 , Combined Loss: tensor(0.8876, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07383209466934204\n",
      "Batch: 126 , Combined Loss: tensor(0.7856, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20938777923583984\n",
      "Batch: 127 , Combined Loss: tensor(0.7510, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.32809150218963623\n",
      "Batch: 128 , Combined Loss: tensor(0.9457, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07105040550231934\n",
      "Batch: 129 , Combined Loss: tensor(0.7812, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4393051862716675\n",
      "Batch: 130 , Combined Loss: tensor(0.8610, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5220789909362793\n",
      "Batch: 131 , Combined Loss: tensor(0.7177, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3518129587173462\n",
      "Batch: 132 , Combined Loss: tensor(0.7919, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5722061395645142\n",
      "Batch: 133 , Combined Loss: tensor(0.8470, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6937363147735596\n",
      "Batch: 134 , Combined Loss: tensor(0.6571, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14575481414794922\n",
      "Batch: 135 , Combined Loss: tensor(0.8497, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5425292253494263\n",
      "Batch: 136 , Combined Loss: tensor(0.7822, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18438851833343506\n",
      "Batch: 137 , Combined Loss: tensor(0.8453, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11261546611785889\n",
      "Batch: 138 , Combined Loss: tensor(0.9611, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05151987075805664\n",
      "Batch: 139 , Combined Loss: tensor(0.8829, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6551897525787354\n",
      "Batch: 140 , Combined Loss: tensor(0.9014, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4975263476371765\n",
      "Batch: 141 , Combined Loss: tensor(0.8045, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5307948589324951\n",
      "Batch: 142 , Combined Loss: tensor(0.6695, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10261988639831543\n",
      "Batch: 143 , Combined Loss: tensor(0.7455, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2773900032043457\n",
      "Batch: 144 , Combined Loss: tensor(0.8833, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4854477643966675\n",
      "Batch: 145 , Combined Loss: tensor(1.0666, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08062994480133057\n",
      "Batch: 146 , Combined Loss: tensor(0.7765, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.02965378761291504\n",
      "Batch: 147 , Combined Loss: tensor(0.7237, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.29490816593170166\n",
      "Batch: 148 , Combined Loss: tensor(0.7421, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18776988983154297\n",
      "Batch: 149 , Combined Loss: tensor(0.6945, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.578890323638916\n",
      "Batch: 150 , Combined Loss: tensor(0.7183, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3332747220993042\n",
      "Batch: 151 , Combined Loss: tensor(0.7962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7643591165542603\n",
      "Batch: 152 , Combined Loss: tensor(0.6329, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1826133131980896\n",
      "Batch: 153 , Combined Loss: tensor(0.7836, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.36836469173431396\n",
      "Batch: 154 , Combined Loss: tensor(0.9316, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7274010181427002\n",
      "Batch: 155 , Combined Loss: tensor(0.8130, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.522908091545105\n",
      "Batch: 156 , Combined Loss: tensor(0.8214, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7692539691925049\n",
      "Batch: 157 , Combined Loss: tensor(0.7251, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.348474383354187\n",
      "Batch: 158 , Combined Loss: tensor(0.9176, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28020310401916504\n",
      "Batch: 159 , Combined Loss: tensor(0.8291, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5219281911849976\n",
      "Batch: 160 , Combined Loss: tensor(0.8685, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2061213254928589\n",
      "Batch: 161 , Combined Loss: tensor(0.7340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09838628768920898\n",
      "Batch: 162 , Combined Loss: tensor(0.7493, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17962777614593506\n",
      "Batch: 163 , Combined Loss: tensor(0.7715, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5649383068084717\n",
      "Batch: 164 , Combined Loss: tensor(0.8919, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2091693878173828\n",
      "Batch: 165 , Combined Loss: tensor(0.7351, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11908197402954102\n",
      "Batch: 166 , Combined Loss: tensor(0.9311, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.015332460403442383\n",
      "Batch: 167 , Combined Loss: tensor(0.8065, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6456878185272217\n",
      "Batch: 168 , Combined Loss: tensor(0.7863, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.35284918546676636\n",
      "Batch: 169 , Combined Loss: tensor(0.8036, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5599988698959351\n",
      "Batch: 170 , Combined Loss: tensor(0.7529, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6678330898284912\n",
      "Batch: 171 , Combined Loss: tensor(0.8418, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1767643690109253\n",
      "Batch: 172 , Combined Loss: tensor(0.7263, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.27542322874069214\n",
      "Batch: 173 , Combined Loss: tensor(0.7975, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3791643977165222\n",
      "Batch: 174 , Combined Loss: tensor(0.8845, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49203574657440186\n",
      "Batch: 175 , Combined Loss: tensor(0.7430, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42052972316741943\n",
      "Batch: 176 , Combined Loss: tensor(0.9339, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14772891998291016\n",
      "Batch: 177 , Combined Loss: tensor(0.8436, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3493051528930664\n",
      "Batch: 178 , Combined Loss: tensor(1.0313, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17269879579544067\n",
      "Batch: 179 , Combined Loss: tensor(0.8164, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05330604314804077\n",
      "Batch: 180 , Combined Loss: tensor(0.9187, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12308788299560547\n",
      "Batch: 181 , Combined Loss: tensor(1.0948, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8724195957183838\n",
      "Batch: 182 , Combined Loss: tensor(0.7227, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2391892671585083\n",
      "Batch: 183 , Combined Loss: tensor(0.8729, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09791576862335205\n",
      "Batch: 184 , Combined Loss: tensor(0.8373, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4120252728462219\n",
      "Batch: 185 , Combined Loss: tensor(0.8614, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.47994285821914673\n",
      "Batch: 186 , Combined Loss: tensor(0.7800, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28101062774658203\n",
      "Batch: 187 , Combined Loss: tensor(0.9388, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08029627799987793\n",
      "Batch: 188 , Combined Loss: tensor(0.8726, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9828985929489136\n",
      "Batch: 189 , Combined Loss: tensor(0.8088, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29605114459991455\n",
      "Batch: 190 , Combined Loss: tensor(0.8339, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42751383781433105\n",
      "Batch: 191 , Combined Loss: tensor(0.7800, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40735435485839844\n",
      "Batch: 192 , Combined Loss: tensor(0.8361, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.018054187297821045\n",
      "Batch: 193 , Combined Loss: tensor(0.8165, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20284593105316162\n",
      "Batch: 194 , Combined Loss: tensor(0.7387, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44144535064697266\n",
      "Batch: 195 , Combined Loss: tensor(0.7795, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5877081155776978\n",
      "Batch: 196 , Combined Loss: tensor(0.7405, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.36307448148727417\n",
      "Batch: 197 , Combined Loss: tensor(0.8899, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4044185280799866\n",
      "Batch: 198 , Combined Loss: tensor(0.8080, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6527886390686035\n",
      "Batch: 199 , Combined Loss: tensor(0.8734, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23379111289978027\n",
      "Batch: 200 , Combined Loss: tensor(0.7389, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3449968099594116\n",
      "Batch: 201 , Combined Loss: tensor(0.8301, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49527835845947266\n",
      "Batch: 202 , Combined Loss: tensor(0.7356, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05582302808761597\n",
      "Batch: 203 , Combined Loss: tensor(0.8000, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3588210344314575\n",
      "Batch: 204 , Combined Loss: tensor(0.8329, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09296083450317383\n",
      "Batch: 205 , Combined Loss: tensor(0.8386, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09658783674240112\n",
      "Batch: 206 , Combined Loss: tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1314651370048523\n",
      "Batch: 207 , Combined Loss: tensor(0.8462, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12613558769226074\n",
      "Batch: 208 , Combined Loss: tensor(0.8161, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.021492362022399902\n",
      "Batch: 209 , Combined Loss: tensor(0.8804, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15635180473327637\n",
      "Batch: 210 , Combined Loss: tensor(0.7955, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16160297393798828\n",
      "Batch: 211 , Combined Loss: tensor(0.7454, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.16266578435897827\n",
      "Batch: 212 , Combined Loss: tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07145392894744873\n",
      "Batch: 213 , Combined Loss: tensor(0.7578, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2721836566925049\n",
      "Batch: 214 , Combined Loss: tensor(1.0300, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30002856254577637\n",
      "Batch: 215 , Combined Loss: tensor(0.7562, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21474683284759521\n",
      "Batch: 216 , Combined Loss: tensor(0.7941, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5644030570983887\n",
      "Batch: 217 , Combined Loss: tensor(0.8172, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2846963405609131\n",
      "Batch: 218 , Combined Loss: tensor(0.8226, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6677470207214355\n",
      "Batch: 219 , Combined Loss: tensor(0.8338, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03636038303375244\n",
      "Batch: 220 , Combined Loss: tensor(0.7921, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.016986608505249023\n",
      "Batch: 221 , Combined Loss: tensor(0.7718, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1938612461090088\n",
      "Batch: 222 , Combined Loss: tensor(0.8030, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7481353282928467\n",
      "Batch: 223 , Combined Loss: tensor(0.8844, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4586414098739624\n",
      "Batch: 224 , Combined Loss: tensor(0.8108, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0035384297370910645\n",
      "Batch: 225 , Combined Loss: tensor(0.9646, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34269487857818604\n",
      "Batch: 226 , Combined Loss: tensor(0.7934, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.63218754529953\n",
      "Batch: 227 , Combined Loss: tensor(0.7652, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6667664051055908\n",
      "Batch: 228 , Combined Loss: tensor(0.7866, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5890048742294312\n",
      "Batch: 229 , Combined Loss: tensor(1.0687, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3864626884460449\n",
      "Batch: 230 , Combined Loss: tensor(0.8429, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6972050666809082\n",
      "Batch: 231 , Combined Loss: tensor(0.7760, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18420052528381348\n",
      "Batch: 232 , Combined Loss: tensor(0.8249, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4990830421447754\n",
      "Batch: 233 , Combined Loss: tensor(0.9118, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3689875602722168\n",
      "Batch: 234 , Combined Loss: tensor(0.8542, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04599571228027344\n",
      "Batch: 235 , Combined Loss: tensor(0.7744, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5349918603897095\n",
      "Batch: 236 , Combined Loss: tensor(0.8174, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5355359315872192\n",
      "Batch: 237 , Combined Loss: tensor(0.8596, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05198776721954346\n",
      "Batch: 238 , Combined Loss: tensor(0.7969, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48249566555023193\n",
      "Batch: 239 , Combined Loss: tensor(0.7913, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5573145151138306\n",
      "Batch: 240 , Combined Loss: tensor(0.8068, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0014113187789916992\n",
      "Batch: 241 , Combined Loss: tensor(0.8576, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2400188446044922\n",
      "Batch: 242 , Combined Loss: tensor(0.8103, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37374114990234375\n",
      "Batch: 243 , Combined Loss: tensor(0.7829, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3600643277168274\n",
      "Batch: 244 , Combined Loss: tensor(0.8253, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7040798664093018\n",
      "Batch: 245 , Combined Loss: tensor(0.9037, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.32110291719436646\n",
      "Batch: 246 , Combined Loss: tensor(0.8017, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.003408074378967285\n",
      "Batch: 247 , Combined Loss: tensor(0.9111, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8242602348327637\n",
      "Batch: 248 , Combined Loss: tensor(0.8416, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.34619688987731934\n",
      "Batch: 249 , Combined Loss: tensor(0.8740, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.25973206758499146\n",
      "Batch: 250 , Combined Loss: tensor(0.8357, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.004770338535308838\n",
      "Batch: 251 , Combined Loss: tensor(0.8134, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07609367370605469\n",
      "Batch: 252 , Combined Loss: tensor(0.7704, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5564917325973511\n",
      "Batch: 253 , Combined Loss: tensor(0.7798, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4845888614654541\n",
      "Batch: 254 , Combined Loss: tensor(0.8116, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16253399848937988\n",
      "Batch: 255 , Combined Loss: tensor(0.7678, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3075907230377197\n",
      "Batch: 256 , Combined Loss: tensor(0.8605, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4523671865463257\n",
      "Batch: 257 , Combined Loss: tensor(0.8171, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4493809938430786\n",
      "Batch: 258 , Combined Loss: tensor(0.8616, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.43980973958969116\n",
      "Batch: 259 , Combined Loss: tensor(0.7557, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43706023693084717\n",
      "Batch: 260 , Combined Loss: tensor(0.8296, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14016848802566528\n",
      "Batch: 261 , Combined Loss: tensor(0.8021, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4691261053085327\n",
      "Batch: 262 , Combined Loss: tensor(0.8569, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18045639991760254\n",
      "Batch: 263 , Combined Loss: tensor(0.8790, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.265849232673645\n",
      "Batch: 264 , Combined Loss: tensor(0.7847, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17638826370239258\n",
      "Batch: 265 , Combined Loss: tensor(0.9949, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04849851131439209\n",
      "Batch: 266 , Combined Loss: tensor(0.7695, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9053807258605957\n",
      "Batch: 267 , Combined Loss: tensor(0.8375, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07863599061965942\n",
      "Batch: 268 , Combined Loss: tensor(0.7392, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21010857820510864\n",
      "Batch: 269 , Combined Loss: tensor(0.8837, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35158729553222656\n",
      "Batch: 270 , Combined Loss: tensor(0.8536, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18794655799865723\n",
      "Batch: 271 , Combined Loss: tensor(0.8027, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7468634843826294\n",
      "Batch: 272 , Combined Loss: tensor(0.7516, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04860734939575195\n",
      "Batch: 273 , Combined Loss: tensor(0.8280, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12035000324249268\n",
      "Batch: 274 , Combined Loss: tensor(0.7377, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4436066150665283\n",
      "Batch: 275 , Combined Loss: tensor(0.9275, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.47362422943115234\n",
      "Batch: 276 , Combined Loss: tensor(0.7917, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.273159384727478\n",
      "Batch: 277 , Combined Loss: tensor(0.9546, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.008520126342773438\n",
      "Batch: 278 , Combined Loss: tensor(0.8149, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.45142698287963867\n",
      "Batch: 279 , Combined Loss: tensor(0.8650, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.120025634765625\n",
      "Batch: 280 , Combined Loss: tensor(0.7934, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0454950332641602\n",
      "Batch: 281 , Combined Loss: tensor(0.7712, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6041778326034546\n",
      "Batch: 282 , Combined Loss: tensor(0.7692, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6869857311248779\n",
      "Batch: 283 , Combined Loss: tensor(0.7854, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7627581357955933\n",
      "Batch: 284 , Combined Loss: tensor(0.8615, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0724707841873169\n",
      "Batch: 285 , Combined Loss: tensor(0.7379, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4334526062011719\n",
      "Batch: 286 , Combined Loss: tensor(0.8545, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6158486604690552\n",
      "Batch: 287 , Combined Loss: tensor(0.8093, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45995640754699707\n",
      "Batch: 288 , Combined Loss: tensor(0.8121, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4345545768737793\n",
      "Batch: 289 , Combined Loss: tensor(0.8605, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14957523345947266\n",
      "Batch: 290 , Combined Loss: tensor(0.9484, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.058246493339538574\n",
      "Batch: 291 , Combined Loss: tensor(0.8054, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.042266130447387695\n",
      "Batch: 292 , Combined Loss: tensor(0.8628, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.46030741930007935\n",
      "Batch: 293 , Combined Loss: tensor(0.9260, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.020339250564575195\n",
      "Batch: 294 , Combined Loss: tensor(0.7087, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.373174786567688\n",
      "Batch: 295 , Combined Loss: tensor(0.9306, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09292632341384888\n",
      "Batch: 296 , Combined Loss: tensor(0.8099, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7425289154052734\n",
      "Batch: 297 , Combined Loss: tensor(0.7925, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2534096837043762\n",
      "Batch: 298 , Combined Loss: tensor(0.6601, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27293193340301514\n",
      "Batch: 299 , Combined Loss: tensor(0.8285, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5542367100715637\n",
      "Batch: 300 , Combined Loss: tensor(0.8065, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5562877655029297\n",
      "Batch: 301 , Combined Loss: tensor(0.8750, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2781558036804199\n",
      "Batch: 302 , Combined Loss: tensor(0.9099, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6009384393692017\n",
      "Batch: 303 , Combined Loss: tensor(0.8043, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3261386752128601\n",
      "Batch: 304 , Combined Loss: tensor(0.7966, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2915515899658203\n",
      "Batch: 305 , Combined Loss: tensor(1.0481, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28287529945373535\n",
      "Batch: 306 , Combined Loss: tensor(0.9611, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7239983081817627\n",
      "Batch: 307 , Combined Loss: tensor(0.7851, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46319150924682617\n",
      "Batch: 308 , Combined Loss: tensor(0.7309, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6257249116897583\n",
      "Batch: 309 , Combined Loss: tensor(0.8873, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5539711713790894\n",
      "Batch: 310 , Combined Loss: tensor(0.8737, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8273231983184814\n",
      "Batch: 311 , Combined Loss: tensor(0.8328, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05605947971343994\n",
      "Batch: 312 , Combined Loss: tensor(0.7717, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10357081890106201\n",
      "Batch: 313 , Combined Loss: tensor(0.9406, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6143530607223511\n",
      "Batch: 314 , Combined Loss: tensor(0.9143, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5007214546203613\n",
      "Batch: 315 , Combined Loss: tensor(0.9961, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8180845975875854\n",
      "Batch: 316 , Combined Loss: tensor(0.9288, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6217377185821533\n",
      "Batch: 317 , Combined Loss: tensor(0.8926, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29049086570739746\n",
      "Batch: 318 , Combined Loss: tensor(0.9133, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.591251790523529\n",
      "Batch: 319 , Combined Loss: tensor(0.7476, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07677257061004639\n",
      "Batch: 320 , Combined Loss: tensor(0.9801, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38905858993530273\n",
      "Batch: 321 , Combined Loss: tensor(0.7652, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.258539080619812\n",
      "Batch: 322 , Combined Loss: tensor(0.8024, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.48908138275146484\n",
      "Batch: 323 , Combined Loss: tensor(0.7183, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.010128378868103027\n",
      "Batch: 324 , Combined Loss: tensor(0.8451, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39972782135009766\n",
      "Batch: 325 , Combined Loss: tensor(0.8552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4480177164077759\n",
      "Batch: 326 , Combined Loss: tensor(0.8668, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20437264442443848\n",
      "Batch: 327 , Combined Loss: tensor(0.8187, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.02531808614730835\n",
      "Batch: 328 , Combined Loss: tensor(0.7697, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1393277645111084\n",
      "Batch: 329 , Combined Loss: tensor(0.7088, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12521374225616455\n",
      "Batch: 330 , Combined Loss: tensor(0.8717, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35671043395996094\n",
      "Batch: 331 , Combined Loss: tensor(0.8862, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18403935432434082\n",
      "Batch: 332 , Combined Loss: tensor(1.0361, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3565991520881653\n",
      "Batch: 333 , Combined Loss: tensor(0.9344, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16125285625457764\n",
      "Batch: 334 , Combined Loss: tensor(0.7615, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.013692498207092285\n",
      "Batch: 335 , Combined Loss: tensor(0.9718, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1880980134010315\n",
      "Batch: 336 , Combined Loss: tensor(0.9005, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1015520691871643\n",
      "Batch: 337 , Combined Loss: tensor(0.7638, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7451050281524658\n",
      "Batch: 338 , Combined Loss: tensor(0.8073, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4247032403945923\n",
      "Batch: 339 , Combined Loss: tensor(0.8228, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9746241569519043\n",
      "Batch: 340 , Combined Loss: tensor(0.9424, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06551909446716309\n",
      "Batch: 341 , Combined Loss: tensor(1.1432, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2470606565475464\n",
      "Batch: 342 , Combined Loss: tensor(1.0295, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36350321769714355\n",
      "Batch: 343 , Combined Loss: tensor(0.8408, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1508786678314209\n",
      "Batch: 344 , Combined Loss: tensor(0.6708, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1661982536315918\n",
      "Batch: 345 , Combined Loss: tensor(0.7598, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.025145411491394043\n",
      "Batch: 346 , Combined Loss: tensor(0.8277, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7126127481460571\n",
      "Batch: 347 , Combined Loss: tensor(0.7745, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29727303981781006\n",
      "Batch: 348 , Combined Loss: tensor(0.7170, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6559521555900574\n",
      "Batch: 349 , Combined Loss: tensor(1.0952, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42172181606292725\n",
      "Batch: 350 , Combined Loss: tensor(0.7375, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.440975546836853\n",
      "Batch: 351 , Combined Loss: tensor(0.7191, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2508086562156677\n",
      "Batch: 352 , Combined Loss: tensor(0.8834, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.010102689266204834\n",
      "Batch: 353 , Combined Loss: tensor(0.9049, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20366311073303223\n",
      "Batch: 354 , Combined Loss: tensor(0.8782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.30313146114349365\n",
      "Batch: 355 , Combined Loss: tensor(0.8920, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6116770505905151\n",
      "Batch: 356 , Combined Loss: tensor(0.8756, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0860031247138977\n",
      "Batch: 357 , Combined Loss: tensor(0.7605, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6796958446502686\n",
      "Batch: 358 , Combined Loss: tensor(0.9075, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.16949433088302612\n",
      "Batch: 359 , Combined Loss: tensor(0.7789, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6525435447692871\n",
      "Batch: 360 , Combined Loss: tensor(0.9302, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3820852041244507\n",
      "Batch: 361 , Combined Loss: tensor(0.7458, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7253051996231079\n",
      "Batch: 362 , Combined Loss: tensor(0.7867, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04353070259094238\n",
      "Batch: 363 , Combined Loss: tensor(0.7358, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0721876621246338\n",
      "Batch: 364 , Combined Loss: tensor(0.7558, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4949582815170288\n",
      "Batch: 365 , Combined Loss: tensor(0.7099, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4457118511199951\n",
      "Batch: 366 , Combined Loss: tensor(0.8083, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16979587078094482\n",
      "Batch: 367 , Combined Loss: tensor(0.8918, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2672746181488037\n",
      "Batch: 368 , Combined Loss: tensor(0.8437, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.017952382564544678\n",
      "Batch: 369 , Combined Loss: tensor(0.7735, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21850574016571045\n",
      "Batch: 370 , Combined Loss: tensor(0.7949, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0629723072052002\n",
      "Batch: 371 , Combined Loss: tensor(0.7630, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6852235794067383\n",
      "Batch: 372 , Combined Loss: tensor(0.7678, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.006473541259765625\n",
      "Batch: 373 , Combined Loss: tensor(0.8112, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23336780071258545\n",
      "Batch: 374 , Combined Loss: tensor(0.8217, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3835982084274292\n",
      "Batch: 375 , Combined Loss: tensor(0.9843, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05438792705535889\n",
      "Batch: 376 , Combined Loss: tensor(0.8028, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3808894157409668\n",
      "Batch: 377 , Combined Loss: tensor(0.7870, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.013306856155395508\n",
      "Batch: 378 , Combined Loss: tensor(0.8643, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49540889263153076\n",
      "Batch: 379 , Combined Loss: tensor(0.8075, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.30029672384262085\n",
      "Batch: 380 , Combined Loss: tensor(0.8758, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.705016016960144\n",
      "Batch: 381 , Combined Loss: tensor(0.7758, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5730574131011963\n",
      "Batch: 382 , Combined Loss: tensor(0.7519, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6552109718322754\n",
      "Batch: 383 , Combined Loss: tensor(0.7761, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49823248386383057\n",
      "Batch: 384 , Combined Loss: tensor(0.8007, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6711369752883911\n",
      "Batch: 385 , Combined Loss: tensor(0.7555, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6372586488723755\n",
      "Batch: 386 , Combined Loss: tensor(0.7686, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04466736316680908\n",
      "Batch: 387 , Combined Loss: tensor(0.7427, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3571951985359192\n",
      "Batch: 388 , Combined Loss: tensor(0.9036, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09032559394836426\n",
      "Batch: 389 , Combined Loss: tensor(0.7449, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4854028820991516\n",
      "Batch: 390 , Combined Loss: tensor(0.7531, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7520828247070312\n",
      "Batch: 391 , Combined Loss: tensor(0.8209, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7925550937652588\n",
      "Batch: 392 , Combined Loss: tensor(0.8164, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14265787601470947\n",
      "Batch: 393 , Combined Loss: tensor(0.7389, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3696855306625366\n",
      "Batch: 394 , Combined Loss: tensor(0.7481, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9166752099990845\n",
      "Batch: 395 , Combined Loss: tensor(0.8248, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.43401187658309937\n",
      "Batch: 396 , Combined Loss: tensor(0.9081, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46884775161743164\n",
      "Batch: 397 , Combined Loss: tensor(0.8044, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4554247260093689\n",
      "Batch: 398 , Combined Loss: tensor(0.8178, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6218103170394897\n",
      "Batch: 399 , Combined Loss: tensor(0.7338, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43922972679138184\n",
      "Batch: 400 , Combined Loss: tensor(0.8072, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6081867218017578\n",
      "Batch: 401 , Combined Loss: tensor(0.8284, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3344807028770447\n",
      "Batch: 402 , Combined Loss: tensor(0.7599, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2848381996154785\n",
      "Batch: 403 , Combined Loss: tensor(0.6982, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21959471702575684\n",
      "Batch: 404 , Combined Loss: tensor(0.9376, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.316353440284729\n",
      "Batch: 405 , Combined Loss: tensor(0.9167, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5223284959793091\n",
      "Batch: 406 , Combined Loss: tensor(0.7604, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4473312497138977\n",
      "Batch: 407 , Combined Loss: tensor(0.8023, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07598471641540527\n",
      "Batch: 408 , Combined Loss: tensor(0.7255, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3844773769378662\n",
      "Batch: 409 , Combined Loss: tensor(0.7692, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.48363804817199707\n",
      "Batch: 410 , Combined Loss: tensor(0.8061, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5678961277008057\n",
      "Batch: 411 , Combined Loss: tensor(0.9521, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.054354190826416016\n",
      "Batch: 412 , Combined Loss: tensor(0.8300, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5079998970031738\n",
      "Batch: 413 , Combined Loss: tensor(0.8947, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5010644197463989\n",
      "Batch: 414 , Combined Loss: tensor(0.8788, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3457334041595459\n",
      "Batch: 415 , Combined Loss: tensor(0.8975, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.040439724922180176\n",
      "Batch: 416 , Combined Loss: tensor(0.8006, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.41907399892807007\n",
      "Batch: 417 , Combined Loss: tensor(0.8347, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4964302182197571\n",
      "Batch: 418 , Combined Loss: tensor(0.8130, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3917323350906372\n",
      "Batch: 419 , Combined Loss: tensor(0.8139, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2575509548187256\n",
      "Batch: 420 , Combined Loss: tensor(0.8451, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3608957529067993\n",
      "Batch: 421 , Combined Loss: tensor(0.7898, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37651848793029785\n",
      "Batch: 422 , Combined Loss: tensor(0.7426, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5275777578353882\n",
      "Batch: 423 , Combined Loss: tensor(0.8161, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24048656225204468\n",
      "Batch: 424 , Combined Loss: tensor(0.8303, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24950826168060303\n",
      "Batch: 425 , Combined Loss: tensor(0.8977, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20067662000656128\n",
      "Batch: 426 , Combined Loss: tensor(0.7661, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.753166675567627\n",
      "Batch: 427 , Combined Loss: tensor(0.8135, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4863314628601074\n",
      "Batch: 428 , Combined Loss: tensor(0.7701, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.32829535007476807\n",
      "Batch: 429 , Combined Loss: tensor(0.7801, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5236403942108154\n",
      "Batch: 430 , Combined Loss: tensor(0.7991, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.023059606552124\n",
      "Batch: 431 , Combined Loss: tensor(1.0026, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26180922985076904\n",
      "Batch: 432 , Combined Loss: tensor(0.8182, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.16173821687698364\n",
      "Batch: 433 , Combined Loss: tensor(0.7941, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6251727342605591\n",
      "Batch: 434 , Combined Loss: tensor(0.8290, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3317391872406006\n",
      "Batch: 435 , Combined Loss: tensor(0.7322, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7148601412773132\n",
      "Batch: 436 , Combined Loss: tensor(0.7320, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6093677282333374\n",
      "Batch: 437 , Combined Loss: tensor(0.7504, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7787493467330933\n",
      "Batch: 438 , Combined Loss: tensor(0.7979, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2929650545120239\n",
      "Batch: 439 , Combined Loss: tensor(0.8060, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6820260286331177\n",
      "Batch: 440 , Combined Loss: tensor(0.8842, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7932184934616089\n",
      "Batch: 441 , Combined Loss: tensor(0.8715, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.170465350151062\n",
      "Batch: 442 , Combined Loss: tensor(0.9010, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8539267778396606\n",
      "Batch: 443 , Combined Loss: tensor(0.7594, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47457456588745117\n",
      "Batch: 444 , Combined Loss: tensor(0.7279, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0649240016937256\n",
      "Batch: 445 , Combined Loss: tensor(0.9989, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05715203285217285\n",
      "Batch: 446 , Combined Loss: tensor(0.8945, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07932883501052856\n",
      "Batch: 447 , Combined Loss: tensor(0.7221, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5933231115341187\n",
      "Batch: 448 , Combined Loss: tensor(0.7804, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.33777540922164917\n",
      "Batch: 449 , Combined Loss: tensor(0.9529, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6439729332923889\n",
      "Batch: 450 , Combined Loss: tensor(0.7725, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6825084686279297\n",
      "Batch: 451 , Combined Loss: tensor(0.8717, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5657922029495239\n",
      "Batch: 452 , Combined Loss: tensor(0.8539, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31479179859161377\n",
      "Batch: 453 , Combined Loss: tensor(0.7295, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8263500928878784\n",
      "Batch: 454 , Combined Loss: tensor(0.7917, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6572219133377075\n",
      "Batch: 455 , Combined Loss: tensor(0.7516, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7327786684036255\n",
      "Batch: 456 , Combined Loss: tensor(0.7662, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23281514644622803\n",
      "Batch: 457 , Combined Loss: tensor(0.8161, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6071867942810059\n",
      "Batch: 458 , Combined Loss: tensor(0.8019, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7479248046875\n",
      "Batch: 459 , Combined Loss: tensor(0.8220, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36142396926879883\n",
      "Batch: 460 , Combined Loss: tensor(1.1768, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1569579839706421\n",
      "Batch: 461 , Combined Loss: tensor(0.7955, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7709368467330933\n",
      "Batch: 462 , Combined Loss: tensor(1.0667, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4237326383590698\n",
      "Batch: 463 , Combined Loss: tensor(0.8148, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8593360185623169\n",
      "Batch: 464 , Combined Loss: tensor(0.9258, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5173788070678711\n",
      "Batch: 465 , Combined Loss: tensor(0.8266, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5927205085754395\n",
      "Batch: 466 , Combined Loss: tensor(0.8741, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7507812976837158\n",
      "Batch: 467 , Combined Loss: tensor(0.7925, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40372955799102783\n",
      "Batch: 468 , Combined Loss: tensor(0.8306, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2380685806274414\n",
      "Batch: 469 , Combined Loss: tensor(0.8713, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6976401805877686\n",
      "Batch: 470 , Combined Loss: tensor(0.8756, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07339787483215332\n",
      "Batch: 471 , Combined Loss: tensor(0.7293, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7913389205932617\n",
      "Batch: 472 , Combined Loss: tensor(0.8538, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2275230884552002\n",
      "Batch: 473 , Combined Loss: tensor(0.7644, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7720627784729004\n",
      "Batch: 474 , Combined Loss: tensor(0.7895, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7055474519729614\n",
      "Batch: 475 , Combined Loss: tensor(0.8323, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5661023855209351\n",
      "Batch: 476 , Combined Loss: tensor(0.8387, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9309078454971313\n",
      "Batch: 477 , Combined Loss: tensor(0.7773, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8940490484237671\n",
      "Batch: 478 , Combined Loss: tensor(0.7384, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09676152467727661\n",
      "Batch: 479 , Combined Loss: tensor(0.7390, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7122296094894409\n",
      "Batch: 480 , Combined Loss: tensor(0.7880, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1426682472229004\n",
      "Batch: 481 , Combined Loss: tensor(0.7462, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.583501935005188\n",
      "Batch: 482 , Combined Loss: tensor(0.8203, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5304710865020752\n",
      "Batch: 483 , Combined Loss: tensor(0.8099, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6680475473403931\n",
      "Batch: 484 , Combined Loss: tensor(0.8826, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.874671459197998\n",
      "Batch: 485 , Combined Loss: tensor(0.7196, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.015635192394256592\n",
      "Batch: 486 , Combined Loss: tensor(0.7771, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1656738519668579\n",
      "Batch: 487 , Combined Loss: tensor(0.7462, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.897297739982605\n",
      "Batch: 488 , Combined Loss: tensor(0.8969, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9609311819076538\n",
      "Batch: 489 , Combined Loss: tensor(0.7731, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9232360124588013\n",
      "Batch: 490 , Combined Loss: tensor(0.7712, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7998312711715698\n",
      "Batch: 491 , Combined Loss: tensor(0.8764, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7206900119781494\n",
      "Batch: 492 , Combined Loss: tensor(0.8125, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7663801908493042\n",
      "Batch: 493 , Combined Loss: tensor(0.7966, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3617360591888428\n",
      "Batch: 494 , Combined Loss: tensor(0.8613, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.29130232334136963\n",
      "Batch: 495 , Combined Loss: tensor(0.8483, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06271564960479736\n",
      "Batch: 496 , Combined Loss: tensor(0.7705, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3230931758880615\n",
      "Batch: 497 , Combined Loss: tensor(0.7666, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5580685138702393\n",
      "Batch: 498 , Combined Loss: tensor(0.7575, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25525963306427\n",
      "Batch: 499 , Combined Loss: tensor(0.7845, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34055113792419434\n",
      "Batch: 500 , Combined Loss: tensor(0.8873, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.434781551361084\n",
      "Batch: 501 , Combined Loss: tensor(0.7183, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0674370527267456\n",
      "Batch: 502 , Combined Loss: tensor(0.7784, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.012569189071655273\n",
      "Batch: 503 , Combined Loss: tensor(0.8548, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.769275426864624\n",
      "Batch: 504 , Combined Loss: tensor(0.7596, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.015152931213378906\n",
      "Batch: 505 , Combined Loss: tensor(0.7731, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8488787412643433\n",
      "Batch: 506 , Combined Loss: tensor(0.7643, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5259181261062622\n",
      "Batch: 507 , Combined Loss: tensor(0.8790, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6358699798583984\n",
      "Batch: 508 , Combined Loss: tensor(0.7511, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17632722854614258\n",
      "Batch: 509 , Combined Loss: tensor(0.8495, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33412158489227295\n",
      "Batch: 510 , Combined Loss: tensor(0.8833, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5537421703338623\n",
      "Batch: 511 , Combined Loss: tensor(0.8279, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2996600866317749\n",
      "Batch: 512 , Combined Loss: tensor(0.9055, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4441065192222595\n",
      "Batch: 513 , Combined Loss: tensor(0.8720, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15460491180419922\n",
      "Batch: 514 , Combined Loss: tensor(0.9110, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4314368963241577\n",
      "Batch: 515 , Combined Loss: tensor(0.7932, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2737434506416321\n",
      "Batch: 516 , Combined Loss: tensor(0.8407, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6820683479309082\n",
      "Batch: 517 , Combined Loss: tensor(1.0725, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7954083681106567\n",
      "Batch: 518 , Combined Loss: tensor(0.7411, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20279288291931152\n",
      "Batch: 519 , Combined Loss: tensor(0.7256, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6371132135391235\n",
      "Batch: 520 , Combined Loss: tensor(0.7438, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6909252405166626\n",
      "Batch: 521 , Combined Loss: tensor(0.6766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6753953695297241\n",
      "Batch: 522 , Combined Loss: tensor(0.7579, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5492497682571411\n",
      "Batch: 523 , Combined Loss: tensor(0.7381, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05659198760986328\n",
      "Batch: 524 , Combined Loss: tensor(0.8812, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5199339389801025\n",
      "Batch: 525 , Combined Loss: tensor(0.7234, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6775027513504028\n",
      "Batch: 526 , Combined Loss: tensor(0.7852, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.71474289894104\n",
      "Batch: 527 , Combined Loss: tensor(0.9104, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6794072389602661\n",
      "Batch: 528 , Combined Loss: tensor(0.9036, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12597507238388062\n",
      "Batch: 529 , Combined Loss: tensor(0.8018, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8515220880508423\n",
      "Batch: 530 , Combined Loss: tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0565831661224365\n",
      "Batch: 531 , Combined Loss: tensor(0.8624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0046961307525635\n",
      "Batch: 532 , Combined Loss: tensor(0.7655, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23414671421051025\n",
      "Batch: 533 , Combined Loss: tensor(0.6918, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7980771064758301\n",
      "Batch: 534 , Combined Loss: tensor(1.0671, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6446123123168945\n",
      "Batch: 535 , Combined Loss: tensor(0.8830, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16112005710601807\n",
      "Batch: 536 , Combined Loss: tensor(0.8677, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3812974691390991\n",
      "Batch: 537 , Combined Loss: tensor(0.7402, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46415984630584717\n",
      "Batch: 538 , Combined Loss: tensor(0.7732, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06004756689071655\n",
      "Batch: 539 , Combined Loss: tensor(0.6925, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6839954853057861\n",
      "Batch: 540 , Combined Loss: tensor(0.7872, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14806324243545532\n",
      "Batch: 541 , Combined Loss: tensor(0.7685, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42736387252807617\n",
      "Batch: 542 , Combined Loss: tensor(0.6804, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.027655482292175293\n",
      "Batch: 543 , Combined Loss: tensor(0.7997, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06207108497619629\n",
      "Batch: 544 , Combined Loss: tensor(0.7697, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.30783361196517944\n",
      "Batch: 545 , Combined Loss: tensor(0.8899, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6622822284698486\n",
      "Batch: 546 , Combined Loss: tensor(0.6751, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.852001428604126\n",
      "Batch: 547 , Combined Loss: tensor(0.8167, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3732520341873169\n",
      "Batch: 548 , Combined Loss: tensor(0.9477, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4519430994987488\n",
      "Batch: 549 , Combined Loss: tensor(1.0725, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10823863744735718\n",
      "Batch: 550 , Combined Loss: tensor(0.9556, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2350776195526123\n",
      "Batch: 551 , Combined Loss: tensor(0.6514, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.35372859239578247\n",
      "Batch: 552 , Combined Loss: tensor(0.7407, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8479758501052856\n",
      "Batch: 553 , Combined Loss: tensor(0.6832, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4359095096588135\n",
      "Batch: 554 , Combined Loss: tensor(0.7725, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22990655899047852\n",
      "Batch: 555 , Combined Loss: tensor(0.7064, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23581254482269287\n",
      "Batch: 556 , Combined Loss: tensor(0.8301, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5196110010147095\n",
      "Batch: 557 , Combined Loss: tensor(0.7379, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4438568353652954\n",
      "Batch: 558 , Combined Loss: tensor(0.7957, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7679978609085083\n",
      "Batch: 559 , Combined Loss: tensor(0.8147, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.787729024887085\n",
      "Batch: 560 , Combined Loss: tensor(1.1188, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38330256938934326\n",
      "Batch: 561 , Combined Loss: tensor(0.7946, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.01798391342163086\n",
      "Batch: 562 , Combined Loss: tensor(0.6526, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5946149826049805\n",
      "Batch: 563 , Combined Loss: tensor(0.6970, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9390226602554321\n",
      "Batch: 564 , Combined Loss: tensor(0.9133, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27717578411102295\n",
      "Batch: 565 , Combined Loss: tensor(0.7322, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4080073833465576\n",
      "Batch: 566 , Combined Loss: tensor(0.7565, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5595183372497559\n",
      "Batch: 567 , Combined Loss: tensor(0.7303, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8462153673171997\n",
      "Batch: 568 , Combined Loss: tensor(0.7633, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.53905189037323\n",
      "Batch: 569 , Combined Loss: tensor(0.7704, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4383620023727417\n",
      "Batch: 570 , Combined Loss: tensor(0.7416, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0118541717529297\n",
      "Batch: 571 , Combined Loss: tensor(0.7236, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4584275484085083\n",
      "Batch: 572 , Combined Loss: tensor(0.7805, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28111398220062256\n",
      "Batch: 573 , Combined Loss: tensor(1.2049, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5011367797851562\n",
      "Batch: 574 , Combined Loss: tensor(0.7491, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7451831102371216\n",
      "Batch: 575 , Combined Loss: tensor(0.8191, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25839877128601074\n",
      "Batch: 576 , Combined Loss: tensor(0.6991, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6779458522796631\n",
      "Batch: 577 , Combined Loss: tensor(0.7711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4263371229171753\n",
      "Batch: 578 , Combined Loss: tensor(0.7205, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23458337783813477\n",
      "Batch: 579 , Combined Loss: tensor(0.7674, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.019707322120666504\n",
      "Batch: 580 , Combined Loss: tensor(0.9294, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22218215465545654\n",
      "Batch: 581 , Combined Loss: tensor(0.7089, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4312746524810791\n",
      "Batch: 582 , Combined Loss: tensor(0.8576, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7512915134429932\n",
      "Batch: 583 , Combined Loss: tensor(0.7287, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6561777591705322\n",
      "Batch: 584 , Combined Loss: tensor(0.8031, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10380589962005615\n",
      "Batch: 585 , Combined Loss: tensor(0.8486, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6158156394958496\n",
      "Batch: 586 , Combined Loss: tensor(0.7672, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.270574688911438\n",
      "Batch: 587 , Combined Loss: tensor(0.7612, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.662245512008667\n",
      "Batch: 588 , Combined Loss: tensor(1.0073, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6832743883132935\n",
      "Batch: 589 , Combined Loss: tensor(0.7715, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44233131408691406\n",
      "Batch: 590 , Combined Loss: tensor(0.7556, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7461535930633545\n",
      "Batch: 591 , Combined Loss: tensor(0.9156, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0024862289428710938\n",
      "Batch: 592 , Combined Loss: tensor(0.7746, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0768166184425354\n",
      "Batch: 593 , Combined Loss: tensor(0.7569, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3520619869232178\n",
      "Batch: 594 , Combined Loss: tensor(0.7704, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7883346080780029\n",
      "Batch: 595 , Combined Loss: tensor(0.7940, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5468264818191528\n",
      "Batch: 596 , Combined Loss: tensor(0.9047, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0456160306930542\n",
      "Batch: 597 , Combined Loss: tensor(0.8505, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15427231788635254\n",
      "Batch: 598 , Combined Loss: tensor(0.8220, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2702378034591675\n",
      "Batch: 599 , Combined Loss: tensor(0.7597, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9357510805130005\n",
      "Batch: 600 , Combined Loss: tensor(0.7338, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6442415714263916\n",
      "Batch: 601 , Combined Loss: tensor(0.7298, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1401679515838623\n",
      "Batch: 602 , Combined Loss: tensor(0.8072, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12434756755828857\n",
      "Batch: 603 , Combined Loss: tensor(0.8514, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6166187524795532\n",
      "Batch: 604 , Combined Loss: tensor(0.8466, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.013492465019226074\n",
      "Batch: 605 , Combined Loss: tensor(0.8326, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0178757905960083\n",
      "Batch: 606 , Combined Loss: tensor(0.7838, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5406457185745239\n",
      "Batch: 607 , Combined Loss: tensor(0.8503, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.563248336315155\n",
      "Batch: 608 , Combined Loss: tensor(0.7894, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8898632526397705\n",
      "Batch: 609 , Combined Loss: tensor(0.9025, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8341718912124634\n",
      "Batch: 610 , Combined Loss: tensor(0.7967, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10256439447402954\n",
      "Batch: 611 , Combined Loss: tensor(0.8007, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9128532409667969\n",
      "Batch: 612 , Combined Loss: tensor(0.8735, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10974526405334473\n",
      "Batch: 613 , Combined Loss: tensor(0.8202, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6164385080337524\n",
      "Batch: 614 , Combined Loss: tensor(0.7711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5693042278289795\n",
      "Batch: 615 , Combined Loss: tensor(0.7305, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21928590536117554\n",
      "Batch: 616 , Combined Loss: tensor(0.8664, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.666748046875\n",
      "Batch: 617 , Combined Loss: tensor(0.8040, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5776697397232056\n",
      "Batch: 618 , Combined Loss: tensor(0.8824, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5708478689193726\n",
      "Batch: 619 , Combined Loss: tensor(0.8520, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45739758014678955\n",
      "Batch: 620 , Combined Loss: tensor(0.9293, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21872150897979736\n",
      "Batch: 621 , Combined Loss: tensor(0.8217, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07312381267547607\n",
      "Batch: 622 , Combined Loss: tensor(0.7120, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8406007289886475\n",
      "Batch: 623 , Combined Loss: tensor(0.7037, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16640734672546387\n",
      "Batch: 624 , Combined Loss: tensor(0.8084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.062342822551727295\n",
      "Batch: 625 , Combined Loss: tensor(0.7910, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3087139129638672\n",
      "Batch: 626 , Combined Loss: tensor(0.8108, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3961421847343445\n",
      "Batch: 627 , Combined Loss: tensor(0.7386, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6330864429473877\n",
      "Batch: 628 , Combined Loss: tensor(0.8907, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4683338403701782\n",
      "----------Epoch 6, Loss: 0.821439029965757, Accuracy: 0.9230606567310036, Dice Coef: [0.96259112805365, 0.36703611060537067, 0.4467115820502497, 0.4449943684845508], Dice Coef Necrotic: 0.41948509055206146, Dice Coef Edema: 0.43983437658869495, Dice Coef Enhancing: 0.35098464735282187, Sensitivity: [0.9298851600891077, 0.6211471961480262, 0.7976859379530142, 0.83456751868456], Specificity: [0.9689673582870744, 0.9925168284551138, 0.9497602336546954, 0.9808073085518065], Precision: [0.9981988128304292, 0.32662568686434723, 0.3386304822546061, 0.33558806794323914]\n",
      "Saving without nn.DataParallel\n",
      "Batch: 0 , Combined Loss: tensor(0.7590, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5083878040313721\n",
      "Batch: 1 , Combined Loss: tensor(0.8371, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.014731764793395996\n",
      "Batch: 2 , Combined Loss: tensor(0.8459, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6089812517166138\n",
      "Batch: 3 , Combined Loss: tensor(0.7589, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3370319604873657\n",
      "Batch: 4 , Combined Loss: tensor(0.8223, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7928190231323242\n",
      "Batch: 5 , Combined Loss: tensor(0.7623, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3836926221847534\n",
      "Batch: 6 , Combined Loss: tensor(0.7569, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19377171993255615\n",
      "Batch: 7 , Combined Loss: tensor(0.7697, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2547262907028198\n",
      "Batch: 8 , Combined Loss: tensor(0.7593, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7203437089920044\n",
      "Batch: 9 , Combined Loss: tensor(0.8831, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3793787956237793\n",
      "Batch: 10 , Combined Loss: tensor(0.7950, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6492922306060791\n",
      "Batch: 11 , Combined Loss: tensor(0.7644, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.01539623737335205\n",
      "Batch: 12 , Combined Loss: tensor(0.7989, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6107755899429321\n",
      "Batch: 13 , Combined Loss: tensor(0.7409, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35853493213653564\n",
      "Batch: 14 , Combined Loss: tensor(0.6983, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8103617429733276\n",
      "Batch: 15 , Combined Loss: tensor(0.8358, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.369939923286438\n",
      "Batch: 16 , Combined Loss: tensor(0.8619, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23144620656967163\n",
      "Batch: 17 , Combined Loss: tensor(0.7066, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7585365772247314\n",
      "Batch: 18 , Combined Loss: tensor(0.6910, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5887305736541748\n",
      "Batch: 19 , Combined Loss: tensor(0.7224, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5237590074539185\n",
      "Batch: 20 , Combined Loss: tensor(0.8358, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4327109456062317\n",
      "Batch: 21 , Combined Loss: tensor(0.7799, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09594887495040894\n",
      "Batch: 22 , Combined Loss: tensor(0.7774, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4281373620033264\n",
      "Batch: 23 , Combined Loss: tensor(0.8450, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2661515474319458\n",
      "Batch: 24 , Combined Loss: tensor(0.7715, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.614094614982605\n",
      "Batch: 25 , Combined Loss: tensor(0.8102, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07054758071899414\n",
      "Batch: 26 , Combined Loss: tensor(0.7433, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30368614196777344\n",
      "Batch: 27 , Combined Loss: tensor(0.8110, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7837755680084229\n",
      "Batch: 28 , Combined Loss: tensor(0.7580, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3459188938140869\n",
      "Batch: 29 , Combined Loss: tensor(0.7079, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.013382196426391602\n",
      "Batch: 30 , Combined Loss: tensor(0.7926, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9984315633773804\n",
      "Batch: 31 , Combined Loss: tensor(0.7091, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7358781099319458\n",
      "Batch: 32 , Combined Loss: tensor(0.8309, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15846574306488037\n",
      "Batch: 33 , Combined Loss: tensor(0.7325, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0007377266883850098\n",
      "Batch: 34 , Combined Loss: tensor(0.8330, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7480816841125488\n",
      "Batch: 35 , Combined Loss: tensor(1.1316, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07144677639007568\n",
      "Batch: 36 , Combined Loss: tensor(0.8306, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12403792142868042\n",
      "Batch: 37 , Combined Loss: tensor(0.8916, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11644285917282104\n",
      "Batch: 38 , Combined Loss: tensor(0.9121, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14488041400909424\n",
      "Batch: 39 , Combined Loss: tensor(0.8377, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1681651473045349\n",
      "Batch: 40 , Combined Loss: tensor(0.8404, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.43133389949798584\n",
      "Batch: 41 , Combined Loss: tensor(0.7956, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5050411224365234\n",
      "Batch: 42 , Combined Loss: tensor(0.7941, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5457288026809692\n",
      "Batch: 43 , Combined Loss: tensor(0.7243, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.16408127546310425\n",
      "Batch: 44 , Combined Loss: tensor(0.7951, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2931908369064331\n",
      "Batch: 45 , Combined Loss: tensor(0.7277, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8954285383224487\n",
      "Batch: 46 , Combined Loss: tensor(0.7556, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6271220445632935\n",
      "Batch: 47 , Combined Loss: tensor(0.7901, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7314612865447998\n",
      "Batch: 48 , Combined Loss: tensor(0.7714, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5929101705551147\n",
      "Batch: 49 , Combined Loss: tensor(0.7937, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.52231764793396\n",
      "Batch: 50 , Combined Loss: tensor(0.7564, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19247543811798096\n",
      "Batch: 51 , Combined Loss: tensor(0.7972, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29884612560272217\n",
      "Batch: 52 , Combined Loss: tensor(0.6951, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4244595766067505\n",
      "Batch: 53 , Combined Loss: tensor(0.8156, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36773109436035156\n",
      "Batch: 54 , Combined Loss: tensor(0.7808, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16685771942138672\n",
      "Batch: 55 , Combined Loss: tensor(0.7177, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6145778894424438\n",
      "Batch: 56 , Combined Loss: tensor(0.8038, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6503179669380188\n",
      "Batch: 57 , Combined Loss: tensor(0.8909, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5104697942733765\n",
      "Batch: 58 , Combined Loss: tensor(0.7571, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39594173431396484\n",
      "Batch: 59 , Combined Loss: tensor(0.7405, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03279721736907959\n",
      "Batch: 60 , Combined Loss: tensor(0.7668, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.41358888149261475\n",
      "Batch: 61 , Combined Loss: tensor(0.7887, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5725290775299072\n",
      "Batch: 62 , Combined Loss: tensor(0.8751, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45854341983795166\n",
      "Batch: 63 , Combined Loss: tensor(0.7543, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9509638547897339\n",
      "Batch: 64 , Combined Loss: tensor(0.6944, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6642470359802246\n",
      "Batch: 65 , Combined Loss: tensor(0.8086, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2614859342575073\n",
      "Batch: 66 , Combined Loss: tensor(0.7946, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4718341827392578\n",
      "Batch: 67 , Combined Loss: tensor(0.7592, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3122519850730896\n",
      "Batch: 68 , Combined Loss: tensor(0.8596, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1758878231048584\n",
      "Batch: 69 , Combined Loss: tensor(0.8730, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.43536776304244995\n",
      "Batch: 70 , Combined Loss: tensor(1.1127, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2830374240875244\n",
      "Batch: 71 , Combined Loss: tensor(0.7358, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24906790256500244\n",
      "Batch: 72 , Combined Loss: tensor(0.8597, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.40021270513534546\n",
      "Batch: 73 , Combined Loss: tensor(0.8102, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9243066310882568\n",
      "Batch: 74 , Combined Loss: tensor(0.7503, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7557048797607422\n",
      "Batch: 75 , Combined Loss: tensor(0.9086, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5990020036697388\n",
      "Batch: 76 , Combined Loss: tensor(0.8933, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.285161554813385\n",
      "Batch: 77 , Combined Loss: tensor(0.7363, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6706700325012207\n",
      "Batch: 78 , Combined Loss: tensor(0.7586, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3965182304382324\n",
      "Batch: 79 , Combined Loss: tensor(0.8157, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6190277338027954\n",
      "Batch: 80 , Combined Loss: tensor(0.8368, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6507878303527832\n",
      "Batch: 81 , Combined Loss: tensor(0.8629, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19080960750579834\n",
      "Batch: 82 , Combined Loss: tensor(0.6940, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.054623425006866455\n",
      "Batch: 83 , Combined Loss: tensor(0.7649, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4723907709121704\n",
      "Batch: 84 , Combined Loss: tensor(0.7729, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3609050512313843\n",
      "Batch: 85 , Combined Loss: tensor(0.7315, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4631150960922241\n",
      "Batch: 86 , Combined Loss: tensor(0.7471, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5074150562286377\n",
      "Batch: 87 , Combined Loss: tensor(0.6876, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.479375958442688\n",
      "Batch: 88 , Combined Loss: tensor(0.8563, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7458072900772095\n",
      "Batch: 89 , Combined Loss: tensor(0.8972, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5780152082443237\n",
      "Batch: 90 , Combined Loss: tensor(0.7777, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21059322357177734\n",
      "Batch: 91 , Combined Loss: tensor(0.7105, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7134355306625366\n",
      "Batch: 92 , Combined Loss: tensor(0.7620, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6644643545150757\n",
      "Batch: 93 , Combined Loss: tensor(0.8565, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24196505546569824\n",
      "Batch: 94 , Combined Loss: tensor(0.8006, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5493232011795044\n",
      "Batch: 95 , Combined Loss: tensor(0.7805, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.18935143947601318\n",
      "Batch: 96 , Combined Loss: tensor(1.1423, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14742469787597656\n",
      "Batch: 97 , Combined Loss: tensor(0.7745, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.714157223701477\n",
      "Batch: 98 , Combined Loss: tensor(0.7828, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.754335880279541\n",
      "Batch: 99 , Combined Loss: tensor(0.9345, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.01458209753036499\n",
      "Batch: 100 , Combined Loss: tensor(0.9040, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14374542236328125\n",
      "Batch: 101 , Combined Loss: tensor(0.7020, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6113505363464355\n",
      "Batch: 102 , Combined Loss: tensor(0.7002, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4982419013977051\n",
      "Batch: 103 , Combined Loss: tensor(0.7592, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13209497928619385\n",
      "Batch: 104 , Combined Loss: tensor(1.1847, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29234981536865234\n",
      "Batch: 105 , Combined Loss: tensor(0.8687, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09169483184814453\n",
      "Batch: 106 , Combined Loss: tensor(0.8101, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2729812264442444\n",
      "Batch: 107 , Combined Loss: tensor(0.7854, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6249321699142456\n",
      "Batch: 108 , Combined Loss: tensor(0.8371, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6359677314758301\n",
      "Batch: 109 , Combined Loss: tensor(0.8160, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5297619104385376\n",
      "Batch: 110 , Combined Loss: tensor(0.7572, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37759482860565186\n",
      "Batch: 111 , Combined Loss: tensor(0.7457, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5624481439590454\n",
      "Batch: 112 , Combined Loss: tensor(0.9007, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7366259098052979\n",
      "Batch: 113 , Combined Loss: tensor(1.0063, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.380859375\n",
      "Batch: 114 , Combined Loss: tensor(0.7474, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.01629781723022461\n",
      "Batch: 115 , Combined Loss: tensor(0.9280, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6299921274185181\n",
      "Batch: 116 , Combined Loss: tensor(0.8675, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8221876621246338\n",
      "Batch: 117 , Combined Loss: tensor(0.7722, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7109525203704834\n",
      "Batch: 118 , Combined Loss: tensor(0.7023, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5017480850219727\n",
      "Batch: 119 , Combined Loss: tensor(0.9606, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5136463642120361\n",
      "Batch: 120 , Combined Loss: tensor(0.7997, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1582949161529541\n",
      "Batch: 121 , Combined Loss: tensor(0.8277, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.637184739112854\n",
      "Batch: 122 , Combined Loss: tensor(0.8319, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5831876993179321\n",
      "Batch: 123 , Combined Loss: tensor(0.7518, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7273421287536621\n",
      "Batch: 124 , Combined Loss: tensor(0.7634, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1878299117088318\n",
      "Batch: 125 , Combined Loss: tensor(0.7472, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4045168161392212\n",
      "Batch: 126 , Combined Loss: tensor(0.8299, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16400694847106934\n",
      "Batch: 127 , Combined Loss: tensor(0.8476, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48000359535217285\n",
      "Batch: 128 , Combined Loss: tensor(0.7181, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45615124702453613\n",
      "Batch: 129 , Combined Loss: tensor(0.7759, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19214165210723877\n",
      "Batch: 130 , Combined Loss: tensor(0.8693, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22339403629302979\n",
      "Batch: 131 , Combined Loss: tensor(0.9762, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.42094480991363525\n",
      "Batch: 132 , Combined Loss: tensor(0.7629, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.02520453929901123\n",
      "Batch: 133 , Combined Loss: tensor(0.7229, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1510082483291626\n",
      "Batch: 134 , Combined Loss: tensor(0.7648, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5076302289962769\n",
      "Batch: 135 , Combined Loss: tensor(0.9579, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06575685739517212\n",
      "Batch: 136 , Combined Loss: tensor(0.8682, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33580029010772705\n",
      "Batch: 137 , Combined Loss: tensor(0.7257, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06295132637023926\n",
      "Batch: 138 , Combined Loss: tensor(0.7631, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.616524875164032\n",
      "Batch: 139 , Combined Loss: tensor(0.7748, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04820692539215088\n",
      "Batch: 140 , Combined Loss: tensor(0.8489, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22219014167785645\n",
      "Batch: 141 , Combined Loss: tensor(0.8068, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4068397283554077\n",
      "Batch: 142 , Combined Loss: tensor(0.7546, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2963602542877197\n",
      "Batch: 143 , Combined Loss: tensor(0.7732, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36039769649505615\n",
      "Batch: 144 , Combined Loss: tensor(0.7864, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8225334882736206\n",
      "Batch: 145 , Combined Loss: tensor(0.8039, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37160933017730713\n",
      "Batch: 146 , Combined Loss: tensor(0.8221, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23815834522247314\n",
      "Batch: 147 , Combined Loss: tensor(0.7940, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.015265882015228271\n",
      "Batch: 148 , Combined Loss: tensor(0.9481, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.599580705165863\n",
      "Batch: 149 , Combined Loss: tensor(0.7920, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7996381521224976\n",
      "Batch: 150 , Combined Loss: tensor(0.7262, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.40339380502700806\n",
      "Batch: 151 , Combined Loss: tensor(0.8254, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3307141065597534\n",
      "Batch: 152 , Combined Loss: tensor(0.9447, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6838912963867188\n",
      "Batch: 153 , Combined Loss: tensor(0.7700, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.990455150604248\n",
      "Batch: 154 , Combined Loss: tensor(0.7893, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33517205715179443\n",
      "Batch: 155 , Combined Loss: tensor(0.6862, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4430917501449585\n",
      "Batch: 156 , Combined Loss: tensor(0.7367, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.38638561964035034\n",
      "Batch: 157 , Combined Loss: tensor(0.9263, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40638041496276855\n",
      "Batch: 158 , Combined Loss: tensor(0.8346, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22591757774353027\n",
      "Batch: 159 , Combined Loss: tensor(0.7324, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18141889572143555\n",
      "Batch: 160 , Combined Loss: tensor(0.7593, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06181865930557251\n",
      "Batch: 161 , Combined Loss: tensor(0.7914, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1032642126083374\n",
      "Batch: 162 , Combined Loss: tensor(0.7445, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6844910383224487\n",
      "Batch: 163 , Combined Loss: tensor(0.7349, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8202930688858032\n",
      "Batch: 164 , Combined Loss: tensor(0.7634, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5735715627670288\n",
      "Batch: 165 , Combined Loss: tensor(0.9216, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.294966459274292\n",
      "Batch: 166 , Combined Loss: tensor(0.7406, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5724118947982788\n",
      "Batch: 167 , Combined Loss: tensor(0.7721, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6718392372131348\n",
      "Batch: 168 , Combined Loss: tensor(0.7068, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3438706398010254\n",
      "Batch: 169 , Combined Loss: tensor(0.7648, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37772297859191895\n",
      "Batch: 170 , Combined Loss: tensor(0.7286, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7656828165054321\n",
      "Batch: 171 , Combined Loss: tensor(0.7832, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3631131649017334\n",
      "Batch: 172 , Combined Loss: tensor(0.7902, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48385512828826904\n",
      "Batch: 173 , Combined Loss: tensor(0.7905, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48546135425567627\n",
      "Batch: 174 , Combined Loss: tensor(1.0051, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42130768299102783\n",
      "Batch: 175 , Combined Loss: tensor(0.8389, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3189321756362915\n",
      "Batch: 176 , Combined Loss: tensor(0.8461, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16628074645996094\n",
      "Batch: 177 , Combined Loss: tensor(0.8730, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47805702686309814\n",
      "Batch: 178 , Combined Loss: tensor(0.7307, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4636486768722534\n",
      "Batch: 179 , Combined Loss: tensor(0.7077, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20101749897003174\n",
      "Batch: 180 , Combined Loss: tensor(0.8806, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.00301969051361084\n",
      "Batch: 181 , Combined Loss: tensor(0.9102, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.563261866569519\n",
      "Batch: 182 , Combined Loss: tensor(0.7364, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.02949810028076172\n",
      "Batch: 183 , Combined Loss: tensor(0.8528, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05770432949066162\n",
      "Batch: 184 , Combined Loss: tensor(0.7760, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13687992095947266\n",
      "Batch: 185 , Combined Loss: tensor(0.9100, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44573473930358887\n",
      "Batch: 186 , Combined Loss: tensor(0.8382, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3989587426185608\n",
      "Batch: 187 , Combined Loss: tensor(0.7425, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24485433101654053\n",
      "Batch: 188 , Combined Loss: tensor(0.8888, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6222951412200928\n",
      "Batch: 189 , Combined Loss: tensor(0.9284, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3876129388809204\n",
      "Batch: 190 , Combined Loss: tensor(0.7614, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5307167768478394\n",
      "Batch: 191 , Combined Loss: tensor(0.8388, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.894099235534668\n",
      "Batch: 192 , Combined Loss: tensor(0.7361, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.13562017679214478\n",
      "Batch: 193 , Combined Loss: tensor(0.7526, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.027288436889648438\n",
      "Batch: 194 , Combined Loss: tensor(0.7752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6958017349243164\n",
      "Batch: 195 , Combined Loss: tensor(0.7281, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7310097217559814\n",
      "Batch: 196 , Combined Loss: tensor(0.8904, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.02408730983734131\n",
      "Batch: 197 , Combined Loss: tensor(0.8015, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.252657413482666\n",
      "Batch: 198 , Combined Loss: tensor(0.7469, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6890872716903687\n",
      "Batch: 199 , Combined Loss: tensor(0.7087, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7299724817276001\n",
      "Batch: 200 , Combined Loss: tensor(0.7182, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0091744065284729\n",
      "Batch: 201 , Combined Loss: tensor(0.7962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33937859535217285\n",
      "Batch: 202 , Combined Loss: tensor(0.7915, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05016815662384033\n",
      "Batch: 203 , Combined Loss: tensor(0.7543, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9469699859619141\n",
      "Batch: 204 , Combined Loss: tensor(0.8233, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.059295713901519775\n",
      "Batch: 205 , Combined Loss: tensor(0.7389, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3446880578994751\n",
      "Batch: 206 , Combined Loss: tensor(0.7761, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7584834098815918\n",
      "Batch: 207 , Combined Loss: tensor(0.7360, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.436132550239563\n",
      "Batch: 208 , Combined Loss: tensor(0.8035, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0609617233276367\n",
      "Batch: 209 , Combined Loss: tensor(0.9637, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11790311336517334\n",
      "Batch: 210 , Combined Loss: tensor(0.8093, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3027228116989136\n",
      "Batch: 211 , Combined Loss: tensor(0.8048, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.319848895072937\n",
      "Batch: 212 , Combined Loss: tensor(0.7955, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19070971012115479\n",
      "Batch: 213 , Combined Loss: tensor(0.6811, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4122440218925476\n",
      "Batch: 214 , Combined Loss: tensor(0.9173, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14085829257965088\n",
      "Batch: 215 , Combined Loss: tensor(0.6638, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.40262359380722046\n",
      "Batch: 216 , Combined Loss: tensor(0.7855, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.00770878791809082\n",
      "Batch: 217 , Combined Loss: tensor(0.8788, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12308412790298462\n",
      "Batch: 218 , Combined Loss: tensor(0.7552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0415724515914917\n",
      "Batch: 219 , Combined Loss: tensor(1.0649, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7616287469863892\n",
      "Batch: 220 , Combined Loss: tensor(0.7857, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3367433547973633\n",
      "Batch: 221 , Combined Loss: tensor(0.8054, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5727676153182983\n",
      "Batch: 222 , Combined Loss: tensor(0.8701, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17188286781311035\n",
      "Batch: 223 , Combined Loss: tensor(0.9690, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15616381168365479\n",
      "Batch: 224 , Combined Loss: tensor(0.8260, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7254630327224731\n",
      "Batch: 225 , Combined Loss: tensor(0.8678, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.400959312915802\n",
      "Batch: 226 , Combined Loss: tensor(0.7687, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5473325252532959\n",
      "Batch: 227 , Combined Loss: tensor(0.8214, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7739784717559814\n",
      "Batch: 228 , Combined Loss: tensor(0.7757, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7534996271133423\n",
      "Batch: 229 , Combined Loss: tensor(0.8987, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6644065380096436\n",
      "Batch: 230 , Combined Loss: tensor(0.9545, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.371265709400177\n",
      "Batch: 231 , Combined Loss: tensor(0.7522, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3700564503669739\n",
      "Batch: 232 , Combined Loss: tensor(0.9066, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1619773507118225\n",
      "Batch: 233 , Combined Loss: tensor(0.7444, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0357782244682312\n",
      "Batch: 234 , Combined Loss: tensor(0.9546, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6711662411689758\n",
      "Batch: 235 , Combined Loss: tensor(0.6919, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18829572200775146\n",
      "Batch: 236 , Combined Loss: tensor(0.7491, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4757721424102783\n",
      "Batch: 237 , Combined Loss: tensor(1.1178, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12814462184906006\n",
      "Batch: 238 , Combined Loss: tensor(0.7754, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04249840974807739\n",
      "Batch: 239 , Combined Loss: tensor(0.7505, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4183802604675293\n",
      "Batch: 240 , Combined Loss: tensor(0.7833, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06391489505767822\n",
      "Batch: 241 , Combined Loss: tensor(0.7128, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42606139183044434\n",
      "Batch: 242 , Combined Loss: tensor(0.8458, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39877116680145264\n",
      "Batch: 243 , Combined Loss: tensor(0.7827, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4937552213668823\n",
      "Batch: 244 , Combined Loss: tensor(0.9057, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06909304857254028\n",
      "Batch: 245 , Combined Loss: tensor(0.8067, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43134284019470215\n",
      "Batch: 246 , Combined Loss: tensor(0.7685, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11359274387359619\n",
      "Batch: 247 , Combined Loss: tensor(0.9607, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1408294439315796\n",
      "Batch: 248 , Combined Loss: tensor(0.7273, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3745821714401245\n",
      "Batch: 249 , Combined Loss: tensor(0.7751, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5223863124847412\n",
      "Batch: 250 , Combined Loss: tensor(0.8747, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06654739379882812\n",
      "Batch: 251 , Combined Loss: tensor(0.7184, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07560104131698608\n",
      "Batch: 252 , Combined Loss: tensor(0.8067, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10494476556777954\n",
      "Batch: 253 , Combined Loss: tensor(0.8636, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06439650058746338\n",
      "Batch: 254 , Combined Loss: tensor(0.7860, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22323620319366455\n",
      "Batch: 255 , Combined Loss: tensor(0.8605, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.013845324516296387\n",
      "Batch: 256 , Combined Loss: tensor(0.8512, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06932926177978516\n",
      "Batch: 257 , Combined Loss: tensor(0.6660, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3910325765609741\n",
      "Batch: 258 , Combined Loss: tensor(0.8052, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14126384258270264\n",
      "Batch: 259 , Combined Loss: tensor(0.7812, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05698192119598389\n",
      "Batch: 260 , Combined Loss: tensor(0.8100, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20306289196014404\n",
      "Batch: 261 , Combined Loss: tensor(0.7324, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2663700580596924\n",
      "Batch: 262 , Combined Loss: tensor(0.8131, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2036120891571045\n",
      "Batch: 263 , Combined Loss: tensor(0.7799, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5907360315322876\n",
      "Batch: 264 , Combined Loss: tensor(0.7834, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8563284873962402\n",
      "Batch: 265 , Combined Loss: tensor(0.7668, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07802373170852661\n",
      "Batch: 266 , Combined Loss: tensor(0.8102, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5220136046409607\n",
      "Batch: 267 , Combined Loss: tensor(0.7885, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4051945209503174\n",
      "Batch: 268 , Combined Loss: tensor(0.8997, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19700407981872559\n",
      "Batch: 269 , Combined Loss: tensor(0.8090, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26957225799560547\n",
      "Batch: 270 , Combined Loss: tensor(0.8710, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10762298107147217\n",
      "Batch: 271 , Combined Loss: tensor(1.0510, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22710299491882324\n",
      "Batch: 272 , Combined Loss: tensor(0.7373, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.539351224899292\n",
      "Batch: 273 , Combined Loss: tensor(0.8673, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4182549715042114\n",
      "Batch: 274 , Combined Loss: tensor(0.9154, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6389374136924744\n",
      "Batch: 275 , Combined Loss: tensor(0.8799, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.463916540145874\n",
      "Batch: 276 , Combined Loss: tensor(0.8070, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.952499270439148\n",
      "Batch: 277 , Combined Loss: tensor(0.7322, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6615781784057617\n",
      "Batch: 278 , Combined Loss: tensor(0.9771, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27466869354248047\n",
      "Batch: 279 , Combined Loss: tensor(0.7224, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39910614490509033\n",
      "Batch: 280 , Combined Loss: tensor(0.8861, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2693108320236206\n",
      "Batch: 281 , Combined Loss: tensor(0.7382, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9170677661895752\n",
      "Batch: 282 , Combined Loss: tensor(0.8120, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48913681507110596\n",
      "Batch: 283 , Combined Loss: tensor(0.8019, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3375016450881958\n",
      "Batch: 284 , Combined Loss: tensor(0.7557, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.656313419342041\n",
      "Batch: 285 , Combined Loss: tensor(0.7549, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9115016460418701\n",
      "Batch: 286 , Combined Loss: tensor(0.8248, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.605940580368042\n",
      "Batch: 287 , Combined Loss: tensor(0.7853, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9309817552566528\n",
      "Batch: 288 , Combined Loss: tensor(0.8895, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45654892921447754\n",
      "Batch: 289 , Combined Loss: tensor(0.7648, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.004839897155761719\n",
      "Batch: 290 , Combined Loss: tensor(0.7459, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.301471471786499\n",
      "Batch: 291 , Combined Loss: tensor(0.8675, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17068469524383545\n",
      "Batch: 292 , Combined Loss: tensor(0.6745, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04310321807861328\n",
      "Batch: 293 , Combined Loss: tensor(0.7986, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.004961490631103516\n",
      "Batch: 294 , Combined Loss: tensor(0.8336, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3702394962310791\n",
      "Batch: 295 , Combined Loss: tensor(0.7752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6007221937179565\n",
      "Batch: 296 , Combined Loss: tensor(0.8812, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6518573760986328\n",
      "Batch: 297 , Combined Loss: tensor(0.8124, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5624161958694458\n",
      "Batch: 298 , Combined Loss: tensor(0.8350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20833897590637207\n",
      "Batch: 299 , Combined Loss: tensor(0.7514, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8088200092315674\n",
      "Batch: 300 , Combined Loss: tensor(0.7100, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5599195957183838\n",
      "Batch: 301 , Combined Loss: tensor(0.7460, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43462979793548584\n",
      "Batch: 302 , Combined Loss: tensor(0.7199, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47861993312835693\n",
      "Batch: 303 , Combined Loss: tensor(0.9218, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4260789155960083\n",
      "Batch: 304 , Combined Loss: tensor(0.7651, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5328966379165649\n",
      "Batch: 305 , Combined Loss: tensor(0.7396, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0153014659881592\n",
      "Batch: 306 , Combined Loss: tensor(0.7587, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30051231384277344\n",
      "Batch: 307 , Combined Loss: tensor(0.8881, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48117125034332275\n",
      "Batch: 308 , Combined Loss: tensor(0.7274, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18331170082092285\n",
      "Batch: 309 , Combined Loss: tensor(0.7851, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6183948516845703\n",
      "Batch: 310 , Combined Loss: tensor(0.7273, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08519935607910156\n",
      "Batch: 311 , Combined Loss: tensor(0.7907, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.41288644075393677\n",
      "Batch: 312 , Combined Loss: tensor(0.7551, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0484833717346191\n",
      "Batch: 313 , Combined Loss: tensor(0.7846, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03692913055419922\n",
      "Batch: 314 , Combined Loss: tensor(0.9648, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4075363874435425\n",
      "Batch: 315 , Combined Loss: tensor(0.7100, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33939826488494873\n",
      "Batch: 316 , Combined Loss: tensor(0.7238, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3132703900337219\n",
      "Batch: 317 , Combined Loss: tensor(0.7029, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5593440532684326\n",
      "Batch: 318 , Combined Loss: tensor(0.9950, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8017449378967285\n",
      "Batch: 319 , Combined Loss: tensor(0.7429, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3357328176498413\n",
      "Batch: 320 , Combined Loss: tensor(0.7576, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1562163233757019\n",
      "Batch: 321 , Combined Loss: tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23298633098602295\n",
      "Batch: 322 , Combined Loss: tensor(0.8332, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.34868913888931274\n",
      "Batch: 323 , Combined Loss: tensor(0.9405, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9161500930786133\n",
      "Batch: 324 , Combined Loss: tensor(0.9027, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06784522533416748\n",
      "Batch: 325 , Combined Loss: tensor(0.8906, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2882261276245117\n",
      "Batch: 326 , Combined Loss: tensor(0.7692, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.30425554513931274\n",
      "Batch: 327 , Combined Loss: tensor(0.8931, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.053721070289611816\n",
      "Batch: 328 , Combined Loss: tensor(0.9909, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20019042491912842\n",
      "Batch: 329 , Combined Loss: tensor(0.8768, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0240325927734375\n",
      "Batch: 330 , Combined Loss: tensor(0.7714, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4164189100265503\n",
      "Batch: 331 , Combined Loss: tensor(0.9181, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4658701419830322\n",
      "Batch: 332 , Combined Loss: tensor(0.7797, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05433785915374756\n",
      "Batch: 333 , Combined Loss: tensor(0.9001, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6614184379577637\n",
      "Batch: 334 , Combined Loss: tensor(0.6836, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.02530515193939209\n",
      "Batch: 335 , Combined Loss: tensor(0.6725, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3778775930404663\n",
      "Batch: 336 , Combined Loss: tensor(0.6777, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7702019214630127\n",
      "Batch: 337 , Combined Loss: tensor(0.8861, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35381221771240234\n",
      "Batch: 338 , Combined Loss: tensor(0.7375, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.346266508102417\n",
      "Batch: 339 , Combined Loss: tensor(0.8343, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4324314594268799\n",
      "Batch: 340 , Combined Loss: tensor(1.0159, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3105851411819458\n",
      "Batch: 341 , Combined Loss: tensor(0.7694, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.316239595413208\n",
      "Batch: 342 , Combined Loss: tensor(0.9198, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6404399871826172\n",
      "Batch: 343 , Combined Loss: tensor(0.7578, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21277225017547607\n",
      "Batch: 344 , Combined Loss: tensor(0.8571, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5657700300216675\n",
      "Batch: 345 , Combined Loss: tensor(0.6770, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4246087074279785\n",
      "Batch: 346 , Combined Loss: tensor(0.7696, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0491214394569397\n",
      "Batch: 347 , Combined Loss: tensor(0.9009, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6908037662506104\n",
      "Batch: 348 , Combined Loss: tensor(0.6970, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5975619554519653\n",
      "Batch: 349 , Combined Loss: tensor(1.0012, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8784587383270264\n",
      "Batch: 350 , Combined Loss: tensor(0.7653, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05215275287628174\n",
      "Batch: 351 , Combined Loss: tensor(1.1227, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5083619356155396\n",
      "Batch: 352 , Combined Loss: tensor(0.6736, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4839322566986084\n",
      "Batch: 353 , Combined Loss: tensor(0.7539, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7411233186721802\n",
      "Batch: 354 , Combined Loss: tensor(0.7791, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4643009901046753\n",
      "Batch: 355 , Combined Loss: tensor(0.9325, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6140069961547852\n",
      "Batch: 356 , Combined Loss: tensor(0.8337, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15070456266403198\n",
      "Batch: 357 , Combined Loss: tensor(0.8851, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12456178665161133\n",
      "Batch: 358 , Combined Loss: tensor(0.9890, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6639806032180786\n",
      "Batch: 359 , Combined Loss: tensor(0.7493, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.568854808807373\n",
      "Batch: 360 , Combined Loss: tensor(0.7865, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5032844543457031\n",
      "Batch: 361 , Combined Loss: tensor(0.6645, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4100673198699951\n",
      "Batch: 362 , Combined Loss: tensor(1.0789, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5757410526275635\n",
      "Batch: 363 , Combined Loss: tensor(0.7909, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9292089939117432\n",
      "Batch: 364 , Combined Loss: tensor(0.9869, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0694894790649414\n",
      "Batch: 365 , Combined Loss: tensor(0.7610, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7356681823730469\n",
      "Batch: 366 , Combined Loss: tensor(0.7525, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5410780906677246\n",
      "Batch: 367 , Combined Loss: tensor(0.8062, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3421398401260376\n",
      "Batch: 368 , Combined Loss: tensor(0.9335, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.046003103256225586\n",
      "Batch: 369 , Combined Loss: tensor(0.8209, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.300345778465271\n",
      "Batch: 370 , Combined Loss: tensor(0.8977, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1565614938735962\n",
      "Batch: 371 , Combined Loss: tensor(0.8607, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.42689210176467896\n",
      "Batch: 372 , Combined Loss: tensor(0.7492, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.040963888168335\n",
      "Batch: 373 , Combined Loss: tensor(0.7728, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6971937417984009\n",
      "Batch: 374 , Combined Loss: tensor(0.8989, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3833127021789551\n",
      "Batch: 375 , Combined Loss: tensor(0.8050, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.068758249282837\n",
      "Batch: 376 , Combined Loss: tensor(0.7976, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9205642938613892\n",
      "Batch: 377 , Combined Loss: tensor(0.7269, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7254612445831299\n",
      "Batch: 378 , Combined Loss: tensor(0.7605, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23711252212524414\n",
      "Batch: 379 , Combined Loss: tensor(0.9133, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24503576755523682\n",
      "Batch: 380 , Combined Loss: tensor(0.8861, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30539822578430176\n",
      "Batch: 381 , Combined Loss: tensor(0.8000, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.768403172492981\n",
      "Batch: 382 , Combined Loss: tensor(0.7342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7520517110824585\n",
      "Batch: 383 , Combined Loss: tensor(0.6733, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3738607168197632\n",
      "Batch: 384 , Combined Loss: tensor(0.7782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15011489391326904\n",
      "Batch: 385 , Combined Loss: tensor(0.7071, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0648300051689148\n",
      "Batch: 386 , Combined Loss: tensor(0.8592, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6646618843078613\n",
      "Batch: 387 , Combined Loss: tensor(0.7876, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0992674827575684\n",
      "Batch: 388 , Combined Loss: tensor(0.7481, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5610784292221069\n",
      "Batch: 389 , Combined Loss: tensor(0.8961, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9276756048202515\n",
      "Batch: 390 , Combined Loss: tensor(0.7725, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6087844371795654\n",
      "Batch: 391 , Combined Loss: tensor(0.8172, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4841920733451843\n",
      "Batch: 392 , Combined Loss: tensor(0.7812, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6458820104598999\n",
      "Batch: 393 , Combined Loss: tensor(0.7011, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.511772632598877\n",
      "Batch: 394 , Combined Loss: tensor(0.8111, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7029812335968018\n",
      "Batch: 395 , Combined Loss: tensor(0.7255, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.16218680143356323\n",
      "Batch: 396 , Combined Loss: tensor(0.9139, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.006559431552886963\n",
      "Batch: 397 , Combined Loss: tensor(0.7815, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.18839073181152344\n",
      "Batch: 398 , Combined Loss: tensor(0.8205, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6504740715026855\n",
      "Batch: 399 , Combined Loss: tensor(0.7313, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6986966133117676\n",
      "Batch: 400 , Combined Loss: tensor(0.8078, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6252913475036621\n",
      "Batch: 401 , Combined Loss: tensor(0.7574, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37612593173980713\n",
      "Batch: 402 , Combined Loss: tensor(0.8777, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6955471038818359\n",
      "Batch: 403 , Combined Loss: tensor(0.7114, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10848790407180786\n",
      "Batch: 404 , Combined Loss: tensor(0.7020, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3417247533798218\n",
      "Batch: 405 , Combined Loss: tensor(0.8298, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3823479413986206\n",
      "Batch: 406 , Combined Loss: tensor(0.7385, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5991197824478149\n",
      "Batch: 407 , Combined Loss: tensor(0.7421, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.545129120349884\n",
      "Batch: 408 , Combined Loss: tensor(0.7373, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09992623329162598\n",
      "Batch: 409 , Combined Loss: tensor(0.7886, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26547253131866455\n",
      "Batch: 410 , Combined Loss: tensor(0.7041, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11053788661956787\n",
      "Batch: 411 , Combined Loss: tensor(0.8056, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6107454895973206\n",
      "Batch: 412 , Combined Loss: tensor(1.0547, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34340524673461914\n",
      "Batch: 413 , Combined Loss: tensor(0.7492, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7180907726287842\n",
      "Batch: 414 , Combined Loss: tensor(0.8135, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14434385299682617\n",
      "Batch: 415 , Combined Loss: tensor(0.8049, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.784366250038147\n",
      "Batch: 416 , Combined Loss: tensor(0.7431, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9765108823776245\n",
      "Batch: 417 , Combined Loss: tensor(0.9064, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4520353078842163\n",
      "Batch: 418 , Combined Loss: tensor(0.8175, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2729443907737732\n",
      "Batch: 419 , Combined Loss: tensor(0.7924, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7382940053939819\n",
      "Batch: 420 , Combined Loss: tensor(0.7102, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1845996379852295\n",
      "Batch: 421 , Combined Loss: tensor(0.7635, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6649959087371826\n",
      "Batch: 422 , Combined Loss: tensor(0.7631, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4493098258972168\n",
      "Batch: 423 , Combined Loss: tensor(0.7241, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35541248321533203\n",
      "Batch: 424 , Combined Loss: tensor(0.9388, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5743476152420044\n",
      "Batch: 425 , Combined Loss: tensor(0.6706, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19974029064178467\n",
      "Batch: 426 , Combined Loss: tensor(0.8316, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19762837886810303\n",
      "Batch: 427 , Combined Loss: tensor(0.7373, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25861990451812744\n",
      "Batch: 428 , Combined Loss: tensor(0.7624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09362566471099854\n",
      "Batch: 429 , Combined Loss: tensor(0.7374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.42675119638442993\n",
      "Batch: 430 , Combined Loss: tensor(0.8002, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.26860547065734863\n",
      "Batch: 431 , Combined Loss: tensor(0.7960, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3727812170982361\n",
      "Batch: 432 , Combined Loss: tensor(0.8150, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.33002936840057373\n",
      "Batch: 433 , Combined Loss: tensor(0.6980, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2230677604675293\n",
      "Batch: 434 , Combined Loss: tensor(0.7764, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17004716396331787\n",
      "Batch: 435 , Combined Loss: tensor(1.0202, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0797344446182251\n",
      "Batch: 436 , Combined Loss: tensor(0.8354, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7902206182479858\n",
      "Batch: 437 , Combined Loss: tensor(0.8071, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20849311351776123\n",
      "Batch: 438 , Combined Loss: tensor(0.8709, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14238214492797852\n",
      "Batch: 439 , Combined Loss: tensor(0.8117, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03184300661087036\n",
      "Batch: 440 , Combined Loss: tensor(0.7800, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5276203155517578\n",
      "Batch: 441 , Combined Loss: tensor(0.8654, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07746171951293945\n",
      "Batch: 442 , Combined Loss: tensor(0.7943, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7803570032119751\n",
      "Batch: 443 , Combined Loss: tensor(0.9797, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21676766872406006\n",
      "Batch: 444 , Combined Loss: tensor(0.7178, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3707004189491272\n",
      "Batch: 445 , Combined Loss: tensor(0.7634, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2996046543121338\n",
      "Batch: 446 , Combined Loss: tensor(0.9042, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.01917719841003418\n",
      "Batch: 447 , Combined Loss: tensor(0.7850, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.33691346645355225\n",
      "Batch: 448 , Combined Loss: tensor(0.8921, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07454288005828857\n",
      "Batch: 449 , Combined Loss: tensor(0.6838, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42130303382873535\n",
      "Batch: 450 , Combined Loss: tensor(0.7303, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4664520025253296\n",
      "Batch: 451 , Combined Loss: tensor(0.7433, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6079995632171631\n",
      "Batch: 452 , Combined Loss: tensor(0.8727, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14650607109069824\n",
      "Batch: 453 , Combined Loss: tensor(0.8313, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07507979869842529\n",
      "Batch: 454 , Combined Loss: tensor(0.7554, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5450266599655151\n",
      "Batch: 455 , Combined Loss: tensor(0.9725, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4726628065109253\n",
      "Batch: 456 , Combined Loss: tensor(0.9368, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12180614471435547\n",
      "Batch: 457 , Combined Loss: tensor(0.7683, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.740045428276062\n",
      "Batch: 458 , Combined Loss: tensor(0.7767, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4955413341522217\n",
      "Batch: 459 , Combined Loss: tensor(0.8119, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.48329591751098633\n",
      "Batch: 460 , Combined Loss: tensor(0.8414, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45893776416778564\n",
      "Batch: 461 , Combined Loss: tensor(0.7891, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8332352638244629\n",
      "Batch: 462 , Combined Loss: tensor(0.7320, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1771094799041748\n",
      "Batch: 463 , Combined Loss: tensor(0.7471, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.020112037658691406\n",
      "Batch: 464 , Combined Loss: tensor(0.7998, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5141506195068359\n",
      "Batch: 465 , Combined Loss: tensor(0.9657, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10561347007751465\n",
      "Batch: 466 , Combined Loss: tensor(0.6205, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03786665201187134\n",
      "Batch: 467 , Combined Loss: tensor(0.8487, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1372421383857727\n",
      "Batch: 468 , Combined Loss: tensor(0.9855, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24915611743927002\n",
      "Batch: 469 , Combined Loss: tensor(0.7119, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.903612494468689\n",
      "Batch: 470 , Combined Loss: tensor(0.7245, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8160840272903442\n",
      "Batch: 471 , Combined Loss: tensor(0.8037, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6381688117980957\n",
      "Batch: 472 , Combined Loss: tensor(0.7776, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7432786226272583\n",
      "Batch: 473 , Combined Loss: tensor(0.8800, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.631446361541748\n",
      "Batch: 474 , Combined Loss: tensor(0.7313, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8321082592010498\n",
      "Batch: 475 , Combined Loss: tensor(0.8938, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7810448408126831\n",
      "Batch: 476 , Combined Loss: tensor(0.8850, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18205034732818604\n",
      "Batch: 477 , Combined Loss: tensor(0.7593, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15195071697235107\n",
      "Batch: 478 , Combined Loss: tensor(0.6269, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6985447406768799\n",
      "Batch: 479 , Combined Loss: tensor(0.8214, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7033398151397705\n",
      "Batch: 480 , Combined Loss: tensor(0.7005, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5024054050445557\n",
      "Batch: 481 , Combined Loss: tensor(0.9621, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2597525119781494\n",
      "Batch: 482 , Combined Loss: tensor(0.7478, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04178619384765625\n",
      "Batch: 483 , Combined Loss: tensor(0.7879, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38300132751464844\n",
      "Batch: 484 , Combined Loss: tensor(0.6298, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.69965660572052\n",
      "Batch: 485 , Combined Loss: tensor(0.7038, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6822311878204346\n",
      "Batch: 486 , Combined Loss: tensor(0.7445, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5985677242279053\n",
      "Batch: 487 , Combined Loss: tensor(1.0028, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.29553061723709106\n",
      "Batch: 488 , Combined Loss: tensor(1.0372, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6935899257659912\n",
      "Batch: 489 , Combined Loss: tensor(0.7905, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4207350015640259\n",
      "Batch: 490 , Combined Loss: tensor(0.7131, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6713888645172119\n",
      "Batch: 491 , Combined Loss: tensor(0.8478, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.059422969818115234\n",
      "Batch: 492 , Combined Loss: tensor(0.8342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4327334761619568\n",
      "Batch: 493 , Combined Loss: tensor(0.7410, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3917652368545532\n",
      "Batch: 494 , Combined Loss: tensor(0.8330, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7019057273864746\n",
      "Batch: 495 , Combined Loss: tensor(0.8153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5478641986846924\n",
      "Batch: 496 , Combined Loss: tensor(0.8442, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5183621644973755\n",
      "Batch: 497 , Combined Loss: tensor(0.8230, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0237648487091064\n",
      "Batch: 498 , Combined Loss: tensor(0.8153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41652989387512207\n",
      "Batch: 499 , Combined Loss: tensor(1.0092, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16877615451812744\n",
      "Batch: 500 , Combined Loss: tensor(0.6958, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08923995494842529\n",
      "Batch: 501 , Combined Loss: tensor(0.8893, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26231956481933594\n",
      "Batch: 502 , Combined Loss: tensor(0.6983, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17940247058868408\n",
      "Batch: 503 , Combined Loss: tensor(0.7693, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5811315774917603\n",
      "Batch: 504 , Combined Loss: tensor(0.7592, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4452483654022217\n",
      "Batch: 505 , Combined Loss: tensor(0.6888, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18179619312286377\n",
      "Batch: 506 , Combined Loss: tensor(0.8620, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06081247329711914\n",
      "Batch: 507 , Combined Loss: tensor(0.7402, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1687333583831787\n",
      "Batch: 508 , Combined Loss: tensor(0.7518, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1058340072631836\n",
      "Batch: 509 , Combined Loss: tensor(0.8343, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8408545255661011\n",
      "Batch: 510 , Combined Loss: tensor(0.8683, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.29694926738739014\n",
      "Batch: 511 , Combined Loss: tensor(0.7855, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4397026300430298\n",
      "Batch: 512 , Combined Loss: tensor(0.7620, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6630879640579224\n",
      "Batch: 513 , Combined Loss: tensor(0.8548, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03925275802612305\n",
      "Batch: 514 , Combined Loss: tensor(0.6880, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7381538152694702\n",
      "Batch: 515 , Combined Loss: tensor(0.8007, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4365352392196655\n",
      "Batch: 516 , Combined Loss: tensor(0.6974, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5040959119796753\n",
      "Batch: 517 , Combined Loss: tensor(0.6903, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8213180303573608\n",
      "Batch: 518 , Combined Loss: tensor(0.7899, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.02552354335784912\n",
      "Batch: 519 , Combined Loss: tensor(0.7848, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18519997596740723\n",
      "Batch: 520 , Combined Loss: tensor(0.7845, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5439941883087158\n",
      "Batch: 521 , Combined Loss: tensor(0.6969, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1391701698303223\n",
      "Batch: 522 , Combined Loss: tensor(0.8688, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4879716634750366\n",
      "Batch: 523 , Combined Loss: tensor(0.6931, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4101285934448242\n",
      "Batch: 524 , Combined Loss: tensor(0.7206, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9142370223999023\n",
      "Batch: 525 , Combined Loss: tensor(0.8282, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14388126134872437\n",
      "Batch: 526 , Combined Loss: tensor(0.9081, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6784814596176147\n",
      "Batch: 527 , Combined Loss: tensor(0.8150, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7768925428390503\n",
      "Batch: 528 , Combined Loss: tensor(0.7739, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.41807204484939575\n",
      "Batch: 529 , Combined Loss: tensor(0.6627, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7973476648330688\n",
      "Batch: 530 , Combined Loss: tensor(0.7048, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.009272098541259766\n",
      "Batch: 531 , Combined Loss: tensor(0.7214, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.054049909114837646\n",
      "Batch: 532 , Combined Loss: tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6063358783721924\n",
      "Batch: 533 , Combined Loss: tensor(0.9891, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5844312906265259\n",
      "Batch: 534 , Combined Loss: tensor(0.7334, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3481273651123047\n",
      "Batch: 535 , Combined Loss: tensor(0.7342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39767134189605713\n",
      "Batch: 536 , Combined Loss: tensor(0.7956, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6640416383743286\n",
      "Batch: 537 , Combined Loss: tensor(0.9101, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4760240316390991\n",
      "Batch: 538 , Combined Loss: tensor(0.6968, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2378387451171875\n",
      "Batch: 539 , Combined Loss: tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.006601810455322266\n",
      "Batch: 540 , Combined Loss: tensor(0.7179, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.859725832939148\n",
      "Batch: 541 , Combined Loss: tensor(0.8074, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2180672287940979\n",
      "Batch: 542 , Combined Loss: tensor(0.9821, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.249034583568573\n",
      "Batch: 543 , Combined Loss: tensor(0.7907, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7090369462966919\n",
      "Batch: 544 , Combined Loss: tensor(0.7724, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7793688774108887\n",
      "Batch: 545 , Combined Loss: tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.436396062374115\n",
      "Batch: 546 , Combined Loss: tensor(0.8278, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.32384705543518066\n",
      "Batch: 547 , Combined Loss: tensor(0.7578, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06608778238296509\n",
      "Batch: 548 , Combined Loss: tensor(0.8619, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14394009113311768\n",
      "Batch: 549 , Combined Loss: tensor(0.8095, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.720232367515564\n",
      "Batch: 550 , Combined Loss: tensor(1.1119, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3636815547943115\n",
      "Batch: 551 , Combined Loss: tensor(0.7574, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.33026933670043945\n",
      "Batch: 552 , Combined Loss: tensor(0.9705, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8194228410720825\n",
      "Batch: 553 , Combined Loss: tensor(0.8365, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5683028697967529\n",
      "Batch: 554 , Combined Loss: tensor(0.7870, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.611628532409668\n",
      "Batch: 555 , Combined Loss: tensor(0.6766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6609421968460083\n",
      "Batch: 556 , Combined Loss: tensor(0.7578, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7905713319778442\n",
      "Batch: 557 , Combined Loss: tensor(0.7024, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.44862037897109985\n",
      "Batch: 558 , Combined Loss: tensor(0.7906, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.483859121799469\n",
      "Batch: 559 , Combined Loss: tensor(0.7608, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32207250595092773\n",
      "Batch: 560 , Combined Loss: tensor(0.9011, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44597434997558594\n",
      "Batch: 561 , Combined Loss: tensor(0.7405, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5060626268386841\n",
      "Batch: 562 , Combined Loss: tensor(0.8180, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5740911960601807\n",
      "Batch: 563 , Combined Loss: tensor(0.7528, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07273751497268677\n",
      "Batch: 564 , Combined Loss: tensor(0.7562, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6916735172271729\n",
      "Batch: 565 , Combined Loss: tensor(0.6508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4845947027206421\n",
      "Batch: 566 , Combined Loss: tensor(1.0429, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.032886385917663574\n",
      "Batch: 567 , Combined Loss: tensor(1.0524, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.495100736618042\n",
      "Batch: 568 , Combined Loss: tensor(0.7251, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8645493984222412\n",
      "Batch: 569 , Combined Loss: tensor(0.7989, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5267469882965088\n",
      "Batch: 570 , Combined Loss: tensor(0.9423, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8118233680725098\n",
      "Batch: 571 , Combined Loss: tensor(0.7958, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6109503507614136\n",
      "Batch: 572 , Combined Loss: tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6508326530456543\n",
      "Batch: 573 , Combined Loss: tensor(0.8080, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5362757444381714\n",
      "Batch: 574 , Combined Loss: tensor(0.8086, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11958998441696167\n",
      "Batch: 575 , Combined Loss: tensor(0.6777, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4290398359298706\n",
      "Batch: 576 , Combined Loss: tensor(0.8393, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33664417266845703\n",
      "Batch: 577 , Combined Loss: tensor(0.7879, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2826354503631592\n",
      "Batch: 578 , Combined Loss: tensor(0.8985, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7682026624679565\n",
      "Batch: 579 , Combined Loss: tensor(0.7298, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9678987264633179\n",
      "Batch: 580 , Combined Loss: tensor(0.7073, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5549721717834473\n",
      "Batch: 581 , Combined Loss: tensor(0.6773, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18370604515075684\n",
      "Batch: 582 , Combined Loss: tensor(0.7770, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12185001373291016\n",
      "Batch: 583 , Combined Loss: tensor(0.8229, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23730647563934326\n",
      "Batch: 584 , Combined Loss: tensor(0.7938, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32028210163116455\n",
      "Batch: 585 , Combined Loss: tensor(0.7492, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06383192539215088\n",
      "Batch: 586 , Combined Loss: tensor(0.7089, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7346893548965454\n",
      "Batch: 587 , Combined Loss: tensor(0.7573, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6771070957183838\n",
      "Batch: 588 , Combined Loss: tensor(0.7546, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8325744867324829\n",
      "Batch: 589 , Combined Loss: tensor(0.7359, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4761221408843994\n",
      "Batch: 590 , Combined Loss: tensor(0.7997, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36022067070007324\n",
      "Batch: 591 , Combined Loss: tensor(0.8182, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6854195594787598\n",
      "Batch: 592 , Combined Loss: tensor(0.7559, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11627054214477539\n",
      "Batch: 593 , Combined Loss: tensor(0.7944, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5443635582923889\n",
      "Batch: 594 , Combined Loss: tensor(0.9219, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.16427546739578247\n",
      "Batch: 595 , Combined Loss: tensor(0.8252, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24339407682418823\n",
      "Batch: 596 , Combined Loss: tensor(0.7874, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09447407722473145\n",
      "Batch: 597 , Combined Loss: tensor(0.6744, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08736109733581543\n",
      "Batch: 598 , Combined Loss: tensor(0.8249, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06788468360900879\n",
      "Batch: 599 , Combined Loss: tensor(0.7079, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6681652665138245\n",
      "Batch: 600 , Combined Loss: tensor(0.7398, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13341987133026123\n",
      "Batch: 601 , Combined Loss: tensor(0.8276, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2223285436630249\n",
      "Batch: 602 , Combined Loss: tensor(0.7761, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.013889908790588379\n",
      "Batch: 603 , Combined Loss: tensor(1.0179, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4981924891471863\n",
      "Batch: 604 , Combined Loss: tensor(0.7695, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.26163703203201294\n",
      "Batch: 605 , Combined Loss: tensor(0.6779, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3098496198654175\n",
      "Batch: 606 , Combined Loss: tensor(0.7854, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6790224313735962\n",
      "Batch: 607 , Combined Loss: tensor(0.8228, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3416149616241455\n",
      "Batch: 608 , Combined Loss: tensor(0.8151, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44111454486846924\n",
      "Batch: 609 , Combined Loss: tensor(0.8064, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09560525417327881\n",
      "Batch: 610 , Combined Loss: tensor(0.7011, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2159753441810608\n",
      "Batch: 611 , Combined Loss: tensor(0.7606, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.189439058303833\n",
      "Batch: 612 , Combined Loss: tensor(0.7735, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3216739892959595\n",
      "Batch: 613 , Combined Loss: tensor(0.8276, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0002917647361755371\n",
      "Batch: 614 , Combined Loss: tensor(0.8862, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23694348335266113\n",
      "Batch: 615 , Combined Loss: tensor(0.7687, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5690373182296753\n",
      "Batch: 616 , Combined Loss: tensor(0.8592, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5677735805511475\n",
      "Batch: 617 , Combined Loss: tensor(0.8070, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15923035144805908\n",
      "Batch: 618 , Combined Loss: tensor(0.7543, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.41047435998916626\n",
      "Batch: 619 , Combined Loss: tensor(0.7188, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7228162288665771\n",
      "Batch: 620 , Combined Loss: tensor(0.7709, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4057976007461548\n",
      "Batch: 621 , Combined Loss: tensor(0.8361, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.156191885471344\n",
      "Batch: 622 , Combined Loss: tensor(1.0428, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27883732318878174\n",
      "Batch: 623 , Combined Loss: tensor(0.7187, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.38190245628356934\n",
      "Batch: 624 , Combined Loss: tensor(0.7895, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5066287517547607\n",
      "Batch: 625 , Combined Loss: tensor(0.7322, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21570295095443726\n",
      "Batch: 626 , Combined Loss: tensor(0.7591, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6277563571929932\n",
      "Batch: 627 , Combined Loss: tensor(0.8111, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07792603969573975\n",
      "Batch: 628 , Combined Loss: tensor(0.7717, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6754326820373535\n",
      "----------Epoch 7, Loss: 0.8042858419243974, Accuracy: 0.9263602599430539, Dice Coef: [0.964406989052868, 0.3832292342404014, 0.4483203483606286, 0.4704557912838304], Dice Coef Necrotic: 0.5052837648286576, Dice Coef Edema: 0.5414073147291275, Dice Coef Enhancing: 0.4347895562906147, Sensitivity: [0.9330086834100927, 0.6334105701128758, 0.8086688613995838, 0.8321722946077917], Specificity: [0.9733332424929487, 0.9935592267964337, 0.949070772988239, 0.9835763443824028], Precision: [0.9984381886847637, 0.3485016509471026, 0.3383258698317141, 0.3619663216328561]\n",
      "Saving without nn.DataParallel\n",
      "Batch: 0 , Combined Loss: tensor(0.7585, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14659863710403442\n",
      "Batch: 1 , Combined Loss: tensor(0.7599, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05559653043746948\n",
      "Batch: 2 , Combined Loss: tensor(0.7086, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7412227392196655\n",
      "Batch: 3 , Combined Loss: tensor(0.7785, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2645862102508545\n",
      "Batch: 4 , Combined Loss: tensor(0.7444, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03366732597351074\n",
      "Batch: 5 , Combined Loss: tensor(0.7680, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8875099420547485\n",
      "Batch: 6 , Combined Loss: tensor(0.7707, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3119422197341919\n",
      "Batch: 7 , Combined Loss: tensor(0.8086, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23588764667510986\n",
      "Batch: 8 , Combined Loss: tensor(0.7356, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08551084995269775\n",
      "Batch: 9 , Combined Loss: tensor(0.8627, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5030469298362732\n",
      "Batch: 10 , Combined Loss: tensor(0.8769, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7441662549972534\n",
      "Batch: 11 , Combined Loss: tensor(0.8018, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6869776248931885\n",
      "Batch: 12 , Combined Loss: tensor(0.8914, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14810705184936523\n",
      "Batch: 13 , Combined Loss: tensor(0.9474, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7736426591873169\n",
      "Batch: 14 , Combined Loss: tensor(0.8238, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0944819450378418\n",
      "Batch: 15 , Combined Loss: tensor(0.7544, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17490720748901367\n",
      "Batch: 16 , Combined Loss: tensor(0.8560, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4052777886390686\n",
      "Batch: 17 , Combined Loss: tensor(0.7428, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9530830383300781\n",
      "Batch: 18 , Combined Loss: tensor(0.7659, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9088826179504395\n",
      "Batch: 19 , Combined Loss: tensor(0.8046, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6246919631958008\n",
      "Batch: 20 , Combined Loss: tensor(0.8893, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13128423690795898\n",
      "Batch: 21 , Combined Loss: tensor(0.7525, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16532480716705322\n",
      "Batch: 22 , Combined Loss: tensor(0.7036, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5867420434951782\n",
      "Batch: 23 , Combined Loss: tensor(0.8743, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13044917583465576\n",
      "Batch: 24 , Combined Loss: tensor(0.8049, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19720935821533203\n",
      "Batch: 25 , Combined Loss: tensor(0.8587, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.625975489616394\n",
      "Batch: 26 , Combined Loss: tensor(0.6883, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.01764047145843506\n",
      "Batch: 27 , Combined Loss: tensor(0.7287, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06475830078125\n",
      "Batch: 28 , Combined Loss: tensor(0.8176, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08342897891998291\n",
      "Batch: 29 , Combined Loss: tensor(0.7249, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7306714057922363\n",
      "Batch: 30 , Combined Loss: tensor(0.7918, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2424182891845703\n",
      "Batch: 31 , Combined Loss: tensor(0.7904, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04978311061859131\n",
      "Batch: 32 , Combined Loss: tensor(0.7034, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06550776958465576\n",
      "Batch: 33 , Combined Loss: tensor(0.7711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8147029876708984\n",
      "Batch: 34 , Combined Loss: tensor(0.8215, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.655931830406189\n",
      "Batch: 35 , Combined Loss: tensor(0.8195, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5957545042037964\n",
      "Batch: 36 , Combined Loss: tensor(0.7428, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7485835552215576\n",
      "Batch: 37 , Combined Loss: tensor(0.7702, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5160874128341675\n",
      "Batch: 38 , Combined Loss: tensor(0.8122, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7432520389556885\n",
      "Batch: 39 , Combined Loss: tensor(0.7373, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5990514755249023\n",
      "Batch: 40 , Combined Loss: tensor(0.7535, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18791484832763672\n",
      "Batch: 41 , Combined Loss: tensor(0.6962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7973110675811768\n",
      "Batch: 42 , Combined Loss: tensor(0.7780, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2531929016113281\n",
      "Batch: 43 , Combined Loss: tensor(0.7530, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6885031461715698\n",
      "Batch: 44 , Combined Loss: tensor(0.6682, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21908462047576904\n",
      "Batch: 45 , Combined Loss: tensor(0.7694, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7827059030532837\n",
      "Batch: 46 , Combined Loss: tensor(0.7066, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.945828914642334\n",
      "Batch: 47 , Combined Loss: tensor(1.0305, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0029430389404296875\n",
      "Batch: 48 , Combined Loss: tensor(0.9282, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5039012432098389\n",
      "Batch: 49 , Combined Loss: tensor(0.8451, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27978456020355225\n",
      "Batch: 50 , Combined Loss: tensor(0.6759, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4444481134414673\n",
      "Batch: 51 , Combined Loss: tensor(0.7535, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6011520624160767\n",
      "Batch: 52 , Combined Loss: tensor(0.8481, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14173471927642822\n",
      "Batch: 53 , Combined Loss: tensor(0.7580, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8195285797119141\n",
      "Batch: 54 , Combined Loss: tensor(0.8667, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8345134258270264\n",
      "Batch: 55 , Combined Loss: tensor(0.7941, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.593329668045044\n",
      "Batch: 56 , Combined Loss: tensor(0.6384, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7003453969955444\n",
      "Batch: 57 , Combined Loss: tensor(0.8745, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3349311351776123\n",
      "Batch: 58 , Combined Loss: tensor(0.7701, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6075295209884644\n",
      "Batch: 59 , Combined Loss: tensor(0.9612, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05068504810333252\n",
      "Batch: 60 , Combined Loss: tensor(0.7195, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5484874248504639\n",
      "Batch: 61 , Combined Loss: tensor(0.8157, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41698741912841797\n",
      "Batch: 62 , Combined Loss: tensor(0.7598, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.025198161602020264\n",
      "Batch: 63 , Combined Loss: tensor(0.7720, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24797320365905762\n",
      "Batch: 64 , Combined Loss: tensor(0.7542, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8377249240875244\n",
      "Batch: 65 , Combined Loss: tensor(0.6715, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5634574890136719\n",
      "Batch: 66 , Combined Loss: tensor(0.6852, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4156804084777832\n",
      "Batch: 67 , Combined Loss: tensor(0.6962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08843684196472168\n",
      "Batch: 68 , Combined Loss: tensor(0.9130, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4077712297439575\n",
      "Batch: 69 , Combined Loss: tensor(0.7075, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0774295330047607\n",
      "Batch: 70 , Combined Loss: tensor(0.7402, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5972656011581421\n",
      "Batch: 71 , Combined Loss: tensor(0.7885, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1910325288772583\n",
      "Batch: 72 , Combined Loss: tensor(0.7875, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4314666986465454\n",
      "Batch: 73 , Combined Loss: tensor(0.7942, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24941504001617432\n",
      "Batch: 74 , Combined Loss: tensor(0.8070, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3755779266357422\n",
      "Batch: 75 , Combined Loss: tensor(0.8867, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17515134811401367\n",
      "Batch: 76 , Combined Loss: tensor(0.7323, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5067740678787231\n",
      "Batch: 77 , Combined Loss: tensor(1.1310, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35532331466674805\n",
      "Batch: 78 , Combined Loss: tensor(0.7552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31516945362091064\n",
      "Batch: 79 , Combined Loss: tensor(0.6785, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47883307933807373\n",
      "Batch: 80 , Combined Loss: tensor(0.7736, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22373557090759277\n",
      "Batch: 81 , Combined Loss: tensor(0.7735, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43080270290374756\n",
      "Batch: 82 , Combined Loss: tensor(0.7978, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7620642185211182\n",
      "Batch: 83 , Combined Loss: tensor(0.7663, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6059038043022156\n",
      "Batch: 84 , Combined Loss: tensor(0.7463, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49303245544433594\n",
      "Batch: 85 , Combined Loss: tensor(0.7819, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2852173447608948\n",
      "Batch: 86 , Combined Loss: tensor(0.7260, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7813303470611572\n",
      "Batch: 87 , Combined Loss: tensor(0.7882, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6833243370056152\n",
      "Batch: 88 , Combined Loss: tensor(0.7755, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21886610984802246\n",
      "Batch: 89 , Combined Loss: tensor(0.7555, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3770860433578491\n",
      "Batch: 90 , Combined Loss: tensor(0.9651, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6877371072769165\n",
      "Batch: 91 , Combined Loss: tensor(0.8776, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20299828052520752\n",
      "Batch: 92 , Combined Loss: tensor(0.9450, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5000220537185669\n",
      "Batch: 93 , Combined Loss: tensor(0.7495, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3380824327468872\n",
      "Batch: 94 , Combined Loss: tensor(0.6992, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.77366042137146\n",
      "Batch: 95 , Combined Loss: tensor(0.8797, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22877144813537598\n",
      "Batch: 96 , Combined Loss: tensor(0.7730, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3092139959335327\n",
      "Batch: 97 , Combined Loss: tensor(0.7451, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6419612169265747\n",
      "Batch: 98 , Combined Loss: tensor(0.7498, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.003102540969848633\n",
      "Batch: 99 , Combined Loss: tensor(0.7581, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7019692659378052\n",
      "Batch: 100 , Combined Loss: tensor(0.8377, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25003504753112793\n",
      "Batch: 101 , Combined Loss: tensor(0.7299, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.008286714553833\n",
      "Batch: 102 , Combined Loss: tensor(0.7922, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6118626594543457\n",
      "Batch: 103 , Combined Loss: tensor(1.0375, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6046521663665771\n",
      "Batch: 104 , Combined Loss: tensor(0.8105, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.194472074508667\n",
      "Batch: 105 , Combined Loss: tensor(0.7699, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6101988554000854\n",
      "Batch: 106 , Combined Loss: tensor(0.7861, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49591195583343506\n",
      "Batch: 107 , Combined Loss: tensor(0.9980, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.38622480630874634\n",
      "Batch: 108 , Combined Loss: tensor(0.7228, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.530524492263794\n",
      "Batch: 109 , Combined Loss: tensor(0.9403, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22363924980163574\n",
      "Batch: 110 , Combined Loss: tensor(0.8175, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3386133909225464\n",
      "Batch: 111 , Combined Loss: tensor(0.7297, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1921064853668213\n",
      "Batch: 112 , Combined Loss: tensor(0.9639, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7660999298095703\n",
      "Batch: 113 , Combined Loss: tensor(0.8610, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6770741939544678\n",
      "Batch: 114 , Combined Loss: tensor(0.7370, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5938143730163574\n",
      "Batch: 115 , Combined Loss: tensor(0.7789, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.44379132986068726\n",
      "Batch: 116 , Combined Loss: tensor(0.9236, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23390018939971924\n",
      "Batch: 117 , Combined Loss: tensor(0.7791, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6561731100082397\n",
      "Batch: 118 , Combined Loss: tensor(0.8154, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08781999349594116\n",
      "Batch: 119 , Combined Loss: tensor(0.7341, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7581994533538818\n",
      "Batch: 120 , Combined Loss: tensor(0.7211, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45853734016418457\n",
      "Batch: 121 , Combined Loss: tensor(1.1539, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43862664699554443\n",
      "Batch: 122 , Combined Loss: tensor(0.7823, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5043046474456787\n",
      "Batch: 123 , Combined Loss: tensor(0.8066, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1962374448776245\n",
      "Batch: 124 , Combined Loss: tensor(0.7066, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22120249271392822\n",
      "Batch: 125 , Combined Loss: tensor(0.7691, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32892119884490967\n",
      "Batch: 126 , Combined Loss: tensor(0.8039, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12363529205322266\n",
      "Batch: 127 , Combined Loss: tensor(0.7626, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45942556858062744\n",
      "Batch: 128 , Combined Loss: tensor(0.8557, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.40099698305130005\n",
      "Batch: 129 , Combined Loss: tensor(0.8231, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0860099196434021\n",
      "Batch: 130 , Combined Loss: tensor(0.8050, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.384670615196228\n",
      "Batch: 131 , Combined Loss: tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8178368806838989\n",
      "Batch: 132 , Combined Loss: tensor(0.6859, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8296008110046387\n",
      "Batch: 133 , Combined Loss: tensor(0.7603, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45480871200561523\n",
      "Batch: 134 , Combined Loss: tensor(0.6757, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19109666347503662\n",
      "Batch: 135 , Combined Loss: tensor(1.0317, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34658312797546387\n",
      "Batch: 136 , Combined Loss: tensor(0.7048, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6720712184906006\n",
      "Batch: 137 , Combined Loss: tensor(0.8015, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4035542607307434\n",
      "Batch: 138 , Combined Loss: tensor(0.7713, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23367315530776978\n",
      "Batch: 139 , Combined Loss: tensor(0.7784, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8472696542739868\n",
      "Batch: 140 , Combined Loss: tensor(0.8352, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21441853046417236\n",
      "Batch: 141 , Combined Loss: tensor(0.7860, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2188485860824585\n",
      "Batch: 142 , Combined Loss: tensor(0.9054, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.050721049308776855\n",
      "Batch: 143 , Combined Loss: tensor(0.7000, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1501502990722656\n",
      "Batch: 144 , Combined Loss: tensor(0.9137, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5264766216278076\n",
      "Batch: 145 , Combined Loss: tensor(0.7376, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17303764820098877\n",
      "Batch: 146 , Combined Loss: tensor(0.7840, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28255629539489746\n",
      "Batch: 147 , Combined Loss: tensor(0.8116, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7565804719924927\n",
      "Batch: 148 , Combined Loss: tensor(0.7276, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8447155952453613\n",
      "Batch: 149 , Combined Loss: tensor(0.8953, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24270939826965332\n",
      "Batch: 150 , Combined Loss: tensor(0.8410, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16815698146820068\n",
      "Batch: 151 , Combined Loss: tensor(0.6971, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21868014335632324\n",
      "Batch: 152 , Combined Loss: tensor(0.7226, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7984285354614258\n",
      "Batch: 153 , Combined Loss: tensor(0.7786, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7465155124664307\n",
      "Batch: 154 , Combined Loss: tensor(0.6956, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3076719045639038\n",
      "Batch: 155 , Combined Loss: tensor(0.7755, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26194655895233154\n",
      "Batch: 156 , Combined Loss: tensor(0.7203, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6706464290618896\n",
      "Batch: 157 , Combined Loss: tensor(0.7187, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7436531782150269\n",
      "Batch: 158 , Combined Loss: tensor(0.8202, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1989051103591919\n",
      "Batch: 159 , Combined Loss: tensor(0.7271, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39352166652679443\n",
      "Batch: 160 , Combined Loss: tensor(1.1727, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3071640729904175\n",
      "Batch: 161 , Combined Loss: tensor(0.8985, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.305212140083313\n",
      "Batch: 162 , Combined Loss: tensor(0.6883, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8067954778671265\n",
      "Batch: 163 , Combined Loss: tensor(0.9089, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07536560297012329\n",
      "Batch: 164 , Combined Loss: tensor(0.8305, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8007080554962158\n",
      "Batch: 165 , Combined Loss: tensor(0.8512, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.32560038566589355\n",
      "Batch: 166 , Combined Loss: tensor(0.8837, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20278137922286987\n",
      "Batch: 167 , Combined Loss: tensor(0.7075, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6540265083312988\n",
      "Batch: 168 , Combined Loss: tensor(0.8018, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9972207546234131\n",
      "Batch: 169 , Combined Loss: tensor(0.7748, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.028900623321533203\n",
      "Batch: 170 , Combined Loss: tensor(0.9402, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.013469576835632324\n",
      "Batch: 171 , Combined Loss: tensor(0.7419, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6809896230697632\n",
      "Batch: 172 , Combined Loss: tensor(0.7655, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8399606943130493\n",
      "Batch: 173 , Combined Loss: tensor(0.7510, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22397691011428833\n",
      "Batch: 174 , Combined Loss: tensor(0.7116, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6675418615341187\n",
      "Batch: 175 , Combined Loss: tensor(0.6970, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17935669422149658\n",
      "Batch: 176 , Combined Loss: tensor(0.7663, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5483393669128418\n",
      "Batch: 177 , Combined Loss: tensor(0.7779, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.34140074253082275\n",
      "Batch: 178 , Combined Loss: tensor(0.8831, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4146301746368408\n",
      "Batch: 179 , Combined Loss: tensor(0.7237, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.38245534896850586\n",
      "Batch: 180 , Combined Loss: tensor(1.0136, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4172232151031494\n",
      "Batch: 181 , Combined Loss: tensor(0.7006, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03873807191848755\n",
      "Batch: 182 , Combined Loss: tensor(0.8138, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40119469165802\n",
      "Batch: 183 , Combined Loss: tensor(0.9118, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7943748831748962\n",
      "Batch: 184 , Combined Loss: tensor(0.7963, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5409421920776367\n",
      "Batch: 185 , Combined Loss: tensor(0.7119, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6284215450286865\n",
      "Batch: 186 , Combined Loss: tensor(0.7962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.77434241771698\n",
      "Batch: 187 , Combined Loss: tensor(0.7103, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4105360507965088\n",
      "Batch: 188 , Combined Loss: tensor(0.7301, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1866391897201538\n",
      "Batch: 189 , Combined Loss: tensor(0.8546, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43617725372314453\n",
      "Batch: 190 , Combined Loss: tensor(0.8166, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13818037509918213\n",
      "Batch: 191 , Combined Loss: tensor(0.7552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7051794528961182\n",
      "Batch: 192 , Combined Loss: tensor(0.7656, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15052998065948486\n",
      "Batch: 193 , Combined Loss: tensor(0.7006, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5774022340774536\n",
      "Batch: 194 , Combined Loss: tensor(0.6749, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19981318712234497\n",
      "Batch: 195 , Combined Loss: tensor(0.6828, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.451401948928833\n",
      "Batch: 196 , Combined Loss: tensor(0.7920, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6325665712356567\n",
      "Batch: 197 , Combined Loss: tensor(0.7732, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10535311698913574\n",
      "Batch: 198 , Combined Loss: tensor(0.7642, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.647322416305542\n",
      "Batch: 199 , Combined Loss: tensor(0.9147, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34238719940185547\n",
      "Batch: 200 , Combined Loss: tensor(0.7958, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09009259939193726\n",
      "Batch: 201 , Combined Loss: tensor(0.8658, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6718499660491943\n",
      "Batch: 202 , Combined Loss: tensor(0.7758, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5576575994491577\n",
      "Batch: 203 , Combined Loss: tensor(0.7808, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07811415195465088\n",
      "Batch: 204 , Combined Loss: tensor(0.8488, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5919350981712341\n",
      "Batch: 205 , Combined Loss: tensor(0.7274, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20213449001312256\n",
      "Batch: 206 , Combined Loss: tensor(0.7554, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8062504529953003\n",
      "Batch: 207 , Combined Loss: tensor(0.8486, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06271588802337646\n",
      "Batch: 208 , Combined Loss: tensor(0.7493, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11830472946166992\n",
      "Batch: 209 , Combined Loss: tensor(0.7239, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9716179370880127\n",
      "Batch: 210 , Combined Loss: tensor(0.6870, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6902640461921692\n",
      "Batch: 211 , Combined Loss: tensor(0.8437, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.592181921005249\n",
      "Batch: 212 , Combined Loss: tensor(0.7085, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5707559585571289\n",
      "Batch: 213 , Combined Loss: tensor(0.7381, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37780213356018066\n",
      "Batch: 214 , Combined Loss: tensor(0.7656, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3856278657913208\n",
      "Batch: 215 , Combined Loss: tensor(0.7924, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.42189091444015503\n",
      "Batch: 216 , Combined Loss: tensor(0.7339, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.638084888458252\n",
      "Batch: 217 , Combined Loss: tensor(0.8194, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2146822214126587\n",
      "Batch: 218 , Combined Loss: tensor(0.7634, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8478924036026001\n",
      "Batch: 219 , Combined Loss: tensor(0.8544, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4946249723434448\n",
      "Batch: 220 , Combined Loss: tensor(0.7477, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5864486694335938\n",
      "Batch: 221 , Combined Loss: tensor(0.7037, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3861905336380005\n",
      "Batch: 222 , Combined Loss: tensor(0.8265, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5544612407684326\n",
      "Batch: 223 , Combined Loss: tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07309770584106445\n",
      "Batch: 224 , Combined Loss: tensor(0.7777, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23342567682266235\n",
      "Batch: 225 , Combined Loss: tensor(0.7253, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11129498481750488\n",
      "Batch: 226 , Combined Loss: tensor(0.8816, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5611045360565186\n",
      "Batch: 227 , Combined Loss: tensor(0.7096, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7479050159454346\n",
      "Batch: 228 , Combined Loss: tensor(0.7641, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4009890556335449\n",
      "Batch: 229 , Combined Loss: tensor(0.7410, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4477663040161133\n",
      "Batch: 230 , Combined Loss: tensor(0.7520, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.36967623233795166\n",
      "Batch: 231 , Combined Loss: tensor(0.7581, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19504821300506592\n",
      "Batch: 232 , Combined Loss: tensor(0.7288, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2819376587867737\n",
      "Batch: 233 , Combined Loss: tensor(0.8476, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4112577438354492\n",
      "Batch: 234 , Combined Loss: tensor(0.7082, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0976790189743042\n",
      "Batch: 235 , Combined Loss: tensor(0.7372, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05975472927093506\n",
      "Batch: 236 , Combined Loss: tensor(0.7667, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5301241874694824\n",
      "Batch: 237 , Combined Loss: tensor(0.7741, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.16367673873901367\n",
      "Batch: 238 , Combined Loss: tensor(1.0344, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.011871278285980225\n",
      "Batch: 239 , Combined Loss: tensor(0.8354, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4185839891433716\n",
      "Batch: 240 , Combined Loss: tensor(0.6753, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3617525100708008\n",
      "Batch: 241 , Combined Loss: tensor(0.7900, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6044958829879761\n",
      "Batch: 242 , Combined Loss: tensor(0.6565, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25182151794433594\n",
      "Batch: 243 , Combined Loss: tensor(0.7125, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21652823686599731\n",
      "Batch: 244 , Combined Loss: tensor(0.8423, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0713117122650146\n",
      "Batch: 245 , Combined Loss: tensor(0.8361, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19944137334823608\n",
      "Batch: 246 , Combined Loss: tensor(0.6575, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39780545234680176\n",
      "Batch: 247 , Combined Loss: tensor(0.7877, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13784193992614746\n",
      "Batch: 248 , Combined Loss: tensor(0.6952, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35416650772094727\n",
      "Batch: 249 , Combined Loss: tensor(0.6939, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6478714942932129\n",
      "Batch: 250 , Combined Loss: tensor(0.7810, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.003399968147277832\n",
      "Batch: 251 , Combined Loss: tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8357540369033813\n",
      "Batch: 252 , Combined Loss: tensor(0.7656, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5408596992492676\n",
      "Batch: 253 , Combined Loss: tensor(0.8335, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3326541781425476\n",
      "Batch: 254 , Combined Loss: tensor(0.8283, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7631652355194092\n",
      "Batch: 255 , Combined Loss: tensor(0.8000, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6982085704803467\n",
      "Batch: 256 , Combined Loss: tensor(0.8549, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8699121475219727\n",
      "Batch: 257 , Combined Loss: tensor(0.6970, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0926053524017334\n",
      "Batch: 258 , Combined Loss: tensor(0.7678, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8162837028503418\n",
      "Batch: 259 , Combined Loss: tensor(0.7325, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8672767877578735\n",
      "Batch: 260 , Combined Loss: tensor(0.8703, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6012900471687317\n",
      "Batch: 261 , Combined Loss: tensor(0.7195, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4732837677001953\n",
      "Batch: 262 , Combined Loss: tensor(0.6862, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5708038806915283\n",
      "Batch: 263 , Combined Loss: tensor(0.7271, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7826491594314575\n",
      "Batch: 264 , Combined Loss: tensor(0.7300, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27100682258605957\n",
      "Batch: 265 , Combined Loss: tensor(0.7779, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49579668045043945\n",
      "Batch: 266 , Combined Loss: tensor(0.7255, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6077375411987305\n",
      "Batch: 267 , Combined Loss: tensor(0.7680, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24608981609344482\n",
      "Batch: 268 , Combined Loss: tensor(0.9096, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05687415599822998\n",
      "Batch: 269 , Combined Loss: tensor(1.1381, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.83917635679245\n",
      "Batch: 270 , Combined Loss: tensor(0.6682, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.634876012802124\n",
      "Batch: 271 , Combined Loss: tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2214803695678711\n",
      "Batch: 272 , Combined Loss: tensor(0.6999, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.248246967792511\n",
      "Batch: 273 , Combined Loss: tensor(0.7377, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7206975221633911\n",
      "Batch: 274 , Combined Loss: tensor(0.6199, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19634318351745605\n",
      "Batch: 275 , Combined Loss: tensor(1.0745, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.28705376386642456\n",
      "Batch: 276 , Combined Loss: tensor(0.7559, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49118638038635254\n",
      "Batch: 277 , Combined Loss: tensor(0.7340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7155909538269043\n",
      "Batch: 278 , Combined Loss: tensor(0.6703, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.36952143907546997\n",
      "Batch: 279 , Combined Loss: tensor(0.7187, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2485155463218689\n",
      "Batch: 280 , Combined Loss: tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2030421495437622\n",
      "Batch: 281 , Combined Loss: tensor(0.7079, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9700331687927246\n",
      "Batch: 282 , Combined Loss: tensor(0.8161, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6172176599502563\n",
      "Batch: 283 , Combined Loss: tensor(0.7877, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7447023391723633\n",
      "Batch: 284 , Combined Loss: tensor(0.8486, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2634701728820801\n",
      "Batch: 285 , Combined Loss: tensor(0.7781, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7301331758499146\n",
      "Batch: 286 , Combined Loss: tensor(0.6972, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3766371011734009\n",
      "Batch: 287 , Combined Loss: tensor(0.8532, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8215646743774414\n",
      "Batch: 288 , Combined Loss: tensor(0.8991, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.938156247138977\n",
      "Batch: 289 , Combined Loss: tensor(0.6478, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6845924854278564\n",
      "Batch: 290 , Combined Loss: tensor(0.9160, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.644631028175354\n",
      "Batch: 291 , Combined Loss: tensor(0.7420, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3840029239654541\n",
      "Batch: 292 , Combined Loss: tensor(0.8660, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8121294975280762\n",
      "Batch: 293 , Combined Loss: tensor(0.8729, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47133052349090576\n",
      "Batch: 294 , Combined Loss: tensor(0.8403, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2203304767608643\n",
      "Batch: 295 , Combined Loss: tensor(0.8611, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.125679612159729\n",
      "Batch: 296 , Combined Loss: tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3099651336669922\n",
      "Batch: 297 , Combined Loss: tensor(0.7233, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8738090991973877\n",
      "Batch: 298 , Combined Loss: tensor(0.8433, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9580035209655762\n",
      "Batch: 299 , Combined Loss: tensor(0.9802, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43788397312164307\n",
      "Batch: 300 , Combined Loss: tensor(0.8326, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07966721057891846\n",
      "Batch: 301 , Combined Loss: tensor(0.9826, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0891522765159607\n",
      "Batch: 302 , Combined Loss: tensor(0.8920, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14712220430374146\n",
      "Batch: 303 , Combined Loss: tensor(0.6764, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09752285480499268\n",
      "Batch: 304 , Combined Loss: tensor(0.6645, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4762686491012573\n",
      "Batch: 305 , Combined Loss: tensor(0.8447, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2316197156906128\n",
      "Batch: 306 , Combined Loss: tensor(0.6735, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15219497680664062\n",
      "Batch: 307 , Combined Loss: tensor(0.7998, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.710401177406311\n",
      "Batch: 308 , Combined Loss: tensor(0.7221, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.019154787063598633\n",
      "Batch: 309 , Combined Loss: tensor(0.6381, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.684502363204956\n",
      "Batch: 310 , Combined Loss: tensor(0.7231, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6394538879394531\n",
      "Batch: 311 , Combined Loss: tensor(0.7685, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6592084169387817\n",
      "Batch: 312 , Combined Loss: tensor(0.7627, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0594172477722168\n",
      "Batch: 313 , Combined Loss: tensor(1.3494, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.410719633102417\n",
      "Batch: 314 , Combined Loss: tensor(0.8808, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0023658275604248047\n",
      "Batch: 315 , Combined Loss: tensor(1.0195, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7679060697555542\n",
      "Batch: 316 , Combined Loss: tensor(0.7324, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6289379596710205\n",
      "Batch: 317 , Combined Loss: tensor(0.8393, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7108550071716309\n",
      "Batch: 318 , Combined Loss: tensor(0.6435, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7214224338531494\n",
      "Batch: 319 , Combined Loss: tensor(0.9547, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3013928532600403\n",
      "Batch: 320 , Combined Loss: tensor(0.9673, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5665171146392822\n",
      "Batch: 321 , Combined Loss: tensor(0.8478, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11191606521606445\n",
      "Batch: 322 , Combined Loss: tensor(0.7083, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9737389087677002\n",
      "Batch: 323 , Combined Loss: tensor(0.7454, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.008734345436096191\n",
      "Batch: 324 , Combined Loss: tensor(1.0145, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08581304550170898\n",
      "Batch: 325 , Combined Loss: tensor(0.8742, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.560623049736023\n",
      "Batch: 326 , Combined Loss: tensor(0.8150, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42335939407348633\n",
      "Batch: 327 , Combined Loss: tensor(0.7006, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6660288572311401\n",
      "Batch: 328 , Combined Loss: tensor(1.0008, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07049775123596191\n",
      "Batch: 329 , Combined Loss: tensor(0.6161, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.014681637287139893\n",
      "Batch: 330 , Combined Loss: tensor(0.6353, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6573567390441895\n",
      "Batch: 331 , Combined Loss: tensor(0.9231, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5356041193008423\n",
      "Batch: 332 , Combined Loss: tensor(0.6916, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5665445327758789\n",
      "Batch: 333 , Combined Loss: tensor(0.8285, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1196221113204956\n",
      "Batch: 334 , Combined Loss: tensor(0.6143, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24397540092468262\n",
      "Batch: 335 , Combined Loss: tensor(0.7893, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17357778549194336\n",
      "Batch: 336 , Combined Loss: tensor(0.7000, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3747599124908447\n",
      "Batch: 337 , Combined Loss: tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2705121636390686\n",
      "Batch: 338 , Combined Loss: tensor(0.7048, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3481006622314453\n",
      "Batch: 339 , Combined Loss: tensor(0.6908, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7545208930969238\n",
      "Batch: 340 , Combined Loss: tensor(0.7030, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4138781428337097\n",
      "Batch: 341 , Combined Loss: tensor(0.6903, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9104666709899902\n",
      "Batch: 342 , Combined Loss: tensor(0.6878, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9496747255325317\n",
      "Batch: 343 , Combined Loss: tensor(0.6803, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7148212194442749\n",
      "Batch: 344 , Combined Loss: tensor(0.7637, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5996754169464111\n",
      "Batch: 345 , Combined Loss: tensor(0.7582, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.464679479598999\n",
      "Batch: 346 , Combined Loss: tensor(0.8172, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5817209482192993\n",
      "Batch: 347 , Combined Loss: tensor(0.8900, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8834877014160156\n",
      "Batch: 348 , Combined Loss: tensor(0.7480, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3945962190628052\n",
      "Batch: 349 , Combined Loss: tensor(0.7469, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9444410800933838\n",
      "Batch: 350 , Combined Loss: tensor(1.0938, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8690402507781982\n",
      "Batch: 351 , Combined Loss: tensor(0.8315, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5646872520446777\n",
      "Batch: 352 , Combined Loss: tensor(0.7366, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1928335428237915\n",
      "Batch: 353 , Combined Loss: tensor(0.6505, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5593271255493164\n",
      "Batch: 354 , Combined Loss: tensor(0.7512, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8122062683105469\n",
      "Batch: 355 , Combined Loss: tensor(0.7819, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7233245372772217\n",
      "Batch: 356 , Combined Loss: tensor(0.6783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.27355241775512695\n",
      "Batch: 357 , Combined Loss: tensor(0.6781, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6236535310745239\n",
      "Batch: 358 , Combined Loss: tensor(0.8268, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.050694823265075684\n",
      "Batch: 359 , Combined Loss: tensor(0.8496, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5380749702453613\n",
      "Batch: 360 , Combined Loss: tensor(0.6889, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8334711790084839\n",
      "Batch: 361 , Combined Loss: tensor(0.6557, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6614047288894653\n",
      "Batch: 362 , Combined Loss: tensor(0.7127, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8610590696334839\n",
      "Batch: 363 , Combined Loss: tensor(0.7407, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8532513380050659\n",
      "Batch: 364 , Combined Loss: tensor(0.8882, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3675553798675537\n",
      "Batch: 365 , Combined Loss: tensor(0.6413, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4524211883544922\n",
      "Batch: 366 , Combined Loss: tensor(0.7289, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6946984529495239\n",
      "Batch: 367 , Combined Loss: tensor(0.6720, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05015754699707031\n",
      "Batch: 368 , Combined Loss: tensor(0.8014, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4133591651916504\n",
      "Batch: 369 , Combined Loss: tensor(0.7518, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21681076288223267\n",
      "Batch: 370 , Combined Loss: tensor(0.7767, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7961602210998535\n",
      "Batch: 371 , Combined Loss: tensor(0.7658, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6060049533843994\n",
      "Batch: 372 , Combined Loss: tensor(0.8535, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.035992980003356934\n",
      "Batch: 373 , Combined Loss: tensor(0.7538, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.534747838973999\n",
      "Batch: 374 , Combined Loss: tensor(0.6685, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5101341605186462\n",
      "Batch: 375 , Combined Loss: tensor(0.7896, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.37076687812805176\n",
      "Batch: 376 , Combined Loss: tensor(0.7416, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8835892677307129\n",
      "Batch: 377 , Combined Loss: tensor(0.7662, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3042449951171875\n",
      "Batch: 378 , Combined Loss: tensor(0.8782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6008527278900146\n",
      "Batch: 379 , Combined Loss: tensor(0.8694, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22408944368362427\n",
      "Batch: 380 , Combined Loss: tensor(0.6787, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6986333131790161\n",
      "Batch: 381 , Combined Loss: tensor(0.8135, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5899674892425537\n",
      "Batch: 382 , Combined Loss: tensor(0.8593, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6224043369293213\n",
      "Batch: 383 , Combined Loss: tensor(0.9120, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5148259401321411\n",
      "Batch: 384 , Combined Loss: tensor(0.9540, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6422609090805054\n",
      "Batch: 385 , Combined Loss: tensor(0.7479, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3868218660354614\n",
      "Batch: 386 , Combined Loss: tensor(0.6967, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14080029726028442\n",
      "Batch: 387 , Combined Loss: tensor(0.7556, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9072309732437134\n",
      "Batch: 388 , Combined Loss: tensor(0.8755, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.25379300117492676\n",
      "Batch: 389 , Combined Loss: tensor(0.7896, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20593374967575073\n",
      "Batch: 390 , Combined Loss: tensor(0.7208, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.590241551399231\n",
      "Batch: 391 , Combined Loss: tensor(0.8224, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.459865927696228\n",
      "Batch: 392 , Combined Loss: tensor(0.8252, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4625210762023926\n",
      "Batch: 393 , Combined Loss: tensor(0.7013, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33265221118927\n",
      "Batch: 394 , Combined Loss: tensor(0.6664, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08913588523864746\n",
      "Batch: 395 , Combined Loss: tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0203495025634766\n",
      "Batch: 396 , Combined Loss: tensor(0.7676, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2803962826728821\n",
      "Batch: 397 , Combined Loss: tensor(0.7958, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4150882959365845\n",
      "Batch: 398 , Combined Loss: tensor(0.7442, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23315829038619995\n",
      "Batch: 399 , Combined Loss: tensor(0.7622, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.088010311126709\n",
      "Batch: 400 , Combined Loss: tensor(0.8449, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8099731206893921\n",
      "Batch: 401 , Combined Loss: tensor(0.8348, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4645155668258667\n",
      "Batch: 402 , Combined Loss: tensor(0.8545, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8067233562469482\n",
      "Batch: 403 , Combined Loss: tensor(0.9024, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4848021864891052\n",
      "Batch: 404 , Combined Loss: tensor(0.8745, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.527389645576477\n",
      "Batch: 405 , Combined Loss: tensor(0.7978, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7030130624771118\n",
      "Batch: 406 , Combined Loss: tensor(0.6913, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5255401134490967\n",
      "Batch: 407 , Combined Loss: tensor(0.9059, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9014990329742432\n",
      "Batch: 408 , Combined Loss: tensor(0.8724, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7507764101028442\n",
      "Batch: 409 , Combined Loss: tensor(0.7185, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5883510112762451\n",
      "Batch: 410 , Combined Loss: tensor(0.7867, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9342542886734009\n",
      "Batch: 411 , Combined Loss: tensor(0.7087, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20677268505096436\n",
      "Batch: 412 , Combined Loss: tensor(0.7664, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46151208877563477\n",
      "Batch: 413 , Combined Loss: tensor(0.7625, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04604959487915039\n",
      "Batch: 414 , Combined Loss: tensor(0.7316, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.35796719789505005\n",
      "Batch: 415 , Combined Loss: tensor(0.7436, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6787687540054321\n",
      "Batch: 416 , Combined Loss: tensor(0.7822, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1279062032699585\n",
      "Batch: 417 , Combined Loss: tensor(0.8794, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0599672794342041\n",
      "Batch: 418 , Combined Loss: tensor(0.6675, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2476288080215454\n",
      "Batch: 419 , Combined Loss: tensor(0.8782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8248429298400879\n",
      "Batch: 420 , Combined Loss: tensor(0.7746, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0689113140106201\n",
      "Batch: 421 , Combined Loss: tensor(0.7750, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8656516075134277\n",
      "Batch: 422 , Combined Loss: tensor(0.8454, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8805036544799805\n",
      "Batch: 423 , Combined Loss: tensor(0.7672, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8026947975158691\n",
      "Batch: 424 , Combined Loss: tensor(0.7363, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0081565380096436\n",
      "Batch: 425 , Combined Loss: tensor(0.8790, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7173118591308594\n",
      "Batch: 426 , Combined Loss: tensor(0.8764, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9012652635574341\n",
      "Batch: 427 , Combined Loss: tensor(0.8438, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8622298240661621\n",
      "Batch: 428 , Combined Loss: tensor(0.7033, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1103711128234863\n",
      "Batch: 429 , Combined Loss: tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0158884525299072\n",
      "Batch: 430 , Combined Loss: tensor(0.7394, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6174522638320923\n",
      "Batch: 431 , Combined Loss: tensor(0.7104, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6004756689071655\n",
      "Batch: 432 , Combined Loss: tensor(0.6754, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8333196640014648\n",
      "Batch: 433 , Combined Loss: tensor(0.8325, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9077889919281006\n",
      "Batch: 434 , Combined Loss: tensor(0.7220, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47231805324554443\n",
      "Batch: 435 , Combined Loss: tensor(0.8558, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8721662759780884\n",
      "Batch: 436 , Combined Loss: tensor(0.9321, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08917129039764404\n",
      "Batch: 437 , Combined Loss: tensor(0.6997, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7849985361099243\n",
      "Batch: 438 , Combined Loss: tensor(0.9031, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.283730149269104\n",
      "Batch: 439 , Combined Loss: tensor(0.8735, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4630557894706726\n",
      "Batch: 440 , Combined Loss: tensor(0.9049, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6785012483596802\n",
      "Batch: 441 , Combined Loss: tensor(0.7962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0248265266418457\n",
      "Batch: 442 , Combined Loss: tensor(0.8023, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8475737571716309\n",
      "Batch: 443 , Combined Loss: tensor(0.7262, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7603408098220825\n",
      "Batch: 444 , Combined Loss: tensor(0.8115, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.047600269317627\n",
      "Batch: 445 , Combined Loss: tensor(0.6998, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4353766441345215\n",
      "Batch: 446 , Combined Loss: tensor(0.7108, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9493707418441772\n",
      "Batch: 447 , Combined Loss: tensor(0.7488, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09742718935012817\n",
      "Batch: 448 , Combined Loss: tensor(0.7769, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0744731426239014\n",
      "Batch: 449 , Combined Loss: tensor(0.7372, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9252395629882812\n",
      "Batch: 450 , Combined Loss: tensor(0.7473, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8878226280212402\n",
      "Batch: 451 , Combined Loss: tensor(1.1138, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6604570150375366\n",
      "Batch: 452 , Combined Loss: tensor(0.7370, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25238800048828125\n",
      "Batch: 453 , Combined Loss: tensor(0.6859, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8239734172821045\n",
      "Batch: 454 , Combined Loss: tensor(0.7914, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8899306058883667\n",
      "Batch: 455 , Combined Loss: tensor(0.9433, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6053755283355713\n",
      "Batch: 456 , Combined Loss: tensor(0.7595, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8678327798843384\n",
      "Batch: 457 , Combined Loss: tensor(0.7352, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5808603763580322\n",
      "Batch: 458 , Combined Loss: tensor(0.8110, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7017819881439209\n",
      "Batch: 459 , Combined Loss: tensor(0.7929, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9615726470947266\n",
      "Batch: 460 , Combined Loss: tensor(0.8532, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9936935901641846\n",
      "Batch: 461 , Combined Loss: tensor(0.8357, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8063522577285767\n",
      "Batch: 462 , Combined Loss: tensor(0.7644, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6805131435394287\n",
      "Batch: 463 , Combined Loss: tensor(0.8546, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27194833755493164\n",
      "Batch: 464 , Combined Loss: tensor(0.6984, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11474764347076416\n",
      "Batch: 465 , Combined Loss: tensor(1.0427, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8733758926391602\n",
      "Batch: 466 , Combined Loss: tensor(0.7107, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18271172046661377\n",
      "Batch: 467 , Combined Loss: tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0709357261657715\n",
      "Batch: 468 , Combined Loss: tensor(0.8277, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5034879446029663\n",
      "Batch: 469 , Combined Loss: tensor(0.7489, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4779937267303467\n",
      "Batch: 470 , Combined Loss: tensor(0.6670, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3800541162490845\n",
      "Batch: 471 , Combined Loss: tensor(0.9663, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3191874027252197\n",
      "Batch: 472 , Combined Loss: tensor(0.7418, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5814440250396729\n",
      "Batch: 473 , Combined Loss: tensor(0.7415, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6904891729354858\n",
      "Batch: 474 , Combined Loss: tensor(0.9048, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4922901391983032\n",
      "Batch: 475 , Combined Loss: tensor(0.8728, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8344082832336426\n",
      "Batch: 476 , Combined Loss: tensor(0.7196, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8053988218307495\n",
      "Batch: 477 , Combined Loss: tensor(0.9786, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.40994787216186523\n",
      "Batch: 478 , Combined Loss: tensor(0.9708, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16195368766784668\n",
      "Batch: 479 , Combined Loss: tensor(0.7056, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.631335973739624\n",
      "Batch: 480 , Combined Loss: tensor(0.7448, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3755321502685547\n",
      "Batch: 481 , Combined Loss: tensor(0.7206, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38992393016815186\n",
      "Batch: 482 , Combined Loss: tensor(0.7079, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6763118505477905\n",
      "Batch: 483 , Combined Loss: tensor(0.7446, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.043534278869629\n",
      "Batch: 484 , Combined Loss: tensor(0.8047, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4240459203720093\n",
      "Batch: 485 , Combined Loss: tensor(0.7488, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4180428981781006\n",
      "Batch: 486 , Combined Loss: tensor(0.9137, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.44543904066085815\n",
      "Batch: 487 , Combined Loss: tensor(0.8737, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7595161199569702\n",
      "Batch: 488 , Combined Loss: tensor(0.8175, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3197089433670044\n",
      "Batch: 489 , Combined Loss: tensor(0.7111, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.770990252494812\n",
      "Batch: 490 , Combined Loss: tensor(0.9940, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26358580589294434\n",
      "Batch: 491 , Combined Loss: tensor(0.8154, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20917069911956787\n",
      "Batch: 492 , Combined Loss: tensor(0.7728, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46231627464294434\n",
      "Batch: 493 , Combined Loss: tensor(0.7670, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.36252403259277344\n",
      "Batch: 494 , Combined Loss: tensor(0.9392, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25757670402526855\n",
      "Batch: 495 , Combined Loss: tensor(0.7798, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2949409484863281\n",
      "Batch: 496 , Combined Loss: tensor(0.8148, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.551270604133606\n",
      "Batch: 497 , Combined Loss: tensor(0.7524, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03597307205200195\n",
      "Batch: 498 , Combined Loss: tensor(0.7379, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18428826332092285\n",
      "Batch: 499 , Combined Loss: tensor(1.0199, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04023241996765137\n",
      "Batch: 500 , Combined Loss: tensor(0.7412, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2212749719619751\n",
      "Batch: 501 , Combined Loss: tensor(0.7115, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6930220127105713\n",
      "Batch: 502 , Combined Loss: tensor(0.6984, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5951551198959351\n",
      "Batch: 503 , Combined Loss: tensor(0.7353, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9534962177276611\n",
      "Batch: 504 , Combined Loss: tensor(0.8298, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21738803386688232\n",
      "Batch: 505 , Combined Loss: tensor(0.6934, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15828382968902588\n",
      "Batch: 506 , Combined Loss: tensor(0.8350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2504657506942749\n",
      "Batch: 507 , Combined Loss: tensor(0.7410, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6137790679931641\n",
      "Batch: 508 , Combined Loss: tensor(0.8030, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5431625843048096\n",
      "Batch: 509 , Combined Loss: tensor(0.8692, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2916877269744873\n",
      "Batch: 510 , Combined Loss: tensor(0.7759, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0585525035858154\n",
      "Batch: 511 , Combined Loss: tensor(0.7754, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5010207891464233\n",
      "Batch: 512 , Combined Loss: tensor(0.7836, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25213623046875\n",
      "Batch: 513 , Combined Loss: tensor(0.7750, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6690247058868408\n",
      "Batch: 514 , Combined Loss: tensor(0.9099, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23161423206329346\n",
      "Batch: 515 , Combined Loss: tensor(0.7525, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7089343070983887\n",
      "Batch: 516 , Combined Loss: tensor(0.8134, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17516326904296875\n",
      "Batch: 517 , Combined Loss: tensor(0.8358, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7634791135787964\n",
      "Batch: 518 , Combined Loss: tensor(0.9449, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06780564785003662\n",
      "Batch: 519 , Combined Loss: tensor(0.8923, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6828744411468506\n",
      "Batch: 520 , Combined Loss: tensor(0.7766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.651136040687561\n",
      "Batch: 521 , Combined Loss: tensor(0.7553, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8951096534729004\n",
      "Batch: 522 , Combined Loss: tensor(1.1350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7690916061401367\n",
      "Batch: 523 , Combined Loss: tensor(0.8049, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3927961587905884\n",
      "Batch: 524 , Combined Loss: tensor(0.8320, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.679706335067749\n",
      "Batch: 525 , Combined Loss: tensor(0.7574, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42261457443237305\n",
      "Batch: 526 , Combined Loss: tensor(0.7548, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1832188367843628\n",
      "Batch: 527 , Combined Loss: tensor(0.8724, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22580260038375854\n",
      "Batch: 528 , Combined Loss: tensor(0.7529, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8528382778167725\n",
      "Batch: 529 , Combined Loss: tensor(0.7750, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9077886343002319\n",
      "Batch: 530 , Combined Loss: tensor(0.9639, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22153866291046143\n",
      "Batch: 531 , Combined Loss: tensor(0.7883, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6281976699829102\n",
      "Batch: 532 , Combined Loss: tensor(0.7364, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2580331563949585\n",
      "Batch: 533 , Combined Loss: tensor(0.8115, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11491978168487549\n",
      "Batch: 534 , Combined Loss: tensor(0.8678, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47823214530944824\n",
      "Batch: 535 , Combined Loss: tensor(0.8883, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09498715400695801\n",
      "Batch: 536 , Combined Loss: tensor(0.9111, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07754969596862793\n",
      "Batch: 537 , Combined Loss: tensor(0.8286, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5210062861442566\n",
      "Batch: 538 , Combined Loss: tensor(0.7442, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10454857349395752\n",
      "Batch: 539 , Combined Loss: tensor(0.7675, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.36445194482803345\n",
      "Batch: 540 , Combined Loss: tensor(0.7938, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1637740135192871\n",
      "Batch: 541 , Combined Loss: tensor(0.8009, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09410595893859863\n",
      "Batch: 542 , Combined Loss: tensor(0.7371, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16926896572113037\n",
      "Batch: 543 , Combined Loss: tensor(0.8500, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.25150197744369507\n",
      "Batch: 544 , Combined Loss: tensor(0.8111, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2125535011291504\n",
      "Batch: 545 , Combined Loss: tensor(0.7894, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.049680113792419434\n",
      "Batch: 546 , Combined Loss: tensor(0.7039, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20767271518707275\n",
      "Batch: 547 , Combined Loss: tensor(0.7340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6664857864379883\n",
      "Batch: 548 , Combined Loss: tensor(0.8679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14572322368621826\n",
      "Batch: 549 , Combined Loss: tensor(0.8157, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40198302268981934\n",
      "Batch: 550 , Combined Loss: tensor(0.7650, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8807233572006226\n",
      "Batch: 551 , Combined Loss: tensor(0.8144, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.007866740226745605\n",
      "Batch: 552 , Combined Loss: tensor(0.7595, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12283504009246826\n",
      "Batch: 553 , Combined Loss: tensor(0.8624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2276374101638794\n",
      "Batch: 554 , Combined Loss: tensor(0.8102, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.021617412567138672\n",
      "Batch: 555 , Combined Loss: tensor(0.7496, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6876027584075928\n",
      "Batch: 556 , Combined Loss: tensor(0.9291, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6922435760498047\n",
      "Batch: 557 , Combined Loss: tensor(0.8239, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.484957218170166\n",
      "Batch: 558 , Combined Loss: tensor(0.8388, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.36515235900878906\n",
      "Batch: 559 , Combined Loss: tensor(0.8210, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2444630265235901\n",
      "Batch: 560 , Combined Loss: tensor(0.8118, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6386111974716187\n",
      "Batch: 561 , Combined Loss: tensor(0.8066, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09077829122543335\n",
      "Batch: 562 , Combined Loss: tensor(0.8635, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5759240388870239\n",
      "Batch: 563 , Combined Loss: tensor(0.7423, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7479945421218872\n",
      "Batch: 564 , Combined Loss: tensor(0.8000, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1972401738166809\n",
      "Batch: 565 , Combined Loss: tensor(0.7436, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6924896240234375\n",
      "Batch: 566 , Combined Loss: tensor(0.7216, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8502931594848633\n",
      "Batch: 567 , Combined Loss: tensor(0.7576, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.001471757888794\n",
      "Batch: 568 , Combined Loss: tensor(0.9454, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10843980312347412\n",
      "Batch: 569 , Combined Loss: tensor(0.8522, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1966235637664795\n",
      "Batch: 570 , Combined Loss: tensor(0.8164, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6704534292221069\n",
      "Batch: 571 , Combined Loss: tensor(0.7562, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1341266632080078\n",
      "Batch: 572 , Combined Loss: tensor(0.7588, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39361149072647095\n",
      "Batch: 573 , Combined Loss: tensor(0.7614, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08830523490905762\n",
      "Batch: 574 , Combined Loss: tensor(0.8052, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6786651611328125\n",
      "Batch: 575 , Combined Loss: tensor(0.7251, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30056798458099365\n",
      "Batch: 576 , Combined Loss: tensor(0.7908, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46886134147644043\n",
      "Batch: 577 , Combined Loss: tensor(0.7984, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3610982894897461\n",
      "Batch: 578 , Combined Loss: tensor(0.7735, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7630070447921753\n",
      "Batch: 579 , Combined Loss: tensor(0.9001, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6418181657791138\n",
      "Batch: 580 , Combined Loss: tensor(0.8183, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07676577568054199\n",
      "Batch: 581 , Combined Loss: tensor(0.7967, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1829073429107666\n",
      "Batch: 582 , Combined Loss: tensor(0.7958, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5452553033828735\n",
      "Batch: 583 , Combined Loss: tensor(0.7723, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10556173324584961\n",
      "Batch: 584 , Combined Loss: tensor(0.7189, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6759785413742065\n",
      "Batch: 585 , Combined Loss: tensor(0.7462, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4353104829788208\n",
      "Batch: 586 , Combined Loss: tensor(0.8414, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6696382761001587\n",
      "Batch: 587 , Combined Loss: tensor(0.8240, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7541842460632324\n",
      "Batch: 588 , Combined Loss: tensor(0.8453, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0935593843460083\n",
      "Batch: 589 , Combined Loss: tensor(0.7402, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5751566886901855\n",
      "Batch: 590 , Combined Loss: tensor(0.7370, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.943378210067749\n",
      "Batch: 591 , Combined Loss: tensor(0.8939, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8874504566192627\n",
      "Batch: 592 , Combined Loss: tensor(0.8907, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13353145122528076\n",
      "Batch: 593 , Combined Loss: tensor(0.8882, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.029364466667175293\n",
      "Batch: 594 , Combined Loss: tensor(0.6977, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22598302364349365\n",
      "Batch: 595 , Combined Loss: tensor(0.8534, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.516731858253479\n",
      "Batch: 596 , Combined Loss: tensor(0.7416, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5294904708862305\n",
      "Batch: 597 , Combined Loss: tensor(0.7607, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.27295392751693726\n",
      "Batch: 598 , Combined Loss: tensor(0.7986, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.435971736907959\n",
      "Batch: 599 , Combined Loss: tensor(0.7183, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3913050889968872\n",
      "Batch: 600 , Combined Loss: tensor(0.7374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08343684673309326\n",
      "Batch: 601 , Combined Loss: tensor(0.7241, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4700249433517456\n",
      "Batch: 602 , Combined Loss: tensor(0.7820, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.16211652755737305\n",
      "Batch: 603 , Combined Loss: tensor(0.6969, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6910511255264282\n",
      "Batch: 604 , Combined Loss: tensor(0.7831, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9666651487350464\n",
      "Batch: 605 , Combined Loss: tensor(0.7478, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2797276973724365\n",
      "Batch: 606 , Combined Loss: tensor(0.7819, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5036665201187134\n",
      "Batch: 607 , Combined Loss: tensor(0.8747, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6581919193267822\n",
      "Batch: 608 , Combined Loss: tensor(0.7753, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.46865755319595337\n",
      "Batch: 609 , Combined Loss: tensor(0.7647, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.015912175178527832\n",
      "Batch: 610 , Combined Loss: tensor(0.9378, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18676722049713135\n",
      "Batch: 611 , Combined Loss: tensor(0.8058, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5019662380218506\n",
      "Batch: 612 , Combined Loss: tensor(0.7575, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8498358726501465\n",
      "Batch: 613 , Combined Loss: tensor(0.8021, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45824873447418213\n",
      "Batch: 614 , Combined Loss: tensor(0.6834, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8507856130599976\n",
      "Batch: 615 , Combined Loss: tensor(0.7895, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6454377174377441\n",
      "Batch: 616 , Combined Loss: tensor(0.6926, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2796533703804016\n",
      "Batch: 617 , Combined Loss: tensor(0.6984, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17234784364700317\n",
      "Batch: 618 , Combined Loss: tensor(0.7501, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31829583644866943\n",
      "Batch: 619 , Combined Loss: tensor(0.8069, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5278888940811157\n",
      "Batch: 620 , Combined Loss: tensor(0.8651, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8436557054519653\n",
      "Batch: 621 , Combined Loss: tensor(0.6581, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34300875663757324\n",
      "Batch: 622 , Combined Loss: tensor(0.7931, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8097633123397827\n",
      "Batch: 623 , Combined Loss: tensor(0.7342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8663938045501709\n",
      "Batch: 624 , Combined Loss: tensor(0.9140, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.030225038528442383\n",
      "Batch: 625 , Combined Loss: tensor(0.7558, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8037495613098145\n",
      "Batch: 626 , Combined Loss: tensor(0.8697, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5734807252883911\n",
      "Batch: 627 , Combined Loss: tensor(0.7032, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6371350288391113\n",
      "Batch: 628 , Combined Loss: tensor(0.7054, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0892987251281738\n",
      "----------Epoch 8, Loss: 0.7912420226773321, Accuracy: 0.9388733706148327, Dice Coef: [0.9710033768121692, 0.433056476113853, 0.4810995180315737, 0.5281042346018482], Dice Coef Necrotic: 0.6339473009431148, Dice Coef Edema: 0.6900483482230158, Dice Coef Enhancing: 0.556263579797951, Sensitivity: [0.9459905137318306, 0.6759863387095921, 0.7968869454483538, 0.8412857361301478], Specificity: [0.9637481257058857, 0.9941913972598381, 0.9580511325683048, 0.9873342703560009], Precision: [0.9978007912067237, 0.3968825403937129, 0.37546742481160056, 0.42520334323194836]\n",
      "Saving without nn.DataParallel\n",
      "Batch: 0 , Combined Loss: tensor(0.8624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6422608494758606\n",
      "Batch: 1 , Combined Loss: tensor(0.7852, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5697371959686279\n",
      "Batch: 2 , Combined Loss: tensor(0.8100, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4481905698776245\n",
      "Batch: 3 , Combined Loss: tensor(0.8106, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7370866537094116\n",
      "Batch: 4 , Combined Loss: tensor(0.7816, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34954679012298584\n",
      "Batch: 5 , Combined Loss: tensor(0.7369, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8789093494415283\n",
      "Batch: 6 , Combined Loss: tensor(0.7508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7633659839630127\n",
      "Batch: 7 , Combined Loss: tensor(0.7771, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3426166772842407\n",
      "Batch: 8 , Combined Loss: tensor(0.8390, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5479767322540283\n",
      "Batch: 9 , Combined Loss: tensor(0.8724, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19775021076202393\n",
      "Batch: 10 , Combined Loss: tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43011045455932617\n",
      "Batch: 11 , Combined Loss: tensor(0.7731, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05117380619049072\n",
      "Batch: 12 , Combined Loss: tensor(0.7664, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5400108098983765\n",
      "Batch: 13 , Combined Loss: tensor(0.6864, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.37502777576446533\n",
      "Batch: 14 , Combined Loss: tensor(0.7609, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.922053337097168\n",
      "Batch: 15 , Combined Loss: tensor(0.8271, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.27143627405166626\n",
      "Batch: 16 , Combined Loss: tensor(0.7535, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.329473614692688\n",
      "Batch: 17 , Combined Loss: tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1367251873016357\n",
      "Batch: 18 , Combined Loss: tensor(0.8154, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2677520513534546\n",
      "Batch: 19 , Combined Loss: tensor(0.9495, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9164865016937256\n",
      "Batch: 20 , Combined Loss: tensor(0.7177, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7184885740280151\n",
      "Batch: 21 , Combined Loss: tensor(0.7867, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4603487253189087\n",
      "Batch: 22 , Combined Loss: tensor(0.8087, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08922052383422852\n",
      "Batch: 23 , Combined Loss: tensor(0.8518, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7121334075927734\n",
      "Batch: 24 , Combined Loss: tensor(0.7855, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10531634092330933\n",
      "Batch: 25 , Combined Loss: tensor(0.8128, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.007754087448120117\n",
      "Batch: 26 , Combined Loss: tensor(0.7585, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7926516532897949\n",
      "Batch: 27 , Combined Loss: tensor(0.7177, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1047595739364624\n",
      "Batch: 28 , Combined Loss: tensor(0.8323, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9092698097229004\n",
      "Batch: 29 , Combined Loss: tensor(0.7084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5093793869018555\n",
      "Batch: 30 , Combined Loss: tensor(0.7400, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27833831310272217\n",
      "Batch: 31 , Combined Loss: tensor(0.6965, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8670002222061157\n",
      "Batch: 32 , Combined Loss: tensor(0.8513, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5351223945617676\n",
      "Batch: 33 , Combined Loss: tensor(0.6915, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.27355122566223145\n",
      "Batch: 34 , Combined Loss: tensor(0.7061, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35915637016296387\n",
      "Batch: 35 , Combined Loss: tensor(0.7789, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9874582290649414\n",
      "Batch: 36 , Combined Loss: tensor(0.7458, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6300760507583618\n",
      "Batch: 37 , Combined Loss: tensor(0.7354, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7475214004516602\n",
      "Batch: 38 , Combined Loss: tensor(0.8980, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30251920223236084\n",
      "Batch: 39 , Combined Loss: tensor(0.7908, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23671770095825195\n",
      "Batch: 40 , Combined Loss: tensor(0.7291, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.090930700302124\n",
      "Batch: 41 , Combined Loss: tensor(0.8605, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1065683364868164\n",
      "Batch: 42 , Combined Loss: tensor(0.6975, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1779932975769043\n",
      "Batch: 43 , Combined Loss: tensor(0.8663, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7147746086120605\n",
      "Batch: 44 , Combined Loss: tensor(0.7757, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9821168184280396\n",
      "Batch: 45 , Combined Loss: tensor(0.7462, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23861932754516602\n",
      "Batch: 46 , Combined Loss: tensor(0.7330, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9098669290542603\n",
      "Batch: 47 , Combined Loss: tensor(0.7228, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7745108604431152\n",
      "Batch: 48 , Combined Loss: tensor(0.6680, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6309430599212646\n",
      "Batch: 49 , Combined Loss: tensor(0.7466, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4920843839645386\n",
      "Batch: 50 , Combined Loss: tensor(0.7908, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5635913610458374\n",
      "Batch: 51 , Combined Loss: tensor(0.8975, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.011749029159546\n",
      "Batch: 52 , Combined Loss: tensor(0.7108, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.804763674736023\n",
      "Batch: 53 , Combined Loss: tensor(0.7343, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.27528470754623413\n",
      "Batch: 54 , Combined Loss: tensor(0.7508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3753401041030884\n",
      "Batch: 55 , Combined Loss: tensor(0.6615, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6567410230636597\n",
      "Batch: 56 , Combined Loss: tensor(0.7621, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4280019998550415\n",
      "Batch: 57 , Combined Loss: tensor(0.7850, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9773406982421875\n",
      "Batch: 58 , Combined Loss: tensor(0.8344, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5323913097381592\n",
      "Batch: 59 , Combined Loss: tensor(0.7776, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.02593684196472168\n",
      "Batch: 60 , Combined Loss: tensor(0.7377, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23812472820281982\n",
      "Batch: 61 , Combined Loss: tensor(0.9155, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9634770154953003\n",
      "Batch: 62 , Combined Loss: tensor(0.9249, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.759734034538269\n",
      "Batch: 63 , Combined Loss: tensor(0.7523, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.049395859241485596\n",
      "Batch: 64 , Combined Loss: tensor(0.7077, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.864287257194519\n",
      "Batch: 65 , Combined Loss: tensor(0.8453, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5942634344100952\n",
      "Batch: 66 , Combined Loss: tensor(0.7764, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6283659934997559\n",
      "Batch: 67 , Combined Loss: tensor(0.7101, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14685416221618652\n",
      "Batch: 68 , Combined Loss: tensor(0.8106, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31532764434814453\n",
      "Batch: 69 , Combined Loss: tensor(0.8205, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5864813327789307\n",
      "Batch: 70 , Combined Loss: tensor(0.7766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6228346824645996\n",
      "Batch: 71 , Combined Loss: tensor(0.6530, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49283790588378906\n",
      "Batch: 72 , Combined Loss: tensor(0.7387, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6058351993560791\n",
      "Batch: 73 , Combined Loss: tensor(0.8179, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9778125286102295\n",
      "Batch: 74 , Combined Loss: tensor(0.9994, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.35258424282073975\n",
      "Batch: 75 , Combined Loss: tensor(0.7195, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7090294361114502\n",
      "Batch: 76 , Combined Loss: tensor(0.7597, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3816021680831909\n",
      "Batch: 77 , Combined Loss: tensor(0.8278, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5291416645050049\n",
      "Batch: 78 , Combined Loss: tensor(0.7275, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2667808532714844\n",
      "Batch: 79 , Combined Loss: tensor(0.7583, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8754796981811523\n",
      "Batch: 80 , Combined Loss: tensor(0.7395, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.011537253856658936\n",
      "Batch: 81 , Combined Loss: tensor(0.6708, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9196333885192871\n",
      "Batch: 82 , Combined Loss: tensor(0.7024, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1284167766571045\n",
      "Batch: 83 , Combined Loss: tensor(0.6399, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6300129890441895\n",
      "Batch: 84 , Combined Loss: tensor(0.6373, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18749845027923584\n",
      "Batch: 85 , Combined Loss: tensor(0.7026, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6065164804458618\n",
      "Batch: 86 , Combined Loss: tensor(0.6879, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.325458288192749\n",
      "Batch: 87 , Combined Loss: tensor(0.6991, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7600784301757812\n",
      "Batch: 88 , Combined Loss: tensor(0.9361, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2593809962272644\n",
      "Batch: 89 , Combined Loss: tensor(0.7703, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6751494407653809\n",
      "Batch: 90 , Combined Loss: tensor(0.7232, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0080575942993164\n",
      "Batch: 91 , Combined Loss: tensor(0.8486, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44209444522857666\n",
      "Batch: 92 , Combined Loss: tensor(0.6660, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6290900707244873\n",
      "Batch: 93 , Combined Loss: tensor(0.8396, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3974330425262451\n",
      "Batch: 94 , Combined Loss: tensor(0.8611, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7338794469833374\n",
      "Batch: 95 , Combined Loss: tensor(0.7781, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7240235805511475\n",
      "Batch: 96 , Combined Loss: tensor(0.7661, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7895718812942505\n",
      "Batch: 97 , Combined Loss: tensor(0.8540, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8987365961074829\n",
      "Batch: 98 , Combined Loss: tensor(0.8175, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25767457485198975\n",
      "Batch: 99 , Combined Loss: tensor(0.6822, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44571399688720703\n",
      "Batch: 100 , Combined Loss: tensor(0.8482, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2901993989944458\n",
      "Batch: 101 , Combined Loss: tensor(0.7048, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21541368961334229\n",
      "Batch: 102 , Combined Loss: tensor(0.7379, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7108862400054932\n",
      "Batch: 103 , Combined Loss: tensor(0.7177, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33509910106658936\n",
      "Batch: 104 , Combined Loss: tensor(0.7219, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5164421796798706\n",
      "Batch: 105 , Combined Loss: tensor(0.9420, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4100632071495056\n",
      "Batch: 106 , Combined Loss: tensor(0.7328, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5603040456771851\n",
      "Batch: 107 , Combined Loss: tensor(0.6658, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15950614213943481\n",
      "Batch: 108 , Combined Loss: tensor(0.8123, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4325000047683716\n",
      "Batch: 109 , Combined Loss: tensor(0.6882, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21032440662384033\n",
      "Batch: 110 , Combined Loss: tensor(0.8488, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6178942918777466\n",
      "Batch: 111 , Combined Loss: tensor(0.7499, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7720350027084351\n",
      "Batch: 112 , Combined Loss: tensor(0.6698, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03362476825714111\n",
      "Batch: 113 , Combined Loss: tensor(0.7094, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8210813999176025\n",
      "Batch: 114 , Combined Loss: tensor(1.0693, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.120633065700531\n",
      "Batch: 115 , Combined Loss: tensor(0.8194, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6345740556716919\n",
      "Batch: 116 , Combined Loss: tensor(0.7824, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.84654700756073\n",
      "Batch: 117 , Combined Loss: tensor(0.7252, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8934346437454224\n",
      "Batch: 118 , Combined Loss: tensor(0.6676, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5976171493530273\n",
      "Batch: 119 , Combined Loss: tensor(0.8257, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5815069675445557\n",
      "Batch: 120 , Combined Loss: tensor(0.7763, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.13136041164398193\n",
      "Batch: 121 , Combined Loss: tensor(0.7687, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.600527286529541\n",
      "Batch: 122 , Combined Loss: tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7548575401306152\n",
      "Batch: 123 , Combined Loss: tensor(0.6567, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.028420746326446533\n",
      "Batch: 124 , Combined Loss: tensor(0.6833, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.16807252168655396\n",
      "Batch: 125 , Combined Loss: tensor(0.6747, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.591834306716919\n",
      "Batch: 126 , Combined Loss: tensor(0.7590, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8569278717041016\n",
      "Batch: 127 , Combined Loss: tensor(0.8165, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12356936931610107\n",
      "Batch: 128 , Combined Loss: tensor(0.8384, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5918605327606201\n",
      "Batch: 129 , Combined Loss: tensor(0.8601, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5461432933807373\n",
      "Batch: 130 , Combined Loss: tensor(0.7322, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06248068809509277\n",
      "Batch: 131 , Combined Loss: tensor(0.8132, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6523654460906982\n",
      "Batch: 132 , Combined Loss: tensor(0.7613, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8280985355377197\n",
      "Batch: 133 , Combined Loss: tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6918878555297852\n",
      "Batch: 134 , Combined Loss: tensor(0.9304, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39227575063705444\n",
      "Batch: 135 , Combined Loss: tensor(0.6867, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0126867294311523\n",
      "Batch: 136 , Combined Loss: tensor(0.9165, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4497331380844116\n",
      "Batch: 137 , Combined Loss: tensor(0.6503, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4357929229736328\n",
      "Batch: 138 , Combined Loss: tensor(0.6819, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6343942880630493\n",
      "Batch: 139 , Combined Loss: tensor(0.8592, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04590427875518799\n",
      "Batch: 140 , Combined Loss: tensor(0.7335, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7950737476348877\n",
      "Batch: 141 , Combined Loss: tensor(0.7699, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6406278610229492\n",
      "Batch: 142 , Combined Loss: tensor(0.8379, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3856844902038574\n",
      "Batch: 143 , Combined Loss: tensor(0.7751, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7241511344909668\n",
      "Batch: 144 , Combined Loss: tensor(0.7598, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.30167967081069946\n",
      "Batch: 145 , Combined Loss: tensor(0.7764, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.25088268518447876\n",
      "Batch: 146 , Combined Loss: tensor(0.8411, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5501070618629456\n",
      "Batch: 147 , Combined Loss: tensor(0.8856, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3832434415817261\n",
      "Batch: 148 , Combined Loss: tensor(0.8867, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5713704824447632\n",
      "Batch: 149 , Combined Loss: tensor(0.6823, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30513739585876465\n",
      "Batch: 150 , Combined Loss: tensor(0.8209, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5783911943435669\n",
      "Batch: 151 , Combined Loss: tensor(0.8350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6329391002655029\n",
      "Batch: 152 , Combined Loss: tensor(0.7385, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6587860584259033\n",
      "Batch: 153 , Combined Loss: tensor(0.7251, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16372215747833252\n",
      "Batch: 154 , Combined Loss: tensor(0.7676, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3002955913543701\n",
      "Batch: 155 , Combined Loss: tensor(0.7711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.799587607383728\n",
      "Batch: 156 , Combined Loss: tensor(0.7229, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.04183030128479\n",
      "Batch: 157 , Combined Loss: tensor(0.8457, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23520338535308838\n",
      "Batch: 158 , Combined Loss: tensor(0.6934, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.717992901802063\n",
      "Batch: 159 , Combined Loss: tensor(0.7332, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1254798173904419\n",
      "Batch: 160 , Combined Loss: tensor(0.9339, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6941953897476196\n",
      "Batch: 161 , Combined Loss: tensor(0.8576, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23185503482818604\n",
      "Batch: 162 , Combined Loss: tensor(0.7584, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7825119495391846\n",
      "Batch: 163 , Combined Loss: tensor(0.8293, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24495172500610352\n",
      "Batch: 164 , Combined Loss: tensor(0.6978, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4139479398727417\n",
      "Batch: 165 , Combined Loss: tensor(0.6752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5798391103744507\n",
      "Batch: 166 , Combined Loss: tensor(0.8027, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2041916847229004\n",
      "Batch: 167 , Combined Loss: tensor(0.6802, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5479744672775269\n",
      "Batch: 168 , Combined Loss: tensor(0.8833, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3592801094055176\n",
      "Batch: 169 , Combined Loss: tensor(0.6570, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6543885469436646\n",
      "Batch: 170 , Combined Loss: tensor(0.7334, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8895924091339111\n",
      "Batch: 171 , Combined Loss: tensor(0.7598, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0510479211807251\n",
      "Batch: 172 , Combined Loss: tensor(0.7471, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8336361646652222\n",
      "Batch: 173 , Combined Loss: tensor(0.6988, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8155297040939331\n",
      "Batch: 174 , Combined Loss: tensor(0.7404, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5483274459838867\n",
      "Batch: 175 , Combined Loss: tensor(0.7172, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8174600601196289\n",
      "Batch: 176 , Combined Loss: tensor(0.8558, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1488208770751953\n",
      "Batch: 177 , Combined Loss: tensor(0.8011, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5783156156539917\n",
      "Batch: 178 , Combined Loss: tensor(0.7420, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22905081510543823\n",
      "Batch: 179 , Combined Loss: tensor(0.7542, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2874406576156616\n",
      "Batch: 180 , Combined Loss: tensor(0.9769, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.021099388599395752\n",
      "Batch: 181 , Combined Loss: tensor(0.8114, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9382224082946777\n",
      "Batch: 182 , Combined Loss: tensor(0.6779, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.25354868173599243\n",
      "Batch: 183 , Combined Loss: tensor(0.9244, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14371073246002197\n",
      "Batch: 184 , Combined Loss: tensor(0.6485, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23168694972991943\n",
      "Batch: 185 , Combined Loss: tensor(0.7784, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44560539722442627\n",
      "Batch: 186 , Combined Loss: tensor(0.8068, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4402581453323364\n",
      "Batch: 187 , Combined Loss: tensor(0.8240, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7471622228622437\n",
      "Batch: 188 , Combined Loss: tensor(0.7303, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0807278156280518\n",
      "Batch: 189 , Combined Loss: tensor(0.7109, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.939677357673645\n",
      "Batch: 190 , Combined Loss: tensor(0.7697, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8150572776794434\n",
      "Batch: 191 , Combined Loss: tensor(0.7109, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03328299522399902\n",
      "Batch: 192 , Combined Loss: tensor(0.8459, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2478596568107605\n",
      "Batch: 193 , Combined Loss: tensor(0.7248, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4514307975769043\n",
      "Batch: 194 , Combined Loss: tensor(0.6787, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8234888315200806\n",
      "Batch: 195 , Combined Loss: tensor(0.6509, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8942209482192993\n",
      "Batch: 196 , Combined Loss: tensor(0.7483, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44268572330474854\n",
      "Batch: 197 , Combined Loss: tensor(0.7617, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4192754030227661\n",
      "Batch: 198 , Combined Loss: tensor(0.7614, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1288222074508667\n",
      "Batch: 199 , Combined Loss: tensor(0.7880, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6995190382003784\n",
      "Batch: 200 , Combined Loss: tensor(0.8094, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6704654693603516\n",
      "Batch: 201 , Combined Loss: tensor(0.7125, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8283449411392212\n",
      "Batch: 202 , Combined Loss: tensor(0.7604, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22507035732269287\n",
      "Batch: 203 , Combined Loss: tensor(0.6646, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46788060665130615\n",
      "Batch: 204 , Combined Loss: tensor(1.1452, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7670083045959473\n",
      "Batch: 205 , Combined Loss: tensor(0.6882, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9075225591659546\n",
      "Batch: 206 , Combined Loss: tensor(0.6080, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.012019753456115723\n",
      "Batch: 207 , Combined Loss: tensor(0.7081, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40642809867858887\n",
      "Batch: 208 , Combined Loss: tensor(0.6568, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16120076179504395\n",
      "Batch: 209 , Combined Loss: tensor(0.7010, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28210508823394775\n",
      "Batch: 210 , Combined Loss: tensor(0.8251, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9116350412368774\n",
      "Batch: 211 , Combined Loss: tensor(0.7008, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09564435482025146\n",
      "Batch: 212 , Combined Loss: tensor(0.7475, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6988542079925537\n",
      "Batch: 213 , Combined Loss: tensor(0.7444, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.556522786617279\n",
      "Batch: 214 , Combined Loss: tensor(0.7786, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4978083372116089\n",
      "Batch: 215 , Combined Loss: tensor(0.6860, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.007251858711242676\n",
      "Batch: 216 , Combined Loss: tensor(0.7596, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7878496646881104\n",
      "Batch: 217 , Combined Loss: tensor(0.6202, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46946120262145996\n",
      "Batch: 218 , Combined Loss: tensor(0.9766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.49949461221694946\n",
      "Batch: 219 , Combined Loss: tensor(0.6791, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15794479846954346\n",
      "Batch: 220 , Combined Loss: tensor(0.7552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0443885326385498\n",
      "Batch: 221 , Combined Loss: tensor(0.7705, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.303011417388916\n",
      "Batch: 222 , Combined Loss: tensor(0.7256, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2917293906211853\n",
      "Batch: 223 , Combined Loss: tensor(0.8314, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41667449474334717\n",
      "Batch: 224 , Combined Loss: tensor(0.7766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6203563213348389\n",
      "Batch: 225 , Combined Loss: tensor(0.6852, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7483521699905396\n",
      "Batch: 226 , Combined Loss: tensor(0.6660, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0385630130767822\n",
      "Batch: 227 , Combined Loss: tensor(0.7388, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06758785247802734\n",
      "Batch: 228 , Combined Loss: tensor(0.7513, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9877458810806274\n",
      "Batch: 229 , Combined Loss: tensor(0.8477, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8051302433013916\n",
      "Batch: 230 , Combined Loss: tensor(0.7450, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4244663715362549\n",
      "Batch: 231 , Combined Loss: tensor(0.7985, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3524059057235718\n",
      "Batch: 232 , Combined Loss: tensor(0.7325, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7787452936172485\n",
      "Batch: 233 , Combined Loss: tensor(0.7764, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0049991607666015625\n",
      "Batch: 234 , Combined Loss: tensor(0.6703, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8206062316894531\n",
      "Batch: 235 , Combined Loss: tensor(0.8232, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.028006553649902344\n",
      "Batch: 236 , Combined Loss: tensor(0.7197, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7270032167434692\n",
      "Batch: 237 , Combined Loss: tensor(0.7090, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.576156497001648\n",
      "Batch: 238 , Combined Loss: tensor(0.9841, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10612773895263672\n",
      "Batch: 239 , Combined Loss: tensor(0.7576, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29843807220458984\n",
      "Batch: 240 , Combined Loss: tensor(0.7832, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7389789819717407\n",
      "Batch: 241 , Combined Loss: tensor(0.6484, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8090575933456421\n",
      "Batch: 242 , Combined Loss: tensor(1.0156, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9315487146377563\n",
      "Batch: 243 , Combined Loss: tensor(0.6656, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0437391996383667\n",
      "Batch: 244 , Combined Loss: tensor(0.7462, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10530436038970947\n",
      "Batch: 245 , Combined Loss: tensor(0.7750, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8041120767593384\n",
      "Batch: 246 , Combined Loss: tensor(0.8945, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5202101469039917\n",
      "Batch: 247 , Combined Loss: tensor(0.7176, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2079395055770874\n",
      "Batch: 248 , Combined Loss: tensor(0.7502, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42241811752319336\n",
      "Batch: 249 , Combined Loss: tensor(0.6892, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.671018123626709\n",
      "Batch: 250 , Combined Loss: tensor(0.7453, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5055807828903198\n",
      "Batch: 251 , Combined Loss: tensor(0.7250, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3509817123413086\n",
      "Batch: 252 , Combined Loss: tensor(0.7489, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6646194458007812\n",
      "Batch: 253 , Combined Loss: tensor(0.8229, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4523669481277466\n",
      "Batch: 254 , Combined Loss: tensor(0.7442, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.13256067037582397\n",
      "Batch: 255 , Combined Loss: tensor(0.6987, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6083869934082031\n",
      "Batch: 256 , Combined Loss: tensor(0.7094, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1771385669708252\n",
      "Batch: 257 , Combined Loss: tensor(0.7471, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8591251373291016\n",
      "Batch: 258 , Combined Loss: tensor(0.7051, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0728986263275146\n",
      "Batch: 259 , Combined Loss: tensor(0.6801, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16608738899230957\n",
      "Batch: 260 , Combined Loss: tensor(0.6624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8871874809265137\n",
      "Batch: 261 , Combined Loss: tensor(0.8232, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2506018877029419\n",
      "Batch: 262 , Combined Loss: tensor(0.6984, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7798929214477539\n",
      "Batch: 263 , Combined Loss: tensor(0.7672, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0427923202514648\n",
      "Batch: 264 , Combined Loss: tensor(0.6606, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6830347776412964\n",
      "Batch: 265 , Combined Loss: tensor(0.8857, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7360464334487915\n",
      "Batch: 266 , Combined Loss: tensor(1.1230, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.30327481031417847\n",
      "Batch: 267 , Combined Loss: tensor(0.7595, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9086165428161621\n",
      "Batch: 268 , Combined Loss: tensor(0.7325, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03982126712799072\n",
      "Batch: 269 , Combined Loss: tensor(0.7245, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5482550859451294\n",
      "Batch: 270 , Combined Loss: tensor(0.6787, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44783759117126465\n",
      "Batch: 271 , Combined Loss: tensor(0.7264, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.77415931224823\n",
      "Batch: 272 , Combined Loss: tensor(0.7358, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7382181882858276\n",
      "Batch: 273 , Combined Loss: tensor(0.7938, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7961373329162598\n",
      "Batch: 274 , Combined Loss: tensor(0.6722, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.542635440826416\n",
      "Batch: 275 , Combined Loss: tensor(0.6838, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4960581064224243\n",
      "Batch: 276 , Combined Loss: tensor(0.6580, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3253241777420044\n",
      "Batch: 277 , Combined Loss: tensor(0.7251, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05039435625076294\n",
      "Batch: 278 , Combined Loss: tensor(0.7190, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6064872741699219\n",
      "Batch: 279 , Combined Loss: tensor(0.7091, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7923331260681152\n",
      "Batch: 280 , Combined Loss: tensor(1.0923, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25080692768096924\n",
      "Batch: 281 , Combined Loss: tensor(0.9513, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7123301029205322\n",
      "Batch: 282 , Combined Loss: tensor(0.8908, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12463819980621338\n",
      "Batch: 283 , Combined Loss: tensor(0.6729, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9413934946060181\n",
      "Batch: 284 , Combined Loss: tensor(1.0288, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7868702411651611\n",
      "Batch: 285 , Combined Loss: tensor(0.7098, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2634916305541992\n",
      "Batch: 286 , Combined Loss: tensor(0.8236, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9318748712539673\n",
      "Batch: 287 , Combined Loss: tensor(0.6772, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5640813112258911\n",
      "Batch: 288 , Combined Loss: tensor(0.8090, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39616096019744873\n",
      "Batch: 289 , Combined Loss: tensor(0.7277, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8837140798568726\n",
      "Batch: 290 , Combined Loss: tensor(0.9344, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21770358085632324\n",
      "Batch: 291 , Combined Loss: tensor(0.7793, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3262195587158203\n",
      "Batch: 292 , Combined Loss: tensor(0.7682, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.396030068397522\n",
      "Batch: 293 , Combined Loss: tensor(0.6841, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3510398864746094\n",
      "Batch: 294 , Combined Loss: tensor(0.7229, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0841844081878662\n",
      "Batch: 295 , Combined Loss: tensor(0.9517, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3997979164123535\n",
      "Batch: 296 , Combined Loss: tensor(0.6959, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7041665315628052\n",
      "Batch: 297 , Combined Loss: tensor(0.6327, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15972024202346802\n",
      "Batch: 298 , Combined Loss: tensor(0.6892, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6367019414901733\n",
      "Batch: 299 , Combined Loss: tensor(0.7565, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38359594345092773\n",
      "Batch: 300 , Combined Loss: tensor(0.7018, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4111142158508301\n",
      "Batch: 301 , Combined Loss: tensor(0.7916, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.945557713508606\n",
      "Batch: 302 , Combined Loss: tensor(1.0970, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3737373352050781\n",
      "Batch: 303 , Combined Loss: tensor(0.9792, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5024658441543579\n",
      "Batch: 304 , Combined Loss: tensor(0.8327, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8642840385437012\n",
      "Batch: 305 , Combined Loss: tensor(0.6815, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8497018814086914\n",
      "Batch: 306 , Combined Loss: tensor(0.7427, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8736332654953003\n",
      "Batch: 307 , Combined Loss: tensor(0.8415, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9906338453292847\n",
      "Batch: 308 , Combined Loss: tensor(0.7306, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5210657119750977\n",
      "Batch: 309 , Combined Loss: tensor(0.7084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0034222602844238\n",
      "Batch: 310 , Combined Loss: tensor(0.7946, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8962104320526123\n",
      "Batch: 311 , Combined Loss: tensor(0.6808, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8182175159454346\n",
      "Batch: 312 , Combined Loss: tensor(0.8084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10919874906539917\n",
      "Batch: 313 , Combined Loss: tensor(0.7236, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05264890193939209\n",
      "Batch: 314 , Combined Loss: tensor(0.6840, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0806515216827393\n",
      "Batch: 315 , Combined Loss: tensor(0.7923, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9404784440994263\n",
      "Batch: 316 , Combined Loss: tensor(0.6844, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20598047971725464\n",
      "Batch: 317 , Combined Loss: tensor(0.6608, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6596763730049133\n",
      "Batch: 318 , Combined Loss: tensor(0.7811, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9340003728866577\n",
      "Batch: 319 , Combined Loss: tensor(0.6881, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8029881715774536\n",
      "Batch: 320 , Combined Loss: tensor(0.9688, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.50240159034729\n",
      "Batch: 321 , Combined Loss: tensor(0.7488, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.030567526817321777\n",
      "Batch: 322 , Combined Loss: tensor(0.8691, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6090086698532104\n",
      "Batch: 323 , Combined Loss: tensor(0.7466, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27858424186706543\n",
      "Batch: 324 , Combined Loss: tensor(0.7481, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9361107349395752\n",
      "Batch: 325 , Combined Loss: tensor(1.3121, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35261595249176025\n",
      "Batch: 326 , Combined Loss: tensor(0.6727, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21818256378173828\n",
      "Batch: 327 , Combined Loss: tensor(0.8372, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8300750255584717\n",
      "Batch: 328 , Combined Loss: tensor(0.6601, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.030645430088043213\n",
      "Batch: 329 , Combined Loss: tensor(0.7638, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2819240093231201\n",
      "Batch: 330 , Combined Loss: tensor(0.8350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9030900001525879\n",
      "Batch: 331 , Combined Loss: tensor(0.7008, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7375509738922119\n",
      "Batch: 332 , Combined Loss: tensor(0.7543, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.046576857566833496\n",
      "Batch: 333 , Combined Loss: tensor(0.7798, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6975281238555908\n",
      "Batch: 334 , Combined Loss: tensor(0.7306, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6535543203353882\n",
      "Batch: 335 , Combined Loss: tensor(0.6924, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8632854223251343\n",
      "Batch: 336 , Combined Loss: tensor(0.6261, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9695889949798584\n",
      "Batch: 337 , Combined Loss: tensor(0.8369, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3226977586746216\n",
      "Batch: 338 , Combined Loss: tensor(0.7785, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32447075843811035\n",
      "Batch: 339 , Combined Loss: tensor(0.7338, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.18961817026138306\n",
      "Batch: 340 , Combined Loss: tensor(0.7686, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6646672487258911\n",
      "Batch: 341 , Combined Loss: tensor(0.7896, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0057648420333862305\n",
      "Batch: 342 , Combined Loss: tensor(0.7694, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42209601402282715\n",
      "Batch: 343 , Combined Loss: tensor(0.9425, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04139852523803711\n",
      "Batch: 344 , Combined Loss: tensor(0.9015, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19583666324615479\n",
      "Batch: 345 , Combined Loss: tensor(0.9559, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.519385814666748\n",
      "Batch: 346 , Combined Loss: tensor(0.6985, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0435302257537842\n",
      "Batch: 347 , Combined Loss: tensor(0.6422, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42042088508605957\n",
      "Batch: 348 , Combined Loss: tensor(0.6878, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7329452037811279\n",
      "Batch: 349 , Combined Loss: tensor(0.8215, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22979986667633057\n",
      "Batch: 350 , Combined Loss: tensor(1.0339, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24117636680603027\n",
      "Batch: 351 , Combined Loss: tensor(0.9295, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.211348295211792\n",
      "Batch: 352 , Combined Loss: tensor(0.7100, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5102640390396118\n",
      "Batch: 353 , Combined Loss: tensor(0.7740, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8291246891021729\n",
      "Batch: 354 , Combined Loss: tensor(0.9281, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08842527866363525\n",
      "Batch: 355 , Combined Loss: tensor(0.7507, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5161899328231812\n",
      "Batch: 356 , Combined Loss: tensor(0.8320, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5764877796173096\n",
      "Batch: 357 , Combined Loss: tensor(0.7041, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.33143121004104614\n",
      "Batch: 358 , Combined Loss: tensor(0.8116, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23916983604431152\n",
      "Batch: 359 , Combined Loss: tensor(0.8739, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14812731742858887\n",
      "Batch: 360 , Combined Loss: tensor(0.7496, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6357842087745667\n",
      "Batch: 361 , Combined Loss: tensor(0.8003, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5442789793014526\n",
      "Batch: 362 , Combined Loss: tensor(0.7457, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6208088397979736\n",
      "Batch: 363 , Combined Loss: tensor(0.7427, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1306447982788086\n",
      "Batch: 364 , Combined Loss: tensor(0.7713, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.34028810262680054\n",
      "Batch: 365 , Combined Loss: tensor(0.9103, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4180647134780884\n",
      "Batch: 366 , Combined Loss: tensor(0.8099, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5066722631454468\n",
      "Batch: 367 , Combined Loss: tensor(0.8362, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.481891393661499\n",
      "Batch: 368 , Combined Loss: tensor(0.7502, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45323169231414795\n",
      "Batch: 369 , Combined Loss: tensor(0.8634, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26769375801086426\n",
      "Batch: 370 , Combined Loss: tensor(0.7954, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3894317150115967\n",
      "Batch: 371 , Combined Loss: tensor(0.6929, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3182051181793213\n",
      "Batch: 372 , Combined Loss: tensor(0.8268, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46190106868743896\n",
      "Batch: 373 , Combined Loss: tensor(0.7804, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24264955520629883\n",
      "Batch: 374 , Combined Loss: tensor(0.7508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5707767009735107\n",
      "Batch: 375 , Combined Loss: tensor(0.8150, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.40675199031829834\n",
      "Batch: 376 , Combined Loss: tensor(0.7231, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.34934502840042114\n",
      "Batch: 377 , Combined Loss: tensor(0.8620, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4131641387939453\n",
      "Batch: 378 , Combined Loss: tensor(0.6826, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4823176860809326\n",
      "Batch: 379 , Combined Loss: tensor(0.7599, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.020733773708343506\n",
      "Batch: 380 , Combined Loss: tensor(0.8518, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6495647430419922\n",
      "Batch: 381 , Combined Loss: tensor(0.7273, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31153762340545654\n",
      "Batch: 382 , Combined Loss: tensor(0.8084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15273022651672363\n",
      "Batch: 383 , Combined Loss: tensor(0.7998, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.739327073097229\n",
      "Batch: 384 , Combined Loss: tensor(0.7329, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8465124368667603\n",
      "Batch: 385 , Combined Loss: tensor(0.7183, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21128177642822266\n",
      "Batch: 386 , Combined Loss: tensor(0.8076, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4052242040634155\n",
      "Batch: 387 , Combined Loss: tensor(0.7325, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5904272794723511\n",
      "Batch: 388 , Combined Loss: tensor(0.8392, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08113622665405273\n",
      "Batch: 389 , Combined Loss: tensor(0.7087, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5079187154769897\n",
      "Batch: 390 , Combined Loss: tensor(0.6534, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32317185401916504\n",
      "Batch: 391 , Combined Loss: tensor(0.7435, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6935815811157227\n",
      "Batch: 392 , Combined Loss: tensor(0.7028, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48311126232147217\n",
      "Batch: 393 , Combined Loss: tensor(0.7408, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4513871669769287\n",
      "Batch: 394 , Combined Loss: tensor(0.9964, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23441171646118164\n",
      "Batch: 395 , Combined Loss: tensor(0.6789, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4594764709472656\n",
      "Batch: 396 , Combined Loss: tensor(0.7244, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24737966060638428\n",
      "Batch: 397 , Combined Loss: tensor(0.8787, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6652984619140625\n",
      "Batch: 398 , Combined Loss: tensor(0.6879, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8411582708358765\n",
      "Batch: 399 , Combined Loss: tensor(0.7237, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3002673387527466\n",
      "Batch: 400 , Combined Loss: tensor(1.1270, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8581429719924927\n",
      "Batch: 401 , Combined Loss: tensor(0.6577, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5236504077911377\n",
      "Batch: 402 , Combined Loss: tensor(0.7172, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7137411832809448\n",
      "Batch: 403 , Combined Loss: tensor(0.8715, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5784374475479126\n",
      "Batch: 404 , Combined Loss: tensor(1.0190, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4777902364730835\n",
      "Batch: 405 , Combined Loss: tensor(0.6811, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5147236585617065\n",
      "Batch: 406 , Combined Loss: tensor(0.7354, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6359610557556152\n",
      "Batch: 407 , Combined Loss: tensor(0.8043, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33327293395996094\n",
      "Batch: 408 , Combined Loss: tensor(0.8351, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4725794792175293\n",
      "Batch: 409 , Combined Loss: tensor(0.7201, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9900075197219849\n",
      "Batch: 410 , Combined Loss: tensor(0.7101, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.087768316268921\n",
      "Batch: 411 , Combined Loss: tensor(0.7449, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4173743724822998\n",
      "Batch: 412 , Combined Loss: tensor(0.8332, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0306975841522217\n",
      "Batch: 413 , Combined Loss: tensor(0.6948, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5446977615356445\n",
      "Batch: 414 , Combined Loss: tensor(0.7273, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5348410606384277\n",
      "Batch: 415 , Combined Loss: tensor(0.7738, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12225890159606934\n",
      "Batch: 416 , Combined Loss: tensor(0.7192, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27580273151397705\n",
      "Batch: 417 , Combined Loss: tensor(0.8100, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26566433906555176\n",
      "Batch: 418 , Combined Loss: tensor(0.6877, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.133514404296875\n",
      "Batch: 419 , Combined Loss: tensor(0.7433, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7648603916168213\n",
      "Batch: 420 , Combined Loss: tensor(0.6815, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.626811146736145\n",
      "Batch: 421 , Combined Loss: tensor(0.8342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29209864139556885\n",
      "Batch: 422 , Combined Loss: tensor(0.7599, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43226373195648193\n",
      "Batch: 423 , Combined Loss: tensor(0.7060, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.37138646841049194\n",
      "Batch: 424 , Combined Loss: tensor(0.6927, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7812215089797974\n",
      "Batch: 425 , Combined Loss: tensor(0.7483, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6068265438079834\n",
      "Batch: 426 , Combined Loss: tensor(0.7103, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26702070236206055\n",
      "Batch: 427 , Combined Loss: tensor(0.7852, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6903591156005859\n",
      "Batch: 428 , Combined Loss: tensor(0.8010, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10848188400268555\n",
      "Batch: 429 , Combined Loss: tensor(0.7128, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09202075004577637\n",
      "Batch: 430 , Combined Loss: tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5983548164367676\n",
      "Batch: 431 , Combined Loss: tensor(0.9034, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7042696475982666\n",
      "Batch: 432 , Combined Loss: tensor(0.8713, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24893081188201904\n",
      "Batch: 433 , Combined Loss: tensor(0.6873, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3567376136779785\n",
      "Batch: 434 , Combined Loss: tensor(0.9238, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24407505989074707\n",
      "Batch: 435 , Combined Loss: tensor(0.7923, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4090254306793213\n",
      "Batch: 436 , Combined Loss: tensor(0.8919, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.267911434173584\n",
      "Batch: 437 , Combined Loss: tensor(0.7542, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.052428483963012695\n",
      "Batch: 438 , Combined Loss: tensor(0.7939, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2514660358428955\n",
      "Batch: 439 , Combined Loss: tensor(0.8254, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48556625843048096\n",
      "Batch: 440 , Combined Loss: tensor(0.8333, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4656570553779602\n",
      "Batch: 441 , Combined Loss: tensor(0.7603, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6226346492767334\n",
      "Batch: 442 , Combined Loss: tensor(0.7942, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7492804527282715\n",
      "Batch: 443 , Combined Loss: tensor(0.7019, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8582427501678467\n",
      "Batch: 444 , Combined Loss: tensor(0.7565, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1844344139099121\n",
      "Batch: 445 , Combined Loss: tensor(0.7659, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2820085287094116\n",
      "Batch: 446 , Combined Loss: tensor(0.6846, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5516645908355713\n",
      "Batch: 447 , Combined Loss: tensor(0.7590, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6967242956161499\n",
      "Batch: 448 , Combined Loss: tensor(0.7517, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6259456872940063\n",
      "Batch: 449 , Combined Loss: tensor(0.7942, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5790647268295288\n",
      "Batch: 450 , Combined Loss: tensor(0.7296, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7533664703369141\n",
      "Batch: 451 , Combined Loss: tensor(0.8110, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5638350248336792\n",
      "Batch: 452 , Combined Loss: tensor(0.6084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19509536027908325\n",
      "Batch: 453 , Combined Loss: tensor(0.9772, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14031541347503662\n",
      "Batch: 454 , Combined Loss: tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07846963405609131\n",
      "Batch: 455 , Combined Loss: tensor(0.6987, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5710060596466064\n",
      "Batch: 456 , Combined Loss: tensor(0.8569, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17434585094451904\n",
      "Batch: 457 , Combined Loss: tensor(0.7634, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23647737503051758\n",
      "Batch: 458 , Combined Loss: tensor(0.6835, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6174226403236389\n",
      "Batch: 459 , Combined Loss: tensor(0.8128, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.570632815361023\n",
      "Batch: 460 , Combined Loss: tensor(0.7583, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0551455020904541\n",
      "Batch: 461 , Combined Loss: tensor(0.7271, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0345733165740967\n",
      "Batch: 462 , Combined Loss: tensor(0.8136, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3941061496734619\n",
      "Batch: 463 , Combined Loss: tensor(0.6983, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43588948249816895\n",
      "Batch: 464 , Combined Loss: tensor(0.7101, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36205554008483887\n",
      "Batch: 465 , Combined Loss: tensor(0.8023, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6691337823867798\n",
      "Batch: 466 , Combined Loss: tensor(0.7015, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.611391007900238\n",
      "Batch: 467 , Combined Loss: tensor(0.8080, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2904832363128662\n",
      "Batch: 468 , Combined Loss: tensor(0.7856, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33558547496795654\n",
      "Batch: 469 , Combined Loss: tensor(1.0597, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10951930284500122\n",
      "Batch: 470 , Combined Loss: tensor(0.7321, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7507550716400146\n",
      "Batch: 471 , Combined Loss: tensor(0.7987, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6212592124938965\n",
      "Batch: 472 , Combined Loss: tensor(0.8462, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1494046449661255\n",
      "Batch: 473 , Combined Loss: tensor(0.8171, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.939476490020752\n",
      "Batch: 474 , Combined Loss: tensor(0.7565, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05529475212097168\n",
      "Batch: 475 , Combined Loss: tensor(0.7279, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4656134843826294\n",
      "Batch: 476 , Combined Loss: tensor(0.7312, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4314936399459839\n",
      "Batch: 477 , Combined Loss: tensor(0.7075, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6715595722198486\n",
      "Batch: 478 , Combined Loss: tensor(0.7766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5984679460525513\n",
      "Batch: 479 , Combined Loss: tensor(0.8913, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7285324335098267\n",
      "Batch: 480 , Combined Loss: tensor(0.7326, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16627848148345947\n",
      "Batch: 481 , Combined Loss: tensor(0.7427, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21629905700683594\n",
      "Batch: 482 , Combined Loss: tensor(0.9756, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.47146284580230713\n",
      "Batch: 483 , Combined Loss: tensor(0.6945, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8112818002700806\n",
      "Batch: 484 , Combined Loss: tensor(0.7914, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7863531112670898\n",
      "Batch: 485 , Combined Loss: tensor(0.6759, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6961671113967896\n",
      "Batch: 486 , Combined Loss: tensor(0.7401, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.691063404083252\n",
      "Batch: 487 , Combined Loss: tensor(0.7226, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5340688228607178\n",
      "Batch: 488 , Combined Loss: tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6839526891708374\n",
      "Batch: 489 , Combined Loss: tensor(0.6708, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5301443338394165\n",
      "Batch: 490 , Combined Loss: tensor(0.8297, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1460515260696411\n",
      "Batch: 491 , Combined Loss: tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7899969816207886\n",
      "Batch: 492 , Combined Loss: tensor(0.7886, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9826951026916504\n",
      "Batch: 493 , Combined Loss: tensor(0.7003, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3361823558807373\n",
      "Batch: 494 , Combined Loss: tensor(0.7930, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.31141161918640137\n",
      "Batch: 495 , Combined Loss: tensor(0.7077, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8556219339370728\n",
      "Batch: 496 , Combined Loss: tensor(0.8518, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26240622997283936\n",
      "Batch: 497 , Combined Loss: tensor(0.7623, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4646705389022827\n",
      "Batch: 498 , Combined Loss: tensor(0.8047, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1360262632369995\n",
      "Batch: 499 , Combined Loss: tensor(0.7372, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08879983425140381\n",
      "Batch: 500 , Combined Loss: tensor(0.7368, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15756464004516602\n",
      "Batch: 501 , Combined Loss: tensor(0.7330, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4809126853942871\n",
      "Batch: 502 , Combined Loss: tensor(0.6614, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17070400714874268\n",
      "Batch: 503 , Combined Loss: tensor(0.7003, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6218527555465698\n",
      "Batch: 504 , Combined Loss: tensor(0.7502, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.045722901821136475\n",
      "Batch: 505 , Combined Loss: tensor(0.7439, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5102368593215942\n",
      "Batch: 506 , Combined Loss: tensor(0.8212, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6198809146881104\n",
      "Batch: 507 , Combined Loss: tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.008020162582397461\n",
      "Batch: 508 , Combined Loss: tensor(0.7695, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3317544460296631\n",
      "Batch: 509 , Combined Loss: tensor(0.9583, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.42733174562454224\n",
      "Batch: 510 , Combined Loss: tensor(0.9647, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17501503229141235\n",
      "Batch: 511 , Combined Loss: tensor(0.7636, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4622470736503601\n",
      "Batch: 512 , Combined Loss: tensor(0.7581, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3322693109512329\n",
      "Batch: 513 , Combined Loss: tensor(0.7775, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5751312971115112\n",
      "Batch: 514 , Combined Loss: tensor(0.8582, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3352556824684143\n",
      "Batch: 515 , Combined Loss: tensor(0.7616, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5303214192390442\n",
      "Batch: 516 , Combined Loss: tensor(0.7710, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.48998910188674927\n",
      "Batch: 517 , Combined Loss: tensor(0.7653, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3615553379058838\n",
      "Batch: 518 , Combined Loss: tensor(0.7912, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3626973032951355\n",
      "Batch: 519 , Combined Loss: tensor(0.7045, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25588762760162354\n",
      "Batch: 520 , Combined Loss: tensor(0.6762, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4665259122848511\n",
      "Batch: 521 , Combined Loss: tensor(0.7767, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8397382497787476\n",
      "Batch: 522 , Combined Loss: tensor(0.8214, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3613203763961792\n",
      "Batch: 523 , Combined Loss: tensor(0.7752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7608473300933838\n",
      "Batch: 524 , Combined Loss: tensor(0.8567, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.49729520082473755\n",
      "Batch: 525 , Combined Loss: tensor(0.9536, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.460713267326355\n",
      "Batch: 526 , Combined Loss: tensor(0.9015, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7925546169281006\n",
      "Batch: 527 , Combined Loss: tensor(0.8665, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6081609725952148\n",
      "Batch: 528 , Combined Loss: tensor(0.7358, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11315500736236572\n",
      "Batch: 529 , Combined Loss: tensor(0.8288, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2609199285507202\n",
      "Batch: 530 , Combined Loss: tensor(0.7071, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1514291763305664\n",
      "Batch: 531 , Combined Loss: tensor(0.6884, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18866276741027832\n",
      "Batch: 532 , Combined Loss: tensor(0.7612, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0974164009094238\n",
      "Batch: 533 , Combined Loss: tensor(0.7391, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7322174310684204\n",
      "Batch: 534 , Combined Loss: tensor(0.8225, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5746872425079346\n",
      "Batch: 535 , Combined Loss: tensor(0.7994, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20002079010009766\n",
      "Batch: 536 , Combined Loss: tensor(0.9442, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5766870975494385\n",
      "Batch: 537 , Combined Loss: tensor(0.7616, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7929837703704834\n",
      "Batch: 538 , Combined Loss: tensor(1.1951, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36088454723358154\n",
      "Batch: 539 , Combined Loss: tensor(0.6830, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8790627717971802\n",
      "Batch: 540 , Combined Loss: tensor(0.7005, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5023782253265381\n",
      "Batch: 541 , Combined Loss: tensor(0.9592, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.13186293840408325\n",
      "Batch: 542 , Combined Loss: tensor(0.6584, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33801937103271484\n",
      "Batch: 543 , Combined Loss: tensor(0.7910, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.43122708797454834\n",
      "Batch: 544 , Combined Loss: tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1381550431251526\n",
      "Batch: 545 , Combined Loss: tensor(0.7851, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.061491429805755615\n",
      "Batch: 546 , Combined Loss: tensor(0.6717, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6285824775695801\n",
      "Batch: 547 , Combined Loss: tensor(0.8050, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14276552200317383\n",
      "Batch: 548 , Combined Loss: tensor(0.8739, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5218358039855957\n",
      "Batch: 549 , Combined Loss: tensor(0.8600, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2857101559638977\n",
      "Batch: 550 , Combined Loss: tensor(0.7072, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5165653228759766\n",
      "Batch: 551 , Combined Loss: tensor(0.6657, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18515312671661377\n",
      "Batch: 552 , Combined Loss: tensor(0.6194, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17424476146697998\n",
      "Batch: 553 , Combined Loss: tensor(0.8576, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6751695871353149\n",
      "Batch: 554 , Combined Loss: tensor(0.6610, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47271060943603516\n",
      "Batch: 555 , Combined Loss: tensor(1.1682, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5134154558181763\n",
      "Batch: 556 , Combined Loss: tensor(0.8639, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.26738762855529785\n",
      "Batch: 557 , Combined Loss: tensor(0.6888, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9259817600250244\n",
      "Batch: 558 , Combined Loss: tensor(0.8638, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08578717708587646\n",
      "Batch: 559 , Combined Loss: tensor(0.7703, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22136646509170532\n",
      "Batch: 560 , Combined Loss: tensor(0.8651, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1335359811782837\n",
      "Batch: 561 , Combined Loss: tensor(0.7126, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5448741912841797\n",
      "Batch: 562 , Combined Loss: tensor(0.7560, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7992929220199585\n",
      "Batch: 563 , Combined Loss: tensor(0.7705, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3159980773925781\n",
      "Batch: 564 , Combined Loss: tensor(0.6995, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6633819341659546\n",
      "Batch: 565 , Combined Loss: tensor(0.6915, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30756616592407227\n",
      "Batch: 566 , Combined Loss: tensor(0.6742, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7592875957489014\n",
      "Batch: 567 , Combined Loss: tensor(0.7432, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09781098365783691\n",
      "Batch: 568 , Combined Loss: tensor(0.6131, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7932363748550415\n",
      "Batch: 569 , Combined Loss: tensor(0.7295, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39072489738464355\n",
      "Batch: 570 , Combined Loss: tensor(0.7214, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3155122399330139\n",
      "Batch: 571 , Combined Loss: tensor(0.7550, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0196185111999512\n",
      "Batch: 572 , Combined Loss: tensor(0.8777, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5876598358154297\n",
      "Batch: 573 , Combined Loss: tensor(0.8436, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7391761541366577\n",
      "Batch: 574 , Combined Loss: tensor(1.0523, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6402961015701294\n",
      "Batch: 575 , Combined Loss: tensor(0.9188, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3450371026992798\n",
      "Batch: 576 , Combined Loss: tensor(0.6860, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5206953287124634\n",
      "Batch: 577 , Combined Loss: tensor(0.7015, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5731799602508545\n",
      "Batch: 578 , Combined Loss: tensor(0.7446, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4505845308303833\n",
      "Batch: 579 , Combined Loss: tensor(0.7213, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3114062547683716\n",
      "Batch: 580 , Combined Loss: tensor(0.7814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1489100456237793\n",
      "Batch: 581 , Combined Loss: tensor(0.6626, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8141602277755737\n",
      "Batch: 582 , Combined Loss: tensor(0.7330, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.814752459526062\n",
      "Batch: 583 , Combined Loss: tensor(1.0654, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7034076452255249\n",
      "Batch: 584 , Combined Loss: tensor(0.7757, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6099294424057007\n",
      "Batch: 585 , Combined Loss: tensor(0.7592, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.004873394966125488\n",
      "Batch: 586 , Combined Loss: tensor(0.6988, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14175117015838623\n",
      "Batch: 587 , Combined Loss: tensor(0.7005, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9192445278167725\n",
      "Batch: 588 , Combined Loss: tensor(0.7575, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9038711786270142\n",
      "Batch: 589 , Combined Loss: tensor(0.8410, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5283753871917725\n",
      "Batch: 590 , Combined Loss: tensor(0.6955, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9370222091674805\n",
      "Batch: 591 , Combined Loss: tensor(0.7249, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11053413152694702\n",
      "Batch: 592 , Combined Loss: tensor(0.7249, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14777588844299316\n",
      "Batch: 593 , Combined Loss: tensor(0.8180, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8757898807525635\n",
      "Batch: 594 , Combined Loss: tensor(0.6756, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5259816646575928\n",
      "Batch: 595 , Combined Loss: tensor(0.7699, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6377396583557129\n",
      "Batch: 596 , Combined Loss: tensor(0.8054, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48429346084594727\n",
      "Batch: 597 , Combined Loss: tensor(0.8674, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18045198917388916\n",
      "Batch: 598 , Combined Loss: tensor(0.6986, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7841596603393555\n",
      "Batch: 599 , Combined Loss: tensor(0.9411, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.845836877822876\n",
      "Batch: 600 , Combined Loss: tensor(0.7418, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15376180410385132\n",
      "Batch: 601 , Combined Loss: tensor(0.8290, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03497302532196045\n",
      "Batch: 602 , Combined Loss: tensor(0.9214, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9217665195465088\n",
      "Batch: 603 , Combined Loss: tensor(0.8251, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06320047378540039\n",
      "Batch: 604 , Combined Loss: tensor(1.1441, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4731025695800781\n",
      "Batch: 605 , Combined Loss: tensor(0.7552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4862055778503418\n",
      "Batch: 606 , Combined Loss: tensor(0.7825, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44239652156829834\n",
      "Batch: 607 , Combined Loss: tensor(0.7688, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44110071659088135\n",
      "Batch: 608 , Combined Loss: tensor(0.7440, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38133394718170166\n",
      "Batch: 609 , Combined Loss: tensor(0.7590, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5638619661331177\n",
      "Batch: 610 , Combined Loss: tensor(0.8090, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5694146156311035\n",
      "Batch: 611 , Combined Loss: tensor(0.9747, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16350293159484863\n",
      "Batch: 612 , Combined Loss: tensor(0.6844, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9447001218795776\n",
      "Batch: 613 , Combined Loss: tensor(0.8913, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.624352216720581\n",
      "Batch: 614 , Combined Loss: tensor(0.7097, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4347085952758789\n",
      "Batch: 615 , Combined Loss: tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43179595470428467\n",
      "Batch: 616 , Combined Loss: tensor(0.7802, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8207502365112305\n",
      "Batch: 617 , Combined Loss: tensor(0.8378, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08698344230651855\n",
      "Batch: 618 , Combined Loss: tensor(0.7340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.575100302696228\n",
      "Batch: 619 , Combined Loss: tensor(0.8096, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5393949747085571\n",
      "Batch: 620 , Combined Loss: tensor(0.7368, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23579812049865723\n",
      "Batch: 621 , Combined Loss: tensor(0.8521, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6997655630111694\n",
      "Batch: 622 , Combined Loss: tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7657506465911865\n",
      "Batch: 623 , Combined Loss: tensor(0.8199, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17783552408218384\n",
      "Batch: 624 , Combined Loss: tensor(0.7646, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6409242153167725\n",
      "Batch: 625 , Combined Loss: tensor(0.8295, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2598288059234619\n",
      "Batch: 626 , Combined Loss: tensor(0.9386, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1041785478591919\n",
      "Batch: 627 , Combined Loss: tensor(0.7869, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3468821048736572\n",
      "Batch: 628 , Combined Loss: tensor(0.8108, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8538364171981812\n",
      "----------Epoch 9, Loss: 0.775639027120199, Accuracy: 0.9425538696810627, Dice Coef: [0.9727950264804882, 0.44658412262621244, 0.49639952659222386, 0.5504720112490699], Dice Coef Necrotic: 0.7167324799437222, Dice Coef Edema: 0.7583248227688009, Dice Coef Enhancing: 0.6398335462839385, Sensitivity: [0.9489184989459185, 0.6681797855829047, 0.8173953998709521, 0.8543318719862233], Specificity: [0.9686170162570874, 0.9948035988405892, 0.9596874551856461, 0.9884530436632554], Precision: [0.9982222285482956, 0.41085832196383404, 0.3869204072311464, 0.4475054537686993]\n",
      "Saving without nn.DataParallel\n",
      "Batch: 0 , Combined Loss: tensor(0.7511, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4890100955963135\n",
      "Batch: 1 , Combined Loss: tensor(0.8264, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2931309938430786\n",
      "Batch: 2 , Combined Loss: tensor(0.8095, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7205958366394043\n",
      "Batch: 3 , Combined Loss: tensor(0.8440, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9821139574050903\n",
      "Batch: 4 , Combined Loss: tensor(0.8066, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03601813316345215\n",
      "Batch: 5 , Combined Loss: tensor(0.6875, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3302934169769287\n",
      "Batch: 6 , Combined Loss: tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09757876396179199\n",
      "Batch: 7 , Combined Loss: tensor(0.8370, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1549656391143799\n",
      "Batch: 8 , Combined Loss: tensor(0.7602, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7625114917755127\n",
      "Batch: 9 , Combined Loss: tensor(0.7188, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7721809148788452\n",
      "Batch: 10 , Combined Loss: tensor(0.7349, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25108885765075684\n",
      "Batch: 11 , Combined Loss: tensor(0.8572, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1533830165863037\n",
      "Batch: 12 , Combined Loss: tensor(0.8716, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.30178868770599365\n",
      "Batch: 13 , Combined Loss: tensor(0.7468, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5477555394172668\n",
      "Batch: 14 , Combined Loss: tensor(0.7535, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5725874900817871\n",
      "Batch: 15 , Combined Loss: tensor(0.7994, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6017634868621826\n",
      "Batch: 16 , Combined Loss: tensor(0.9204, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37554895877838135\n",
      "Batch: 17 , Combined Loss: tensor(0.7717, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5596826076507568\n",
      "Batch: 18 , Combined Loss: tensor(0.7678, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4747188091278076\n",
      "Batch: 19 , Combined Loss: tensor(0.6937, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31033122539520264\n",
      "Batch: 20 , Combined Loss: tensor(0.7864, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6911044120788574\n",
      "Batch: 21 , Combined Loss: tensor(0.6776, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9258687496185303\n",
      "Batch: 22 , Combined Loss: tensor(0.7664, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5838810205459595\n",
      "Batch: 23 , Combined Loss: tensor(0.7421, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.02670145034790039\n",
      "Batch: 24 , Combined Loss: tensor(0.8004, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.056472599506378174\n",
      "Batch: 25 , Combined Loss: tensor(0.8062, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3581613302230835\n",
      "Batch: 26 , Combined Loss: tensor(0.6955, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7718201875686646\n",
      "Batch: 27 , Combined Loss: tensor(0.8122, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25849461555480957\n",
      "Batch: 28 , Combined Loss: tensor(0.8400, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06763184070587158\n",
      "Batch: 29 , Combined Loss: tensor(0.7369, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2709208130836487\n",
      "Batch: 30 , Combined Loss: tensor(0.7926, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6406824588775635\n",
      "Batch: 31 , Combined Loss: tensor(0.9133, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1408900022506714\n",
      "Batch: 32 , Combined Loss: tensor(0.9021, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15249234437942505\n",
      "Batch: 33 , Combined Loss: tensor(0.8340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.43930017948150635\n",
      "Batch: 34 , Combined Loss: tensor(0.7466, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0898466110229492\n",
      "Batch: 35 , Combined Loss: tensor(0.7971, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37790465354919434\n",
      "Batch: 36 , Combined Loss: tensor(0.7177, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9270205497741699\n",
      "Batch: 37 , Combined Loss: tensor(0.7602, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.710412859916687\n",
      "Batch: 38 , Combined Loss: tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5576993227005005\n",
      "Batch: 39 , Combined Loss: tensor(0.9909, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.042951881885528564\n",
      "Batch: 40 , Combined Loss: tensor(0.9189, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25213611125946045\n",
      "Batch: 41 , Combined Loss: tensor(0.7761, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8756649494171143\n",
      "Batch: 42 , Combined Loss: tensor(0.9146, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.49954932928085327\n",
      "Batch: 43 , Combined Loss: tensor(0.8080, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33843421936035156\n",
      "Batch: 44 , Combined Loss: tensor(0.8345, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23366141319274902\n",
      "Batch: 45 , Combined Loss: tensor(0.7302, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0835590362548828\n",
      "Batch: 46 , Combined Loss: tensor(0.8749, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.008848428726196289\n",
      "Batch: 47 , Combined Loss: tensor(0.7293, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8759430646896362\n",
      "Batch: 48 , Combined Loss: tensor(0.6981, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6837680339813232\n",
      "Batch: 49 , Combined Loss: tensor(0.7339, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18159770965576172\n",
      "Batch: 50 , Combined Loss: tensor(0.8783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0030755996704101562\n",
      "Batch: 51 , Combined Loss: tensor(0.8654, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8808944225311279\n",
      "Batch: 52 , Combined Loss: tensor(0.8174, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5040727853775024\n",
      "Batch: 53 , Combined Loss: tensor(0.7862, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1012120246887207\n",
      "Batch: 54 , Combined Loss: tensor(0.8183, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10088729858398438\n",
      "Batch: 55 , Combined Loss: tensor(0.7781, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03239285945892334\n",
      "Batch: 56 , Combined Loss: tensor(0.7000, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2835286855697632\n",
      "Batch: 57 , Combined Loss: tensor(0.8000, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5523358583450317\n",
      "Batch: 58 , Combined Loss: tensor(0.7768, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47036242485046387\n",
      "Batch: 59 , Combined Loss: tensor(0.7043, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5986824035644531\n",
      "Batch: 60 , Combined Loss: tensor(0.8380, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5009011030197144\n",
      "Batch: 61 , Combined Loss: tensor(0.7342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6320480108261108\n",
      "Batch: 62 , Combined Loss: tensor(0.7349, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6248927712440491\n",
      "Batch: 63 , Combined Loss: tensor(0.8721, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3635150194168091\n",
      "Batch: 64 , Combined Loss: tensor(0.7654, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7285411357879639\n",
      "Batch: 65 , Combined Loss: tensor(0.7552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04441404342651367\n",
      "Batch: 66 , Combined Loss: tensor(0.7986, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5648082494735718\n",
      "Batch: 67 , Combined Loss: tensor(0.9275, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09327512979507446\n",
      "Batch: 68 , Combined Loss: tensor(0.7393, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.422063946723938\n",
      "Batch: 69 , Combined Loss: tensor(0.7418, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6767200231552124\n",
      "Batch: 70 , Combined Loss: tensor(0.8246, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06100106239318848\n",
      "Batch: 71 , Combined Loss: tensor(1.1840, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7781999111175537\n",
      "Batch: 72 , Combined Loss: tensor(0.8158, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4234275221824646\n",
      "Batch: 73 , Combined Loss: tensor(0.7545, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0464980602264404\n",
      "Batch: 74 , Combined Loss: tensor(0.7908, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8333044052124023\n",
      "Batch: 75 , Combined Loss: tensor(0.7739, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6009598970413208\n",
      "Batch: 76 , Combined Loss: tensor(0.7186, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24893581867218018\n",
      "Batch: 77 , Combined Loss: tensor(0.8226, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.551284670829773\n",
      "Batch: 78 , Combined Loss: tensor(0.7734, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6342235803604126\n",
      "Batch: 79 , Combined Loss: tensor(0.8027, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5135935544967651\n",
      "Batch: 80 , Combined Loss: tensor(0.7014, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6870499849319458\n",
      "Batch: 81 , Combined Loss: tensor(0.9055, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45558393001556396\n",
      "Batch: 82 , Combined Loss: tensor(0.7529, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1635777950286865\n",
      "Batch: 83 , Combined Loss: tensor(0.6974, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7231301069259644\n",
      "Batch: 84 , Combined Loss: tensor(0.6988, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7504136562347412\n",
      "Batch: 85 , Combined Loss: tensor(0.6994, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5518919229507446\n",
      "Batch: 86 , Combined Loss: tensor(0.7257, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0615601539611816\n",
      "Batch: 87 , Combined Loss: tensor(0.7331, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24203908443450928\n",
      "Batch: 88 , Combined Loss: tensor(0.7717, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0303137302398682\n",
      "Batch: 89 , Combined Loss: tensor(0.7103, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5484975576400757\n",
      "Batch: 90 , Combined Loss: tensor(0.7059, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0551743507385254\n",
      "Batch: 91 , Combined Loss: tensor(0.9438, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3445085287094116\n",
      "Batch: 92 , Combined Loss: tensor(0.6761, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07595181465148926\n",
      "Batch: 93 , Combined Loss: tensor(0.6993, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0363926887512207\n",
      "Batch: 94 , Combined Loss: tensor(0.7725, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8541079759597778\n",
      "Batch: 95 , Combined Loss: tensor(0.8174, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0174376964569092\n",
      "Batch: 96 , Combined Loss: tensor(0.7924, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5575734376907349\n",
      "Batch: 97 , Combined Loss: tensor(0.8253, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6975116729736328\n",
      "Batch: 98 , Combined Loss: tensor(0.7653, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6617748737335205\n",
      "Batch: 99 , Combined Loss: tensor(0.6618, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22449082136154175\n",
      "Batch: 100 , Combined Loss: tensor(0.7236, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8589209318161011\n",
      "Batch: 101 , Combined Loss: tensor(0.7576, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39568865299224854\n",
      "Batch: 102 , Combined Loss: tensor(0.7069, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7371976375579834\n",
      "Batch: 103 , Combined Loss: tensor(0.7056, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7914721965789795\n",
      "Batch: 104 , Combined Loss: tensor(0.8696, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11088907718658447\n",
      "Batch: 105 , Combined Loss: tensor(0.7422, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8154028654098511\n",
      "Batch: 106 , Combined Loss: tensor(0.8324, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.944464921951294\n",
      "Batch: 107 , Combined Loss: tensor(0.7357, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4084571599960327\n",
      "Batch: 108 , Combined Loss: tensor(0.8458, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.02926504611968994\n",
      "Batch: 109 , Combined Loss: tensor(0.7321, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8891319036483765\n",
      "Batch: 110 , Combined Loss: tensor(0.8342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08754938840866089\n",
      "Batch: 111 , Combined Loss: tensor(0.8315, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7518301010131836\n",
      "Batch: 112 , Combined Loss: tensor(0.8983, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05288165807723999\n",
      "Batch: 113 , Combined Loss: tensor(0.6923, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7069722414016724\n",
      "Batch: 114 , Combined Loss: tensor(0.6869, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.124295711517334\n",
      "Batch: 115 , Combined Loss: tensor(0.7617, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2501866817474365\n",
      "Batch: 116 , Combined Loss: tensor(0.9455, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7445664405822754\n",
      "Batch: 117 , Combined Loss: tensor(0.7922, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9477196931838989\n",
      "Batch: 118 , Combined Loss: tensor(0.7377, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24970930814743042\n",
      "Batch: 119 , Combined Loss: tensor(0.8285, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.22666335105896\n",
      "Batch: 120 , Combined Loss: tensor(0.7860, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2069123387336731\n",
      "Batch: 121 , Combined Loss: tensor(0.6859, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9485582113265991\n",
      "Batch: 122 , Combined Loss: tensor(0.7618, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.009304642677307129\n",
      "Batch: 123 , Combined Loss: tensor(1.0609, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3797649145126343\n",
      "Batch: 124 , Combined Loss: tensor(0.8119, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26014649868011475\n",
      "Batch: 125 , Combined Loss: tensor(0.7408, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.037506341934204\n",
      "Batch: 126 , Combined Loss: tensor(0.6781, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.818111777305603\n",
      "Batch: 127 , Combined Loss: tensor(0.8459, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6764869689941406\n",
      "Batch: 128 , Combined Loss: tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7302550077438354\n",
      "Batch: 129 , Combined Loss: tensor(0.7334, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1760960817337036\n",
      "Batch: 130 , Combined Loss: tensor(0.7292, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9057326316833496\n",
      "Batch: 131 , Combined Loss: tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7146697044372559\n",
      "Batch: 132 , Combined Loss: tensor(0.7069, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03823554515838623\n",
      "Batch: 133 , Combined Loss: tensor(0.7640, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.706061840057373\n",
      "Batch: 134 , Combined Loss: tensor(0.7602, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.931631326675415\n",
      "Batch: 135 , Combined Loss: tensor(0.6842, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.053745985031128\n",
      "Batch: 136 , Combined Loss: tensor(0.7032, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6593196392059326\n",
      "Batch: 137 , Combined Loss: tensor(0.7565, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.004519462585449219\n",
      "Batch: 138 , Combined Loss: tensor(0.7667, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.18770289421081543\n",
      "Batch: 139 , Combined Loss: tensor(0.7602, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7512830495834351\n",
      "Batch: 140 , Combined Loss: tensor(0.6433, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7141199111938477\n",
      "Batch: 141 , Combined Loss: tensor(0.7905, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8747440576553345\n",
      "Batch: 142 , Combined Loss: tensor(0.8308, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5137971639633179\n",
      "Batch: 143 , Combined Loss: tensor(1.0116, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07822573184967041\n",
      "Batch: 144 , Combined Loss: tensor(0.6979, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3249962329864502\n",
      "Batch: 145 , Combined Loss: tensor(0.6943, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6209602355957031\n",
      "Batch: 146 , Combined Loss: tensor(0.6925, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8790420293807983\n",
      "Batch: 147 , Combined Loss: tensor(0.6950, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30640673637390137\n",
      "Batch: 148 , Combined Loss: tensor(0.7402, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5285531282424927\n",
      "Batch: 149 , Combined Loss: tensor(0.7952, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.45397329330444336\n",
      "Batch: 150 , Combined Loss: tensor(0.6974, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7626020908355713\n",
      "Batch: 151 , Combined Loss: tensor(0.7800, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9131467342376709\n",
      "Batch: 152 , Combined Loss: tensor(0.7115, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17755699157714844\n",
      "Batch: 153 , Combined Loss: tensor(0.7308, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8161952495574951\n",
      "Batch: 154 , Combined Loss: tensor(0.8899, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9207984209060669\n",
      "Batch: 155 , Combined Loss: tensor(0.8545, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.42887169122695923\n",
      "Batch: 156 , Combined Loss: tensor(0.6738, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6085958480834961\n",
      "Batch: 157 , Combined Loss: tensor(0.7622, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9313277006149292\n",
      "Batch: 158 , Combined Loss: tensor(0.6939, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24355757236480713\n",
      "Batch: 159 , Combined Loss: tensor(0.6785, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4119933247566223\n",
      "Batch: 160 , Combined Loss: tensor(0.7284, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.604267954826355\n",
      "Batch: 161 , Combined Loss: tensor(0.7634, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0913994312286377\n",
      "Batch: 162 , Combined Loss: tensor(0.7481, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24606454372406006\n",
      "Batch: 163 , Combined Loss: tensor(0.7845, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4954236149787903\n",
      "Batch: 164 , Combined Loss: tensor(0.6688, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08294910192489624\n",
      "Batch: 165 , Combined Loss: tensor(0.9232, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2765262722969055\n",
      "Batch: 166 , Combined Loss: tensor(0.8261, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5177489519119263\n",
      "Batch: 167 , Combined Loss: tensor(0.8427, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.014574706554412842\n",
      "Batch: 168 , Combined Loss: tensor(0.8121, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6105183362960815\n",
      "Batch: 169 , Combined Loss: tensor(0.9457, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45529747009277344\n",
      "Batch: 170 , Combined Loss: tensor(0.9749, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7765710353851318\n",
      "Batch: 171 , Combined Loss: tensor(0.8035, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22378480434417725\n",
      "Batch: 172 , Combined Loss: tensor(0.7529, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2684630751609802\n",
      "Batch: 173 , Combined Loss: tensor(0.7567, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4995439052581787\n",
      "Batch: 174 , Combined Loss: tensor(0.6528, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6063719987869263\n",
      "Batch: 175 , Combined Loss: tensor(0.7355, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3147889971733093\n",
      "Batch: 176 , Combined Loss: tensor(0.8952, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2093796730041504\n",
      "Batch: 177 , Combined Loss: tensor(0.7388, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11244010925292969\n",
      "Batch: 178 , Combined Loss: tensor(0.7294, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7615689039230347\n",
      "Batch: 179 , Combined Loss: tensor(0.7093, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8376476764678955\n",
      "Batch: 180 , Combined Loss: tensor(0.7817, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3019859194755554\n",
      "Batch: 181 , Combined Loss: tensor(0.7209, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8428871631622314\n",
      "Batch: 182 , Combined Loss: tensor(0.9418, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1615762710571289\n",
      "Batch: 183 , Combined Loss: tensor(0.6743, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5934560298919678\n",
      "Batch: 184 , Combined Loss: tensor(0.7449, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23550891876220703\n",
      "Batch: 185 , Combined Loss: tensor(0.7727, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.427791953086853\n",
      "Batch: 186 , Combined Loss: tensor(0.8242, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9037414789199829\n",
      "Batch: 187 , Combined Loss: tensor(0.7605, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07325750589370728\n",
      "Batch: 188 , Combined Loss: tensor(0.7842, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39363592863082886\n",
      "Batch: 189 , Combined Loss: tensor(0.6862, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8408335447311401\n",
      "Batch: 190 , Combined Loss: tensor(0.7388, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32281458377838135\n",
      "Batch: 191 , Combined Loss: tensor(0.7383, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5264177322387695\n",
      "Batch: 192 , Combined Loss: tensor(0.8779, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8072571754455566\n",
      "Batch: 193 , Combined Loss: tensor(0.7992, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.882217526435852\n",
      "Batch: 194 , Combined Loss: tensor(0.6790, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.967681884765625\n",
      "Batch: 195 , Combined Loss: tensor(0.7047, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5582820177078247\n",
      "Batch: 196 , Combined Loss: tensor(0.7968, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5039489269256592\n",
      "Batch: 197 , Combined Loss: tensor(0.7342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8587727546691895\n",
      "Batch: 198 , Combined Loss: tensor(0.6993, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4704310894012451\n",
      "Batch: 199 , Combined Loss: tensor(0.7714, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3399782180786133\n",
      "Batch: 200 , Combined Loss: tensor(0.8043, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4282948970794678\n",
      "Batch: 201 , Combined Loss: tensor(0.6910, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3939732313156128\n",
      "Batch: 202 , Combined Loss: tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0692791938781738\n",
      "Batch: 203 , Combined Loss: tensor(0.8014, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5717586278915405\n",
      "Batch: 204 , Combined Loss: tensor(0.7511, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7286214828491211\n",
      "Batch: 205 , Combined Loss: tensor(0.6849, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06810617446899414\n",
      "Batch: 206 , Combined Loss: tensor(0.6774, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4370921850204468\n",
      "Batch: 207 , Combined Loss: tensor(0.6005, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04258263111114502\n",
      "Batch: 208 , Combined Loss: tensor(0.7690, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9097763299942017\n",
      "Batch: 209 , Combined Loss: tensor(0.7690, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.37632185220718384\n",
      "Batch: 210 , Combined Loss: tensor(0.6479, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1062726974487305\n",
      "Batch: 211 , Combined Loss: tensor(0.6782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6199195384979248\n",
      "Batch: 212 , Combined Loss: tensor(0.6821, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9231874942779541\n",
      "Batch: 213 , Combined Loss: tensor(0.8292, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.001805067062378\n",
      "Batch: 214 , Combined Loss: tensor(0.6914, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0020693540573120117\n",
      "Batch: 215 , Combined Loss: tensor(0.7217, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12241578102111816\n",
      "Batch: 216 , Combined Loss: tensor(0.7576, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7717267274856567\n",
      "Batch: 217 , Combined Loss: tensor(0.6910, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9441103935241699\n",
      "Batch: 218 , Combined Loss: tensor(0.6629, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35390448570251465\n",
      "Batch: 219 , Combined Loss: tensor(0.7598, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05917578935623169\n",
      "Batch: 220 , Combined Loss: tensor(0.7660, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08774065971374512\n",
      "Batch: 221 , Combined Loss: tensor(0.7248, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7773281335830688\n",
      "Batch: 222 , Combined Loss: tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8750072717666626\n",
      "Batch: 223 , Combined Loss: tensor(0.7607, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0647544264793396\n",
      "Batch: 224 , Combined Loss: tensor(0.9733, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4681352376937866\n",
      "Batch: 225 , Combined Loss: tensor(0.7263, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4867134094238281\n",
      "Batch: 226 , Combined Loss: tensor(0.6994, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5887396335601807\n",
      "Batch: 227 , Combined Loss: tensor(0.7540, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7889337539672852\n",
      "Batch: 228 , Combined Loss: tensor(0.7225, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8326969146728516\n",
      "Batch: 229 , Combined Loss: tensor(0.7352, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7731331586837769\n",
      "Batch: 230 , Combined Loss: tensor(0.7072, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0578441619873047\n",
      "Batch: 231 , Combined Loss: tensor(0.7062, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9022557735443115\n",
      "Batch: 232 , Combined Loss: tensor(0.9730, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4864480495452881\n",
      "Batch: 233 , Combined Loss: tensor(0.6467, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9956479072570801\n",
      "Batch: 234 , Combined Loss: tensor(0.6825, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5612039566040039\n",
      "Batch: 235 , Combined Loss: tensor(0.7813, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6459529399871826\n",
      "Batch: 236 , Combined Loss: tensor(0.6551, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1052722930908203\n",
      "Batch: 237 , Combined Loss: tensor(0.6111, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7411859035491943\n",
      "Batch: 238 , Combined Loss: tensor(0.7008, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2859607934951782\n",
      "Batch: 239 , Combined Loss: tensor(0.8313, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5730444192886353\n",
      "Batch: 240 , Combined Loss: tensor(0.8461, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12214946746826172\n",
      "Batch: 241 , Combined Loss: tensor(0.7210, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7645102739334106\n",
      "Batch: 242 , Combined Loss: tensor(0.7050, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8163305521011353\n",
      "Batch: 243 , Combined Loss: tensor(0.9421, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7787692546844482\n",
      "Batch: 244 , Combined Loss: tensor(0.7336, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5285398960113525\n",
      "Batch: 245 , Combined Loss: tensor(0.8299, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9707913398742676\n",
      "Batch: 246 , Combined Loss: tensor(0.7856, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5576835870742798\n",
      "Batch: 247 , Combined Loss: tensor(0.7330, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31638872623443604\n",
      "Batch: 248 , Combined Loss: tensor(0.8264, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4150667190551758\n",
      "Batch: 249 , Combined Loss: tensor(0.6538, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05321568250656128\n",
      "Batch: 250 , Combined Loss: tensor(0.6622, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2428758144378662\n",
      "Batch: 251 , Combined Loss: tensor(0.8306, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20823335647583008\n",
      "Batch: 252 , Combined Loss: tensor(1.2300, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5844689607620239\n",
      "Batch: 253 , Combined Loss: tensor(0.6620, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36327028274536133\n",
      "Batch: 254 , Combined Loss: tensor(0.6036, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06811642646789551\n",
      "Batch: 255 , Combined Loss: tensor(0.8857, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9067500829696655\n",
      "Batch: 256 , Combined Loss: tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7951782941818237\n",
      "Batch: 257 , Combined Loss: tensor(0.6904, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23280620574951172\n",
      "Batch: 258 , Combined Loss: tensor(0.8295, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8260600566864014\n",
      "Batch: 259 , Combined Loss: tensor(0.6466, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7358098030090332\n",
      "Batch: 260 , Combined Loss: tensor(0.6862, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9011039733886719\n",
      "Batch: 261 , Combined Loss: tensor(0.6947, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1113948822021484\n",
      "Batch: 262 , Combined Loss: tensor(0.8797, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8327181339263916\n",
      "Batch: 263 , Combined Loss: tensor(0.9824, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28217458724975586\n",
      "Batch: 264 , Combined Loss: tensor(0.6781, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0869942307472229\n",
      "Batch: 265 , Combined Loss: tensor(0.8508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8117578029632568\n",
      "Batch: 266 , Combined Loss: tensor(0.8166, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2821580171585083\n",
      "Batch: 267 , Combined Loss: tensor(0.7354, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4826488494873047\n",
      "Batch: 268 , Combined Loss: tensor(0.7204, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4437206983566284\n",
      "Batch: 269 , Combined Loss: tensor(0.9048, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8112921714782715\n",
      "Batch: 270 , Combined Loss: tensor(0.9379, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48439180850982666\n",
      "Batch: 271 , Combined Loss: tensor(0.8158, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33552610874176025\n",
      "Batch: 272 , Combined Loss: tensor(0.6946, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6498726606369019\n",
      "Batch: 273 , Combined Loss: tensor(1.2168, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5047433376312256\n",
      "Batch: 274 , Combined Loss: tensor(0.6571, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21915674209594727\n",
      "Batch: 275 , Combined Loss: tensor(0.6830, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9022641181945801\n",
      "Batch: 276 , Combined Loss: tensor(0.6681, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2133488655090332\n",
      "Batch: 277 , Combined Loss: tensor(0.6919, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29951417446136475\n",
      "Batch: 278 , Combined Loss: tensor(0.9574, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23492074012756348\n",
      "Batch: 279 , Combined Loss: tensor(0.9611, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1936323642730713\n",
      "Batch: 280 , Combined Loss: tensor(0.8056, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47056543827056885\n",
      "Batch: 281 , Combined Loss: tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6515522003173828\n",
      "Batch: 282 , Combined Loss: tensor(0.7509, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8678981065750122\n",
      "Batch: 283 , Combined Loss: tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9065616130828857\n",
      "Batch: 284 , Combined Loss: tensor(0.7372, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9020402431488037\n",
      "Batch: 285 , Combined Loss: tensor(0.9756, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7223547697067261\n",
      "Batch: 286 , Combined Loss: tensor(0.7858, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6381791830062866\n",
      "Batch: 287 , Combined Loss: tensor(0.7386, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5825424194335938\n",
      "Batch: 288 , Combined Loss: tensor(0.6889, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2822161912918091\n",
      "Batch: 289 , Combined Loss: tensor(0.6991, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38190770149230957\n",
      "Batch: 290 , Combined Loss: tensor(0.7359, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37030720710754395\n",
      "Batch: 291 , Combined Loss: tensor(0.8626, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3712494373321533\n",
      "Batch: 292 , Combined Loss: tensor(0.6672, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12773102521896362\n",
      "Batch: 293 , Combined Loss: tensor(0.7526, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45728516578674316\n",
      "Batch: 294 , Combined Loss: tensor(0.6917, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.023921966552734375\n",
      "Batch: 295 , Combined Loss: tensor(0.8390, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2728421688079834\n",
      "Batch: 296 , Combined Loss: tensor(0.7067, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8197846412658691\n",
      "Batch: 297 , Combined Loss: tensor(0.8261, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09253710508346558\n",
      "Batch: 298 , Combined Loss: tensor(0.6175, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3960613012313843\n",
      "Batch: 299 , Combined Loss: tensor(0.6941, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9697349071502686\n",
      "Batch: 300 , Combined Loss: tensor(0.7584, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15292590856552124\n",
      "Batch: 301 , Combined Loss: tensor(0.7198, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9524285793304443\n",
      "Batch: 302 , Combined Loss: tensor(0.9799, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0735111236572266\n",
      "Batch: 303 , Combined Loss: tensor(0.6452, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3083547353744507\n",
      "Batch: 304 , Combined Loss: tensor(0.8988, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3318955898284912\n",
      "Batch: 305 , Combined Loss: tensor(0.7407, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5371525883674622\n",
      "Batch: 306 , Combined Loss: tensor(0.7112, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.316402792930603\n",
      "Batch: 307 , Combined Loss: tensor(0.9285, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4168360233306885\n",
      "Batch: 308 , Combined Loss: tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.063704013824463\n",
      "Batch: 309 , Combined Loss: tensor(0.6696, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9118372201919556\n",
      "Batch: 310 , Combined Loss: tensor(0.8087, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4181128740310669\n",
      "Batch: 311 , Combined Loss: tensor(0.8488, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9697808027267456\n",
      "Batch: 312 , Combined Loss: tensor(0.6581, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6474794149398804\n",
      "Batch: 313 , Combined Loss: tensor(0.7214, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5489448308944702\n",
      "Batch: 314 , Combined Loss: tensor(0.7469, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.885729193687439\n",
      "Batch: 315 , Combined Loss: tensor(0.9242, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5145835876464844\n",
      "Batch: 316 , Combined Loss: tensor(0.8715, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7002185583114624\n",
      "Batch: 317 , Combined Loss: tensor(0.8007, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5442830324172974\n",
      "Batch: 318 , Combined Loss: tensor(0.7273, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5566885471343994\n",
      "Batch: 319 , Combined Loss: tensor(0.9300, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6921106576919556\n",
      "Batch: 320 , Combined Loss: tensor(0.7326, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47608351707458496\n",
      "Batch: 321 , Combined Loss: tensor(0.7450, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10630691051483154\n",
      "Batch: 322 , Combined Loss: tensor(0.8099, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40982961654663086\n",
      "Batch: 323 , Combined Loss: tensor(0.6400, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31662166118621826\n",
      "Batch: 324 , Combined Loss: tensor(0.6554, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6945409774780273\n",
      "Batch: 325 , Combined Loss: tensor(0.7359, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27754437923431396\n",
      "Batch: 326 , Combined Loss: tensor(0.7826, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8887714147567749\n",
      "Batch: 327 , Combined Loss: tensor(0.7426, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.28697896003723145\n",
      "Batch: 328 , Combined Loss: tensor(0.8036, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7105264663696289\n",
      "Batch: 329 , Combined Loss: tensor(0.6891, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4354250431060791\n",
      "Batch: 330 , Combined Loss: tensor(0.7452, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6966315507888794\n",
      "Batch: 331 , Combined Loss: tensor(0.8580, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.255626916885376\n",
      "Batch: 332 , Combined Loss: tensor(0.7679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37291061878204346\n",
      "Batch: 333 , Combined Loss: tensor(0.7273, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2618354558944702\n",
      "Batch: 334 , Combined Loss: tensor(0.7881, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6666057109832764\n",
      "Batch: 335 , Combined Loss: tensor(0.8004, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8835493326187134\n",
      "Batch: 336 , Combined Loss: tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3339686393737793\n",
      "Batch: 337 , Combined Loss: tensor(0.7881, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.33979088068008423\n",
      "Batch: 338 , Combined Loss: tensor(0.8129, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2607116103172302\n",
      "Batch: 339 , Combined Loss: tensor(0.7028, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9897223711013794\n",
      "Batch: 340 , Combined Loss: tensor(0.6937, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3271002769470215\n",
      "Batch: 341 , Combined Loss: tensor(0.6590, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3422439694404602\n",
      "Batch: 342 , Combined Loss: tensor(0.6886, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5815912485122681\n",
      "Batch: 343 , Combined Loss: tensor(0.6376, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6360995769500732\n",
      "Batch: 344 , Combined Loss: tensor(1.0145, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4205244779586792\n",
      "Batch: 345 , Combined Loss: tensor(0.8136, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10670024156570435\n",
      "Batch: 346 , Combined Loss: tensor(0.7223, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5065162181854248\n",
      "Batch: 347 , Combined Loss: tensor(0.7587, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.465783953666687\n",
      "Batch: 348 , Combined Loss: tensor(0.7458, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4023447036743164\n",
      "Batch: 349 , Combined Loss: tensor(0.6731, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7000739574432373\n",
      "Batch: 350 , Combined Loss: tensor(0.7008, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2499856948852539\n",
      "Batch: 351 , Combined Loss: tensor(0.7584, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24936425685882568\n",
      "Batch: 352 , Combined Loss: tensor(0.8110, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8696572780609131\n",
      "Batch: 353 , Combined Loss: tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5705225467681885\n",
      "Batch: 354 , Combined Loss: tensor(0.7430, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.881623387336731\n",
      "Batch: 355 , Combined Loss: tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39763665199279785\n",
      "Batch: 356 , Combined Loss: tensor(1.0812, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24265670776367188\n",
      "Batch: 357 , Combined Loss: tensor(0.7353, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6348068714141846\n",
      "Batch: 358 , Combined Loss: tensor(0.8811, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6075700521469116\n",
      "Batch: 359 , Combined Loss: tensor(0.8366, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7734003067016602\n",
      "Batch: 360 , Combined Loss: tensor(0.8529, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4585920572280884\n",
      "Batch: 361 , Combined Loss: tensor(0.8635, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45482170581817627\n",
      "Batch: 362 , Combined Loss: tensor(0.8540, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1871943473815918\n",
      "Batch: 363 , Combined Loss: tensor(0.6878, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3034053444862366\n",
      "Batch: 364 , Combined Loss: tensor(0.7198, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3755974769592285\n",
      "Batch: 365 , Combined Loss: tensor(0.7535, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3357347249984741\n",
      "Batch: 366 , Combined Loss: tensor(0.6808, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8118388652801514\n",
      "Batch: 367 , Combined Loss: tensor(0.7217, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8525365591049194\n",
      "Batch: 368 , Combined Loss: tensor(0.7055, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.021386265754699707\n",
      "Batch: 369 , Combined Loss: tensor(0.6614, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4112146496772766\n",
      "Batch: 370 , Combined Loss: tensor(0.8838, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13527965545654297\n",
      "Batch: 371 , Combined Loss: tensor(0.7016, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5870847702026367\n",
      "Batch: 372 , Combined Loss: tensor(0.7092, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3707960844039917\n",
      "Batch: 373 , Combined Loss: tensor(0.6993, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20125693082809448\n",
      "Batch: 374 , Combined Loss: tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7326273918151855\n",
      "Batch: 375 , Combined Loss: tensor(1.0504, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6654759645462036\n",
      "Batch: 376 , Combined Loss: tensor(0.8739, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6641450524330139\n",
      "Batch: 377 , Combined Loss: tensor(0.7872, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8946542739868164\n",
      "Batch: 378 , Combined Loss: tensor(0.7103, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5276894569396973\n",
      "Batch: 379 , Combined Loss: tensor(0.6818, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.591814398765564\n",
      "Batch: 380 , Combined Loss: tensor(0.8270, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.452380895614624\n",
      "Batch: 381 , Combined Loss: tensor(0.6886, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1507847309112549\n",
      "Batch: 382 , Combined Loss: tensor(0.8041, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7745177745819092\n",
      "Batch: 383 , Combined Loss: tensor(0.6975, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6356143951416016\n",
      "Batch: 384 , Combined Loss: tensor(0.7223, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1758662462234497\n",
      "Batch: 385 , Combined Loss: tensor(0.9301, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3247509002685547\n",
      "Batch: 386 , Combined Loss: tensor(0.7014, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8904260396957397\n",
      "Batch: 387 , Combined Loss: tensor(0.8546, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8577463626861572\n",
      "Batch: 388 , Combined Loss: tensor(0.6978, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9204002618789673\n",
      "Batch: 389 , Combined Loss: tensor(1.0053, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7682995796203613\n",
      "Batch: 390 , Combined Loss: tensor(0.6814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05292034149169922\n",
      "Batch: 391 , Combined Loss: tensor(0.7003, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9468287229537964\n",
      "Batch: 392 , Combined Loss: tensor(0.6935, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3834826946258545\n",
      "Batch: 393 , Combined Loss: tensor(0.5813, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.017205476760864258\n",
      "Batch: 394 , Combined Loss: tensor(0.7026, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4443354606628418\n",
      "Batch: 395 , Combined Loss: tensor(1.1522, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8705344200134277\n",
      "Batch: 396 , Combined Loss: tensor(0.6500, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9114214181900024\n",
      "Batch: 397 , Combined Loss: tensor(1.0518, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37580180168151855\n",
      "Batch: 398 , Combined Loss: tensor(0.6508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5868033170700073\n",
      "Batch: 399 , Combined Loss: tensor(1.0492, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10116547346115112\n",
      "Batch: 400 , Combined Loss: tensor(0.9665, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09544169902801514\n",
      "Batch: 401 , Combined Loss: tensor(0.7317, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.42672431468963623\n",
      "Batch: 402 , Combined Loss: tensor(0.9986, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10488271713256836\n",
      "Batch: 403 , Combined Loss: tensor(0.7315, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7852731943130493\n",
      "Batch: 404 , Combined Loss: tensor(0.6368, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0826500654220581\n",
      "Batch: 405 , Combined Loss: tensor(0.8631, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4507141709327698\n",
      "Batch: 406 , Combined Loss: tensor(0.7085, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7750605344772339\n",
      "Batch: 407 , Combined Loss: tensor(0.7057, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5818778276443481\n",
      "Batch: 408 , Combined Loss: tensor(0.7624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38391876220703125\n",
      "Batch: 409 , Combined Loss: tensor(0.7955, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7339375019073486\n",
      "Batch: 410 , Combined Loss: tensor(0.7811, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19687151908874512\n",
      "Batch: 411 , Combined Loss: tensor(0.7861, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09091496467590332\n",
      "Batch: 412 , Combined Loss: tensor(0.7955, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5278737545013428\n",
      "Batch: 413 , Combined Loss: tensor(0.7485, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6972572803497314\n",
      "Batch: 414 , Combined Loss: tensor(0.6967, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8533892631530762\n",
      "Batch: 415 , Combined Loss: tensor(0.7962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4784395694732666\n",
      "Batch: 416 , Combined Loss: tensor(0.7504, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0985492467880249\n",
      "Batch: 417 , Combined Loss: tensor(0.7891, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7244827747344971\n",
      "Batch: 418 , Combined Loss: tensor(0.6585, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8479357957839966\n",
      "Batch: 419 , Combined Loss: tensor(0.6715, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5775301456451416\n",
      "Batch: 420 , Combined Loss: tensor(0.7339, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7512211799621582\n",
      "Batch: 421 , Combined Loss: tensor(0.8270, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6518902778625488\n",
      "Batch: 422 , Combined Loss: tensor(1.0243, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4774143695831299\n",
      "Batch: 423 , Combined Loss: tensor(0.9384, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31332409381866455\n",
      "Batch: 424 , Combined Loss: tensor(0.7329, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09827518463134766\n",
      "Batch: 425 , Combined Loss: tensor(0.7756, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4475635290145874\n",
      "Batch: 426 , Combined Loss: tensor(0.6701, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8296633958816528\n",
      "Batch: 427 , Combined Loss: tensor(0.7537, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.702018141746521\n",
      "Batch: 428 , Combined Loss: tensor(0.7038, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8300046920776367\n",
      "Batch: 429 , Combined Loss: tensor(0.7278, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2325214147567749\n",
      "Batch: 430 , Combined Loss: tensor(0.7186, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5954102277755737\n",
      "Batch: 431 , Combined Loss: tensor(0.7327, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15265601873397827\n",
      "Batch: 432 , Combined Loss: tensor(0.7568, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8709431886672974\n",
      "Batch: 433 , Combined Loss: tensor(0.7414, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33373820781707764\n",
      "Batch: 434 , Combined Loss: tensor(0.7775, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6782474517822266\n",
      "Batch: 435 , Combined Loss: tensor(0.6749, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5152828693389893\n",
      "Batch: 436 , Combined Loss: tensor(0.6859, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7344024181365967\n",
      "Batch: 437 , Combined Loss: tensor(0.6663, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0942646861076355\n",
      "Batch: 438 , Combined Loss: tensor(0.8438, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3555569648742676\n",
      "Batch: 439 , Combined Loss: tensor(0.7486, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3094189167022705\n",
      "Batch: 440 , Combined Loss: tensor(0.6420, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6374382972717285\n",
      "Batch: 441 , Combined Loss: tensor(0.8208, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5056886672973633\n",
      "Batch: 442 , Combined Loss: tensor(0.7609, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8455955982208252\n",
      "Batch: 443 , Combined Loss: tensor(0.7406, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17085039615631104\n",
      "Batch: 444 , Combined Loss: tensor(0.7727, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.698954701423645\n",
      "Batch: 445 , Combined Loss: tensor(0.7665, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8958991765975952\n",
      "Batch: 446 , Combined Loss: tensor(0.6288, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4488765001296997\n",
      "Batch: 447 , Combined Loss: tensor(0.7105, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2266790866851807\n",
      "Batch: 448 , Combined Loss: tensor(0.7111, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5995160341262817\n",
      "Batch: 449 , Combined Loss: tensor(0.7986, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.789289116859436\n",
      "Batch: 450 , Combined Loss: tensor(0.7436, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.054927110671997\n",
      "Batch: 451 , Combined Loss: tensor(0.7955, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2327839732170105\n",
      "Batch: 452 , Combined Loss: tensor(0.6977, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40009117126464844\n",
      "Batch: 453 , Combined Loss: tensor(0.8029, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.29668480157852173\n",
      "Batch: 454 , Combined Loss: tensor(0.7017, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8588879108428955\n",
      "Batch: 455 , Combined Loss: tensor(0.6124, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4955630302429199\n",
      "Batch: 456 , Combined Loss: tensor(0.7585, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.528954267501831\n",
      "Batch: 457 , Combined Loss: tensor(0.6559, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5358196496963501\n",
      "Batch: 458 , Combined Loss: tensor(0.6628, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9584523439407349\n",
      "Batch: 459 , Combined Loss: tensor(0.6649, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43689990043640137\n",
      "Batch: 460 , Combined Loss: tensor(0.9458, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.025172114372253418\n",
      "Batch: 461 , Combined Loss: tensor(0.9035, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4961707592010498\n",
      "Batch: 462 , Combined Loss: tensor(0.6045, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45715057849884033\n",
      "Batch: 463 , Combined Loss: tensor(0.8595, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.373077392578125\n",
      "Batch: 464 , Combined Loss: tensor(0.7118, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8565467596054077\n",
      "Batch: 465 , Combined Loss: tensor(0.6986, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38303136825561523\n",
      "Batch: 466 , Combined Loss: tensor(0.6779, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14316928386688232\n",
      "Batch: 467 , Combined Loss: tensor(0.7410, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2548050880432129\n",
      "Batch: 468 , Combined Loss: tensor(0.7862, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8360921144485474\n",
      "Batch: 469 , Combined Loss: tensor(0.6232, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7448837757110596\n",
      "Batch: 470 , Combined Loss: tensor(0.8314, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28917670249938965\n",
      "Batch: 471 , Combined Loss: tensor(0.6785, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6330801248550415\n",
      "Batch: 472 , Combined Loss: tensor(0.6820, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7553631067276001\n",
      "Batch: 473 , Combined Loss: tensor(0.6937, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6879373788833618\n",
      "Batch: 474 , Combined Loss: tensor(0.7903, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7189540863037109\n",
      "Batch: 475 , Combined Loss: tensor(0.6533, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4650578498840332\n",
      "Batch: 476 , Combined Loss: tensor(0.6879, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.076939344406128\n",
      "Batch: 477 , Combined Loss: tensor(0.7749, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.37830084562301636\n",
      "Batch: 478 , Combined Loss: tensor(0.7537, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0137836933135986\n",
      "Batch: 479 , Combined Loss: tensor(0.9182, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9659508466720581\n",
      "Batch: 480 , Combined Loss: tensor(0.8674, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8933470249176025\n",
      "Batch: 481 , Combined Loss: tensor(0.6890, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4054983854293823\n",
      "Batch: 482 , Combined Loss: tensor(0.9223, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24641764163970947\n",
      "Batch: 483 , Combined Loss: tensor(0.6752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03811401128768921\n",
      "Batch: 484 , Combined Loss: tensor(0.9024, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5772101879119873\n",
      "Batch: 485 , Combined Loss: tensor(0.8362, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7324237823486328\n",
      "Batch: 486 , Combined Loss: tensor(0.7899, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7074073553085327\n",
      "Batch: 487 , Combined Loss: tensor(0.8054, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10582375526428223\n",
      "Batch: 488 , Combined Loss: tensor(0.6105, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35713040828704834\n",
      "Batch: 489 , Combined Loss: tensor(0.7229, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.771984338760376\n",
      "Batch: 490 , Combined Loss: tensor(0.6691, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08089548349380493\n",
      "Batch: 491 , Combined Loss: tensor(0.7750, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09619438648223877\n",
      "Batch: 492 , Combined Loss: tensor(0.6119, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6034119129180908\n",
      "Batch: 493 , Combined Loss: tensor(0.9862, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6722683906555176\n",
      "Batch: 494 , Combined Loss: tensor(0.6714, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21954405307769775\n",
      "Batch: 495 , Combined Loss: tensor(0.6898, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42581748962402344\n",
      "Batch: 496 , Combined Loss: tensor(0.7109, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15501052141189575\n",
      "Batch: 497 , Combined Loss: tensor(0.6764, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6471661329269409\n",
      "Batch: 498 , Combined Loss: tensor(0.6395, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10458600521087646\n",
      "Batch: 499 , Combined Loss: tensor(1.2029, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.28866779804229736\n",
      "Batch: 500 , Combined Loss: tensor(0.7294, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.322279155254364\n",
      "Batch: 501 , Combined Loss: tensor(0.7895, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9315395355224609\n",
      "Batch: 502 , Combined Loss: tensor(0.6939, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12391072511672974\n",
      "Batch: 503 , Combined Loss: tensor(0.8545, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.581853985786438\n",
      "Batch: 504 , Combined Loss: tensor(0.7773, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7343028783798218\n",
      "Batch: 505 , Combined Loss: tensor(0.8531, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8014658689498901\n",
      "Batch: 506 , Combined Loss: tensor(0.7322, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.648759126663208\n",
      "Batch: 507 , Combined Loss: tensor(0.7825, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.96732497215271\n",
      "Batch: 508 , Combined Loss: tensor(0.7878, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6028932332992554\n",
      "Batch: 509 , Combined Loss: tensor(0.6613, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8473951816558838\n",
      "Batch: 510 , Combined Loss: tensor(0.8059, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21630346775054932\n",
      "Batch: 511 , Combined Loss: tensor(0.7242, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7044690847396851\n",
      "Batch: 512 , Combined Loss: tensor(0.7550, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9910039901733398\n",
      "Batch: 513 , Combined Loss: tensor(0.7084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1531652808189392\n",
      "Batch: 514 , Combined Loss: tensor(0.7668, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5854860544204712\n",
      "Batch: 515 , Combined Loss: tensor(0.7210, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6763949394226074\n",
      "Batch: 516 , Combined Loss: tensor(0.6881, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0326435565948486\n",
      "Batch: 517 , Combined Loss: tensor(0.7367, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.965779185295105\n",
      "Batch: 518 , Combined Loss: tensor(0.8934, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.407770037651062\n",
      "Batch: 519 , Combined Loss: tensor(0.6658, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2510406970977783\n",
      "Batch: 520 , Combined Loss: tensor(0.8150, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8580796718597412\n",
      "Batch: 521 , Combined Loss: tensor(0.7597, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.583767294883728\n",
      "Batch: 522 , Combined Loss: tensor(0.8984, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12094181776046753\n",
      "Batch: 523 , Combined Loss: tensor(0.7792, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5931271314620972\n",
      "Batch: 524 , Combined Loss: tensor(0.7536, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2979394197463989\n",
      "Batch: 525 , Combined Loss: tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4734833240509033\n",
      "Batch: 526 , Combined Loss: tensor(0.6742, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4157867431640625\n",
      "Batch: 527 , Combined Loss: tensor(0.7079, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8285790681838989\n",
      "Batch: 528 , Combined Loss: tensor(0.7604, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7952694892883301\n",
      "Batch: 529 , Combined Loss: tensor(0.8882, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39673030376434326\n",
      "Batch: 530 , Combined Loss: tensor(0.8910, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2733687162399292\n",
      "Batch: 531 , Combined Loss: tensor(0.7684, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34081411361694336\n",
      "Batch: 532 , Combined Loss: tensor(0.9576, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1956629753112793\n",
      "Batch: 533 , Combined Loss: tensor(0.6923, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.670012354850769\n",
      "Batch: 534 , Combined Loss: tensor(0.7602, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2515407204627991\n",
      "Batch: 535 , Combined Loss: tensor(0.7838, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3222130537033081\n",
      "Batch: 536 , Combined Loss: tensor(0.7393, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.553357720375061\n",
      "Batch: 537 , Combined Loss: tensor(0.6901, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2874019145965576\n",
      "Batch: 538 , Combined Loss: tensor(0.9613, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1270662546157837\n",
      "Batch: 539 , Combined Loss: tensor(0.7766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35497331619262695\n",
      "Batch: 540 , Combined Loss: tensor(0.7724, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2629326581954956\n",
      "Batch: 541 , Combined Loss: tensor(0.8334, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5301989316940308\n",
      "Batch: 542 , Combined Loss: tensor(0.7128, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7245388031005859\n",
      "Batch: 543 , Combined Loss: tensor(1.1603, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15867853164672852\n",
      "Batch: 544 , Combined Loss: tensor(0.6974, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7219181060791016\n",
      "Batch: 545 , Combined Loss: tensor(0.6743, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2610623836517334\n",
      "Batch: 546 , Combined Loss: tensor(0.6897, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21715128421783447\n",
      "Batch: 547 , Combined Loss: tensor(0.9060, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5495109558105469\n",
      "Batch: 548 , Combined Loss: tensor(0.6692, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7525660991668701\n",
      "Batch: 549 , Combined Loss: tensor(0.6449, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09113502502441406\n",
      "Batch: 550 , Combined Loss: tensor(0.7513, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7373301982879639\n",
      "Batch: 551 , Combined Loss: tensor(0.8731, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6100966930389404\n",
      "Batch: 552 , Combined Loss: tensor(0.7486, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2801119089126587\n",
      "Batch: 553 , Combined Loss: tensor(0.8811, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.789172887802124\n",
      "Batch: 554 , Combined Loss: tensor(0.7612, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2949790954589844\n",
      "Batch: 555 , Combined Loss: tensor(0.7751, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7592605352401733\n",
      "Batch: 556 , Combined Loss: tensor(0.6846, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03292679786682129\n",
      "Batch: 557 , Combined Loss: tensor(0.9866, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3078927993774414\n",
      "Batch: 558 , Combined Loss: tensor(0.7543, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0746411681175232\n",
      "Batch: 559 , Combined Loss: tensor(0.8116, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6089757680892944\n",
      "Batch: 560 , Combined Loss: tensor(0.7644, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09783583879470825\n",
      "Batch: 561 , Combined Loss: tensor(0.8701, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5069564580917358\n",
      "Batch: 562 , Combined Loss: tensor(0.6194, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1616988182067871\n",
      "Batch: 563 , Combined Loss: tensor(0.6656, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4868379831314087\n",
      "Batch: 564 , Combined Loss: tensor(0.7625, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5846184492111206\n",
      "Batch: 565 , Combined Loss: tensor(0.6872, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4629620313644409\n",
      "Batch: 566 , Combined Loss: tensor(0.7109, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40721333026885986\n",
      "Batch: 567 , Combined Loss: tensor(0.7487, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6282364130020142\n",
      "Batch: 568 , Combined Loss: tensor(0.6747, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6395841836929321\n",
      "Batch: 569 , Combined Loss: tensor(0.6569, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5663933753967285\n",
      "Batch: 570 , Combined Loss: tensor(0.5992, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7399072647094727\n",
      "Batch: 571 , Combined Loss: tensor(0.6414, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33991575241088867\n",
      "Batch: 572 , Combined Loss: tensor(0.7276, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0316033363342285\n",
      "Batch: 573 , Combined Loss: tensor(0.6810, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5883718729019165\n",
      "Batch: 574 , Combined Loss: tensor(0.7449, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8235533237457275\n",
      "Batch: 575 , Combined Loss: tensor(0.7071, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.871679425239563\n",
      "Batch: 576 , Combined Loss: tensor(0.7903, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6599531173706055\n",
      "Batch: 577 , Combined Loss: tensor(0.8800, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7104322910308838\n",
      "Batch: 578 , Combined Loss: tensor(0.9244, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6212084293365479\n",
      "Batch: 579 , Combined Loss: tensor(0.7812, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7172756195068359\n",
      "Batch: 580 , Combined Loss: tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8729864358901978\n",
      "Batch: 581 , Combined Loss: tensor(0.6796, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6988420486450195\n",
      "Batch: 582 , Combined Loss: tensor(0.6316, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5943576097488403\n",
      "Batch: 583 , Combined Loss: tensor(0.7415, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.38794243335723877\n",
      "Batch: 584 , Combined Loss: tensor(0.7940, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7400797605514526\n",
      "Batch: 585 , Combined Loss: tensor(0.7809, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7767190933227539\n",
      "Batch: 586 , Combined Loss: tensor(0.6825, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5987560749053955\n",
      "Batch: 587 , Combined Loss: tensor(0.7078, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5920519828796387\n",
      "Batch: 588 , Combined Loss: tensor(0.8077, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8413554430007935\n",
      "Batch: 589 , Combined Loss: tensor(0.6885, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04036414623260498\n",
      "Batch: 590 , Combined Loss: tensor(0.9006, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5987234115600586\n",
      "Batch: 591 , Combined Loss: tensor(0.6922, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9965517520904541\n",
      "Batch: 592 , Combined Loss: tensor(0.8679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9425826072692871\n",
      "Batch: 593 , Combined Loss: tensor(0.8361, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.894270658493042\n",
      "Batch: 594 , Combined Loss: tensor(0.7077, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6932506561279297\n",
      "Batch: 595 , Combined Loss: tensor(0.9423, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40026819705963135\n",
      "Batch: 596 , Combined Loss: tensor(0.9717, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.560151219367981\n",
      "Batch: 597 , Combined Loss: tensor(1.4422, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31424617767333984\n",
      "Batch: 598 , Combined Loss: tensor(0.8473, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7072217464447021\n",
      "Batch: 599 , Combined Loss: tensor(0.8099, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42164528369903564\n",
      "Batch: 600 , Combined Loss: tensor(0.7380, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7771486043930054\n",
      "Batch: 601 , Combined Loss: tensor(0.7797, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9106371402740479\n",
      "Batch: 602 , Combined Loss: tensor(0.6878, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.080054759979248\n",
      "Batch: 603 , Combined Loss: tensor(0.7556, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0153486728668213\n",
      "Batch: 604 , Combined Loss: tensor(0.6931, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19115972518920898\n",
      "Batch: 605 , Combined Loss: tensor(0.7535, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.554578423500061\n",
      "Batch: 606 , Combined Loss: tensor(0.8237, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.027498245239257812\n",
      "Batch: 607 , Combined Loss: tensor(0.9009, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32523810863494873\n",
      "Batch: 608 , Combined Loss: tensor(0.7946, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.754660964012146\n",
      "Batch: 609 , Combined Loss: tensor(0.6688, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.819880485534668\n",
      "Batch: 610 , Combined Loss: tensor(0.9023, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7279155254364014\n",
      "Batch: 611 , Combined Loss: tensor(0.6502, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4082447290420532\n",
      "Batch: 612 , Combined Loss: tensor(0.7012, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12780272960662842\n",
      "Batch: 613 , Combined Loss: tensor(0.7112, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8961318731307983\n",
      "Batch: 614 , Combined Loss: tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.06414794921875\n",
      "Batch: 615 , Combined Loss: tensor(0.7388, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8511272668838501\n",
      "Batch: 616 , Combined Loss: tensor(0.6413, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6306518316268921\n",
      "Batch: 617 , Combined Loss: tensor(0.6780, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1253864765167236\n",
      "Batch: 618 , Combined Loss: tensor(0.7118, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5152593851089478\n",
      "Batch: 619 , Combined Loss: tensor(0.7039, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6501286029815674\n",
      "Batch: 620 , Combined Loss: tensor(0.7345, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6985642910003662\n",
      "Batch: 621 , Combined Loss: tensor(0.6589, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.502076268196106\n",
      "Batch: 622 , Combined Loss: tensor(0.7121, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7083427906036377\n",
      "Batch: 623 , Combined Loss: tensor(0.6513, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7452926635742188\n",
      "Batch: 624 , Combined Loss: tensor(0.7404, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.558971643447876\n",
      "Batch: 625 , Combined Loss: tensor(0.7326, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7827800512313843\n",
      "Batch: 626 , Combined Loss: tensor(0.7669, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7801692485809326\n",
      "Batch: 627 , Combined Loss: tensor(0.6875, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8602008819580078\n",
      "Batch: 628 , Combined Loss: tensor(0.7496, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6576871871948242\n",
      "----------Epoch 10, Loss: 0.768347771918262, Accuracy: 0.950167240512769, Dice Coef: [0.976791693030935, 0.46516470018410244, 0.5244088466775241, 0.5816461607239746], Dice Coef Necrotic: 0.8578445790849637, Dice Coef Edema: 0.8892364242717331, Dice Coef Enhancing: 0.7956967405596918, Sensitivity: [0.9567764987058595, 0.6908526916946366, 0.8122427846484229, 0.862887184043446], Specificity: [0.9634486322183109, 0.9948794311104973, 0.9664830313388418, 0.9896914033139264], Precision: [0.9978949154693106, 0.42691836617733286, 0.4186276956202258, 0.48411226749344466]\n",
      "-----------Validation Epoch 10, Loss: 0.7818140021157921, Accuracy: 0.9611811375399248, Dice Coef: [0.9833919455152039, 0.4105140100539895, 0.533232500521406, 0.5398700782852511], Dice Coef Necrotic: 0.15039750407379862, Dice Coef Edema: 0.16228553553010241, Dice Coef Enhancing: 0.13676669776468253, Sensitivity: [0.9766071608307165, 0.5605125346417548, 0.6290600783183077, 0.6505117960265675], Specificity: [0.8057038042771228, 0.9958603518818496, 0.9833179400601518, 0.9899161201004588], Precision: [0.9910337804654322, 0.4319225108483806, 0.545927986558185, 0.5888761613569266]\n",
      "Saving without nn.DataParallel\n",
      "Batch: 0 , Combined Loss: tensor(0.7436, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8429470062255859\n",
      "Batch: 1 , Combined Loss: tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.039734482765197754\n",
      "Batch: 2 , Combined Loss: tensor(0.6870, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7239110469818115\n",
      "Batch: 3 , Combined Loss: tensor(0.7718, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0615451335906982\n",
      "Batch: 4 , Combined Loss: tensor(0.7471, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07261514663696289\n",
      "Batch: 5 , Combined Loss: tensor(0.6516, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.012365341186523438\n",
      "Batch: 6 , Combined Loss: tensor(0.7082, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1319856643676758\n",
      "Batch: 7 , Combined Loss: tensor(0.8159, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8884104490280151\n",
      "Batch: 8 , Combined Loss: tensor(0.7937, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33994972705841064\n",
      "Batch: 9 , Combined Loss: tensor(1.0166, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10497713088989258\n",
      "Batch: 10 , Combined Loss: tensor(0.6600, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7960892915725708\n",
      "Batch: 11 , Combined Loss: tensor(0.6715, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03221487998962402\n",
      "Batch: 12 , Combined Loss: tensor(1.2731, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.004400908946990967\n",
      "Batch: 13 , Combined Loss: tensor(0.6543, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6195751428604126\n",
      "Batch: 14 , Combined Loss: tensor(0.8039, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8719892501831055\n",
      "Batch: 15 , Combined Loss: tensor(0.6687, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8476238250732422\n",
      "Batch: 16 , Combined Loss: tensor(0.6215, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36040055751800537\n",
      "Batch: 17 , Combined Loss: tensor(0.8009, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.005638241767883301\n",
      "Batch: 18 , Combined Loss: tensor(0.7833, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5007702112197876\n",
      "Batch: 19 , Combined Loss: tensor(0.6702, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40326249599456787\n",
      "Batch: 20 , Combined Loss: tensor(0.8491, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7023699283599854\n",
      "Batch: 21 , Combined Loss: tensor(0.7576, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6393760442733765\n",
      "Batch: 22 , Combined Loss: tensor(0.7824, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8208163976669312\n",
      "Batch: 23 , Combined Loss: tensor(0.6478, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1365973949432373\n",
      "Batch: 24 , Combined Loss: tensor(1.0435, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6955100297927856\n",
      "Batch: 25 , Combined Loss: tensor(0.6945, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8405416011810303\n",
      "Batch: 26 , Combined Loss: tensor(0.6371, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10541021823883057\n",
      "Batch: 27 , Combined Loss: tensor(0.7510, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9561886787414551\n",
      "Batch: 28 , Combined Loss: tensor(0.7202, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0519382953643799\n",
      "Batch: 29 , Combined Loss: tensor(0.7586, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5346899032592773\n",
      "Batch: 30 , Combined Loss: tensor(0.7302, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3055912256240845\n",
      "Batch: 31 , Combined Loss: tensor(0.7335, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0958903431892395\n",
      "Batch: 32 , Combined Loss: tensor(0.7506, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.777018666267395\n",
      "Batch: 33 , Combined Loss: tensor(0.6957, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6523874998092651\n",
      "Batch: 34 , Combined Loss: tensor(0.8241, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.530184268951416\n",
      "Batch: 35 , Combined Loss: tensor(0.8774, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45568716526031494\n",
      "Batch: 36 , Combined Loss: tensor(0.8610, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.01001209020614624\n",
      "Batch: 37 , Combined Loss: tensor(0.8071, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5415836572647095\n",
      "Batch: 38 , Combined Loss: tensor(0.7454, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4741400480270386\n",
      "Batch: 39 , Combined Loss: tensor(0.7846, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3503667116165161\n",
      "Batch: 40 , Combined Loss: tensor(0.7768, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17800837755203247\n",
      "Batch: 41 , Combined Loss: tensor(0.7480, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05668628215789795\n",
      "Batch: 42 , Combined Loss: tensor(0.8783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0297822952270508\n",
      "Batch: 43 , Combined Loss: tensor(0.6644, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6783888339996338\n",
      "Batch: 44 , Combined Loss: tensor(0.7838, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.48228126764297485\n",
      "Batch: 45 , Combined Loss: tensor(0.7205, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2184104919433594\n",
      "Batch: 46 , Combined Loss: tensor(0.8616, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6246743202209473\n",
      "Batch: 47 , Combined Loss: tensor(0.7056, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36180949211120605\n",
      "Batch: 48 , Combined Loss: tensor(0.7676, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8335858583450317\n",
      "Batch: 49 , Combined Loss: tensor(0.7578, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.648957371711731\n",
      "Batch: 50 , Combined Loss: tensor(0.7923, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.254899263381958\n",
      "Batch: 51 , Combined Loss: tensor(0.6869, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7492936849594116\n",
      "Batch: 52 , Combined Loss: tensor(0.7053, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35715341567993164\n",
      "Batch: 53 , Combined Loss: tensor(0.7450, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6067624092102051\n",
      "Batch: 54 , Combined Loss: tensor(0.8164, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8429561853408813\n",
      "Batch: 55 , Combined Loss: tensor(0.7405, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6379745006561279\n",
      "Batch: 56 , Combined Loss: tensor(0.8087, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3424391746520996\n",
      "Batch: 57 , Combined Loss: tensor(0.7519, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6532682180404663\n",
      "Batch: 58 , Combined Loss: tensor(0.8940, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.250612735748291\n",
      "Batch: 59 , Combined Loss: tensor(0.6648, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7712706327438354\n",
      "Batch: 60 , Combined Loss: tensor(0.6651, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44437384605407715\n",
      "Batch: 61 , Combined Loss: tensor(0.7577, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6760954856872559\n",
      "Batch: 62 , Combined Loss: tensor(0.7076, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48117613792419434\n",
      "Batch: 63 , Combined Loss: tensor(0.6640, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7991667985916138\n",
      "Batch: 64 , Combined Loss: tensor(0.7219, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7238492965698242\n",
      "Batch: 65 , Combined Loss: tensor(0.7100, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7903671264648438\n",
      "Batch: 66 , Combined Loss: tensor(0.7115, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21368402242660522\n",
      "Batch: 67 , Combined Loss: tensor(0.7050, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35896623134613037\n",
      "Batch: 68 , Combined Loss: tensor(0.8301, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6865568161010742\n",
      "Batch: 69 , Combined Loss: tensor(0.7936, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7186213731765747\n",
      "Batch: 70 , Combined Loss: tensor(0.8964, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6446982622146606\n",
      "Batch: 71 , Combined Loss: tensor(0.7226, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8296283483505249\n",
      "Batch: 72 , Combined Loss: tensor(0.7049, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3502403497695923\n",
      "Batch: 73 , Combined Loss: tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3880186080932617\n",
      "Batch: 74 , Combined Loss: tensor(0.7541, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8561598062515259\n",
      "Batch: 75 , Combined Loss: tensor(0.7333, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5538394451141357\n",
      "Batch: 76 , Combined Loss: tensor(0.7423, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24731802940368652\n",
      "Batch: 77 , Combined Loss: tensor(0.8126, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7593010663986206\n",
      "Batch: 78 , Combined Loss: tensor(0.6508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.566727876663208\n",
      "Batch: 79 , Combined Loss: tensor(0.7803, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9137487411499023\n",
      "Batch: 80 , Combined Loss: tensor(0.7420, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16416501998901367\n",
      "Batch: 81 , Combined Loss: tensor(0.7065, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7157410383224487\n",
      "Batch: 82 , Combined Loss: tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0094621181488037\n",
      "Batch: 83 , Combined Loss: tensor(0.9875, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.020621418952941895\n",
      "Batch: 84 , Combined Loss: tensor(0.6876, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7881293296813965\n",
      "Batch: 85 , Combined Loss: tensor(0.6590, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.020362138748169\n",
      "Batch: 86 , Combined Loss: tensor(0.6801, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7664542198181152\n",
      "Batch: 87 , Combined Loss: tensor(0.8179, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15696227550506592\n",
      "Batch: 88 , Combined Loss: tensor(0.7471, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5663048028945923\n",
      "Batch: 89 , Combined Loss: tensor(0.7574, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4763299822807312\n",
      "Batch: 90 , Combined Loss: tensor(0.9202, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3676433563232422\n",
      "Batch: 91 , Combined Loss: tensor(0.6815, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7762943506240845\n",
      "Batch: 92 , Combined Loss: tensor(0.7068, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.003068864345550537\n",
      "Batch: 93 , Combined Loss: tensor(0.8033, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14268076419830322\n",
      "Batch: 94 , Combined Loss: tensor(0.7185, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30204319953918457\n",
      "Batch: 95 , Combined Loss: tensor(0.7872, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9784723520278931\n",
      "Batch: 96 , Combined Loss: tensor(0.7458, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6092104911804199\n",
      "Batch: 97 , Combined Loss: tensor(0.8357, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.43276065587997437\n",
      "Batch: 98 , Combined Loss: tensor(0.7580, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08517146110534668\n",
      "Batch: 99 , Combined Loss: tensor(0.7791, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9848262071609497\n",
      "Batch: 100 , Combined Loss: tensor(0.7470, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5163496732711792\n",
      "Batch: 101 , Combined Loss: tensor(0.6403, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6704543828964233\n",
      "Batch: 102 , Combined Loss: tensor(0.7417, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8028695583343506\n",
      "Batch: 103 , Combined Loss: tensor(0.7689, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07051312923431396\n",
      "Batch: 104 , Combined Loss: tensor(0.6814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6714358329772949\n",
      "Batch: 105 , Combined Loss: tensor(0.8239, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3343430161476135\n",
      "Batch: 106 , Combined Loss: tensor(0.7180, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0177304744720459\n",
      "Batch: 107 , Combined Loss: tensor(0.7204, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6434890031814575\n",
      "Batch: 108 , Combined Loss: tensor(0.7318, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7949776649475098\n",
      "Batch: 109 , Combined Loss: tensor(0.8960, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07445251941680908\n",
      "Batch: 110 , Combined Loss: tensor(0.8968, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3610076904296875\n",
      "Batch: 111 , Combined Loss: tensor(0.8136, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.010033369064331\n",
      "Batch: 112 , Combined Loss: tensor(0.6890, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15116631984710693\n",
      "Batch: 113 , Combined Loss: tensor(0.6455, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2618858814239502\n",
      "Batch: 114 , Combined Loss: tensor(0.7262, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04347097873687744\n",
      "Batch: 115 , Combined Loss: tensor(0.7679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6780595779418945\n",
      "Batch: 116 , Combined Loss: tensor(0.7184, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2324080467224121\n",
      "Batch: 117 , Combined Loss: tensor(0.6975, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6720613241195679\n",
      "Batch: 118 , Combined Loss: tensor(0.9603, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4913516044616699\n",
      "Batch: 119 , Combined Loss: tensor(0.7656, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.011766135692596436\n",
      "Batch: 120 , Combined Loss: tensor(0.7598, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3721349239349365\n",
      "Batch: 121 , Combined Loss: tensor(0.7307, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2331981658935547\n",
      "Batch: 122 , Combined Loss: tensor(0.7754, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8333351612091064\n",
      "Batch: 123 , Combined Loss: tensor(0.7000, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8792463541030884\n",
      "Batch: 124 , Combined Loss: tensor(0.7119, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7131898403167725\n",
      "Batch: 125 , Combined Loss: tensor(0.7394, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.648574948310852\n",
      "Batch: 126 , Combined Loss: tensor(0.7971, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8659580945968628\n",
      "Batch: 127 , Combined Loss: tensor(0.7586, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1752457618713379\n",
      "Batch: 128 , Combined Loss: tensor(0.6835, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4492301344871521\n",
      "Batch: 129 , Combined Loss: tensor(0.6720, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5917179584503174\n",
      "Batch: 130 , Combined Loss: tensor(0.8364, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20234060287475586\n",
      "Batch: 131 , Combined Loss: tensor(0.7622, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1026870608329773\n",
      "Batch: 132 , Combined Loss: tensor(0.7503, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8673242330551147\n",
      "Batch: 133 , Combined Loss: tensor(0.7005, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1893429160118103\n",
      "Batch: 134 , Combined Loss: tensor(0.6845, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2778940200805664\n",
      "Batch: 135 , Combined Loss: tensor(0.7059, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5552643537521362\n",
      "Batch: 136 , Combined Loss: tensor(0.7358, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9262038469314575\n",
      "Batch: 137 , Combined Loss: tensor(0.8011, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.64421546459198\n",
      "Batch: 138 , Combined Loss: tensor(0.7595, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7837916612625122\n",
      "Batch: 139 , Combined Loss: tensor(0.6915, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9187657833099365\n",
      "Batch: 140 , Combined Loss: tensor(0.8084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43914794921875\n",
      "Batch: 141 , Combined Loss: tensor(0.7283, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0579895973205566\n",
      "Batch: 142 , Combined Loss: tensor(0.7650, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9202229976654053\n",
      "Batch: 143 , Combined Loss: tensor(0.6905, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0809242725372314\n",
      "Batch: 144 , Combined Loss: tensor(0.7000, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6034748554229736\n",
      "Batch: 145 , Combined Loss: tensor(0.7700, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8843363523483276\n",
      "Batch: 146 , Combined Loss: tensor(0.7598, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6215634346008301\n",
      "Batch: 147 , Combined Loss: tensor(0.7442, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35554957389831543\n",
      "Batch: 148 , Combined Loss: tensor(0.6799, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0924614667892456\n",
      "Batch: 149 , Combined Loss: tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0009191036224365\n",
      "Batch: 150 , Combined Loss: tensor(0.6791, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9445772171020508\n",
      "Batch: 151 , Combined Loss: tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29150068759918213\n",
      "Batch: 152 , Combined Loss: tensor(0.6901, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8724765777587891\n",
      "Batch: 153 , Combined Loss: tensor(0.6608, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1753944754600525\n",
      "Batch: 154 , Combined Loss: tensor(0.9380, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6643353700637817\n",
      "Batch: 155 , Combined Loss: tensor(0.7774, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05717146396636963\n",
      "Batch: 156 , Combined Loss: tensor(0.6290, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5116622447967529\n",
      "Batch: 157 , Combined Loss: tensor(0.7620, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7189909219741821\n",
      "Batch: 158 , Combined Loss: tensor(0.9877, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.60945725440979\n",
      "Batch: 159 , Combined Loss: tensor(0.6637, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5273556709289551\n",
      "Batch: 160 , Combined Loss: tensor(0.8024, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9183869361877441\n",
      "Batch: 161 , Combined Loss: tensor(0.8207, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6632574796676636\n",
      "Batch: 162 , Combined Loss: tensor(0.7043, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6107347011566162\n",
      "Batch: 163 , Combined Loss: tensor(0.8592, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.37598586082458496\n",
      "Batch: 164 , Combined Loss: tensor(0.7721, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.44975167512893677\n",
      "Batch: 165 , Combined Loss: tensor(0.7642, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40848517417907715\n",
      "Batch: 166 , Combined Loss: tensor(0.8305, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.010543882846832275\n",
      "Batch: 167 , Combined Loss: tensor(0.7218, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8679801225662231\n",
      "Batch: 168 , Combined Loss: tensor(0.7601, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11725735664367676\n",
      "Batch: 169 , Combined Loss: tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6039093732833862\n",
      "Batch: 170 , Combined Loss: tensor(0.6785, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2379087209701538\n",
      "Batch: 171 , Combined Loss: tensor(0.7645, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5551095008850098\n",
      "Batch: 172 , Combined Loss: tensor(0.8850, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9436852931976318\n",
      "Batch: 173 , Combined Loss: tensor(0.8298, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.956468939781189\n",
      "Batch: 174 , Combined Loss: tensor(0.6928, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2997475862503052\n",
      "Batch: 175 , Combined Loss: tensor(0.7451, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39641642570495605\n",
      "Batch: 176 , Combined Loss: tensor(0.6814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8129072189331055\n",
      "Batch: 177 , Combined Loss: tensor(0.7643, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6843321323394775\n",
      "Batch: 178 , Combined Loss: tensor(0.7556, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4409753084182739\n",
      "Batch: 179 , Combined Loss: tensor(0.7057, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0123848915100098\n",
      "Batch: 180 , Combined Loss: tensor(0.6608, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.087873935699463\n",
      "Batch: 181 , Combined Loss: tensor(0.6309, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9367094039916992\n",
      "Batch: 182 , Combined Loss: tensor(0.7304, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4024388790130615\n",
      "Batch: 183 , Combined Loss: tensor(0.8038, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8731153011322021\n",
      "Batch: 184 , Combined Loss: tensor(0.7449, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8954470157623291\n",
      "Batch: 185 , Combined Loss: tensor(0.8363, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6974588632583618\n",
      "Batch: 186 , Combined Loss: tensor(0.7280, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8425151109695435\n",
      "Batch: 187 , Combined Loss: tensor(0.8626, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3480100631713867\n",
      "Batch: 188 , Combined Loss: tensor(0.9462, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3870965242385864\n",
      "Batch: 189 , Combined Loss: tensor(0.6741, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6609389781951904\n",
      "Batch: 190 , Combined Loss: tensor(1.1886, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8809672594070435\n",
      "Batch: 191 , Combined Loss: tensor(0.7695, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5070241689682007\n",
      "Batch: 192 , Combined Loss: tensor(0.8153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5591741800308228\n",
      "Batch: 193 , Combined Loss: tensor(0.9556, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8471322059631348\n",
      "Batch: 194 , Combined Loss: tensor(0.7511, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5964580774307251\n",
      "Batch: 195 , Combined Loss: tensor(0.7555, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7962933778762817\n",
      "Batch: 196 , Combined Loss: tensor(0.6685, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9711531400680542\n",
      "Batch: 197 , Combined Loss: tensor(0.6684, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.02681875228881836\n",
      "Batch: 198 , Combined Loss: tensor(0.9188, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4786912202835083\n",
      "Batch: 199 , Combined Loss: tensor(0.8106, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6481912136077881\n",
      "Batch: 200 , Combined Loss: tensor(0.8934, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5016746520996094\n",
      "Batch: 201 , Combined Loss: tensor(0.6929, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.420166552066803\n",
      "Batch: 202 , Combined Loss: tensor(0.6767, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7177801132202148\n",
      "Batch: 203 , Combined Loss: tensor(0.6635, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.13096338510513306\n",
      "Batch: 204 , Combined Loss: tensor(0.8896, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7366701364517212\n",
      "Batch: 205 , Combined Loss: tensor(0.7375, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7869052886962891\n",
      "Batch: 206 , Combined Loss: tensor(0.7453, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10769462585449219\n",
      "Batch: 207 , Combined Loss: tensor(0.6711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6132885217666626\n",
      "Batch: 208 , Combined Loss: tensor(0.7410, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9871319532394409\n",
      "Batch: 209 , Combined Loss: tensor(0.6754, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6818540096282959\n",
      "Batch: 210 , Combined Loss: tensor(0.7236, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9416530132293701\n",
      "Batch: 211 , Combined Loss: tensor(0.7549, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6869603395462036\n",
      "Batch: 212 , Combined Loss: tensor(0.6711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14177393913269043\n",
      "Batch: 213 , Combined Loss: tensor(0.8357, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21450567245483398\n",
      "Batch: 214 , Combined Loss: tensor(0.6899, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7089515924453735\n",
      "Batch: 215 , Combined Loss: tensor(0.9139, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2409043312072754\n",
      "Batch: 216 , Combined Loss: tensor(0.9350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05252492427825928\n",
      "Batch: 217 , Combined Loss: tensor(0.6719, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5512627363204956\n",
      "Batch: 218 , Combined Loss: tensor(0.8442, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5009710788726807\n",
      "Batch: 219 , Combined Loss: tensor(0.8131, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.425098180770874\n",
      "Batch: 220 , Combined Loss: tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5404065847396851\n",
      "Batch: 221 , Combined Loss: tensor(0.6875, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9027316570281982\n",
      "Batch: 222 , Combined Loss: tensor(0.6658, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.013425767421722412\n",
      "Batch: 223 , Combined Loss: tensor(0.6469, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7843027114868164\n",
      "Batch: 224 , Combined Loss: tensor(0.7989, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8160514831542969\n",
      "Batch: 225 , Combined Loss: tensor(0.6990, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8757166862487793\n",
      "Batch: 226 , Combined Loss: tensor(0.6933, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5934150218963623\n",
      "Batch: 227 , Combined Loss: tensor(0.6530, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.598720908164978\n",
      "Batch: 228 , Combined Loss: tensor(0.8088, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4495958089828491\n",
      "Batch: 229 , Combined Loss: tensor(0.7451, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0878525972366333\n",
      "Batch: 230 , Combined Loss: tensor(0.9308, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8700840473175049\n",
      "Batch: 231 , Combined Loss: tensor(0.7054, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6542906761169434\n",
      "Batch: 232 , Combined Loss: tensor(0.6823, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0292959213256836\n",
      "Batch: 233 , Combined Loss: tensor(0.8666, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38974320888519287\n",
      "Batch: 234 , Combined Loss: tensor(0.8589, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8395123481750488\n",
      "Batch: 235 , Combined Loss: tensor(0.7252, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05147135257720947\n",
      "Batch: 236 , Combined Loss: tensor(0.6868, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7774615287780762\n",
      "Batch: 237 , Combined Loss: tensor(0.8640, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20071792602539062\n",
      "Batch: 238 , Combined Loss: tensor(0.7320, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6721041202545166\n",
      "Batch: 239 , Combined Loss: tensor(0.6359, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24920248985290527\n",
      "Batch: 240 , Combined Loss: tensor(0.8452, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4007580280303955\n",
      "Batch: 241 , Combined Loss: tensor(0.6780, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6694654226303101\n",
      "Batch: 242 , Combined Loss: tensor(0.8898, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8357197046279907\n",
      "Batch: 243 , Combined Loss: tensor(0.7066, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.571326494216919\n",
      "Batch: 244 , Combined Loss: tensor(0.7670, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40632760524749756\n",
      "Batch: 245 , Combined Loss: tensor(0.6340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08874154090881348\n",
      "Batch: 246 , Combined Loss: tensor(0.6753, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8190094232559204\n",
      "Batch: 247 , Combined Loss: tensor(0.7119, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14106202125549316\n",
      "Batch: 248 , Combined Loss: tensor(0.6986, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7544183731079102\n",
      "Batch: 249 , Combined Loss: tensor(0.7455, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11223816871643066\n",
      "Batch: 250 , Combined Loss: tensor(0.8395, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43367838859558105\n",
      "Batch: 251 , Combined Loss: tensor(0.6265, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4034477472305298\n",
      "Batch: 252 , Combined Loss: tensor(0.9647, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07100796699523926\n",
      "Batch: 253 , Combined Loss: tensor(0.7629, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7756533622741699\n",
      "Batch: 254 , Combined Loss: tensor(0.7809, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5844130516052246\n",
      "Batch: 255 , Combined Loss: tensor(0.7728, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44992148876190186\n",
      "Batch: 256 , Combined Loss: tensor(0.7534, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9308626651763916\n",
      "Batch: 257 , Combined Loss: tensor(0.7909, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9221681356430054\n",
      "Batch: 258 , Combined Loss: tensor(0.7211, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9198811054229736\n",
      "Batch: 259 , Combined Loss: tensor(0.6909, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9682856798171997\n",
      "Batch: 260 , Combined Loss: tensor(0.7076, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1669166088104248\n",
      "Batch: 261 , Combined Loss: tensor(0.7350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06746172904968262\n",
      "Batch: 262 , Combined Loss: tensor(0.7591, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5224648714065552\n",
      "Batch: 263 , Combined Loss: tensor(0.8244, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.677960991859436\n",
      "Batch: 264 , Combined Loss: tensor(0.8018, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48906731605529785\n",
      "Batch: 265 , Combined Loss: tensor(0.6791, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7404195070266724\n",
      "Batch: 266 , Combined Loss: tensor(0.8306, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8523942232131958\n",
      "Batch: 267 , Combined Loss: tensor(0.8622, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4727668762207031\n",
      "Batch: 268 , Combined Loss: tensor(0.7585, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.678769588470459\n",
      "Batch: 269 , Combined Loss: tensor(0.7622, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25162267684936523\n",
      "Batch: 270 , Combined Loss: tensor(0.6786, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35280776023864746\n",
      "Batch: 271 , Combined Loss: tensor(0.6349, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27866876125335693\n",
      "Batch: 272 , Combined Loss: tensor(0.6502, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7959580421447754\n",
      "Batch: 273 , Combined Loss: tensor(0.6755, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5464221239089966\n",
      "Batch: 274 , Combined Loss: tensor(0.7262, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5185317993164062\n",
      "Batch: 275 , Combined Loss: tensor(0.7763, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6286787986755371\n",
      "Batch: 276 , Combined Loss: tensor(0.7639, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9772630929946899\n",
      "Batch: 277 , Combined Loss: tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2808576226234436\n",
      "Batch: 278 , Combined Loss: tensor(0.9352, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3614710569381714\n",
      "Batch: 279 , Combined Loss: tensor(0.7449, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45387327671051025\n",
      "Batch: 280 , Combined Loss: tensor(0.6644, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24167346954345703\n",
      "Batch: 281 , Combined Loss: tensor(0.7319, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.826122522354126\n",
      "Batch: 282 , Combined Loss: tensor(0.6325, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8730330467224121\n",
      "Batch: 283 , Combined Loss: tensor(0.8666, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46708381175994873\n",
      "Batch: 284 , Combined Loss: tensor(0.8496, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9181568622589111\n",
      "Batch: 285 , Combined Loss: tensor(0.9246, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3178156614303589\n",
      "Batch: 286 , Combined Loss: tensor(0.8010, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9599001407623291\n",
      "Batch: 287 , Combined Loss: tensor(0.7863, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9071975946426392\n",
      "Batch: 288 , Combined Loss: tensor(0.7055, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2980763912200928\n",
      "Batch: 289 , Combined Loss: tensor(0.7236, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5393178462982178\n",
      "Batch: 290 , Combined Loss: tensor(0.7744, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.956041693687439\n",
      "Batch: 291 , Combined Loss: tensor(0.6251, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8265783786773682\n",
      "Batch: 292 , Combined Loss: tensor(0.7233, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8112139701843262\n",
      "Batch: 293 , Combined Loss: tensor(0.7995, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2580331563949585\n",
      "Batch: 294 , Combined Loss: tensor(0.6474, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2579784393310547\n",
      "Batch: 295 , Combined Loss: tensor(0.7469, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6842026710510254\n",
      "Batch: 296 , Combined Loss: tensor(0.8526, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6116889715194702\n",
      "Batch: 297 , Combined Loss: tensor(0.6678, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6379550695419312\n",
      "Batch: 298 , Combined Loss: tensor(1.0918, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4019526243209839\n",
      "Batch: 299 , Combined Loss: tensor(0.7265, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0006916522979736\n",
      "Batch: 300 , Combined Loss: tensor(0.7450, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4759708642959595\n",
      "Batch: 301 , Combined Loss: tensor(1.0599, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1330661177635193\n",
      "Batch: 302 , Combined Loss: tensor(0.7220, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06077754497528076\n",
      "Batch: 303 , Combined Loss: tensor(0.6971, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5317056179046631\n",
      "Batch: 304 , Combined Loss: tensor(0.9639, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3430687189102173\n",
      "Batch: 305 , Combined Loss: tensor(0.6832, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21148407459259033\n",
      "Batch: 306 , Combined Loss: tensor(0.8312, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6720163822174072\n",
      "Batch: 307 , Combined Loss: tensor(0.7040, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9675244092941284\n",
      "Batch: 308 , Combined Loss: tensor(0.6766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6014264822006226\n",
      "Batch: 309 , Combined Loss: tensor(0.7104, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7377791404724121\n",
      "Batch: 310 , Combined Loss: tensor(0.6059, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.488877534866333\n",
      "Batch: 311 , Combined Loss: tensor(0.6931, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48006904125213623\n",
      "Batch: 312 , Combined Loss: tensor(0.8486, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2437436580657959\n",
      "Batch: 313 , Combined Loss: tensor(0.6770, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0073050856590271\n",
      "Batch: 314 , Combined Loss: tensor(0.6895, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8015919923782349\n",
      "Batch: 315 , Combined Loss: tensor(0.7503, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7621232271194458\n",
      "Batch: 316 , Combined Loss: tensor(0.5883, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.518812894821167\n",
      "Batch: 317 , Combined Loss: tensor(0.7276, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.38120967149734497\n",
      "Batch: 318 , Combined Loss: tensor(0.7227, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9002249240875244\n",
      "Batch: 319 , Combined Loss: tensor(0.6806, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11613833904266357\n",
      "Batch: 320 , Combined Loss: tensor(0.7547, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6269921064376831\n",
      "Batch: 321 , Combined Loss: tensor(0.6849, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33236050605773926\n",
      "Batch: 322 , Combined Loss: tensor(0.8858, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4699513912200928\n",
      "Batch: 323 , Combined Loss: tensor(0.7408, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4627799987792969\n",
      "Batch: 324 , Combined Loss: tensor(0.6431, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7305054664611816\n",
      "Batch: 325 , Combined Loss: tensor(0.6516, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4365922212600708\n",
      "Batch: 326 , Combined Loss: tensor(0.8200, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.783586859703064\n",
      "Batch: 327 , Combined Loss: tensor(0.7514, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.016403138637542725\n",
      "Batch: 328 , Combined Loss: tensor(0.7848, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7487583160400391\n",
      "Batch: 329 , Combined Loss: tensor(0.8567, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40194594860076904\n",
      "Batch: 330 , Combined Loss: tensor(0.7605, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6111916303634644\n",
      "Batch: 331 , Combined Loss: tensor(0.6994, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4862908124923706\n",
      "Batch: 332 , Combined Loss: tensor(0.7521, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7649308443069458\n",
      "Batch: 333 , Combined Loss: tensor(0.7674, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2772985100746155\n",
      "Batch: 334 , Combined Loss: tensor(0.6746, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.000676155090332\n",
      "Batch: 335 , Combined Loss: tensor(0.8004, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2869343757629395\n",
      "Batch: 336 , Combined Loss: tensor(0.6918, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0178499221801758\n",
      "Batch: 337 , Combined Loss: tensor(0.7622, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2349582314491272\n",
      "Batch: 338 , Combined Loss: tensor(0.7040, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12958204746246338\n",
      "Batch: 339 , Combined Loss: tensor(0.7797, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7767057418823242\n",
      "Batch: 340 , Combined Loss: tensor(0.7317, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25888824462890625\n",
      "Batch: 341 , Combined Loss: tensor(0.6441, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.025448203086853027\n",
      "Batch: 342 , Combined Loss: tensor(0.6766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0221474170684814\n",
      "Batch: 343 , Combined Loss: tensor(0.9925, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.45697176456451416\n",
      "Batch: 344 , Combined Loss: tensor(0.7358, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7464807033538818\n",
      "Batch: 345 , Combined Loss: tensor(0.6705, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44451045989990234\n",
      "Batch: 346 , Combined Loss: tensor(0.7955, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.42140406370162964\n",
      "Batch: 347 , Combined Loss: tensor(0.6884, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08983063697814941\n",
      "Batch: 348 , Combined Loss: tensor(0.7831, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.328616738319397\n",
      "Batch: 349 , Combined Loss: tensor(0.7733, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4086265563964844\n",
      "Batch: 350 , Combined Loss: tensor(0.9278, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.382016122341156\n",
      "Batch: 351 , Combined Loss: tensor(0.9929, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3080037236213684\n",
      "Batch: 352 , Combined Loss: tensor(0.8713, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0678633451461792\n",
      "Batch: 353 , Combined Loss: tensor(0.6247, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14998042583465576\n",
      "Batch: 354 , Combined Loss: tensor(0.7753, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03636389970779419\n",
      "Batch: 355 , Combined Loss: tensor(0.7612, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3804495334625244\n",
      "Batch: 356 , Combined Loss: tensor(1.0938, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5808943510055542\n",
      "Batch: 357 , Combined Loss: tensor(0.7313, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07259070873260498\n",
      "Batch: 358 , Combined Loss: tensor(0.8367, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16991710662841797\n",
      "Batch: 359 , Combined Loss: tensor(0.7699, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22371864318847656\n",
      "Batch: 360 , Combined Loss: tensor(0.7976, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5014578104019165\n",
      "Batch: 361 , Combined Loss: tensor(0.6870, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3201889395713806\n",
      "Batch: 362 , Combined Loss: tensor(0.8004, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2932802438735962\n",
      "Batch: 363 , Combined Loss: tensor(0.8275, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11863374710083008\n",
      "Batch: 364 , Combined Loss: tensor(0.6888, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20646560192108154\n",
      "Batch: 365 , Combined Loss: tensor(0.8123, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26659226417541504\n",
      "Batch: 366 , Combined Loss: tensor(0.8855, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8608353137969971\n",
      "Batch: 367 , Combined Loss: tensor(0.6818, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21999502182006836\n",
      "Batch: 368 , Combined Loss: tensor(0.8269, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20049631595611572\n",
      "Batch: 369 , Combined Loss: tensor(0.8737, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7955360412597656\n",
      "Batch: 370 , Combined Loss: tensor(0.7237, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.579209566116333\n",
      "Batch: 371 , Combined Loss: tensor(0.7509, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7547779083251953\n",
      "Batch: 372 , Combined Loss: tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13722193241119385\n",
      "Batch: 373 , Combined Loss: tensor(0.7395, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.504381537437439\n",
      "Batch: 374 , Combined Loss: tensor(0.7333, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5911655426025391\n",
      "Batch: 375 , Combined Loss: tensor(0.6955, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9610385894775391\n",
      "Batch: 376 , Combined Loss: tensor(0.9512, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2418004274368286\n",
      "Batch: 377 , Combined Loss: tensor(0.7569, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8795753717422485\n",
      "Batch: 378 , Combined Loss: tensor(0.8960, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6579222679138184\n",
      "Batch: 379 , Combined Loss: tensor(0.8379, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7213038206100464\n",
      "Batch: 380 , Combined Loss: tensor(0.7593, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6309089660644531\n",
      "Batch: 381 , Combined Loss: tensor(0.8833, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2789914608001709\n",
      "Batch: 382 , Combined Loss: tensor(0.7658, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.41191327571868896\n",
      "Batch: 383 , Combined Loss: tensor(0.7517, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5714037418365479\n",
      "Batch: 384 , Combined Loss: tensor(0.7123, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37917208671569824\n",
      "Batch: 385 , Combined Loss: tensor(0.7270, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6853598356246948\n",
      "Batch: 386 , Combined Loss: tensor(0.7879, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.001801609992980957\n",
      "Batch: 387 , Combined Loss: tensor(0.7298, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2676982283592224\n",
      "Batch: 388 , Combined Loss: tensor(0.7239, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6135728359222412\n",
      "Batch: 389 , Combined Loss: tensor(0.7387, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1912769079208374\n",
      "Batch: 390 , Combined Loss: tensor(0.5676, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.013142108917236328\n",
      "Batch: 391 , Combined Loss: tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21462011337280273\n",
      "Batch: 392 , Combined Loss: tensor(0.7193, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21207588911056519\n",
      "Batch: 393 , Combined Loss: tensor(0.7254, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3049944043159485\n",
      "Batch: 394 , Combined Loss: tensor(0.7101, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1701737642288208\n",
      "Batch: 395 , Combined Loss: tensor(0.7126, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09469926357269287\n",
      "Batch: 396 , Combined Loss: tensor(0.8200, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9058324098587036\n",
      "Batch: 397 , Combined Loss: tensor(0.8040, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17020970582962036\n",
      "Batch: 398 , Combined Loss: tensor(0.8229, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0626239776611328\n",
      "Batch: 399 , Combined Loss: tensor(0.7053, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.02372753620147705\n",
      "Batch: 400 , Combined Loss: tensor(0.7057, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5746641159057617\n",
      "Batch: 401 , Combined Loss: tensor(0.7357, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6072953939437866\n",
      "Batch: 402 , Combined Loss: tensor(0.7711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4839128255844116\n",
      "Batch: 403 , Combined Loss: tensor(0.7091, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8482939004898071\n",
      "Batch: 404 , Combined Loss: tensor(0.7714, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.412369966506958\n",
      "Batch: 405 , Combined Loss: tensor(0.7206, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5964168310165405\n",
      "Batch: 406 , Combined Loss: tensor(0.6649, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6573939323425293\n",
      "Batch: 407 , Combined Loss: tensor(0.6852, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48384392261505127\n",
      "Batch: 408 , Combined Loss: tensor(0.6546, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6006466150283813\n",
      "Batch: 409 , Combined Loss: tensor(0.8849, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6335506439208984\n",
      "Batch: 410 , Combined Loss: tensor(0.6630, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.039732277393341064\n",
      "Batch: 411 , Combined Loss: tensor(0.7418, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20414292812347412\n",
      "Batch: 412 , Combined Loss: tensor(0.7001, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8851577043533325\n",
      "Batch: 413 , Combined Loss: tensor(0.7322, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8361896276473999\n",
      "Batch: 414 , Combined Loss: tensor(0.7588, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9810408353805542\n",
      "Batch: 415 , Combined Loss: tensor(0.6613, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9669817686080933\n",
      "Batch: 416 , Combined Loss: tensor(0.6631, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9498934745788574\n",
      "Batch: 417 , Combined Loss: tensor(0.6446, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7909526824951172\n",
      "Batch: 418 , Combined Loss: tensor(1.0989, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5736366510391235\n",
      "Batch: 419 , Combined Loss: tensor(0.8469, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8234294652938843\n",
      "Batch: 420 , Combined Loss: tensor(0.8886, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9803133010864258\n",
      "Batch: 421 , Combined Loss: tensor(0.7769, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06856346130371094\n",
      "Batch: 422 , Combined Loss: tensor(0.7770, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7929785251617432\n",
      "Batch: 423 , Combined Loss: tensor(0.6583, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3539630174636841\n",
      "Batch: 424 , Combined Loss: tensor(0.6102, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5151641368865967\n",
      "Batch: 425 , Combined Loss: tensor(0.7351, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6956144571304321\n",
      "Batch: 426 , Combined Loss: tensor(0.8867, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.26219820976257324\n",
      "Batch: 427 , Combined Loss: tensor(0.8413, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5776784420013428\n",
      "Batch: 428 , Combined Loss: tensor(0.6982, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.29378652572631836\n",
      "Batch: 429 , Combined Loss: tensor(0.6838, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8041086196899414\n",
      "Batch: 430 , Combined Loss: tensor(0.7237, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8693976402282715\n",
      "Batch: 431 , Combined Loss: tensor(0.8250, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31884312629699707\n",
      "Batch: 432 , Combined Loss: tensor(0.6842, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9471601247787476\n",
      "Batch: 433 , Combined Loss: tensor(0.6892, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7275477647781372\n",
      "Batch: 434 , Combined Loss: tensor(0.6218, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7988007068634033\n",
      "Batch: 435 , Combined Loss: tensor(0.6488, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5205948352813721\n",
      "Batch: 436 , Combined Loss: tensor(0.7668, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2436286211013794\n",
      "Batch: 437 , Combined Loss: tensor(0.6474, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5471246242523193\n",
      "Batch: 438 , Combined Loss: tensor(0.7254, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9972207546234131\n",
      "Batch: 439 , Combined Loss: tensor(0.6940, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5504372119903564\n",
      "Batch: 440 , Combined Loss: tensor(0.6293, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6952968835830688\n",
      "Batch: 441 , Combined Loss: tensor(0.7108, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6714255809783936\n",
      "Batch: 442 , Combined Loss: tensor(0.5997, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7744271755218506\n",
      "Batch: 443 , Combined Loss: tensor(0.6599, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9021908044815063\n",
      "Batch: 444 , Combined Loss: tensor(0.8693, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7347375154495239\n",
      "Batch: 445 , Combined Loss: tensor(0.6433, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7075315713882446\n",
      "Batch: 446 , Combined Loss: tensor(0.7591, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7429690361022949\n",
      "Batch: 447 , Combined Loss: tensor(0.9314, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5172531604766846\n",
      "Batch: 448 , Combined Loss: tensor(0.6238, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23917114734649658\n",
      "Batch: 449 , Combined Loss: tensor(0.8059, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6435233354568481\n",
      "Batch: 450 , Combined Loss: tensor(0.7589, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21374082565307617\n",
      "Batch: 451 , Combined Loss: tensor(0.6531, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4963153600692749\n",
      "Batch: 452 , Combined Loss: tensor(0.7204, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9512258768081665\n",
      "Batch: 453 , Combined Loss: tensor(0.7041, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8968030214309692\n",
      "Batch: 454 , Combined Loss: tensor(0.6459, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8371593952178955\n",
      "Batch: 455 , Combined Loss: tensor(0.7748, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0367953777313232\n",
      "Batch: 456 , Combined Loss: tensor(0.7373, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03134649991989136\n",
      "Batch: 457 , Combined Loss: tensor(1.0885, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5222917795181274\n",
      "Batch: 458 , Combined Loss: tensor(0.7783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8707449436187744\n",
      "Batch: 459 , Combined Loss: tensor(0.6574, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3542330265045166\n",
      "Batch: 460 , Combined Loss: tensor(0.7350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6064028739929199\n",
      "Batch: 461 , Combined Loss: tensor(0.6783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6395831108093262\n",
      "Batch: 462 , Combined Loss: tensor(0.6877, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8031129837036133\n",
      "Batch: 463 , Combined Loss: tensor(0.7050, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19376683235168457\n",
      "Batch: 464 , Combined Loss: tensor(0.7497, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7598685026168823\n",
      "Batch: 465 , Combined Loss: tensor(0.7193, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9308258295059204\n",
      "Batch: 466 , Combined Loss: tensor(0.6742, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.193315029144287\n",
      "Batch: 467 , Combined Loss: tensor(0.7608, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9598281383514404\n",
      "Batch: 468 , Combined Loss: tensor(0.6734, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1477426290512085\n",
      "Batch: 469 , Combined Loss: tensor(0.7100, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7034674882888794\n",
      "Batch: 470 , Combined Loss: tensor(0.6814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38307058811187744\n",
      "Batch: 471 , Combined Loss: tensor(0.9263, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22683322429656982\n",
      "Batch: 472 , Combined Loss: tensor(0.7275, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8863092660903931\n",
      "Batch: 473 , Combined Loss: tensor(0.7197, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6847299337387085\n",
      "Batch: 474 , Combined Loss: tensor(0.7551, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9982671737670898\n",
      "Batch: 475 , Combined Loss: tensor(1.0324, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22954416275024414\n",
      "Batch: 476 , Combined Loss: tensor(0.8838, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0140254497528076\n",
      "Batch: 477 , Combined Loss: tensor(0.7624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1007978916168213\n",
      "Batch: 478 , Combined Loss: tensor(0.7996, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3693338632583618\n",
      "Batch: 479 , Combined Loss: tensor(0.7119, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7672638893127441\n",
      "Batch: 480 , Combined Loss: tensor(0.6236, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4865003824234009\n",
      "Batch: 481 , Combined Loss: tensor(0.6563, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9659032821655273\n",
      "Batch: 482 , Combined Loss: tensor(0.6740, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9233851432800293\n",
      "Batch: 483 , Combined Loss: tensor(0.7673, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6378780603408813\n",
      "Batch: 484 , Combined Loss: tensor(0.7290, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8756344318389893\n",
      "Batch: 485 , Combined Loss: tensor(0.7066, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9294333457946777\n",
      "Batch: 486 , Combined Loss: tensor(0.6468, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5977258682250977\n",
      "Batch: 487 , Combined Loss: tensor(0.7487, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.583167552947998\n",
      "Batch: 488 , Combined Loss: tensor(0.6968, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11362087726593018\n",
      "Batch: 489 , Combined Loss: tensor(0.7394, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.014698028564453125\n",
      "Batch: 490 , Combined Loss: tensor(0.6726, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7539691925048828\n",
      "Batch: 491 , Combined Loss: tensor(0.8163, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2502560615539551\n",
      "Batch: 492 , Combined Loss: tensor(1.1861, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15694093704223633\n",
      "Batch: 493 , Combined Loss: tensor(0.7262, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4838191866874695\n",
      "Batch: 494 , Combined Loss: tensor(0.5808, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03470480442047119\n",
      "Batch: 495 , Combined Loss: tensor(0.7200, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0254311561584473\n",
      "Batch: 496 , Combined Loss: tensor(0.7042, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1189343929290771\n",
      "Batch: 497 , Combined Loss: tensor(0.9246, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5589817762374878\n",
      "Batch: 498 , Combined Loss: tensor(0.6666, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8614872694015503\n",
      "Batch: 499 , Combined Loss: tensor(0.8623, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5445116758346558\n",
      "Batch: 500 , Combined Loss: tensor(0.6797, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0499086380004883\n",
      "Batch: 501 , Combined Loss: tensor(0.7369, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5913718938827515\n",
      "Batch: 502 , Combined Loss: tensor(0.6014, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7968034744262695\n",
      "Batch: 503 , Combined Loss: tensor(0.7622, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8312656879425049\n",
      "Batch: 504 , Combined Loss: tensor(0.6778, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1205909252166748\n",
      "Batch: 505 , Combined Loss: tensor(0.6352, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7414765357971191\n",
      "Batch: 506 , Combined Loss: tensor(0.6055, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6826292276382446\n",
      "Batch: 507 , Combined Loss: tensor(0.7300, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4841192960739136\n",
      "Batch: 508 , Combined Loss: tensor(0.6774, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9130344390869141\n",
      "Batch: 509 , Combined Loss: tensor(0.7128, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29167020320892334\n",
      "Batch: 510 , Combined Loss: tensor(0.6153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6894254684448242\n",
      "Batch: 511 , Combined Loss: tensor(0.6433, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29225945472717285\n",
      "Batch: 512 , Combined Loss: tensor(0.8015, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48268628120422363\n",
      "Batch: 513 , Combined Loss: tensor(0.6743, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5826189517974854\n",
      "Batch: 514 , Combined Loss: tensor(0.7196, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7269011735916138\n",
      "Batch: 515 , Combined Loss: tensor(0.6836, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0707697868347168\n",
      "Batch: 516 , Combined Loss: tensor(1.0896, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4166116714477539\n",
      "Batch: 517 , Combined Loss: tensor(0.8512, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4176434278488159\n",
      "Batch: 518 , Combined Loss: tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.008744955062866211\n",
      "Batch: 519 , Combined Loss: tensor(0.6162, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36957740783691406\n",
      "Batch: 520 , Combined Loss: tensor(0.7256, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9088360071182251\n",
      "Batch: 521 , Combined Loss: tensor(0.9237, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.040716469287872314\n",
      "Batch: 522 , Combined Loss: tensor(0.6580, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7257180213928223\n",
      "Batch: 523 , Combined Loss: tensor(0.6710, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9009757041931152\n",
      "Batch: 524 , Combined Loss: tensor(0.6766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4732820987701416\n",
      "Batch: 525 , Combined Loss: tensor(0.6932, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0284466743469238\n",
      "Batch: 526 , Combined Loss: tensor(0.6271, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.49380725622177124\n",
      "Batch: 527 , Combined Loss: tensor(0.7846, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5776338577270508\n",
      "Batch: 528 , Combined Loss: tensor(0.8678, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0867340564727783\n",
      "Batch: 529 , Combined Loss: tensor(0.7550, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09520530700683594\n",
      "Batch: 530 , Combined Loss: tensor(0.8616, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7442886829376221\n",
      "Batch: 531 , Combined Loss: tensor(0.7017, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14578747749328613\n",
      "Batch: 532 , Combined Loss: tensor(0.7455, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9419935941696167\n",
      "Batch: 533 , Combined Loss: tensor(0.6991, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6352133750915527\n",
      "Batch: 534 , Combined Loss: tensor(0.8968, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07784944772720337\n",
      "Batch: 535 , Combined Loss: tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1395493745803833\n",
      "Batch: 536 , Combined Loss: tensor(0.7876, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.220908522605896\n",
      "Batch: 537 , Combined Loss: tensor(0.6862, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10819768905639648\n",
      "Batch: 538 , Combined Loss: tensor(0.6770, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11593133211135864\n",
      "Batch: 539 , Combined Loss: tensor(0.7220, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09320223331451416\n",
      "Batch: 540 , Combined Loss: tensor(0.8762, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.747739315032959\n",
      "Batch: 541 , Combined Loss: tensor(0.6259, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.13075852394104004\n",
      "Batch: 542 , Combined Loss: tensor(0.8165, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8730933666229248\n",
      "Batch: 543 , Combined Loss: tensor(0.7396, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.688676118850708\n",
      "Batch: 544 , Combined Loss: tensor(0.6560, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7349618673324585\n",
      "Batch: 545 , Combined Loss: tensor(0.6252, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6276497840881348\n",
      "Batch: 546 , Combined Loss: tensor(0.6760, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0533154010772705\n",
      "Batch: 547 , Combined Loss: tensor(0.7374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7492153644561768\n",
      "Batch: 548 , Combined Loss: tensor(0.7066, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12418860197067261\n",
      "Batch: 549 , Combined Loss: tensor(0.6264, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8208781480789185\n",
      "Batch: 550 , Combined Loss: tensor(0.6884, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9396073818206787\n",
      "Batch: 551 , Combined Loss: tensor(0.7272, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9026834964752197\n",
      "Batch: 552 , Combined Loss: tensor(0.7708, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40350210666656494\n",
      "Batch: 553 , Combined Loss: tensor(0.6276, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9649927616119385\n",
      "Batch: 554 , Combined Loss: tensor(0.6856, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.999151349067688\n",
      "Batch: 555 , Combined Loss: tensor(0.8011, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3058203458786011\n",
      "Batch: 556 , Combined Loss: tensor(0.8318, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8425660133361816\n",
      "Batch: 557 , Combined Loss: tensor(0.6903, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8114819526672363\n",
      "Batch: 558 , Combined Loss: tensor(0.8484, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9999688863754272\n",
      "Batch: 559 , Combined Loss: tensor(0.6662, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9326748847961426\n",
      "Batch: 560 , Combined Loss: tensor(0.9336, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3432124853134155\n",
      "Batch: 561 , Combined Loss: tensor(0.9031, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26907122135162354\n",
      "Batch: 562 , Combined Loss: tensor(0.8816, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4568812847137451\n",
      "Batch: 563 , Combined Loss: tensor(0.7548, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9557141065597534\n",
      "Batch: 564 , Combined Loss: tensor(0.7637, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7419531345367432\n",
      "Batch: 565 , Combined Loss: tensor(0.6022, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7347668409347534\n",
      "Batch: 566 , Combined Loss: tensor(0.6594, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0160534381866455\n",
      "Batch: 567 , Combined Loss: tensor(0.7631, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7333171367645264\n",
      "Batch: 568 , Combined Loss: tensor(0.6351, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6744376420974731\n",
      "Batch: 569 , Combined Loss: tensor(0.6895, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42397618293762207\n",
      "Batch: 570 , Combined Loss: tensor(0.7078, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3516339063644409\n",
      "Batch: 571 , Combined Loss: tensor(0.8401, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8542535305023193\n",
      "Batch: 572 , Combined Loss: tensor(0.9411, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.814583420753479\n",
      "Batch: 573 , Combined Loss: tensor(0.6423, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9252612590789795\n",
      "Batch: 574 , Combined Loss: tensor(1.0273, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.44766032695770264\n",
      "Batch: 575 , Combined Loss: tensor(0.6081, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3947601318359375\n",
      "Batch: 576 , Combined Loss: tensor(1.0962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08216708898544312\n",
      "Batch: 577 , Combined Loss: tensor(0.6988, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3867288827896118\n",
      "Batch: 578 , Combined Loss: tensor(0.7378, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08708643913269043\n",
      "Batch: 579 , Combined Loss: tensor(0.6282, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.092435359954834\n",
      "Batch: 580 , Combined Loss: tensor(0.6643, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11171364784240723\n",
      "Batch: 581 , Combined Loss: tensor(0.7492, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5349775552749634\n",
      "Batch: 582 , Combined Loss: tensor(0.8928, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41959667205810547\n",
      "Batch: 583 , Combined Loss: tensor(0.8702, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8404146432876587\n",
      "Batch: 584 , Combined Loss: tensor(0.8530, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8726263046264648\n",
      "Batch: 585 , Combined Loss: tensor(0.8889, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6797295808792114\n",
      "Batch: 586 , Combined Loss: tensor(0.6522, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6473963260650635\n",
      "Batch: 587 , Combined Loss: tensor(0.7826, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6497045755386353\n",
      "Batch: 588 , Combined Loss: tensor(0.6289, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8880867958068848\n",
      "Batch: 589 , Combined Loss: tensor(0.6236, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7397068738937378\n",
      "Batch: 590 , Combined Loss: tensor(0.7893, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13628363609313965\n",
      "Batch: 591 , Combined Loss: tensor(0.8368, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4573373794555664\n",
      "Batch: 592 , Combined Loss: tensor(0.6368, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.575709342956543\n",
      "Batch: 593 , Combined Loss: tensor(0.8477, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2540891170501709\n",
      "Batch: 594 , Combined Loss: tensor(0.9944, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5949380397796631\n",
      "Batch: 595 , Combined Loss: tensor(0.6586, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3598116636276245\n",
      "Batch: 596 , Combined Loss: tensor(0.6247, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6860837936401367\n",
      "Batch: 597 , Combined Loss: tensor(0.6831, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.050613462924957275\n",
      "Batch: 598 , Combined Loss: tensor(1.0020, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8462278842926025\n",
      "Batch: 599 , Combined Loss: tensor(0.6311, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0249383449554443\n",
      "Batch: 600 , Combined Loss: tensor(0.6401, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.673430323600769\n",
      "Batch: 601 , Combined Loss: tensor(0.7192, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9324896335601807\n",
      "Batch: 602 , Combined Loss: tensor(0.6652, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8143719434738159\n",
      "Batch: 603 , Combined Loss: tensor(0.7238, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6630220413208008\n",
      "Batch: 604 , Combined Loss: tensor(0.8830, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.00990629196167\n",
      "Batch: 605 , Combined Loss: tensor(0.7291, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7640794515609741\n",
      "Batch: 606 , Combined Loss: tensor(0.8537, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24222278594970703\n",
      "Batch: 607 , Combined Loss: tensor(0.7690, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8159087896347046\n",
      "Batch: 608 , Combined Loss: tensor(0.9622, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10662829875946045\n",
      "Batch: 609 , Combined Loss: tensor(0.7864, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5768177509307861\n",
      "Batch: 610 , Combined Loss: tensor(0.6879, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.13966113328933716\n",
      "Batch: 611 , Combined Loss: tensor(0.8034, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3120962381362915\n",
      "Batch: 612 , Combined Loss: tensor(0.6654, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6125459671020508\n",
      "Batch: 613 , Combined Loss: tensor(0.7560, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4937136173248291\n",
      "Batch: 614 , Combined Loss: tensor(0.7668, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.840800404548645\n",
      "Batch: 615 , Combined Loss: tensor(0.8349, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07185804843902588\n",
      "Batch: 616 , Combined Loss: tensor(0.6507, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8279691934585571\n",
      "Batch: 617 , Combined Loss: tensor(0.6900, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.896060585975647\n",
      "Batch: 618 , Combined Loss: tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14133286476135254\n",
      "Batch: 619 , Combined Loss: tensor(0.7112, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28458642959594727\n",
      "Batch: 620 , Combined Loss: tensor(0.7580, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.674038290977478\n",
      "Batch: 621 , Combined Loss: tensor(0.6486, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5009928941726685\n",
      "Batch: 622 , Combined Loss: tensor(0.6786, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7019195556640625\n",
      "Batch: 623 , Combined Loss: tensor(0.7391, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5633310079574585\n",
      "Batch: 624 , Combined Loss: tensor(0.6960, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3781135082244873\n",
      "Batch: 625 , Combined Loss: tensor(0.7774, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43582653999328613\n",
      "Batch: 626 , Combined Loss: tensor(0.6504, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4157315492630005\n",
      "Batch: 627 , Combined Loss: tensor(1.0116, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38746702671051025\n",
      "Batch: 628 , Combined Loss: tensor(0.6114, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06334435939788818\n",
      "----------Epoch 11, Loss: 0.7529506683349609, Accuracy: 0.9545297880430479, Dice Coef: [0.9788676480420633, 0.5058481189798881, 0.5347284739079611, 0.6410301107513895], Dice Coef Necrotic: 0.9019569355814703, Dice Coef Edema: 0.9180145157152461, Dice Coef Enhancing: 0.8489706390535037, Sensitivity: [0.9609165372643828, 0.7144367709434414, 0.83479682883227, 0.8451628262630185], Specificity: [0.9623932269400368, 0.9963297551121735, 0.9660431330457969, 0.9932375218606715], Precision: [0.9977274856430927, 0.4700914297069849, 0.4259024205309356, 0.5636930432083087]\n",
      "Saving without nn.DataParallel\n",
      "Batch: 0 , Combined Loss: tensor(0.9042, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09600555896759033\n",
      "Batch: 1 , Combined Loss: tensor(0.9371, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.055394887924194336\n",
      "Batch: 2 , Combined Loss: tensor(0.8026, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3244633674621582\n",
      "Batch: 3 , Combined Loss: tensor(0.7084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9002394676208496\n",
      "Batch: 4 , Combined Loss: tensor(0.7834, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23987972736358643\n",
      "Batch: 5 , Combined Loss: tensor(0.8322, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9004716873168945\n",
      "Batch: 6 , Combined Loss: tensor(0.7100, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.16520977020263672\n",
      "Batch: 7 , Combined Loss: tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7062505483627319\n",
      "Batch: 8 , Combined Loss: tensor(1.0122, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3447202444076538\n",
      "Batch: 9 , Combined Loss: tensor(0.7288, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.910732626914978\n",
      "Batch: 10 , Combined Loss: tensor(0.7299, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22100591659545898\n",
      "Batch: 11 , Combined Loss: tensor(0.8664, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2717643976211548\n",
      "Batch: 12 , Combined Loss: tensor(0.8683, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.01633155345916748\n",
      "Batch: 13 , Combined Loss: tensor(0.6632, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5269027948379517\n",
      "Batch: 14 , Combined Loss: tensor(0.7079, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34888267517089844\n",
      "Batch: 15 , Combined Loss: tensor(0.6661, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.752851128578186\n",
      "Batch: 16 , Combined Loss: tensor(0.7267, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9161549806594849\n",
      "Batch: 17 , Combined Loss: tensor(0.6827, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7732634544372559\n",
      "Batch: 18 , Combined Loss: tensor(0.7654, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48742127418518066\n",
      "Batch: 19 , Combined Loss: tensor(0.7521, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3491858243942261\n",
      "Batch: 20 , Combined Loss: tensor(0.7393, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4223521947860718\n",
      "Batch: 21 , Combined Loss: tensor(0.7863, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7138432264328003\n",
      "Batch: 22 , Combined Loss: tensor(0.6136, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6805661916732788\n",
      "Batch: 23 , Combined Loss: tensor(0.9800, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5271815061569214\n",
      "Batch: 24 , Combined Loss: tensor(0.8009, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.285403847694397\n",
      "Batch: 25 , Combined Loss: tensor(0.7419, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22404956817626953\n",
      "Batch: 26 , Combined Loss: tensor(0.6726, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8694648742675781\n",
      "Batch: 27 , Combined Loss: tensor(0.8829, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7843936681747437\n",
      "Batch: 28 , Combined Loss: tensor(0.9011, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44156670570373535\n",
      "Batch: 29 , Combined Loss: tensor(0.9413, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18596947193145752\n",
      "Batch: 30 , Combined Loss: tensor(0.6404, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9932072162628174\n",
      "Batch: 31 , Combined Loss: tensor(0.6169, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7282979488372803\n",
      "Batch: 32 , Combined Loss: tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5391838550567627\n",
      "Batch: 33 , Combined Loss: tensor(0.6698, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34198808670043945\n",
      "Batch: 34 , Combined Loss: tensor(0.8378, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6873364448547363\n",
      "Batch: 35 , Combined Loss: tensor(0.6985, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7027690410614014\n",
      "Batch: 36 , Combined Loss: tensor(0.6661, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5307550430297852\n",
      "Batch: 37 , Combined Loss: tensor(0.6799, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32818281650543213\n",
      "Batch: 38 , Combined Loss: tensor(0.7497, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7286543846130371\n",
      "Batch: 39 , Combined Loss: tensor(0.7743, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47260987758636475\n",
      "Batch: 40 , Combined Loss: tensor(0.7377, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7921737432479858\n",
      "Batch: 41 , Combined Loss: tensor(0.7197, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26859724521636963\n",
      "Batch: 42 , Combined Loss: tensor(0.7270, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9521142244338989\n",
      "Batch: 43 , Combined Loss: tensor(0.7788, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7149627208709717\n",
      "Batch: 44 , Combined Loss: tensor(0.6785, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8981828689575195\n",
      "Batch: 45 , Combined Loss: tensor(0.9516, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5257008075714111\n",
      "Batch: 46 , Combined Loss: tensor(0.8963, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.852837085723877\n",
      "Batch: 47 , Combined Loss: tensor(0.8338, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8109008073806763\n",
      "Batch: 48 , Combined Loss: tensor(0.7016, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.42428022623062134\n",
      "Batch: 49 , Combined Loss: tensor(0.7938, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2730633020401001\n",
      "Batch: 50 , Combined Loss: tensor(0.7781, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16303789615631104\n",
      "Batch: 51 , Combined Loss: tensor(0.8404, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3324298858642578\n",
      "Batch: 52 , Combined Loss: tensor(0.6906, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6506808996200562\n",
      "Batch: 53 , Combined Loss: tensor(0.7692, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7612905502319336\n",
      "Batch: 54 , Combined Loss: tensor(0.8328, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1406412124633789\n",
      "Batch: 55 , Combined Loss: tensor(0.6862, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36050426959991455\n",
      "Batch: 56 , Combined Loss: tensor(0.6722, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49850308895111084\n",
      "Batch: 57 , Combined Loss: tensor(0.7679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46612024307250977\n",
      "Batch: 58 , Combined Loss: tensor(0.8446, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31471550464630127\n",
      "Batch: 59 , Combined Loss: tensor(0.7131, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42191648483276367\n",
      "Batch: 60 , Combined Loss: tensor(0.7430, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.026172161102295\n",
      "Batch: 61 , Combined Loss: tensor(0.7419, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27819252014160156\n",
      "Batch: 62 , Combined Loss: tensor(0.7718, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5730863809585571\n",
      "Batch: 63 , Combined Loss: tensor(0.8007, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3151590824127197\n",
      "Batch: 64 , Combined Loss: tensor(0.6734, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31384921073913574\n",
      "Batch: 65 , Combined Loss: tensor(0.7287, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3328373432159424\n",
      "Batch: 66 , Combined Loss: tensor(0.7716, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5683093667030334\n",
      "Batch: 67 , Combined Loss: tensor(0.9815, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3207136392593384\n",
      "Batch: 68 , Combined Loss: tensor(0.8169, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1475650668144226\n",
      "Batch: 69 , Combined Loss: tensor(0.7534, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28533661365509033\n",
      "Batch: 70 , Combined Loss: tensor(0.8143, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6721516847610474\n",
      "Batch: 71 , Combined Loss: tensor(0.7299, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5757617950439453\n",
      "Batch: 72 , Combined Loss: tensor(0.7364, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6192811727523804\n",
      "Batch: 73 , Combined Loss: tensor(0.7227, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44028735160827637\n",
      "Batch: 74 , Combined Loss: tensor(0.8717, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15680480003356934\n",
      "Batch: 75 , Combined Loss: tensor(0.7486, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6255065202713013\n",
      "Batch: 76 , Combined Loss: tensor(0.6732, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4864910840988159\n",
      "Batch: 77 , Combined Loss: tensor(0.8366, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9064168930053711\n",
      "Batch: 78 , Combined Loss: tensor(0.8126, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4551053047180176\n",
      "Batch: 79 , Combined Loss: tensor(0.6501, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09910106658935547\n",
      "Batch: 80 , Combined Loss: tensor(0.6991, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09734910726547241\n",
      "Batch: 81 , Combined Loss: tensor(0.7176, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06454765796661377\n",
      "Batch: 82 , Combined Loss: tensor(0.8829, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4101858139038086\n",
      "Batch: 83 , Combined Loss: tensor(0.7190, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14518678188323975\n",
      "Batch: 84 , Combined Loss: tensor(0.6664, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.600088357925415\n",
      "Batch: 85 , Combined Loss: tensor(0.6810, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6466935873031616\n",
      "Batch: 86 , Combined Loss: tensor(0.6677, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49591755867004395\n",
      "Batch: 87 , Combined Loss: tensor(0.7304, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25211453437805176\n",
      "Batch: 88 , Combined Loss: tensor(0.6830, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7406789064407349\n",
      "Batch: 89 , Combined Loss: tensor(0.8051, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6594201326370239\n",
      "Batch: 90 , Combined Loss: tensor(0.8593, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23444092273712158\n",
      "Batch: 91 , Combined Loss: tensor(0.7303, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27338945865631104\n",
      "Batch: 92 , Combined Loss: tensor(0.8315, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4773746728897095\n",
      "Batch: 93 , Combined Loss: tensor(0.7323, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.019710004329681396\n",
      "Batch: 94 , Combined Loss: tensor(0.8938, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.02695596218109131\n",
      "Batch: 95 , Combined Loss: tensor(0.7207, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5813729763031006\n",
      "Batch: 96 , Combined Loss: tensor(0.6951, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3629491329193115\n",
      "Batch: 97 , Combined Loss: tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30996012687683105\n",
      "Batch: 98 , Combined Loss: tensor(0.6792, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3062865734100342\n",
      "Batch: 99 , Combined Loss: tensor(0.7326, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.648167610168457\n",
      "Batch: 100 , Combined Loss: tensor(0.7237, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0639867782592773\n",
      "Batch: 101 , Combined Loss: tensor(1.1070, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.831740140914917\n",
      "Batch: 102 , Combined Loss: tensor(0.7013, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0390162467956543\n",
      "Batch: 103 , Combined Loss: tensor(0.7360, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6371755599975586\n",
      "Batch: 104 , Combined Loss: tensor(0.8098, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41890156269073486\n",
      "Batch: 105 , Combined Loss: tensor(0.7501, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3523958921432495\n",
      "Batch: 106 , Combined Loss: tensor(0.7018, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.16873526573181152\n",
      "Batch: 107 , Combined Loss: tensor(1.2445, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.906690239906311\n",
      "Batch: 108 , Combined Loss: tensor(0.6904, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7915229797363281\n",
      "Batch: 109 , Combined Loss: tensor(0.6789, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09809005260467529\n",
      "Batch: 110 , Combined Loss: tensor(0.7215, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7897095680236816\n",
      "Batch: 111 , Combined Loss: tensor(0.7120, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7590829133987427\n",
      "Batch: 112 , Combined Loss: tensor(0.8661, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0096945762634277\n",
      "Batch: 113 , Combined Loss: tensor(0.6285, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3632241487503052\n",
      "Batch: 114 , Combined Loss: tensor(0.7459, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3817870616912842\n",
      "Batch: 115 , Combined Loss: tensor(0.7534, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1130373477935791\n",
      "Batch: 116 , Combined Loss: tensor(0.8843, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36102378368377686\n",
      "Batch: 117 , Combined Loss: tensor(0.6749, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0413782596588135\n",
      "Batch: 118 , Combined Loss: tensor(0.6507, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.697800874710083\n",
      "Batch: 119 , Combined Loss: tensor(0.6476, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7387878894805908\n",
      "Batch: 120 , Combined Loss: tensor(0.7316, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.00859975814819336\n",
      "Batch: 121 , Combined Loss: tensor(0.8152, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33440208435058594\n",
      "Batch: 122 , Combined Loss: tensor(0.6555, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9091821908950806\n",
      "Batch: 123 , Combined Loss: tensor(0.7939, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.324007511138916\n",
      "Batch: 124 , Combined Loss: tensor(0.8748, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7581433057785034\n",
      "Batch: 125 , Combined Loss: tensor(0.7029, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43358123302459717\n",
      "Batch: 126 , Combined Loss: tensor(0.6968, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.307180404663086\n",
      "Batch: 127 , Combined Loss: tensor(0.7921, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1258143186569214\n",
      "Batch: 128 , Combined Loss: tensor(0.7178, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5701189041137695\n",
      "Batch: 129 , Combined Loss: tensor(0.7240, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2802006006240845\n",
      "Batch: 130 , Combined Loss: tensor(0.7029, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6421370506286621\n",
      "Batch: 131 , Combined Loss: tensor(0.6691, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7973207235336304\n",
      "Batch: 132 , Combined Loss: tensor(0.6979, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.920981764793396\n",
      "Batch: 133 , Combined Loss: tensor(0.7191, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9016036987304688\n",
      "Batch: 134 , Combined Loss: tensor(0.6378, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03638070821762085\n",
      "Batch: 135 , Combined Loss: tensor(0.8711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5526809692382812\n",
      "Batch: 136 , Combined Loss: tensor(0.9852, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2978663444519043\n",
      "Batch: 137 , Combined Loss: tensor(0.7777, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03131401538848877\n",
      "Batch: 138 , Combined Loss: tensor(0.6212, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7178627252578735\n",
      "Batch: 139 , Combined Loss: tensor(0.8209, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2642223834991455\n",
      "Batch: 140 , Combined Loss: tensor(0.7119, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5626240968704224\n",
      "Batch: 141 , Combined Loss: tensor(0.7316, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8691043853759766\n",
      "Batch: 142 , Combined Loss: tensor(0.7925, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9133732318878174\n",
      "Batch: 143 , Combined Loss: tensor(0.7779, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20653706789016724\n",
      "Batch: 144 , Combined Loss: tensor(0.7247, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.02914726734161377\n",
      "Batch: 145 , Combined Loss: tensor(0.9191, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22275221347808838\n",
      "Batch: 146 , Combined Loss: tensor(0.7766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7658978700637817\n",
      "Batch: 147 , Combined Loss: tensor(0.7186, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3909754753112793\n",
      "Batch: 148 , Combined Loss: tensor(0.7557, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2944068908691406\n",
      "Batch: 149 , Combined Loss: tensor(0.7388, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6000477075576782\n",
      "Batch: 150 , Combined Loss: tensor(0.8901, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6354131698608398\n",
      "Batch: 151 , Combined Loss: tensor(0.9008, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0664360523223877\n",
      "Batch: 152 , Combined Loss: tensor(0.7590, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7227613925933838\n",
      "Batch: 153 , Combined Loss: tensor(0.7490, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22027570009231567\n",
      "Batch: 154 , Combined Loss: tensor(0.7334, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06612622737884521\n",
      "Batch: 155 , Combined Loss: tensor(0.6535, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.027202963829040527\n",
      "Batch: 156 , Combined Loss: tensor(0.6533, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7169346809387207\n",
      "Batch: 157 , Combined Loss: tensor(0.6892, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0543577671051025\n",
      "Batch: 158 , Combined Loss: tensor(0.7887, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9411032199859619\n",
      "Batch: 159 , Combined Loss: tensor(0.8393, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21951240301132202\n",
      "Batch: 160 , Combined Loss: tensor(0.6444, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5552295446395874\n",
      "Batch: 161 , Combined Loss: tensor(0.6274, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42321622371673584\n",
      "Batch: 162 , Combined Loss: tensor(0.6668, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9186615943908691\n",
      "Batch: 163 , Combined Loss: tensor(0.6845, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8279589414596558\n",
      "Batch: 164 , Combined Loss: tensor(0.6772, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9650437831878662\n",
      "Batch: 165 , Combined Loss: tensor(0.7274, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7082653045654297\n",
      "Batch: 166 , Combined Loss: tensor(0.6977, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0875048637390137\n",
      "Batch: 167 , Combined Loss: tensor(0.6817, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0647823810577393\n",
      "Batch: 168 , Combined Loss: tensor(0.7956, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8992897272109985\n",
      "Batch: 169 , Combined Loss: tensor(0.7991, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2884312868118286\n",
      "Batch: 170 , Combined Loss: tensor(0.6692, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0638580322265625\n",
      "Batch: 171 , Combined Loss: tensor(0.6560, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6954680681228638\n",
      "Batch: 172 , Combined Loss: tensor(0.6814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0638070106506348\n",
      "Batch: 173 , Combined Loss: tensor(0.7434, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8196650743484497\n",
      "Batch: 174 , Combined Loss: tensor(0.6832, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1603002548217773\n",
      "Batch: 175 , Combined Loss: tensor(0.7013, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9486671686172485\n",
      "Batch: 176 , Combined Loss: tensor(0.6929, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9839541912078857\n",
      "Batch: 177 , Combined Loss: tensor(0.7043, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8499571084976196\n",
      "Batch: 178 , Combined Loss: tensor(0.6721, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8714505434036255\n",
      "Batch: 179 , Combined Loss: tensor(0.6287, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.006232798099517822\n",
      "Batch: 180 , Combined Loss: tensor(0.9219, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2710390090942383\n",
      "Batch: 181 , Combined Loss: tensor(0.7598, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.703439474105835\n",
      "Batch: 182 , Combined Loss: tensor(0.6374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4128537178039551\n",
      "Batch: 183 , Combined Loss: tensor(0.8306, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.001233518123626709\n",
      "Batch: 184 , Combined Loss: tensor(0.6904, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.599183201789856\n",
      "Batch: 185 , Combined Loss: tensor(0.7485, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2210032939910889\n",
      "Batch: 186 , Combined Loss: tensor(0.7537, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9111981391906738\n",
      "Batch: 187 , Combined Loss: tensor(0.6634, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5036770105361938\n",
      "Batch: 188 , Combined Loss: tensor(0.8237, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8775266408920288\n",
      "Batch: 189 , Combined Loss: tensor(0.7176, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24901235103607178\n",
      "Batch: 190 , Combined Loss: tensor(0.7051, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8739738464355469\n",
      "Batch: 191 , Combined Loss: tensor(0.6232, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.994593620300293\n",
      "Batch: 192 , Combined Loss: tensor(0.8638, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7958289384841919\n",
      "Batch: 193 , Combined Loss: tensor(0.8342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8312846422195435\n",
      "Batch: 194 , Combined Loss: tensor(0.8830, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4137219190597534\n",
      "Batch: 195 , Combined Loss: tensor(0.6694, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20511507987976074\n",
      "Batch: 196 , Combined Loss: tensor(0.6631, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0470499992370605\n",
      "Batch: 197 , Combined Loss: tensor(0.6867, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.27886420488357544\n",
      "Batch: 198 , Combined Loss: tensor(0.7430, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4058716297149658\n",
      "Batch: 199 , Combined Loss: tensor(0.7498, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6366641521453857\n",
      "Batch: 200 , Combined Loss: tensor(0.6523, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6830439567565918\n",
      "Batch: 201 , Combined Loss: tensor(0.7991, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.541776180267334\n",
      "Batch: 202 , Combined Loss: tensor(0.9236, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21871894598007202\n",
      "Batch: 203 , Combined Loss: tensor(0.8365, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7176955938339233\n",
      "Batch: 204 , Combined Loss: tensor(0.7842, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8946092128753662\n",
      "Batch: 205 , Combined Loss: tensor(0.7391, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6633709669113159\n",
      "Batch: 206 , Combined Loss: tensor(0.7650, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1084134578704834\n",
      "Batch: 207 , Combined Loss: tensor(0.7937, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8301645517349243\n",
      "Batch: 208 , Combined Loss: tensor(0.6362, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8892545700073242\n",
      "Batch: 209 , Combined Loss: tensor(0.7093, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.30524784326553345\n",
      "Batch: 210 , Combined Loss: tensor(0.7686, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8945906162261963\n",
      "Batch: 211 , Combined Loss: tensor(0.6525, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.208195447921753\n",
      "Batch: 212 , Combined Loss: tensor(0.7118, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5322990417480469\n",
      "Batch: 213 , Combined Loss: tensor(0.6037, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5430556535720825\n",
      "Batch: 214 , Combined Loss: tensor(0.7843, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.587407112121582\n",
      "Batch: 215 , Combined Loss: tensor(0.7320, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9574382305145264\n",
      "Batch: 216 , Combined Loss: tensor(0.7446, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16549921035766602\n",
      "Batch: 217 , Combined Loss: tensor(0.7441, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6431522369384766\n",
      "Batch: 218 , Combined Loss: tensor(0.7890, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9519530534744263\n",
      "Batch: 219 , Combined Loss: tensor(0.7647, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17566066980361938\n",
      "Batch: 220 , Combined Loss: tensor(0.7217, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5642166137695312\n",
      "Batch: 221 , Combined Loss: tensor(0.7530, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8692587614059448\n",
      "Batch: 222 , Combined Loss: tensor(0.7615, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.002398192882537842\n",
      "Batch: 223 , Combined Loss: tensor(1.0241, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11015689373016357\n",
      "Batch: 224 , Combined Loss: tensor(0.7073, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8985333442687988\n",
      "Batch: 225 , Combined Loss: tensor(0.7747, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4231635332107544\n",
      "Batch: 226 , Combined Loss: tensor(0.7676, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.851038932800293\n",
      "Batch: 227 , Combined Loss: tensor(0.7486, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.02750265598297119\n",
      "Batch: 228 , Combined Loss: tensor(0.6261, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12593984603881836\n",
      "Batch: 229 , Combined Loss: tensor(0.6545, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5513222217559814\n",
      "Batch: 230 , Combined Loss: tensor(0.7106, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18781352043151855\n",
      "Batch: 231 , Combined Loss: tensor(0.6736, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06047183275222778\n",
      "Batch: 232 , Combined Loss: tensor(0.7560, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.564727783203125\n",
      "Batch: 233 , Combined Loss: tensor(0.7615, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7923717498779297\n",
      "Batch: 234 , Combined Loss: tensor(0.7118, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9914300441741943\n",
      "Batch: 235 , Combined Loss: tensor(0.6943, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6457169055938721\n",
      "Batch: 236 , Combined Loss: tensor(0.7268, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07104277610778809\n",
      "Batch: 237 , Combined Loss: tensor(0.6980, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7071346044540405\n",
      "Batch: 238 , Combined Loss: tensor(0.6459, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1661590337753296\n",
      "Batch: 239 , Combined Loss: tensor(0.8146, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.625430703163147\n",
      "Batch: 240 , Combined Loss: tensor(0.7350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.662659764289856\n",
      "Batch: 241 , Combined Loss: tensor(0.7235, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9761813879013062\n",
      "Batch: 242 , Combined Loss: tensor(0.6382, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5650948286056519\n",
      "Batch: 243 , Combined Loss: tensor(0.8263, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4486454725265503\n",
      "Batch: 244 , Combined Loss: tensor(0.7976, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.302773654460907\n",
      "Batch: 245 , Combined Loss: tensor(0.6585, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.898002028465271\n",
      "Batch: 246 , Combined Loss: tensor(0.8106, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.807231068611145\n",
      "Batch: 247 , Combined Loss: tensor(0.7581, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9137264490127563\n",
      "Batch: 248 , Combined Loss: tensor(0.6957, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9105261564254761\n",
      "Batch: 249 , Combined Loss: tensor(0.6899, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5885922908782959\n",
      "Batch: 250 , Combined Loss: tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2256622314453125\n",
      "Batch: 251 , Combined Loss: tensor(0.8420, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5873446464538574\n",
      "Batch: 252 , Combined Loss: tensor(0.8059, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12092411518096924\n",
      "Batch: 253 , Combined Loss: tensor(0.7380, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0035934448242188\n",
      "Batch: 254 , Combined Loss: tensor(0.6648, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33872246742248535\n",
      "Batch: 255 , Combined Loss: tensor(0.8702, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4801734685897827\n",
      "Batch: 256 , Combined Loss: tensor(0.7649, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1334521770477295\n",
      "Batch: 257 , Combined Loss: tensor(0.8365, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05650782585144043\n",
      "Batch: 258 , Combined Loss: tensor(0.7412, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5930540561676025\n",
      "Batch: 259 , Combined Loss: tensor(0.7191, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11147260665893555\n",
      "Batch: 260 , Combined Loss: tensor(0.7893, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7469910383224487\n",
      "Batch: 261 , Combined Loss: tensor(0.7737, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7722282409667969\n",
      "Batch: 262 , Combined Loss: tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8678616285324097\n",
      "Batch: 263 , Combined Loss: tensor(0.6392, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9601047039031982\n",
      "Batch: 264 , Combined Loss: tensor(0.7897, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.098807692527771\n",
      "Batch: 265 , Combined Loss: tensor(0.8453, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8638874292373657\n",
      "Batch: 266 , Combined Loss: tensor(0.6642, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23816072940826416\n",
      "Batch: 267 , Combined Loss: tensor(0.8482, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6664083003997803\n",
      "Batch: 268 , Combined Loss: tensor(0.7373, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5268210172653198\n",
      "Batch: 269 , Combined Loss: tensor(0.6733, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6328960657119751\n",
      "Batch: 270 , Combined Loss: tensor(0.7460, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5862756967544556\n",
      "Batch: 271 , Combined Loss: tensor(0.7700, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9443447589874268\n",
      "Batch: 272 , Combined Loss: tensor(0.6595, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.765488862991333\n",
      "Batch: 273 , Combined Loss: tensor(0.7075, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0470619201660156\n",
      "Batch: 274 , Combined Loss: tensor(0.6765, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1697070598602295\n",
      "Batch: 275 , Combined Loss: tensor(0.7170, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7920091152191162\n",
      "Batch: 276 , Combined Loss: tensor(0.7881, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.29142117500305176\n",
      "Batch: 277 , Combined Loss: tensor(0.6412, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0242924690246582\n",
      "Batch: 278 , Combined Loss: tensor(0.7703, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3205162286758423\n",
      "Batch: 279 , Combined Loss: tensor(0.7078, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7606990337371826\n",
      "Batch: 280 , Combined Loss: tensor(0.7509, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6336950063705444\n",
      "Batch: 281 , Combined Loss: tensor(1.0731, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44554030895233154\n",
      "Batch: 282 , Combined Loss: tensor(0.6536, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.001802682876587\n",
      "Batch: 283 , Combined Loss: tensor(0.8232, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8081954717636108\n",
      "Batch: 284 , Combined Loss: tensor(0.9027, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7483375072479248\n",
      "Batch: 285 , Combined Loss: tensor(0.7448, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0923081636428833\n",
      "Batch: 286 , Combined Loss: tensor(0.8879, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0077519416809082\n",
      "Batch: 287 , Combined Loss: tensor(0.6963, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08900809288024902\n",
      "Batch: 288 , Combined Loss: tensor(1.0617, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5528450012207031\n",
      "Batch: 289 , Combined Loss: tensor(0.6815, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4310082197189331\n",
      "Batch: 290 , Combined Loss: tensor(0.7405, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30281293392181396\n",
      "Batch: 291 , Combined Loss: tensor(0.6636, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6386934518814087\n",
      "Batch: 292 , Combined Loss: tensor(0.8903, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5974196195602417\n",
      "Batch: 293 , Combined Loss: tensor(0.6885, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4041556119918823\n",
      "Batch: 294 , Combined Loss: tensor(0.7614, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6147373914718628\n",
      "Batch: 295 , Combined Loss: tensor(0.6816, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5528254508972168\n",
      "Batch: 296 , Combined Loss: tensor(0.7107, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9825824499130249\n",
      "Batch: 297 , Combined Loss: tensor(0.6509, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8510072231292725\n",
      "Batch: 298 , Combined Loss: tensor(0.6097, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9644649028778076\n",
      "Batch: 299 , Combined Loss: tensor(1.2340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6102622747421265\n",
      "Batch: 300 , Combined Loss: tensor(0.6690, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7784140110015869\n",
      "Batch: 301 , Combined Loss: tensor(0.6871, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5806471109390259\n",
      "Batch: 302 , Combined Loss: tensor(0.6367, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6476126909255981\n",
      "Batch: 303 , Combined Loss: tensor(0.7282, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9110347032546997\n",
      "Batch: 304 , Combined Loss: tensor(0.7686, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24638307094573975\n",
      "Batch: 305 , Combined Loss: tensor(0.7208, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6888216733932495\n",
      "Batch: 306 , Combined Loss: tensor(0.7112, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.000779151916504\n",
      "Batch: 307 , Combined Loss: tensor(0.7275, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0130202770233154\n",
      "Batch: 308 , Combined Loss: tensor(0.6900, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7221896648406982\n",
      "Batch: 309 , Combined Loss: tensor(0.7090, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1303949356079102\n",
      "Batch: 310 , Combined Loss: tensor(0.7242, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9695682525634766\n",
      "Batch: 311 , Combined Loss: tensor(0.6677, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39648306369781494\n",
      "Batch: 312 , Combined Loss: tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5918569564819336\n",
      "Batch: 313 , Combined Loss: tensor(0.7567, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5254292488098145\n",
      "Batch: 314 , Combined Loss: tensor(0.6497, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9665298461914062\n",
      "Batch: 315 , Combined Loss: tensor(0.8037, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6923040151596069\n",
      "Batch: 316 , Combined Loss: tensor(0.6165, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5358176231384277\n",
      "Batch: 317 , Combined Loss: tensor(0.7180, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1158726215362549\n",
      "Batch: 318 , Combined Loss: tensor(0.6764, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.932199239730835\n",
      "Batch: 319 , Combined Loss: tensor(0.7061, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7231868505477905\n",
      "Batch: 320 , Combined Loss: tensor(0.7417, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5316904783248901\n",
      "Batch: 321 , Combined Loss: tensor(0.9639, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6794586181640625\n",
      "Batch: 322 , Combined Loss: tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08980798721313477\n",
      "Batch: 323 , Combined Loss: tensor(0.8772, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7625160217285156\n",
      "Batch: 324 , Combined Loss: tensor(0.6670, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48405539989471436\n",
      "Batch: 325 , Combined Loss: tensor(0.7465, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7949717044830322\n",
      "Batch: 326 , Combined Loss: tensor(0.7052, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12680959701538086\n",
      "Batch: 327 , Combined Loss: tensor(0.6492, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8019856214523315\n",
      "Batch: 328 , Combined Loss: tensor(0.7399, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.796363353729248\n",
      "Batch: 329 , Combined Loss: tensor(0.7927, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8912301063537598\n",
      "Batch: 330 , Combined Loss: tensor(0.6878, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7321755886077881\n",
      "Batch: 331 , Combined Loss: tensor(0.6974, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1604795455932617\n",
      "Batch: 332 , Combined Loss: tensor(0.8253, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44148457050323486\n",
      "Batch: 333 , Combined Loss: tensor(0.7205, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1479690074920654\n",
      "Batch: 334 , Combined Loss: tensor(0.7172, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7949215173721313\n",
      "Batch: 335 , Combined Loss: tensor(0.8903, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6506468057632446\n",
      "Batch: 336 , Combined Loss: tensor(0.6705, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47196412086486816\n",
      "Batch: 337 , Combined Loss: tensor(0.7237, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.34261393547058105\n",
      "Batch: 338 , Combined Loss: tensor(0.6552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09647095203399658\n",
      "Batch: 339 , Combined Loss: tensor(0.7235, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.050187110900878906\n",
      "Batch: 340 , Combined Loss: tensor(0.7128, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6416085958480835\n",
      "Batch: 341 , Combined Loss: tensor(0.6880, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39001476764678955\n",
      "Batch: 342 , Combined Loss: tensor(0.7876, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4835057258605957\n",
      "Batch: 343 , Combined Loss: tensor(0.7108, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9783331155776978\n",
      "Batch: 344 , Combined Loss: tensor(0.8956, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9478863477706909\n",
      "Batch: 345 , Combined Loss: tensor(0.6434, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6829527616500854\n",
      "Batch: 346 , Combined Loss: tensor(0.8071, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12824445962905884\n",
      "Batch: 347 , Combined Loss: tensor(0.6964, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8538538217544556\n",
      "Batch: 348 , Combined Loss: tensor(0.7411, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14919447898864746\n",
      "Batch: 349 , Combined Loss: tensor(0.7671, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.554850697517395\n",
      "Batch: 350 , Combined Loss: tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7652977705001831\n",
      "Batch: 351 , Combined Loss: tensor(0.8274, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3335353136062622\n",
      "Batch: 352 , Combined Loss: tensor(0.6814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5829273462295532\n",
      "Batch: 353 , Combined Loss: tensor(0.6939, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7025341987609863\n",
      "Batch: 354 , Combined Loss: tensor(0.6680, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9752376079559326\n",
      "Batch: 355 , Combined Loss: tensor(0.7238, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6132206916809082\n",
      "Batch: 356 , Combined Loss: tensor(0.7412, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08913671970367432\n",
      "Batch: 357 , Combined Loss: tensor(0.8982, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.032257914543151855\n",
      "Batch: 358 , Combined Loss: tensor(0.7719, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5697966814041138\n",
      "Batch: 359 , Combined Loss: tensor(0.6877, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.834735631942749\n",
      "Batch: 360 , Combined Loss: tensor(0.6752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.26113802194595337\n",
      "Batch: 361 , Combined Loss: tensor(0.8846, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47442305088043213\n",
      "Batch: 362 , Combined Loss: tensor(0.7323, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.25499361753463745\n",
      "Batch: 363 , Combined Loss: tensor(0.8449, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4478175640106201\n",
      "Batch: 364 , Combined Loss: tensor(0.8548, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3906278610229492\n",
      "Batch: 365 , Combined Loss: tensor(0.8520, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6110327243804932\n",
      "Batch: 366 , Combined Loss: tensor(0.8918, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5966289043426514\n",
      "Batch: 367 , Combined Loss: tensor(0.9028, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4777182936668396\n",
      "Batch: 368 , Combined Loss: tensor(0.6963, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8358008861541748\n",
      "Batch: 369 , Combined Loss: tensor(0.7391, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43930041790008545\n",
      "Batch: 370 , Combined Loss: tensor(0.7806, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5863274335861206\n",
      "Batch: 371 , Combined Loss: tensor(0.7649, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.46791237592697144\n",
      "Batch: 372 , Combined Loss: tensor(0.8506, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5706756114959717\n",
      "Batch: 373 , Combined Loss: tensor(0.6957, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5064777135848999\n",
      "Batch: 374 , Combined Loss: tensor(0.9893, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3920125961303711\n",
      "Batch: 375 , Combined Loss: tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12019169330596924\n",
      "Batch: 376 , Combined Loss: tensor(0.7922, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14930272102355957\n",
      "Batch: 377 , Combined Loss: tensor(0.6712, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48008668422698975\n",
      "Batch: 378 , Combined Loss: tensor(0.6371, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0238571166992188\n",
      "Batch: 379 , Combined Loss: tensor(0.8389, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11854934692382812\n",
      "Batch: 380 , Combined Loss: tensor(0.6601, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2548331022262573\n",
      "Batch: 381 , Combined Loss: tensor(0.7113, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.40992438793182373\n",
      "Batch: 382 , Combined Loss: tensor(0.7200, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.840821385383606\n",
      "Batch: 383 , Combined Loss: tensor(0.8037, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6543471813201904\n",
      "Batch: 384 , Combined Loss: tensor(0.7002, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.842927098274231\n",
      "Batch: 385 , Combined Loss: tensor(0.7758, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20421981811523438\n",
      "Batch: 386 , Combined Loss: tensor(0.6788, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10617607831954956\n",
      "Batch: 387 , Combined Loss: tensor(0.8125, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.625975489616394\n",
      "Batch: 388 , Combined Loss: tensor(0.7429, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8962454795837402\n",
      "Batch: 389 , Combined Loss: tensor(0.7282, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.003042459487915\n",
      "Batch: 390 , Combined Loss: tensor(0.7014, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4600052833557129\n",
      "Batch: 391 , Combined Loss: tensor(0.7572, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6105910539627075\n",
      "Batch: 392 , Combined Loss: tensor(0.7510, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8689125776290894\n",
      "Batch: 393 , Combined Loss: tensor(0.7697, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5596722364425659\n",
      "Batch: 394 , Combined Loss: tensor(0.7495, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5148986577987671\n",
      "Batch: 395 , Combined Loss: tensor(0.8634, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5008955001831055\n",
      "Batch: 396 , Combined Loss: tensor(0.8196, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7806341648101807\n",
      "Batch: 397 , Combined Loss: tensor(0.6497, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14094692468643188\n",
      "Batch: 398 , Combined Loss: tensor(0.7715, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9460042715072632\n",
      "Batch: 399 , Combined Loss: tensor(0.7621, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7317918539047241\n",
      "Batch: 400 , Combined Loss: tensor(0.7620, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.278841495513916\n",
      "Batch: 401 , Combined Loss: tensor(0.7480, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4329008460044861\n",
      "Batch: 402 , Combined Loss: tensor(0.8483, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25852203369140625\n",
      "Batch: 403 , Combined Loss: tensor(0.6947, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9708846807479858\n",
      "Batch: 404 , Combined Loss: tensor(0.7337, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48625802993774414\n",
      "Batch: 405 , Combined Loss: tensor(0.6822, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7933565378189087\n",
      "Batch: 406 , Combined Loss: tensor(0.6990, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2447878122329712\n",
      "Batch: 407 , Combined Loss: tensor(0.7479, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42197883129119873\n",
      "Batch: 408 , Combined Loss: tensor(0.6648, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09821265935897827\n",
      "Batch: 409 , Combined Loss: tensor(0.6794, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9678083658218384\n",
      "Batch: 410 , Combined Loss: tensor(0.6725, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24797523021697998\n",
      "Batch: 411 , Combined Loss: tensor(0.7337, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6393266916275024\n",
      "Batch: 412 , Combined Loss: tensor(0.7353, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8028689622879028\n",
      "Batch: 413 , Combined Loss: tensor(0.6801, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6281144618988037\n",
      "Batch: 414 , Combined Loss: tensor(0.7188, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16165339946746826\n",
      "Batch: 415 , Combined Loss: tensor(0.6682, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13515877723693848\n",
      "Batch: 416 , Combined Loss: tensor(0.7449, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.009673118591308594\n",
      "Batch: 417 , Combined Loss: tensor(0.6855, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2377556562423706\n",
      "Batch: 418 , Combined Loss: tensor(0.6493, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.053578734397888184\n",
      "Batch: 419 , Combined Loss: tensor(0.9867, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8447526693344116\n",
      "Batch: 420 , Combined Loss: tensor(0.8112, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7873090505599976\n",
      "Batch: 421 , Combined Loss: tensor(0.6613, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0336675643920898\n",
      "Batch: 422 , Combined Loss: tensor(0.6800, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14318305253982544\n",
      "Batch: 423 , Combined Loss: tensor(0.6795, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9894022941589355\n",
      "Batch: 424 , Combined Loss: tensor(0.6384, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1820802092552185\n",
      "Batch: 425 , Combined Loss: tensor(0.6955, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1175272464752197\n",
      "Batch: 426 , Combined Loss: tensor(0.7406, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19928324222564697\n",
      "Batch: 427 , Combined Loss: tensor(0.6815, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15721505880355835\n",
      "Batch: 428 , Combined Loss: tensor(0.7708, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9478583335876465\n",
      "Batch: 429 , Combined Loss: tensor(0.6396, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5294476747512817\n",
      "Batch: 430 , Combined Loss: tensor(0.6359, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6391183137893677\n",
      "Batch: 431 , Combined Loss: tensor(0.6774, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5181986093521118\n",
      "Batch: 432 , Combined Loss: tensor(0.7604, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.02758347988128662\n",
      "Batch: 433 , Combined Loss: tensor(0.7443, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2272658348083496\n",
      "Batch: 434 , Combined Loss: tensor(0.6337, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.47750478982925415\n",
      "Batch: 435 , Combined Loss: tensor(0.6736, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9493207931518555\n",
      "Batch: 436 , Combined Loss: tensor(0.7435, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1469942331314087\n",
      "Batch: 437 , Combined Loss: tensor(0.6875, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9055241346359253\n",
      "Batch: 438 , Combined Loss: tensor(0.8798, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05768251419067383\n",
      "Batch: 439 , Combined Loss: tensor(0.6823, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.666332483291626\n",
      "Batch: 440 , Combined Loss: tensor(0.7939, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5894006490707397\n",
      "Batch: 441 , Combined Loss: tensor(0.7127, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22262394428253174\n",
      "Batch: 442 , Combined Loss: tensor(0.7528, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4402432441711426\n",
      "Batch: 443 , Combined Loss: tensor(0.7652, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0433118343353271\n",
      "Batch: 444 , Combined Loss: tensor(0.8212, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.011246085166931152\n",
      "Batch: 445 , Combined Loss: tensor(0.7524, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7557588815689087\n",
      "Batch: 446 , Combined Loss: tensor(0.6982, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3964895009994507\n",
      "Batch: 447 , Combined Loss: tensor(0.7448, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9951452016830444\n",
      "Batch: 448 , Combined Loss: tensor(0.6170, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8804351091384888\n",
      "Batch: 449 , Combined Loss: tensor(0.6620, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2850003242492676\n",
      "Batch: 450 , Combined Loss: tensor(0.6783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9005011320114136\n",
      "Batch: 451 , Combined Loss: tensor(0.7339, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.604871392250061\n",
      "Batch: 452 , Combined Loss: tensor(1.0521, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5873063802719116\n",
      "Batch: 453 , Combined Loss: tensor(0.8273, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5904414653778076\n",
      "Batch: 454 , Combined Loss: tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.013492166996002197\n",
      "Batch: 455 , Combined Loss: tensor(0.8650, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8558454513549805\n",
      "Batch: 456 , Combined Loss: tensor(0.6810, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8366445302963257\n",
      "Batch: 457 , Combined Loss: tensor(0.9203, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7051293849945068\n",
      "Batch: 458 , Combined Loss: tensor(0.7267, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9221881628036499\n",
      "Batch: 459 , Combined Loss: tensor(0.9225, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7687186002731323\n",
      "Batch: 460 , Combined Loss: tensor(0.8679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0670945644378662\n",
      "Batch: 461 , Combined Loss: tensor(0.6276, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5453382730484009\n",
      "Batch: 462 , Combined Loss: tensor(0.8037, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8555814027786255\n",
      "Batch: 463 , Combined Loss: tensor(0.6741, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14910662174224854\n",
      "Batch: 464 , Combined Loss: tensor(0.7008, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36615073680877686\n",
      "Batch: 465 , Combined Loss: tensor(0.6313, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6536749601364136\n",
      "Batch: 466 , Combined Loss: tensor(0.7622, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6550275087356567\n",
      "Batch: 467 , Combined Loss: tensor(0.8442, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.723239541053772\n",
      "Batch: 468 , Combined Loss: tensor(0.7219, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1390763521194458\n",
      "Batch: 469 , Combined Loss: tensor(0.6908, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9330214262008667\n",
      "Batch: 470 , Combined Loss: tensor(0.6547, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.137145757675171\n",
      "Batch: 471 , Combined Loss: tensor(0.6538, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0303263664245605\n",
      "Batch: 472 , Combined Loss: tensor(0.5889, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46477317810058594\n",
      "Batch: 473 , Combined Loss: tensor(0.6732, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46713435649871826\n",
      "Batch: 474 , Combined Loss: tensor(0.5508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14144766330718994\n",
      "Batch: 475 , Combined Loss: tensor(0.8018, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9254186153411865\n",
      "Batch: 476 , Combined Loss: tensor(0.7862, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7854875326156616\n",
      "Batch: 477 , Combined Loss: tensor(0.8468, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43175792694091797\n",
      "Batch: 478 , Combined Loss: tensor(0.7967, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5130249261856079\n",
      "Batch: 479 , Combined Loss: tensor(0.6556, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30214929580688477\n",
      "Batch: 480 , Combined Loss: tensor(1.2186, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6709492206573486\n",
      "Batch: 481 , Combined Loss: tensor(0.7345, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0284008979797363\n",
      "Batch: 482 , Combined Loss: tensor(0.6782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.815733790397644\n",
      "Batch: 483 , Combined Loss: tensor(0.7207, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7953530550003052\n",
      "Batch: 484 , Combined Loss: tensor(0.6437, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11337542533874512\n",
      "Batch: 485 , Combined Loss: tensor(0.6046, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.18394583463668823\n",
      "Batch: 486 , Combined Loss: tensor(0.8427, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.974709153175354\n",
      "Batch: 487 , Combined Loss: tensor(0.7711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.837051510810852\n",
      "Batch: 488 , Combined Loss: tensor(0.8641, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7153856754302979\n",
      "Batch: 489 , Combined Loss: tensor(0.8890, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4880162477493286\n",
      "Batch: 490 , Combined Loss: tensor(0.7752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.18681764602661133\n",
      "Batch: 491 , Combined Loss: tensor(0.6858, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1137874126434326\n",
      "Batch: 492 , Combined Loss: tensor(0.7666, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.816131591796875\n",
      "Batch: 493 , Combined Loss: tensor(0.6421, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7499654293060303\n",
      "Batch: 494 , Combined Loss: tensor(1.0441, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9178482294082642\n",
      "Batch: 495 , Combined Loss: tensor(1.0157, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.008518397808074951\n",
      "Batch: 496 , Combined Loss: tensor(0.8825, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33742475509643555\n",
      "Batch: 497 , Combined Loss: tensor(0.6982, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10779738426208496\n",
      "Batch: 498 , Combined Loss: tensor(0.6398, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9353998899459839\n",
      "Batch: 499 , Combined Loss: tensor(0.7770, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.540736198425293\n",
      "Batch: 500 , Combined Loss: tensor(0.9760, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06006664037704468\n",
      "Batch: 501 , Combined Loss: tensor(0.7086, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1283254623413086\n",
      "Batch: 502 , Combined Loss: tensor(0.6523, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9761888980865479\n",
      "Batch: 503 , Combined Loss: tensor(0.8937, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28605151176452637\n",
      "Batch: 504 , Combined Loss: tensor(0.7464, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.858841061592102\n",
      "Batch: 505 , Combined Loss: tensor(0.8635, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2519923448562622\n",
      "Batch: 506 , Combined Loss: tensor(0.7246, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9100538492202759\n",
      "Batch: 507 , Combined Loss: tensor(0.7847, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0414786338806152\n",
      "Batch: 508 , Combined Loss: tensor(0.7054, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0136687755584717\n",
      "Batch: 509 , Combined Loss: tensor(0.5869, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5931248664855957\n",
      "Batch: 510 , Combined Loss: tensor(0.6255, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7398003339767456\n",
      "Batch: 511 , Combined Loss: tensor(0.8794, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6079550981521606\n",
      "Batch: 512 , Combined Loss: tensor(0.8035, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44866466522216797\n",
      "Batch: 513 , Combined Loss: tensor(0.6722, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.584522008895874\n",
      "Batch: 514 , Combined Loss: tensor(0.7053, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9086060523986816\n",
      "Batch: 515 , Combined Loss: tensor(0.7248, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.701521635055542\n",
      "Batch: 516 , Combined Loss: tensor(0.7290, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5725973844528198\n",
      "Batch: 517 , Combined Loss: tensor(0.8367, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.280531406402588\n",
      "Batch: 518 , Combined Loss: tensor(0.7647, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6011369228363037\n",
      "Batch: 519 , Combined Loss: tensor(1.2016, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04130053520202637\n",
      "Batch: 520 , Combined Loss: tensor(0.7421, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7635351419448853\n",
      "Batch: 521 , Combined Loss: tensor(0.7120, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2996909022331238\n",
      "Batch: 522 , Combined Loss: tensor(0.6298, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07905685901641846\n",
      "Batch: 523 , Combined Loss: tensor(0.7324, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18006539344787598\n",
      "Batch: 524 , Combined Loss: tensor(0.8527, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1345584392547607\n",
      "Batch: 525 , Combined Loss: tensor(0.6543, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5907902717590332\n",
      "Batch: 526 , Combined Loss: tensor(0.7948, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8738688230514526\n",
      "Batch: 527 , Combined Loss: tensor(0.7445, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8170380592346191\n",
      "Batch: 528 , Combined Loss: tensor(0.7850, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12904322147369385\n",
      "Batch: 529 , Combined Loss: tensor(0.6468, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5376331806182861\n",
      "Batch: 530 , Combined Loss: tensor(0.6312, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35218870639801025\n",
      "Batch: 531 , Combined Loss: tensor(0.6563, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33759891986846924\n",
      "Batch: 532 , Combined Loss: tensor(0.7283, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12430822849273682\n",
      "Batch: 533 , Combined Loss: tensor(0.7463, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19752246141433716\n",
      "Batch: 534 , Combined Loss: tensor(0.7714, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5863860845565796\n",
      "Batch: 535 , Combined Loss: tensor(0.6431, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8155115842819214\n",
      "Batch: 536 , Combined Loss: tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7211779356002808\n",
      "Batch: 537 , Combined Loss: tensor(0.7661, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5858285427093506\n",
      "Batch: 538 , Combined Loss: tensor(0.6901, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3723026514053345\n",
      "Batch: 539 , Combined Loss: tensor(0.6794, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6537355184555054\n",
      "Batch: 540 , Combined Loss: tensor(0.7007, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6058764457702637\n",
      "Batch: 541 , Combined Loss: tensor(0.7293, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8470897674560547\n",
      "Batch: 542 , Combined Loss: tensor(0.7361, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5877991914749146\n",
      "Batch: 543 , Combined Loss: tensor(0.6964, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.25255095958709717\n",
      "Batch: 544 , Combined Loss: tensor(0.6851, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6522312164306641\n",
      "Batch: 545 , Combined Loss: tensor(0.7985, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6072360277175903\n",
      "Batch: 546 , Combined Loss: tensor(0.6691, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11512947082519531\n",
      "Batch: 547 , Combined Loss: tensor(0.7490, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35147523880004883\n",
      "Batch: 548 , Combined Loss: tensor(0.6991, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2471768856048584\n",
      "Batch: 549 , Combined Loss: tensor(0.7051, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.40414077043533325\n",
      "Batch: 550 , Combined Loss: tensor(0.7242, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0670342445373535\n",
      "Batch: 551 , Combined Loss: tensor(0.7811, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5665674209594727\n",
      "Batch: 552 , Combined Loss: tensor(0.8785, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8632655143737793\n",
      "Batch: 553 , Combined Loss: tensor(0.7518, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1009988784790039\n",
      "Batch: 554 , Combined Loss: tensor(0.8208, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5784471035003662\n",
      "Batch: 555 , Combined Loss: tensor(0.6773, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7683056592941284\n",
      "Batch: 556 , Combined Loss: tensor(0.6858, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7280735969543457\n",
      "Batch: 557 , Combined Loss: tensor(0.7972, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2792978286743164\n",
      "Batch: 558 , Combined Loss: tensor(0.8643, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13012325763702393\n",
      "Batch: 559 , Combined Loss: tensor(0.7250, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5553075671195984\n",
      "Batch: 560 , Combined Loss: tensor(0.6597, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.546695351600647\n",
      "Batch: 561 , Combined Loss: tensor(0.6767, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24890166521072388\n",
      "Batch: 562 , Combined Loss: tensor(0.7804, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7457431554794312\n",
      "Batch: 563 , Combined Loss: tensor(0.7591, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3342247009277344\n",
      "Batch: 564 , Combined Loss: tensor(0.6568, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12451624870300293\n",
      "Batch: 565 , Combined Loss: tensor(0.6712, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5520267486572266\n",
      "Batch: 566 , Combined Loss: tensor(0.6821, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4670875072479248\n",
      "Batch: 567 , Combined Loss: tensor(0.7099, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2163219451904297\n",
      "Batch: 568 , Combined Loss: tensor(0.6794, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08761441707611084\n",
      "Batch: 569 , Combined Loss: tensor(0.8311, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4800907373428345\n",
      "Batch: 570 , Combined Loss: tensor(0.7690, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5702457427978516\n",
      "Batch: 571 , Combined Loss: tensor(0.7433, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8828905820846558\n",
      "Batch: 572 , Combined Loss: tensor(0.7599, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5490982532501221\n",
      "Batch: 573 , Combined Loss: tensor(0.7024, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6381909847259521\n",
      "Batch: 574 , Combined Loss: tensor(0.7131, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07275474071502686\n",
      "Batch: 575 , Combined Loss: tensor(0.7482, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6720905303955078\n",
      "Batch: 576 , Combined Loss: tensor(0.6809, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9904638528823853\n",
      "Batch: 577 , Combined Loss: tensor(0.7448, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24367618560791016\n",
      "Batch: 578 , Combined Loss: tensor(0.8027, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7471957206726074\n",
      "Batch: 579 , Combined Loss: tensor(0.7930, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8773238658905029\n",
      "Batch: 580 , Combined Loss: tensor(0.9290, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.048353672027588\n",
      "Batch: 581 , Combined Loss: tensor(0.6745, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8763998746871948\n",
      "Batch: 582 , Combined Loss: tensor(0.7106, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44649481773376465\n",
      "Batch: 583 , Combined Loss: tensor(0.6437, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.852148175239563\n",
      "Batch: 584 , Combined Loss: tensor(0.6941, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7314578294754028\n",
      "Batch: 585 , Combined Loss: tensor(0.6135, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5418106317520142\n",
      "Batch: 586 , Combined Loss: tensor(0.7585, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.881424069404602\n",
      "Batch: 587 , Combined Loss: tensor(0.6066, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35416269302368164\n",
      "Batch: 588 , Combined Loss: tensor(0.6370, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8047462701797485\n",
      "Batch: 589 , Combined Loss: tensor(0.7013, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9691765308380127\n",
      "Batch: 590 , Combined Loss: tensor(0.7544, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7934677600860596\n",
      "Batch: 591 , Combined Loss: tensor(0.9120, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0361255407333374\n",
      "Batch: 592 , Combined Loss: tensor(0.8069, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45534443855285645\n",
      "Batch: 593 , Combined Loss: tensor(0.6573, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8995267152786255\n",
      "Batch: 594 , Combined Loss: tensor(0.6325, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47865521907806396\n",
      "Batch: 595 , Combined Loss: tensor(0.7864, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08038413524627686\n",
      "Batch: 596 , Combined Loss: tensor(0.6692, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9078483581542969\n",
      "Batch: 597 , Combined Loss: tensor(0.6378, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8242971897125244\n",
      "Batch: 598 , Combined Loss: tensor(0.6783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8525632619857788\n",
      "Batch: 599 , Combined Loss: tensor(0.7261, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4680863618850708\n",
      "Batch: 600 , Combined Loss: tensor(0.6208, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8012874126434326\n",
      "Batch: 601 , Combined Loss: tensor(0.6560, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5092613697052002\n",
      "Batch: 602 , Combined Loss: tensor(0.7491, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8896009922027588\n",
      "Batch: 603 , Combined Loss: tensor(0.6812, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9006626605987549\n",
      "Batch: 604 , Combined Loss: tensor(0.7268, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3890465497970581\n",
      "Batch: 605 , Combined Loss: tensor(0.7291, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2948194742202759\n",
      "Batch: 606 , Combined Loss: tensor(0.7651, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5608096122741699\n",
      "Batch: 607 , Combined Loss: tensor(0.6943, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6695561408996582\n",
      "Batch: 608 , Combined Loss: tensor(0.7301, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7514925003051758\n",
      "Batch: 609 , Combined Loss: tensor(0.8695, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0606253147125244\n",
      "Batch: 610 , Combined Loss: tensor(0.7417, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.510263204574585\n",
      "Batch: 611 , Combined Loss: tensor(0.7824, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1302812099456787\n",
      "Batch: 612 , Combined Loss: tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7058604955673218\n",
      "Batch: 613 , Combined Loss: tensor(0.6682, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22992873191833496\n",
      "Batch: 614 , Combined Loss: tensor(0.7611, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7053108215332031\n",
      "Batch: 615 , Combined Loss: tensor(0.6848, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5135220289230347\n",
      "Batch: 616 , Combined Loss: tensor(0.6522, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5590373277664185\n",
      "Batch: 617 , Combined Loss: tensor(0.6872, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.695443868637085\n",
      "Batch: 618 , Combined Loss: tensor(0.7639, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0465912818908691\n",
      "Batch: 619 , Combined Loss: tensor(0.9018, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19215059280395508\n",
      "Batch: 620 , Combined Loss: tensor(0.7017, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4503648281097412\n",
      "Batch: 621 , Combined Loss: tensor(0.6009, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.863772988319397\n",
      "Batch: 622 , Combined Loss: tensor(0.6630, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08387863636016846\n",
      "Batch: 623 , Combined Loss: tensor(0.7016, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45965349674224854\n",
      "Batch: 624 , Combined Loss: tensor(0.6932, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.033488690853118896\n",
      "Batch: 625 , Combined Loss: tensor(0.6171, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7672502994537354\n",
      "Batch: 626 , Combined Loss: tensor(0.6752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.087756872177124\n",
      "Batch: 627 , Combined Loss: tensor(0.7380, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.134726881980896\n",
      "Batch: 628 , Combined Loss: tensor(0.8259, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7142777442932129\n",
      "----------Epoch 12, Loss: 0.7462416493077726, Accuracy: 0.9546750111117461, Dice Coef: [0.9790796140040048, 0.4885703821510872, 0.5421772012923861, 0.6121220083913599], Dice Coef Necrotic: 0.9366931453421836, Dice Coef Edema: 0.936330751724207, Dice Coef Enhancing: 0.9121872868149962, Sensitivity: [0.9611043139747292, 0.6900815577242547, 0.8260861487854835, 0.862148988370107], Specificity: [0.966460383326905, 0.9958709463216542, 0.9680253243597967, 0.9916721523660924], Precision: [0.997963109816201, 0.46179764041581245, 0.43542395444773435, 0.5232552331302238]\n",
      "Saving without nn.DataParallel\n",
      "Batch: 0 , Combined Loss: tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7764194011688232\n",
      "Batch: 1 , Combined Loss: tensor(0.7433, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0427136421203613\n",
      "Batch: 2 , Combined Loss: tensor(0.6160, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6740961074829102\n",
      "Batch: 3 , Combined Loss: tensor(0.8518, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0022641420364379883\n",
      "Batch: 4 , Combined Loss: tensor(0.9205, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44363439083099365\n",
      "Batch: 5 , Combined Loss: tensor(0.9406, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5510045289993286\n",
      "Batch: 6 , Combined Loss: tensor(0.7358, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5404143333435059\n",
      "Batch: 7 , Combined Loss: tensor(0.6677, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5485085248947144\n",
      "Batch: 8 , Combined Loss: tensor(0.7692, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8702597618103027\n",
      "Batch: 9 , Combined Loss: tensor(0.7296, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2578613758087158\n",
      "Batch: 10 , Combined Loss: tensor(0.7536, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6297619342803955\n",
      "Batch: 11 , Combined Loss: tensor(0.7216, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6109673976898193\n",
      "Batch: 12 , Combined Loss: tensor(0.8204, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8231767416000366\n",
      "Batch: 13 , Combined Loss: tensor(0.7669, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7227567434310913\n",
      "Batch: 14 , Combined Loss: tensor(0.6984, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8657369613647461\n",
      "Batch: 15 , Combined Loss: tensor(0.6201, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1743837594985962\n",
      "Batch: 16 , Combined Loss: tensor(0.6013, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08392888307571411\n",
      "Batch: 17 , Combined Loss: tensor(0.7192, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8202434778213501\n",
      "Batch: 18 , Combined Loss: tensor(0.7567, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5912514925003052\n",
      "Batch: 19 , Combined Loss: tensor(0.9475, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4653329849243164\n",
      "Batch: 20 , Combined Loss: tensor(0.7260, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9848242998123169\n",
      "Batch: 21 , Combined Loss: tensor(0.7798, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9301691055297852\n",
      "Batch: 22 , Combined Loss: tensor(0.8181, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8027346134185791\n",
      "Batch: 23 , Combined Loss: tensor(0.7304, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10325026512145996\n",
      "Batch: 24 , Combined Loss: tensor(0.8148, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.789444088935852\n",
      "Batch: 25 , Combined Loss: tensor(0.6371, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7196916341781616\n",
      "Batch: 26 , Combined Loss: tensor(0.8842, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.30125004053115845\n",
      "Batch: 27 , Combined Loss: tensor(0.7180, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7424429655075073\n",
      "Batch: 28 , Combined Loss: tensor(0.7112, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12568128108978271\n",
      "Batch: 29 , Combined Loss: tensor(0.7359, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3610008955001831\n",
      "Batch: 30 , Combined Loss: tensor(0.9767, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5493847131729126\n",
      "Batch: 31 , Combined Loss: tensor(0.6822, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9752990007400513\n",
      "Batch: 32 , Combined Loss: tensor(0.8101, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.010187327861785889\n",
      "Batch: 33 , Combined Loss: tensor(0.7535, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4666558504104614\n",
      "Batch: 34 , Combined Loss: tensor(0.6946, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9985891580581665\n",
      "Batch: 35 , Combined Loss: tensor(0.7004, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2346118688583374\n",
      "Batch: 36 , Combined Loss: tensor(0.7099, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.45635974407196045\n",
      "Batch: 37 , Combined Loss: tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8036664724349976\n",
      "Batch: 38 , Combined Loss: tensor(0.7432, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3285001516342163\n",
      "Batch: 39 , Combined Loss: tensor(0.7783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7323682308197021\n",
      "Batch: 40 , Combined Loss: tensor(0.7229, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.45725393295288086\n",
      "Batch: 41 , Combined Loss: tensor(0.7083, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32602012157440186\n",
      "Batch: 42 , Combined Loss: tensor(0.7331, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2875248193740845\n",
      "Batch: 43 , Combined Loss: tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.43789142370224\n",
      "Batch: 44 , Combined Loss: tensor(0.6986, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6736776828765869\n",
      "Batch: 45 , Combined Loss: tensor(0.7433, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.477681040763855\n",
      "Batch: 46 , Combined Loss: tensor(0.7170, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8249194622039795\n",
      "Batch: 47 , Combined Loss: tensor(0.6858, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46402060985565186\n",
      "Batch: 48 , Combined Loss: tensor(0.8051, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1343877911567688\n",
      "Batch: 49 , Combined Loss: tensor(0.8466, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.27716994285583496\n",
      "Batch: 50 , Combined Loss: tensor(0.6994, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7780454158782959\n",
      "Batch: 51 , Combined Loss: tensor(0.8209, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4701263904571533\n",
      "Batch: 52 , Combined Loss: tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4428609609603882\n",
      "Batch: 53 , Combined Loss: tensor(0.6887, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.658553957939148\n",
      "Batch: 54 , Combined Loss: tensor(0.8492, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8352854251861572\n",
      "Batch: 55 , Combined Loss: tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6500812768936157\n",
      "Batch: 56 , Combined Loss: tensor(0.6856, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30069613456726074\n",
      "Batch: 57 , Combined Loss: tensor(0.6583, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8484249114990234\n",
      "Batch: 58 , Combined Loss: tensor(0.7307, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6024441719055176\n",
      "Batch: 59 , Combined Loss: tensor(0.7942, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3630506992340088\n",
      "Batch: 60 , Combined Loss: tensor(0.7188, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8026025295257568\n",
      "Batch: 61 , Combined Loss: tensor(0.6312, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21579337120056152\n",
      "Batch: 62 , Combined Loss: tensor(0.6949, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28118324279785156\n",
      "Batch: 63 , Combined Loss: tensor(0.7727, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39150571823120117\n",
      "Batch: 64 , Combined Loss: tensor(0.8009, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17717456817626953\n",
      "Batch: 65 , Combined Loss: tensor(0.7185, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9142743349075317\n",
      "Batch: 66 , Combined Loss: tensor(0.7353, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.28108227252960205\n",
      "Batch: 67 , Combined Loss: tensor(0.7528, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8433490991592407\n",
      "Batch: 68 , Combined Loss: tensor(0.7997, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.46432244777679443\n",
      "Batch: 69 , Combined Loss: tensor(0.6815, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40533626079559326\n",
      "Batch: 70 , Combined Loss: tensor(0.7194, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39334332942962646\n",
      "Batch: 71 , Combined Loss: tensor(0.6262, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6102249622344971\n",
      "Batch: 72 , Combined Loss: tensor(0.6678, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6929675340652466\n",
      "Batch: 73 , Combined Loss: tensor(0.8590, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04156053066253662\n",
      "Batch: 74 , Combined Loss: tensor(0.6757, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6519341468811035\n",
      "Batch: 75 , Combined Loss: tensor(0.6767, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.743986964225769\n",
      "Batch: 76 , Combined Loss: tensor(0.6843, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12328708171844482\n",
      "Batch: 77 , Combined Loss: tensor(0.7288, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5673102140426636\n",
      "Batch: 78 , Combined Loss: tensor(0.8347, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2833210229873657\n",
      "Batch: 79 , Combined Loss: tensor(0.8894, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2133517861366272\n",
      "Batch: 80 , Combined Loss: tensor(0.8659, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6012065410614014\n",
      "Batch: 81 , Combined Loss: tensor(0.7207, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7306580543518066\n",
      "Batch: 82 , Combined Loss: tensor(0.7561, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7369507551193237\n",
      "Batch: 83 , Combined Loss: tensor(0.6574, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.192378044128418\n",
      "Batch: 84 , Combined Loss: tensor(0.7787, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2687661647796631\n",
      "Batch: 85 , Combined Loss: tensor(0.7813, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2570892572402954\n",
      "Batch: 86 , Combined Loss: tensor(0.6910, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.941491961479187\n",
      "Batch: 87 , Combined Loss: tensor(0.6525, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42860162258148193\n",
      "Batch: 88 , Combined Loss: tensor(0.7050, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3766496181488037\n",
      "Batch: 89 , Combined Loss: tensor(0.7257, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9664976596832275\n",
      "Batch: 90 , Combined Loss: tensor(0.7779, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9657847881317139\n",
      "Batch: 91 , Combined Loss: tensor(0.7428, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33063650131225586\n",
      "Batch: 92 , Combined Loss: tensor(0.6900, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5053350925445557\n",
      "Batch: 93 , Combined Loss: tensor(0.7251, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7879657745361328\n",
      "Batch: 94 , Combined Loss: tensor(0.6815, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8526787757873535\n",
      "Batch: 95 , Combined Loss: tensor(0.6296, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1900855302810669\n",
      "Batch: 96 , Combined Loss: tensor(0.7941, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9503916501998901\n",
      "Batch: 97 , Combined Loss: tensor(0.8817, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.519200325012207\n",
      "Batch: 98 , Combined Loss: tensor(0.7574, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15518105030059814\n",
      "Batch: 99 , Combined Loss: tensor(0.6610, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8844045400619507\n",
      "Batch: 100 , Combined Loss: tensor(0.7362, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7417758703231812\n",
      "Batch: 101 , Combined Loss: tensor(0.7109, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.025486946105957\n",
      "Batch: 102 , Combined Loss: tensor(0.8898, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4779188632965088\n",
      "Batch: 103 , Combined Loss: tensor(0.7917, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32477402687072754\n",
      "Batch: 104 , Combined Loss: tensor(0.6145, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46959757804870605\n",
      "Batch: 105 , Combined Loss: tensor(0.7901, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6703240871429443\n",
      "Batch: 106 , Combined Loss: tensor(0.6878, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6133790016174316\n",
      "Batch: 107 , Combined Loss: tensor(0.7015, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2578215599060059\n",
      "Batch: 108 , Combined Loss: tensor(0.6736, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16726815700531006\n",
      "Batch: 109 , Combined Loss: tensor(0.6091, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3941323757171631\n",
      "Batch: 110 , Combined Loss: tensor(0.8321, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4969308376312256\n",
      "Batch: 111 , Combined Loss: tensor(0.6756, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.089615821838379\n",
      "Batch: 112 , Combined Loss: tensor(0.7415, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6861273050308228\n",
      "Batch: 113 , Combined Loss: tensor(0.8374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6236844062805176\n",
      "Batch: 114 , Combined Loss: tensor(0.7467, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6934168338775635\n",
      "Batch: 115 , Combined Loss: tensor(0.6918, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6192877292633057\n",
      "Batch: 116 , Combined Loss: tensor(0.8169, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8614515066146851\n",
      "Batch: 117 , Combined Loss: tensor(0.6666, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08593666553497314\n",
      "Batch: 118 , Combined Loss: tensor(0.7411, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23736357688903809\n",
      "Batch: 119 , Combined Loss: tensor(0.8208, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7940069437026978\n",
      "Batch: 120 , Combined Loss: tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7030963897705078\n",
      "Batch: 121 , Combined Loss: tensor(0.7365, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8520747423171997\n",
      "Batch: 122 , Combined Loss: tensor(0.6505, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3550668954849243\n",
      "Batch: 123 , Combined Loss: tensor(0.6862, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1631411910057068\n",
      "Batch: 124 , Combined Loss: tensor(0.7307, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8041433095932007\n",
      "Batch: 125 , Combined Loss: tensor(0.8253, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9284850358963013\n",
      "Batch: 126 , Combined Loss: tensor(0.6228, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9441347122192383\n",
      "Batch: 127 , Combined Loss: tensor(0.8211, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5331504344940186\n",
      "Batch: 128 , Combined Loss: tensor(0.6440, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7745085954666138\n",
      "Batch: 129 , Combined Loss: tensor(0.6317, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.333756685256958\n",
      "Batch: 130 , Combined Loss: tensor(0.7559, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07686001062393188\n",
      "Batch: 131 , Combined Loss: tensor(0.6866, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09168094396591187\n",
      "Batch: 132 , Combined Loss: tensor(0.5841, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5086052417755127\n",
      "Batch: 133 , Combined Loss: tensor(0.7088, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.00012862682342529297\n",
      "Batch: 134 , Combined Loss: tensor(0.6477, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5556046962738037\n",
      "Batch: 135 , Combined Loss: tensor(0.7911, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2191523313522339\n",
      "Batch: 136 , Combined Loss: tensor(0.7956, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3193953037261963\n",
      "Batch: 137 , Combined Loss: tensor(0.7080, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3792020082473755\n",
      "Batch: 138 , Combined Loss: tensor(0.7410, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4236641526222229\n",
      "Batch: 139 , Combined Loss: tensor(0.6487, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44845497608184814\n",
      "Batch: 140 , Combined Loss: tensor(0.6799, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7012003660202026\n",
      "Batch: 141 , Combined Loss: tensor(0.7220, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17509251832962036\n",
      "Batch: 142 , Combined Loss: tensor(0.6347, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46615612506866455\n",
      "Batch: 143 , Combined Loss: tensor(0.8745, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6454319953918457\n",
      "Batch: 144 , Combined Loss: tensor(0.7542, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15055608749389648\n",
      "Batch: 145 , Combined Loss: tensor(0.9470, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6753606796264648\n",
      "Batch: 146 , Combined Loss: tensor(0.6593, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7169287204742432\n",
      "Batch: 147 , Combined Loss: tensor(0.6722, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7251505851745605\n",
      "Batch: 148 , Combined Loss: tensor(0.8407, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3712003231048584\n",
      "Batch: 149 , Combined Loss: tensor(0.9751, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5348410606384277\n",
      "Batch: 150 , Combined Loss: tensor(0.6983, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8337429761886597\n",
      "Batch: 151 , Combined Loss: tensor(0.7322, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8625165224075317\n",
      "Batch: 152 , Combined Loss: tensor(0.6081, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.815859317779541\n",
      "Batch: 153 , Combined Loss: tensor(0.6433, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9859904050827026\n",
      "Batch: 154 , Combined Loss: tensor(0.8482, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1935635805130005\n",
      "Batch: 155 , Combined Loss: tensor(0.8867, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0307388305664062\n",
      "Batch: 156 , Combined Loss: tensor(0.7661, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6726640462875366\n",
      "Batch: 157 , Combined Loss: tensor(0.8424, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6219854354858398\n",
      "Batch: 158 , Combined Loss: tensor(0.7256, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8844696283340454\n",
      "Batch: 159 , Combined Loss: tensor(0.7932, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3968604803085327\n",
      "Batch: 160 , Combined Loss: tensor(0.7905, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36298108100891113\n",
      "Batch: 161 , Combined Loss: tensor(0.6885, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.016485154628753662\n",
      "Batch: 162 , Combined Loss: tensor(0.7776, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8099104166030884\n",
      "Batch: 163 , Combined Loss: tensor(0.6286, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6270824670791626\n",
      "Batch: 164 , Combined Loss: tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38781237602233887\n",
      "Batch: 165 , Combined Loss: tensor(1.1109, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5180941820144653\n",
      "Batch: 166 , Combined Loss: tensor(0.6146, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5700923204421997\n",
      "Batch: 167 , Combined Loss: tensor(0.6817, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4336991310119629\n",
      "Batch: 168 , Combined Loss: tensor(0.7606, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0061018466949463\n",
      "Batch: 169 , Combined Loss: tensor(0.6073, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7339950799942017\n",
      "Batch: 170 , Combined Loss: tensor(0.8155, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13579106330871582\n",
      "Batch: 171 , Combined Loss: tensor(0.6713, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8670976161956787\n",
      "Batch: 172 , Combined Loss: tensor(0.6927, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19269943237304688\n",
      "Batch: 173 , Combined Loss: tensor(0.6452, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6935211420059204\n",
      "Batch: 174 , Combined Loss: tensor(0.7778, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6924248933792114\n",
      "Batch: 175 , Combined Loss: tensor(0.9766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05780893564224243\n",
      "Batch: 176 , Combined Loss: tensor(0.7259, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.01652359962463379\n",
      "Batch: 177 , Combined Loss: tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6075237989425659\n",
      "Batch: 178 , Combined Loss: tensor(0.7206, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31747376918792725\n",
      "Batch: 179 , Combined Loss: tensor(0.7654, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.794853687286377\n",
      "Batch: 180 , Combined Loss: tensor(0.6359, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6040672063827515\n",
      "Batch: 181 , Combined Loss: tensor(0.7087, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5215233564376831\n",
      "Batch: 182 , Combined Loss: tensor(0.8244, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4512723684310913\n",
      "Batch: 183 , Combined Loss: tensor(0.8678, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.327539324760437\n",
      "Batch: 184 , Combined Loss: tensor(0.8427, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4994117021560669\n",
      "Batch: 185 , Combined Loss: tensor(0.8075, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7171974182128906\n",
      "Batch: 186 , Combined Loss: tensor(0.7677, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5125261545181274\n",
      "Batch: 187 , Combined Loss: tensor(0.6957, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.821431040763855\n",
      "Batch: 188 , Combined Loss: tensor(0.8572, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4466606378555298\n",
      "Batch: 189 , Combined Loss: tensor(0.6992, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.953208327293396\n",
      "Batch: 190 , Combined Loss: tensor(0.8121, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6297694444656372\n",
      "Batch: 191 , Combined Loss: tensor(0.6916, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6008002758026123\n",
      "Batch: 192 , Combined Loss: tensor(0.7744, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5426698923110962\n",
      "Batch: 193 , Combined Loss: tensor(0.7806, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4809424877166748\n",
      "Batch: 194 , Combined Loss: tensor(0.9882, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34740757942199707\n",
      "Batch: 195 , Combined Loss: tensor(0.7191, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8838709592819214\n",
      "Batch: 196 , Combined Loss: tensor(0.7346, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2940561771392822\n",
      "Batch: 197 , Combined Loss: tensor(0.6769, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3636760711669922\n",
      "Batch: 198 , Combined Loss: tensor(0.6953, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7787151336669922\n",
      "Batch: 199 , Combined Loss: tensor(0.9620, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3100193738937378\n",
      "Batch: 200 , Combined Loss: tensor(0.7053, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6511998176574707\n",
      "Batch: 201 , Combined Loss: tensor(0.7504, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.41520196199417114\n",
      "Batch: 202 , Combined Loss: tensor(0.7062, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.288830041885376\n",
      "Batch: 203 , Combined Loss: tensor(0.6558, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39916419982910156\n",
      "Batch: 204 , Combined Loss: tensor(0.6825, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07254636287689209\n",
      "Batch: 205 , Combined Loss: tensor(0.7284, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.020864248275756836\n",
      "Batch: 206 , Combined Loss: tensor(0.7043, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.631413459777832\n",
      "Batch: 207 , Combined Loss: tensor(0.7126, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3799874186515808\n",
      "Batch: 208 , Combined Loss: tensor(0.7461, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06991136074066162\n",
      "Batch: 209 , Combined Loss: tensor(0.6988, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4514586329460144\n",
      "Batch: 210 , Combined Loss: tensor(0.9070, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5835636854171753\n",
      "Batch: 211 , Combined Loss: tensor(0.7382, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1749567985534668\n",
      "Batch: 212 , Combined Loss: tensor(0.6908, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9662265777587891\n",
      "Batch: 213 , Combined Loss: tensor(0.6595, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21148931980133057\n",
      "Batch: 214 , Combined Loss: tensor(0.7241, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7560362815856934\n",
      "Batch: 215 , Combined Loss: tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.832457423210144\n",
      "Batch: 216 , Combined Loss: tensor(0.6748, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1684245467185974\n",
      "Batch: 217 , Combined Loss: tensor(0.7312, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12737518548965454\n",
      "Batch: 218 , Combined Loss: tensor(0.8005, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3365737199783325\n",
      "Batch: 219 , Combined Loss: tensor(0.7301, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8933089971542358\n",
      "Batch: 220 , Combined Loss: tensor(0.6887, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.30984002351760864\n",
      "Batch: 221 , Combined Loss: tensor(0.7911, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7709680795669556\n",
      "Batch: 222 , Combined Loss: tensor(0.6342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.13060355186462402\n",
      "Batch: 223 , Combined Loss: tensor(0.7246, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5548437833786011\n",
      "Batch: 224 , Combined Loss: tensor(0.7391, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6368964910507202\n",
      "Batch: 225 , Combined Loss: tensor(0.7002, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6958163976669312\n",
      "Batch: 226 , Combined Loss: tensor(0.6791, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7503948211669922\n",
      "Batch: 227 , Combined Loss: tensor(0.7354, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4491908550262451\n",
      "Batch: 228 , Combined Loss: tensor(0.6765, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0407655239105225\n",
      "Batch: 229 , Combined Loss: tensor(0.8014, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7272889614105225\n",
      "Batch: 230 , Combined Loss: tensor(0.7437, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3318737745285034\n",
      "Batch: 231 , Combined Loss: tensor(0.6921, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6476540565490723\n",
      "Batch: 232 , Combined Loss: tensor(0.7192, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7958900928497314\n",
      "Batch: 233 , Combined Loss: tensor(0.8648, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18600332736968994\n",
      "Batch: 234 , Combined Loss: tensor(0.9209, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34451961517333984\n",
      "Batch: 235 , Combined Loss: tensor(0.8005, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17646455764770508\n",
      "Batch: 236 , Combined Loss: tensor(0.6675, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5939273834228516\n",
      "Batch: 237 , Combined Loss: tensor(0.6835, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41105735301971436\n",
      "Batch: 238 , Combined Loss: tensor(0.9696, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24354714155197144\n",
      "Batch: 239 , Combined Loss: tensor(0.7111, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.026811122894287\n",
      "Batch: 240 , Combined Loss: tensor(0.6439, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6804928779602051\n",
      "Batch: 241 , Combined Loss: tensor(0.6927, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7904694080352783\n",
      "Batch: 242 , Combined Loss: tensor(0.6919, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.489288330078125\n",
      "Batch: 243 , Combined Loss: tensor(0.6984, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3918793201446533\n",
      "Batch: 244 , Combined Loss: tensor(0.6789, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3806573152542114\n",
      "Batch: 245 , Combined Loss: tensor(0.7667, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49153661727905273\n",
      "Batch: 246 , Combined Loss: tensor(0.8576, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09570431709289551\n",
      "Batch: 247 , Combined Loss: tensor(1.0494, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.378887414932251\n",
      "Batch: 248 , Combined Loss: tensor(0.7382, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3634806275367737\n",
      "Batch: 249 , Combined Loss: tensor(0.7742, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5689452886581421\n",
      "Batch: 250 , Combined Loss: tensor(0.7023, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8415758609771729\n",
      "Batch: 251 , Combined Loss: tensor(0.7588, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7704458236694336\n",
      "Batch: 252 , Combined Loss: tensor(0.8622, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40860307216644287\n",
      "Batch: 253 , Combined Loss: tensor(0.6720, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8327244520187378\n",
      "Batch: 254 , Combined Loss: tensor(0.7495, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35728919506073\n",
      "Batch: 255 , Combined Loss: tensor(0.6876, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21576905250549316\n",
      "Batch: 256 , Combined Loss: tensor(0.7263, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0011536478996276855\n",
      "Batch: 257 , Combined Loss: tensor(0.6622, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44716691970825195\n",
      "Batch: 258 , Combined Loss: tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7309938669204712\n",
      "Batch: 259 , Combined Loss: tensor(0.9672, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5581927299499512\n",
      "Batch: 260 , Combined Loss: tensor(0.7126, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5052920579910278\n",
      "Batch: 261 , Combined Loss: tensor(0.6717, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.46403276920318604\n",
      "Batch: 262 , Combined Loss: tensor(0.6210, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9142605066299438\n",
      "Batch: 263 , Combined Loss: tensor(0.8645, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7505273818969727\n",
      "Batch: 264 , Combined Loss: tensor(0.8512, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6895577907562256\n",
      "Batch: 265 , Combined Loss: tensor(0.6717, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21677541732788086\n",
      "Batch: 266 , Combined Loss: tensor(0.7184, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2691233158111572\n",
      "Batch: 267 , Combined Loss: tensor(0.7971, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5444847345352173\n",
      "Batch: 268 , Combined Loss: tensor(0.6946, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6050142049789429\n",
      "Batch: 269 , Combined Loss: tensor(0.6657, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9195679426193237\n",
      "Batch: 270 , Combined Loss: tensor(0.6570, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5676722526550293\n",
      "Batch: 271 , Combined Loss: tensor(0.7114, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.035402655601501465\n",
      "Batch: 272 , Combined Loss: tensor(0.6595, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44997358322143555\n",
      "Batch: 273 , Combined Loss: tensor(0.7053, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9400087594985962\n",
      "Batch: 274 , Combined Loss: tensor(1.1339, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8872600793838501\n",
      "Batch: 275 , Combined Loss: tensor(0.7433, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7622637748718262\n",
      "Batch: 276 , Combined Loss: tensor(0.6952, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.013283789157867432\n",
      "Batch: 277 , Combined Loss: tensor(0.7482, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15805268287658691\n",
      "Batch: 278 , Combined Loss: tensor(0.8540, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38060081005096436\n",
      "Batch: 279 , Combined Loss: tensor(0.6646, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1992124319076538\n",
      "Batch: 280 , Combined Loss: tensor(0.7556, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4674534797668457\n",
      "Batch: 281 , Combined Loss: tensor(0.6743, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3189355731010437\n",
      "Batch: 282 , Combined Loss: tensor(0.6878, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7125885486602783\n",
      "Batch: 283 , Combined Loss: tensor(0.7246, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04028719663619995\n",
      "Batch: 284 , Combined Loss: tensor(0.6802, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6232001781463623\n",
      "Batch: 285 , Combined Loss: tensor(0.6759, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07235360145568848\n",
      "Batch: 286 , Combined Loss: tensor(0.6472, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4554938077926636\n",
      "Batch: 287 , Combined Loss: tensor(0.6631, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6207661628723145\n",
      "Batch: 288 , Combined Loss: tensor(0.6738, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46450841426849365\n",
      "Batch: 289 , Combined Loss: tensor(0.8875, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32461369037628174\n",
      "Batch: 290 , Combined Loss: tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27200591564178467\n",
      "Batch: 291 , Combined Loss: tensor(0.7814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6957414150238037\n",
      "Batch: 292 , Combined Loss: tensor(0.6623, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7867883443832397\n",
      "Batch: 293 , Combined Loss: tensor(0.7580, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10026246309280396\n",
      "Batch: 294 , Combined Loss: tensor(0.6432, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30788254737854004\n",
      "Batch: 295 , Combined Loss: tensor(0.8607, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.957618236541748\n",
      "Batch: 296 , Combined Loss: tensor(0.6835, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8615633249282837\n",
      "Batch: 297 , Combined Loss: tensor(0.6998, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8757834434509277\n",
      "Batch: 298 , Combined Loss: tensor(0.7039, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45249998569488525\n",
      "Batch: 299 , Combined Loss: tensor(0.6889, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37448549270629883\n",
      "Batch: 300 , Combined Loss: tensor(0.7888, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6083669662475586\n",
      "Batch: 301 , Combined Loss: tensor(0.7413, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17159819602966309\n",
      "Batch: 302 , Combined Loss: tensor(0.6834, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8194006681442261\n",
      "Batch: 303 , Combined Loss: tensor(0.6321, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7106317281723022\n",
      "Batch: 304 , Combined Loss: tensor(0.6525, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2522907257080078\n",
      "Batch: 305 , Combined Loss: tensor(0.6832, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.620742678642273\n",
      "Batch: 306 , Combined Loss: tensor(0.6529, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5636963844299316\n",
      "Batch: 307 , Combined Loss: tensor(0.6840, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29252195358276367\n",
      "Batch: 308 , Combined Loss: tensor(0.7032, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5040323734283447\n",
      "Batch: 309 , Combined Loss: tensor(0.7405, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4384331703186035\n",
      "Batch: 310 , Combined Loss: tensor(0.6753, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8094092607498169\n",
      "Batch: 311 , Combined Loss: tensor(0.6293, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5067142248153687\n",
      "Batch: 312 , Combined Loss: tensor(0.7702, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5487353801727295\n",
      "Batch: 313 , Combined Loss: tensor(0.6419, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0034525394439697\n",
      "Batch: 314 , Combined Loss: tensor(0.6859, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9134787321090698\n",
      "Batch: 315 , Combined Loss: tensor(0.5789, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.007649362087249756\n",
      "Batch: 316 , Combined Loss: tensor(0.6607, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8901876211166382\n",
      "Batch: 317 , Combined Loss: tensor(0.8528, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6544762849807739\n",
      "Batch: 318 , Combined Loss: tensor(0.7765, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29221808910369873\n",
      "Batch: 319 , Combined Loss: tensor(0.7589, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27954423427581787\n",
      "Batch: 320 , Combined Loss: tensor(0.6963, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07736372947692871\n",
      "Batch: 321 , Combined Loss: tensor(0.7319, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.194097638130188\n",
      "Batch: 322 , Combined Loss: tensor(0.6909, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.049684762954711914\n",
      "Batch: 323 , Combined Loss: tensor(0.6310, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8072885274887085\n",
      "Batch: 324 , Combined Loss: tensor(0.8275, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38737308979034424\n",
      "Batch: 325 , Combined Loss: tensor(0.9138, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40233802795410156\n",
      "Batch: 326 , Combined Loss: tensor(0.7219, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8568718433380127\n",
      "Batch: 327 , Combined Loss: tensor(0.7385, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06000471115112305\n",
      "Batch: 328 , Combined Loss: tensor(0.6706, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7098329067230225\n",
      "Batch: 329 , Combined Loss: tensor(0.6901, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8241114616394043\n",
      "Batch: 330 , Combined Loss: tensor(0.6757, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05425882339477539\n",
      "Batch: 331 , Combined Loss: tensor(0.7259, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9493110179901123\n",
      "Batch: 332 , Combined Loss: tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1956607699394226\n",
      "Batch: 333 , Combined Loss: tensor(0.6989, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.658843994140625\n",
      "Batch: 334 , Combined Loss: tensor(0.6636, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.830105185508728\n",
      "Batch: 335 , Combined Loss: tensor(0.7476, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3571072816848755\n",
      "Batch: 336 , Combined Loss: tensor(0.7745, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7337522506713867\n",
      "Batch: 337 , Combined Loss: tensor(0.8388, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9113372564315796\n",
      "Batch: 338 , Combined Loss: tensor(0.6796, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6664474010467529\n",
      "Batch: 339 , Combined Loss: tensor(0.6417, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08635246753692627\n",
      "Batch: 340 , Combined Loss: tensor(0.8901, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28550589084625244\n",
      "Batch: 341 , Combined Loss: tensor(0.6869, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.017678916454315186\n",
      "Batch: 342 , Combined Loss: tensor(0.6198, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3442925214767456\n",
      "Batch: 343 , Combined Loss: tensor(0.7948, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07744276523590088\n",
      "Batch: 344 , Combined Loss: tensor(0.7322, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6085177659988403\n",
      "Batch: 345 , Combined Loss: tensor(0.6488, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5054198503494263\n",
      "Batch: 346 , Combined Loss: tensor(0.6502, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3381732702255249\n",
      "Batch: 347 , Combined Loss: tensor(0.6923, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37987279891967773\n",
      "Batch: 348 , Combined Loss: tensor(0.6165, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5893658399581909\n",
      "Batch: 349 , Combined Loss: tensor(0.7876, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8846741914749146\n",
      "Batch: 350 , Combined Loss: tensor(0.6772, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6257299184799194\n",
      "Batch: 351 , Combined Loss: tensor(0.6715, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2239639163017273\n",
      "Batch: 352 , Combined Loss: tensor(0.6568, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6435965299606323\n",
      "Batch: 353 , Combined Loss: tensor(0.8935, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6324760913848877\n",
      "Batch: 354 , Combined Loss: tensor(0.7466, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0147969722747803\n",
      "Batch: 355 , Combined Loss: tensor(0.6663, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6735032796859741\n",
      "Batch: 356 , Combined Loss: tensor(0.6437, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4514273405075073\n",
      "Batch: 357 , Combined Loss: tensor(0.7940, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.505092978477478\n",
      "Batch: 358 , Combined Loss: tensor(0.6942, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7220540046691895\n",
      "Batch: 359 , Combined Loss: tensor(0.9334, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36697089672088623\n",
      "Batch: 360 , Combined Loss: tensor(0.7638, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8355473279953003\n",
      "Batch: 361 , Combined Loss: tensor(0.8224, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13515591621398926\n",
      "Batch: 362 , Combined Loss: tensor(0.6475, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8803563117980957\n",
      "Batch: 363 , Combined Loss: tensor(0.6865, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.824907660484314\n",
      "Batch: 364 , Combined Loss: tensor(0.6696, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6316863298416138\n",
      "Batch: 365 , Combined Loss: tensor(0.7093, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6529349088668823\n",
      "Batch: 366 , Combined Loss: tensor(0.6540, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1128835678100586\n",
      "Batch: 367 , Combined Loss: tensor(0.7344, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8228802680969238\n",
      "Batch: 368 , Combined Loss: tensor(0.8280, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4141455888748169\n",
      "Batch: 369 , Combined Loss: tensor(0.8338, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49766361713409424\n",
      "Batch: 370 , Combined Loss: tensor(0.7050, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7660351991653442\n",
      "Batch: 371 , Combined Loss: tensor(0.7529, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3690016269683838\n",
      "Batch: 372 , Combined Loss: tensor(0.7645, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2002401351928711\n",
      "Batch: 373 , Combined Loss: tensor(0.7187, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8473598957061768\n",
      "Batch: 374 , Combined Loss: tensor(0.7649, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7621619701385498\n",
      "Batch: 375 , Combined Loss: tensor(0.7213, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.707432746887207\n",
      "Batch: 376 , Combined Loss: tensor(0.7622, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5439320802688599\n",
      "Batch: 377 , Combined Loss: tensor(0.6648, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6176848411560059\n",
      "Batch: 378 , Combined Loss: tensor(0.8187, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5462592840194702\n",
      "Batch: 379 , Combined Loss: tensor(0.6869, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2981325387954712\n",
      "Batch: 380 , Combined Loss: tensor(0.7783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3312801122665405\n",
      "Batch: 381 , Combined Loss: tensor(0.8163, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9391700029373169\n",
      "Batch: 382 , Combined Loss: tensor(0.6324, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6334195137023926\n",
      "Batch: 383 , Combined Loss: tensor(0.8176, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6205496788024902\n",
      "Batch: 384 , Combined Loss: tensor(0.7772, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.770051121711731\n",
      "Batch: 385 , Combined Loss: tensor(0.6232, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.816552996635437\n",
      "Batch: 386 , Combined Loss: tensor(0.9421, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9669744968414307\n",
      "Batch: 387 , Combined Loss: tensor(0.7046, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.705000638961792\n",
      "Batch: 388 , Combined Loss: tensor(0.7213, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4989814758300781\n",
      "Batch: 389 , Combined Loss: tensor(0.6863, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9027233123779297\n",
      "Batch: 390 , Combined Loss: tensor(0.6466, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3916890621185303\n",
      "Batch: 391 , Combined Loss: tensor(0.6691, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8979243040084839\n",
      "Batch: 392 , Combined Loss: tensor(0.7653, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26109743118286133\n",
      "Batch: 393 , Combined Loss: tensor(0.6157, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6265127658843994\n",
      "Batch: 394 , Combined Loss: tensor(0.7708, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.28072112798690796\n",
      "Batch: 395 , Combined Loss: tensor(1.0106, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2605644464492798\n",
      "Batch: 396 , Combined Loss: tensor(0.6229, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6982735395431519\n",
      "Batch: 397 , Combined Loss: tensor(0.6903, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4904797077178955\n",
      "Batch: 398 , Combined Loss: tensor(0.6534, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8971391916275024\n",
      "Batch: 399 , Combined Loss: tensor(0.6826, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.079477310180664\n",
      "Batch: 400 , Combined Loss: tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8017622232437134\n",
      "Batch: 401 , Combined Loss: tensor(0.7431, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.105629563331604\n",
      "Batch: 402 , Combined Loss: tensor(0.7229, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6098595857620239\n",
      "Batch: 403 , Combined Loss: tensor(0.6471, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18992376327514648\n",
      "Batch: 404 , Combined Loss: tensor(1.0256, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06387758255004883\n",
      "Batch: 405 , Combined Loss: tensor(0.6507, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7316045761108398\n",
      "Batch: 406 , Combined Loss: tensor(0.6874, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6214368343353271\n",
      "Batch: 407 , Combined Loss: tensor(0.9036, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7218477725982666\n",
      "Batch: 408 , Combined Loss: tensor(0.7003, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0465898513793945\n",
      "Batch: 409 , Combined Loss: tensor(0.6210, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.78337562084198\n",
      "Batch: 410 , Combined Loss: tensor(0.6364, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3659406900405884\n",
      "Batch: 411 , Combined Loss: tensor(0.7631, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11015206575393677\n",
      "Batch: 412 , Combined Loss: tensor(0.6586, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5679084062576294\n",
      "Batch: 413 , Combined Loss: tensor(0.6521, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8885674476623535\n",
      "Batch: 414 , Combined Loss: tensor(0.6091, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7307913303375244\n",
      "Batch: 415 , Combined Loss: tensor(0.8595, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6133028268814087\n",
      "Batch: 416 , Combined Loss: tensor(0.6523, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06112933158874512\n",
      "Batch: 417 , Combined Loss: tensor(0.7283, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0359933376312256\n",
      "Batch: 418 , Combined Loss: tensor(0.7853, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7687335014343262\n",
      "Batch: 419 , Combined Loss: tensor(0.7600, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4543640613555908\n",
      "Batch: 420 , Combined Loss: tensor(0.5754, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4839057922363281\n",
      "Batch: 421 , Combined Loss: tensor(0.6457, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6631743907928467\n",
      "Batch: 422 , Combined Loss: tensor(0.6192, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5969414710998535\n",
      "Batch: 423 , Combined Loss: tensor(0.9508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5638886094093323\n",
      "Batch: 424 , Combined Loss: tensor(0.9519, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20170187950134277\n",
      "Batch: 425 , Combined Loss: tensor(0.6801, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9697767496109009\n",
      "Batch: 426 , Combined Loss: tensor(0.6840, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9009695053100586\n",
      "Batch: 427 , Combined Loss: tensor(0.6748, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7322310209274292\n",
      "Batch: 428 , Combined Loss: tensor(0.8477, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28801023960113525\n",
      "Batch: 429 , Combined Loss: tensor(0.6704, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5519415140151978\n",
      "Batch: 430 , Combined Loss: tensor(0.8668, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3883146047592163\n",
      "Batch: 431 , Combined Loss: tensor(0.8011, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8747791051864624\n",
      "Batch: 432 , Combined Loss: tensor(0.6961, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08371347188949585\n",
      "Batch: 433 , Combined Loss: tensor(0.8380, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05706381797790527\n",
      "Batch: 434 , Combined Loss: tensor(0.6947, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5066419243812561\n",
      "Batch: 435 , Combined Loss: tensor(0.6436, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0123956203460693\n",
      "Batch: 436 , Combined Loss: tensor(0.8923, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4101295471191406\n",
      "Batch: 437 , Combined Loss: tensor(0.7103, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14246195554733276\n",
      "Batch: 438 , Combined Loss: tensor(0.9193, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.290449857711792\n",
      "Batch: 439 , Combined Loss: tensor(0.7932, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7126748561859131\n",
      "Batch: 440 , Combined Loss: tensor(0.6546, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2280101776123047\n",
      "Batch: 441 , Combined Loss: tensor(0.7654, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6876002550125122\n",
      "Batch: 442 , Combined Loss: tensor(0.7089, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1345529556274414\n",
      "Batch: 443 , Combined Loss: tensor(0.7260, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5542800426483154\n",
      "Batch: 444 , Combined Loss: tensor(0.6942, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8341748714447021\n",
      "Batch: 445 , Combined Loss: tensor(0.7814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6586745977401733\n",
      "Batch: 446 , Combined Loss: tensor(0.6668, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1488516926765442\n",
      "Batch: 447 , Combined Loss: tensor(0.7692, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07134783267974854\n",
      "Batch: 448 , Combined Loss: tensor(0.6779, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8229149580001831\n",
      "Batch: 449 , Combined Loss: tensor(0.6901, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7220067977905273\n",
      "Batch: 450 , Combined Loss: tensor(0.8410, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7508412599563599\n",
      "Batch: 451 , Combined Loss: tensor(0.7418, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6865561008453369\n",
      "Batch: 452 , Combined Loss: tensor(0.8326, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5075967311859131\n",
      "Batch: 453 , Combined Loss: tensor(0.6599, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7709801197052002\n",
      "Batch: 454 , Combined Loss: tensor(0.6852, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8848150968551636\n",
      "Batch: 455 , Combined Loss: tensor(0.7762, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6860276460647583\n",
      "Batch: 456 , Combined Loss: tensor(0.7363, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10661900043487549\n",
      "Batch: 457 , Combined Loss: tensor(0.7525, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6759448051452637\n",
      "Batch: 458 , Combined Loss: tensor(0.6327, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9138867855072021\n",
      "Batch: 459 , Combined Loss: tensor(0.6814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2326946258544922\n",
      "Batch: 460 , Combined Loss: tensor(0.6419, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9208056926727295\n",
      "Batch: 461 , Combined Loss: tensor(0.7625, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.463977575302124\n",
      "Batch: 462 , Combined Loss: tensor(0.6526, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.495463490486145\n",
      "Batch: 463 , Combined Loss: tensor(0.6696, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15912878513336182\n",
      "Batch: 464 , Combined Loss: tensor(0.6660, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0589988231658936\n",
      "Batch: 465 , Combined Loss: tensor(0.7447, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3597135543823242\n",
      "Batch: 466 , Combined Loss: tensor(0.7356, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2809252142906189\n",
      "Batch: 467 , Combined Loss: tensor(0.6736, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6024061441421509\n",
      "Batch: 468 , Combined Loss: tensor(0.6822, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1897682547569275\n",
      "Batch: 469 , Combined Loss: tensor(0.7075, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09514164924621582\n",
      "Batch: 470 , Combined Loss: tensor(0.6709, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17112362384796143\n",
      "Batch: 471 , Combined Loss: tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.035895586013794\n",
      "Batch: 472 , Combined Loss: tensor(0.6483, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8403714895248413\n",
      "Batch: 473 , Combined Loss: tensor(0.8003, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1778796911239624\n",
      "Batch: 474 , Combined Loss: tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8584858179092407\n",
      "Batch: 475 , Combined Loss: tensor(0.6635, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3235362768173218\n",
      "Batch: 476 , Combined Loss: tensor(1.1492, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5846524238586426\n",
      "Batch: 477 , Combined Loss: tensor(0.7061, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1061618328094482\n",
      "Batch: 478 , Combined Loss: tensor(0.9495, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7633404731750488\n",
      "Batch: 479 , Combined Loss: tensor(1.1201, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7180222272872925\n",
      "Batch: 480 , Combined Loss: tensor(1.0486, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5635969638824463\n",
      "Batch: 481 , Combined Loss: tensor(0.6935, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9571539163589478\n",
      "Batch: 482 , Combined Loss: tensor(0.6571, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11948060989379883\n",
      "Batch: 483 , Combined Loss: tensor(0.7082, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.071946620941162\n",
      "Batch: 484 , Combined Loss: tensor(0.7675, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19743764400482178\n",
      "Batch: 485 , Combined Loss: tensor(0.6821, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7865420579910278\n",
      "Batch: 486 , Combined Loss: tensor(0.7504, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1441890001296997\n",
      "Batch: 487 , Combined Loss: tensor(0.5946, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.319988489151001\n",
      "Batch: 488 , Combined Loss: tensor(0.7594, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7423828840255737\n",
      "Batch: 489 , Combined Loss: tensor(0.6469, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7152358293533325\n",
      "Batch: 490 , Combined Loss: tensor(0.7247, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2930178642272949\n",
      "Batch: 491 , Combined Loss: tensor(0.6143, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8562854528427124\n",
      "Batch: 492 , Combined Loss: tensor(0.6774, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9094229936599731\n",
      "Batch: 493 , Combined Loss: tensor(0.6377, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11840546131134033\n",
      "Batch: 494 , Combined Loss: tensor(0.6160, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0772426128387451\n",
      "Batch: 495 , Combined Loss: tensor(0.6695, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.732213020324707\n",
      "Batch: 496 , Combined Loss: tensor(0.6571, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7956427335739136\n",
      "Batch: 497 , Combined Loss: tensor(0.6475, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0073215961456299\n",
      "Batch: 498 , Combined Loss: tensor(0.7503, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6583108901977539\n",
      "Batch: 499 , Combined Loss: tensor(0.6065, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18838322162628174\n",
      "Batch: 500 , Combined Loss: tensor(0.8947, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3221418857574463\n",
      "Batch: 501 , Combined Loss: tensor(0.7644, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2320237159729004\n",
      "Batch: 502 , Combined Loss: tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8603259325027466\n",
      "Batch: 503 , Combined Loss: tensor(0.7345, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5340603590011597\n",
      "Batch: 504 , Combined Loss: tensor(0.7113, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.18239760398864746\n",
      "Batch: 505 , Combined Loss: tensor(0.7108, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.18490135669708252\n",
      "Batch: 506 , Combined Loss: tensor(1.0495, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45425915718078613\n",
      "Batch: 507 , Combined Loss: tensor(0.7668, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4407954216003418\n",
      "Batch: 508 , Combined Loss: tensor(0.8629, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.657940149307251\n",
      "Batch: 509 , Combined Loss: tensor(0.8250, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8273283243179321\n",
      "Batch: 510 , Combined Loss: tensor(0.6926, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48657047748565674\n",
      "Batch: 511 , Combined Loss: tensor(1.0806, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48857414722442627\n",
      "Batch: 512 , Combined Loss: tensor(0.6347, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.514927864074707\n",
      "Batch: 513 , Combined Loss: tensor(0.7362, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12887901067733765\n",
      "Batch: 514 , Combined Loss: tensor(0.6974, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30578386783599854\n",
      "Batch: 515 , Combined Loss: tensor(0.6279, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8450870513916016\n",
      "Batch: 516 , Combined Loss: tensor(0.7094, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04904359579086304\n",
      "Batch: 517 , Combined Loss: tensor(0.8169, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9674447774887085\n",
      "Batch: 518 , Combined Loss: tensor(0.8304, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10265278816223145\n",
      "Batch: 519 , Combined Loss: tensor(0.5631, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06643426418304443\n",
      "Batch: 520 , Combined Loss: tensor(0.6831, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7312189340591431\n",
      "Batch: 521 , Combined Loss: tensor(0.6426, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.016419589519500732\n",
      "Batch: 522 , Combined Loss: tensor(0.8844, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2027679681777954\n",
      "Batch: 523 , Combined Loss: tensor(0.8349, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7861459255218506\n",
      "Batch: 524 , Combined Loss: tensor(0.7911, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5744673013687134\n",
      "Batch: 525 , Combined Loss: tensor(0.7117, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0281071662902832\n",
      "Batch: 526 , Combined Loss: tensor(0.7099, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6456533670425415\n",
      "Batch: 527 , Combined Loss: tensor(0.7455, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.601313591003418\n",
      "Batch: 528 , Combined Loss: tensor(0.7568, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7391061782836914\n",
      "Batch: 529 , Combined Loss: tensor(0.6037, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5761191844940186\n",
      "Batch: 530 , Combined Loss: tensor(0.8129, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09677350521087646\n",
      "Batch: 531 , Combined Loss: tensor(0.6149, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16398882865905762\n",
      "Batch: 532 , Combined Loss: tensor(0.6683, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7056516408920288\n",
      "Batch: 533 , Combined Loss: tensor(0.6306, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5222945213317871\n",
      "Batch: 534 , Combined Loss: tensor(0.8555, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0301170349121094\n",
      "Batch: 535 , Combined Loss: tensor(0.7695, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5949898958206177\n",
      "Batch: 536 , Combined Loss: tensor(0.6922, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5433963537216187\n",
      "Batch: 537 , Combined Loss: tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4080955386161804\n",
      "Batch: 538 , Combined Loss: tensor(0.7974, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45498132705688477\n",
      "Batch: 539 , Combined Loss: tensor(0.6472, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0304899215698242\n",
      "Batch: 540 , Combined Loss: tensor(0.6955, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22642481327056885\n",
      "Batch: 541 , Combined Loss: tensor(0.7685, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8624286651611328\n",
      "Batch: 542 , Combined Loss: tensor(0.7380, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8564527034759521\n",
      "Batch: 543 , Combined Loss: tensor(0.6967, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23832964897155762\n",
      "Batch: 544 , Combined Loss: tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.007507085800171\n",
      "Batch: 545 , Combined Loss: tensor(0.7528, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47716808319091797\n",
      "Batch: 546 , Combined Loss: tensor(0.7252, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36300790309906006\n",
      "Batch: 547 , Combined Loss: tensor(0.7248, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7451601028442383\n",
      "Batch: 548 , Combined Loss: tensor(0.7815, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9853932857513428\n",
      "Batch: 549 , Combined Loss: tensor(0.7001, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5240076780319214\n",
      "Batch: 550 , Combined Loss: tensor(0.7279, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11796092987060547\n",
      "Batch: 551 , Combined Loss: tensor(0.6404, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07293033599853516\n",
      "Batch: 552 , Combined Loss: tensor(0.6237, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7992478609085083\n",
      "Batch: 553 , Combined Loss: tensor(0.8016, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6392151117324829\n",
      "Batch: 554 , Combined Loss: tensor(0.8080, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9181957244873047\n",
      "Batch: 555 , Combined Loss: tensor(0.6250, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6815732717514038\n",
      "Batch: 556 , Combined Loss: tensor(0.7612, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3702658414840698\n",
      "Batch: 557 , Combined Loss: tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6024943590164185\n",
      "Batch: 558 , Combined Loss: tensor(0.6643, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7117670774459839\n",
      "Batch: 559 , Combined Loss: tensor(0.9130, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06653034687042236\n",
      "Batch: 560 , Combined Loss: tensor(0.6943, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4206699728965759\n",
      "Batch: 561 , Combined Loss: tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6310758590698242\n",
      "Batch: 562 , Combined Loss: tensor(0.7857, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07644796371459961\n",
      "Batch: 563 , Combined Loss: tensor(0.6707, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6421386003494263\n",
      "Batch: 564 , Combined Loss: tensor(0.7703, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20766979455947876\n",
      "Batch: 565 , Combined Loss: tensor(0.6650, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3756999969482422\n",
      "Batch: 566 , Combined Loss: tensor(0.8034, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14961540699005127\n",
      "Batch: 567 , Combined Loss: tensor(0.6725, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6538232564926147\n",
      "Batch: 568 , Combined Loss: tensor(0.6681, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0462086200714111\n",
      "Batch: 569 , Combined Loss: tensor(0.7588, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9639939069747925\n",
      "Batch: 570 , Combined Loss: tensor(0.6992, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4530527591705322\n",
      "Batch: 571 , Combined Loss: tensor(0.6462, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6587167978286743\n",
      "Batch: 572 , Combined Loss: tensor(0.6819, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33275115489959717\n",
      "Batch: 573 , Combined Loss: tensor(0.6374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6401791572570801\n",
      "Batch: 574 , Combined Loss: tensor(0.8474, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03685784339904785\n",
      "Batch: 575 , Combined Loss: tensor(0.6905, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8854243755340576\n",
      "Batch: 576 , Combined Loss: tensor(0.8635, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5118799209594727\n",
      "Batch: 577 , Combined Loss: tensor(0.8121, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8636326789855957\n",
      "Batch: 578 , Combined Loss: tensor(0.6148, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5114765763282776\n",
      "Batch: 579 , Combined Loss: tensor(0.7345, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2136132717132568\n",
      "Batch: 580 , Combined Loss: tensor(0.8557, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.008645176887512207\n",
      "Batch: 581 , Combined Loss: tensor(0.7216, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03962218761444092\n",
      "Batch: 582 , Combined Loss: tensor(0.6531, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7533249855041504\n",
      "Batch: 583 , Combined Loss: tensor(0.7768, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3363948464393616\n",
      "Batch: 584 , Combined Loss: tensor(0.8186, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8535436391830444\n",
      "Batch: 585 , Combined Loss: tensor(0.8220, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7105879783630371\n",
      "Batch: 586 , Combined Loss: tensor(0.7303, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.003981828689575195\n",
      "Batch: 587 , Combined Loss: tensor(0.7101, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21733331680297852\n",
      "Batch: 588 , Combined Loss: tensor(0.6566, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21972978115081787\n",
      "Batch: 589 , Combined Loss: tensor(0.7843, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3394765257835388\n",
      "Batch: 590 , Combined Loss: tensor(0.8031, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.452384352684021\n",
      "Batch: 591 , Combined Loss: tensor(0.7708, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39029133319854736\n",
      "Batch: 592 , Combined Loss: tensor(0.7049, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03525876998901367\n",
      "Batch: 593 , Combined Loss: tensor(0.7720, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8355379104614258\n",
      "Batch: 594 , Combined Loss: tensor(0.7219, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5042659044265747\n",
      "Batch: 595 , Combined Loss: tensor(0.7009, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5448354482650757\n",
      "Batch: 596 , Combined Loss: tensor(0.8503, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2180788516998291\n",
      "Batch: 597 , Combined Loss: tensor(0.7371, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2942279577255249\n",
      "Batch: 598 , Combined Loss: tensor(0.8022, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31541013717651367\n",
      "Batch: 599 , Combined Loss: tensor(0.7501, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8755432367324829\n",
      "Batch: 600 , Combined Loss: tensor(0.7712, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04924279451370239\n",
      "Batch: 601 , Combined Loss: tensor(0.6546, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.62087082862854\n",
      "Batch: 602 , Combined Loss: tensor(0.6524, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.037071943283081055\n",
      "Batch: 603 , Combined Loss: tensor(0.6668, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8505178689956665\n",
      "Batch: 604 , Combined Loss: tensor(0.8123, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2496582269668579\n",
      "Batch: 605 , Combined Loss: tensor(0.7050, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3369835615158081\n",
      "Batch: 606 , Combined Loss: tensor(0.7295, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12063217163085938\n",
      "Batch: 607 , Combined Loss: tensor(0.6639, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.980178713798523\n",
      "Batch: 608 , Combined Loss: tensor(0.5978, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7503451108932495\n",
      "Batch: 609 , Combined Loss: tensor(0.7561, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3726072311401367\n",
      "Batch: 610 , Combined Loss: tensor(0.7924, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20122569799423218\n",
      "Batch: 611 , Combined Loss: tensor(0.6889, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1020219326019287\n",
      "Batch: 612 , Combined Loss: tensor(0.7127, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7001339197158813\n",
      "Batch: 613 , Combined Loss: tensor(0.6541, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.253206729888916\n",
      "Batch: 614 , Combined Loss: tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5227895975112915\n",
      "Batch: 615 , Combined Loss: tensor(0.7505, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5366417169570923\n",
      "Batch: 616 , Combined Loss: tensor(0.6730, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7087287902832031\n",
      "Batch: 617 , Combined Loss: tensor(0.6159, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.47443926334381104\n",
      "Batch: 618 , Combined Loss: tensor(0.6590, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8686965703964233\n",
      "Batch: 619 , Combined Loss: tensor(0.7201, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8512297868728638\n",
      "Batch: 620 , Combined Loss: tensor(0.7303, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9366424083709717\n",
      "Batch: 621 , Combined Loss: tensor(0.6332, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5563173294067383\n",
      "Batch: 622 , Combined Loss: tensor(0.6331, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3360482454299927\n",
      "Batch: 623 , Combined Loss: tensor(0.7292, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9537932872772217\n",
      "Batch: 624 , Combined Loss: tensor(0.7652, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8260606527328491\n",
      "Batch: 625 , Combined Loss: tensor(0.6758, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0491113662719727\n",
      "Batch: 626 , Combined Loss: tensor(0.7234, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.845407247543335\n",
      "Batch: 627 , Combined Loss: tensor(0.6628, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5910009145736694\n",
      "Batch: 628 , Combined Loss: tensor(0.6540, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9221301078796387\n",
      "----------Epoch 13, Loss: 0.7349466616095345, Accuracy: 0.9521035299013074, Dice Coef: [0.9775819605977433, 0.4849171339229926, 0.5279292706645734, 0.624456476707416], Dice Coef Necrotic: 0.9769900204545756, Dice Coef Edema: 0.9770288463200244, Dice Coef Enhancing: 0.9356815333914207, Sensitivity: [0.9577824756716318, 0.7150756393412879, 0.8453099992487503, 0.8590358704778651], Specificity: [0.973003401760077, 0.9953490974224618, 0.9646893121858848, 0.9924657329656361], Precision: [0.9983970547518404, 0.43938980975587116, 0.41383073079067756, 0.5374836449793411]\n",
      "Saving without nn.DataParallel\n",
      "Batch: 0 , Combined Loss: tensor(0.6837, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9748938083648682\n",
      "Batch: 1 , Combined Loss: tensor(0.7573, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21735340356826782\n",
      "Batch: 2 , Combined Loss: tensor(0.6436, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3615860939025879\n",
      "Batch: 3 , Combined Loss: tensor(0.6875, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3316013813018799\n",
      "Batch: 4 , Combined Loss: tensor(0.6369, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5116623640060425\n",
      "Batch: 5 , Combined Loss: tensor(0.7493, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6658530235290527\n",
      "Batch: 6 , Combined Loss: tensor(0.7621, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7794040441513062\n",
      "Batch: 7 , Combined Loss: tensor(0.6797, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3598750829696655\n",
      "Batch: 8 , Combined Loss: tensor(0.6328, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7034347057342529\n",
      "Batch: 9 , Combined Loss: tensor(0.7671, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10322558879852295\n",
      "Batch: 10 , Combined Loss: tensor(0.5893, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6278992891311646\n",
      "Batch: 11 , Combined Loss: tensor(0.7752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.29667896032333374\n",
      "Batch: 12 , Combined Loss: tensor(0.7057, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8210231065750122\n",
      "Batch: 13 , Combined Loss: tensor(1.0265, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5822790861129761\n",
      "Batch: 14 , Combined Loss: tensor(0.8727, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17992961406707764\n",
      "Batch: 15 , Combined Loss: tensor(0.7114, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6795181035995483\n",
      "Batch: 16 , Combined Loss: tensor(0.8253, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26937031745910645\n",
      "Batch: 17 , Combined Loss: tensor(0.6451, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9950573444366455\n",
      "Batch: 18 , Combined Loss: tensor(0.7930, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49137842655181885\n",
      "Batch: 19 , Combined Loss: tensor(0.9370, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7284491062164307\n",
      "Batch: 20 , Combined Loss: tensor(0.6141, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2362259030342102\n",
      "Batch: 21 , Combined Loss: tensor(0.6635, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06340587139129639\n",
      "Batch: 22 , Combined Loss: tensor(0.7820, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1557403802871704\n",
      "Batch: 23 , Combined Loss: tensor(0.6624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.667809247970581\n",
      "Batch: 24 , Combined Loss: tensor(0.7369, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.607157826423645\n",
      "Batch: 25 , Combined Loss: tensor(0.7742, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0327534675598145\n",
      "Batch: 26 , Combined Loss: tensor(0.8006, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5642794370651245\n",
      "Batch: 27 , Combined Loss: tensor(0.6276, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.038468360900878906\n",
      "Batch: 28 , Combined Loss: tensor(0.6849, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.674208402633667\n",
      "Batch: 29 , Combined Loss: tensor(0.6500, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8834067583084106\n",
      "Batch: 30 , Combined Loss: tensor(0.7205, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6861191987991333\n",
      "Batch: 31 , Combined Loss: tensor(0.6549, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2773996591567993\n",
      "Batch: 32 , Combined Loss: tensor(0.7906, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3072853088378906\n",
      "Batch: 33 , Combined Loss: tensor(0.6041, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07888299226760864\n",
      "Batch: 34 , Combined Loss: tensor(0.7335, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2742929458618164\n",
      "Batch: 35 , Combined Loss: tensor(0.6689, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1661784648895264\n",
      "Batch: 36 , Combined Loss: tensor(0.7327, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7047100067138672\n",
      "Batch: 37 , Combined Loss: tensor(0.6266, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5735985040664673\n",
      "Batch: 38 , Combined Loss: tensor(0.6239, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6074936389923096\n",
      "Batch: 39 , Combined Loss: tensor(0.7701, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9381328821182251\n",
      "Batch: 40 , Combined Loss: tensor(0.6230, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.664216160774231\n",
      "Batch: 41 , Combined Loss: tensor(0.6368, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.490821897983551\n",
      "Batch: 42 , Combined Loss: tensor(0.6596, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44460034370422363\n",
      "Batch: 43 , Combined Loss: tensor(0.7025, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4947391748428345\n",
      "Batch: 44 , Combined Loss: tensor(0.6446, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0639493465423584\n",
      "Batch: 45 , Combined Loss: tensor(0.8107, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4665452241897583\n",
      "Batch: 46 , Combined Loss: tensor(0.7520, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8706640005111694\n",
      "Batch: 47 , Combined Loss: tensor(0.6656, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7522307634353638\n",
      "Batch: 48 , Combined Loss: tensor(0.8297, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5779143571853638\n",
      "Batch: 49 , Combined Loss: tensor(0.6569, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4203212261199951\n",
      "Batch: 50 , Combined Loss: tensor(0.7482, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11335903406143188\n",
      "Batch: 51 , Combined Loss: tensor(0.6916, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5201681852340698\n",
      "Batch: 52 , Combined Loss: tensor(0.7423, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.92267906665802\n",
      "Batch: 53 , Combined Loss: tensor(0.6803, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8636102676391602\n",
      "Batch: 54 , Combined Loss: tensor(0.7800, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8972114324569702\n",
      "Batch: 55 , Combined Loss: tensor(1.0965, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42253851890563965\n",
      "Batch: 56 , Combined Loss: tensor(0.7303, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10778319835662842\n",
      "Batch: 57 , Combined Loss: tensor(0.7657, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8897122144699097\n",
      "Batch: 58 , Combined Loss: tensor(0.7656, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7474437952041626\n",
      "Batch: 59 , Combined Loss: tensor(0.6567, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2712293863296509\n",
      "Batch: 60 , Combined Loss: tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.652018666267395\n",
      "Batch: 61 , Combined Loss: tensor(0.6778, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0030750632286071777\n",
      "Batch: 62 , Combined Loss: tensor(0.6547, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8662382364273071\n",
      "Batch: 63 , Combined Loss: tensor(0.7751, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7889819145202637\n",
      "Batch: 64 , Combined Loss: tensor(0.8117, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8909584283828735\n",
      "Batch: 65 , Combined Loss: tensor(0.6338, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4387451410293579\n",
      "Batch: 66 , Combined Loss: tensor(0.6970, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.050132155418395996\n",
      "Batch: 67 , Combined Loss: tensor(0.8624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7464008331298828\n",
      "Batch: 68 , Combined Loss: tensor(0.7621, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.667999267578125\n",
      "Batch: 69 , Combined Loss: tensor(0.7189, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.720220685005188\n",
      "Batch: 70 , Combined Loss: tensor(0.6624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5252383947372437\n",
      "Batch: 71 , Combined Loss: tensor(0.6732, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.060932457447052\n",
      "Batch: 72 , Combined Loss: tensor(0.6276, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5323162078857422\n",
      "Batch: 73 , Combined Loss: tensor(0.6772, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5475280284881592\n",
      "Batch: 74 , Combined Loss: tensor(0.6478, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36965370178222656\n",
      "Batch: 75 , Combined Loss: tensor(0.7787, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2927258014678955\n",
      "Batch: 76 , Combined Loss: tensor(0.6841, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1984574794769287\n",
      "Batch: 77 , Combined Loss: tensor(0.6849, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.933537483215332\n",
      "Batch: 78 , Combined Loss: tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9359633922576904\n",
      "Batch: 79 , Combined Loss: tensor(0.6965, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0576167106628418\n",
      "Batch: 80 , Combined Loss: tensor(0.7606, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13501405715942383\n",
      "Batch: 81 , Combined Loss: tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8472247123718262\n",
      "Batch: 82 , Combined Loss: tensor(0.6165, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9059978723526001\n",
      "Batch: 83 , Combined Loss: tensor(0.7260, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6138448715209961\n",
      "Batch: 84 , Combined Loss: tensor(0.6814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6869477033615112\n",
      "Batch: 85 , Combined Loss: tensor(0.6459, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8610715866088867\n",
      "Batch: 86 , Combined Loss: tensor(0.7569, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4527280330657959\n",
      "Batch: 87 , Combined Loss: tensor(0.6973, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0532491207122803\n",
      "Batch: 88 , Combined Loss: tensor(0.8111, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2663871645927429\n",
      "Batch: 89 , Combined Loss: tensor(0.6175, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8346421718597412\n",
      "Batch: 90 , Combined Loss: tensor(0.6615, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6711183786392212\n",
      "Batch: 91 , Combined Loss: tensor(0.8015, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5850141644477844\n",
      "Batch: 92 , Combined Loss: tensor(0.7698, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5382658243179321\n",
      "Batch: 93 , Combined Loss: tensor(0.5462, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.033594369888305664\n",
      "Batch: 94 , Combined Loss: tensor(0.6756, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9448873996734619\n",
      "Batch: 95 , Combined Loss: tensor(0.7583, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4787534475326538\n",
      "Batch: 96 , Combined Loss: tensor(0.8029, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6402721405029297\n",
      "Batch: 97 , Combined Loss: tensor(0.8256, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4777226448059082\n",
      "Batch: 98 , Combined Loss: tensor(0.7244, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6777849197387695\n",
      "Batch: 99 , Combined Loss: tensor(0.7440, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5499130487442017\n",
      "Batch: 100 , Combined Loss: tensor(0.7288, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05454891920089722\n",
      "Batch: 101 , Combined Loss: tensor(0.6964, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8009873628616333\n",
      "Batch: 102 , Combined Loss: tensor(0.6630, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6111568212509155\n",
      "Batch: 103 , Combined Loss: tensor(0.6558, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6404541730880737\n",
      "Batch: 104 , Combined Loss: tensor(0.7358, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4050954580307007\n",
      "Batch: 105 , Combined Loss: tensor(0.6710, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0508317947387695\n",
      "Batch: 106 , Combined Loss: tensor(0.7323, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6068300008773804\n",
      "Batch: 107 , Combined Loss: tensor(0.6775, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6372886896133423\n",
      "Batch: 108 , Combined Loss: tensor(0.6964, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9963940382003784\n",
      "Batch: 109 , Combined Loss: tensor(0.7265, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.183382511138916\n",
      "Batch: 110 , Combined Loss: tensor(0.9200, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.33003145456314087\n",
      "Batch: 111 , Combined Loss: tensor(0.6092, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08387410640716553\n",
      "Batch: 112 , Combined Loss: tensor(0.7543, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4345334768295288\n",
      "Batch: 113 , Combined Loss: tensor(0.6784, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3034043312072754\n",
      "Batch: 114 , Combined Loss: tensor(0.7039, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07730764150619507\n",
      "Batch: 115 , Combined Loss: tensor(0.8005, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.02079141139984131\n",
      "Batch: 116 , Combined Loss: tensor(0.6859, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10885453224182129\n",
      "Batch: 117 , Combined Loss: tensor(0.7796, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27489423751831055\n",
      "Batch: 118 , Combined Loss: tensor(0.6662, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2359987497329712\n",
      "Batch: 119 , Combined Loss: tensor(0.6606, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5933115482330322\n",
      "Batch: 120 , Combined Loss: tensor(0.6106, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.38326382637023926\n",
      "Batch: 121 , Combined Loss: tensor(0.8123, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2988837957382202\n",
      "Batch: 122 , Combined Loss: tensor(0.6566, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7228198051452637\n",
      "Batch: 123 , Combined Loss: tensor(0.7084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47644782066345215\n",
      "Batch: 124 , Combined Loss: tensor(0.7189, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6438853740692139\n",
      "Batch: 125 , Combined Loss: tensor(0.6679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6277676820755005\n",
      "Batch: 126 , Combined Loss: tensor(0.6084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.587334156036377\n",
      "Batch: 127 , Combined Loss: tensor(1.1052, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28656435012817383\n",
      "Batch: 128 , Combined Loss: tensor(0.7196, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9353170394897461\n",
      "Batch: 129 , Combined Loss: tensor(0.7318, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8653879165649414\n",
      "Batch: 130 , Combined Loss: tensor(0.8081, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1431030035018921\n",
      "Batch: 131 , Combined Loss: tensor(0.7432, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17182707786560059\n",
      "Batch: 132 , Combined Loss: tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14861524105072021\n",
      "Batch: 133 , Combined Loss: tensor(0.6456, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8080825805664062\n",
      "Batch: 134 , Combined Loss: tensor(0.6634, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46825897693634033\n",
      "Batch: 135 , Combined Loss: tensor(0.7521, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13290178775787354\n",
      "Batch: 136 , Combined Loss: tensor(0.9983, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4000760316848755\n",
      "Batch: 137 , Combined Loss: tensor(0.6222, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6274510622024536\n",
      "Batch: 138 , Combined Loss: tensor(0.9656, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12409448623657227\n",
      "Batch: 139 , Combined Loss: tensor(0.7724, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4702188968658447\n",
      "Batch: 140 , Combined Loss: tensor(0.8250, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7133543491363525\n",
      "Batch: 141 , Combined Loss: tensor(0.6804, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.107097864151001\n",
      "Batch: 142 , Combined Loss: tensor(0.6906, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2505958080291748\n",
      "Batch: 143 , Combined Loss: tensor(0.6520, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4745136499404907\n",
      "Batch: 144 , Combined Loss: tensor(0.7102, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10659956932067871\n",
      "Batch: 145 , Combined Loss: tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.759392499923706\n",
      "Batch: 146 , Combined Loss: tensor(0.6753, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04535001516342163\n",
      "Batch: 147 , Combined Loss: tensor(0.7906, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7911041975021362\n",
      "Batch: 148 , Combined Loss: tensor(0.6342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9214819669723511\n",
      "Batch: 149 , Combined Loss: tensor(0.6917, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22312891483306885\n",
      "Batch: 150 , Combined Loss: tensor(0.7584, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6327214241027832\n",
      "Batch: 151 , Combined Loss: tensor(0.6442, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14987075328826904\n",
      "Batch: 152 , Combined Loss: tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22863376140594482\n",
      "Batch: 153 , Combined Loss: tensor(0.8595, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5403773784637451\n",
      "Batch: 154 , Combined Loss: tensor(0.6869, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9196107387542725\n",
      "Batch: 155 , Combined Loss: tensor(0.8645, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16430675983428955\n",
      "Batch: 156 , Combined Loss: tensor(0.6702, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7547324895858765\n",
      "Batch: 157 , Combined Loss: tensor(0.6778, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5001991987228394\n",
      "Batch: 158 , Combined Loss: tensor(0.7324, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5312464237213135\n",
      "Batch: 159 , Combined Loss: tensor(0.6846, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.093907356262207\n",
      "Batch: 160 , Combined Loss: tensor(0.6198, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5356634259223938\n",
      "Batch: 161 , Combined Loss: tensor(0.6169, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6972349882125854\n",
      "Batch: 162 , Combined Loss: tensor(0.7467, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6369307041168213\n",
      "Batch: 163 , Combined Loss: tensor(0.6821, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6423808336257935\n",
      "Batch: 164 , Combined Loss: tensor(0.7201, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3456629514694214\n",
      "Batch: 165 , Combined Loss: tensor(0.8680, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4007655382156372\n",
      "Batch: 166 , Combined Loss: tensor(0.7740, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6083247661590576\n",
      "Batch: 167 , Combined Loss: tensor(0.8096, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3932473659515381\n",
      "Batch: 168 , Combined Loss: tensor(0.6682, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0130832195281982\n",
      "Batch: 169 , Combined Loss: tensor(0.7583, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4003685712814331\n",
      "Batch: 170 , Combined Loss: tensor(0.6574, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6770076751708984\n",
      "Batch: 171 , Combined Loss: tensor(0.8147, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0407252311706543\n",
      "Batch: 172 , Combined Loss: tensor(0.8754, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4251211881637573\n",
      "Batch: 173 , Combined Loss: tensor(0.8388, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8178384304046631\n",
      "Batch: 174 , Combined Loss: tensor(0.6540, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12356412410736084\n",
      "Batch: 175 , Combined Loss: tensor(0.6411, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6418901681900024\n",
      "Batch: 176 , Combined Loss: tensor(0.6848, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3210976719856262\n",
      "Batch: 177 , Combined Loss: tensor(0.7883, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.720976710319519\n",
      "Batch: 178 , Combined Loss: tensor(0.6953, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.27227330207824707\n",
      "Batch: 179 , Combined Loss: tensor(0.8444, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15126067399978638\n",
      "Batch: 180 , Combined Loss: tensor(0.5505, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11546981334686279\n",
      "Batch: 181 , Combined Loss: tensor(0.6975, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9656467437744141\n",
      "Batch: 182 , Combined Loss: tensor(0.6587, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.508086621761322\n",
      "Batch: 183 , Combined Loss: tensor(0.6546, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19215905666351318\n",
      "Batch: 184 , Combined Loss: tensor(0.7811, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5442668199539185\n",
      "Batch: 185 , Combined Loss: tensor(0.6649, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7222737073898315\n",
      "Batch: 186 , Combined Loss: tensor(0.6487, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7592304944992065\n",
      "Batch: 187 , Combined Loss: tensor(0.6609, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0530247688293457\n",
      "Batch: 188 , Combined Loss: tensor(0.6921, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2353001832962036\n",
      "Batch: 189 , Combined Loss: tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.938528299331665\n",
      "Batch: 190 , Combined Loss: tensor(0.9688, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.404654860496521\n",
      "Batch: 191 , Combined Loss: tensor(0.7117, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6174949407577515\n",
      "Batch: 192 , Combined Loss: tensor(0.8216, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.266491174697876\n",
      "Batch: 193 , Combined Loss: tensor(0.7613, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7432475090026855\n",
      "Batch: 194 , Combined Loss: tensor(0.7015, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5134303569793701\n",
      "Batch: 195 , Combined Loss: tensor(0.8334, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7120492458343506\n",
      "Batch: 196 , Combined Loss: tensor(0.6551, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4804433584213257\n",
      "Batch: 197 , Combined Loss: tensor(0.6813, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.513192892074585\n",
      "Batch: 198 , Combined Loss: tensor(0.8756, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1466735601425171\n",
      "Batch: 199 , Combined Loss: tensor(0.6997, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6984810829162598\n",
      "Batch: 200 , Combined Loss: tensor(0.7059, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.32368671894073486\n",
      "Batch: 201 , Combined Loss: tensor(0.6479, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22040534019470215\n",
      "Batch: 202 , Combined Loss: tensor(0.8100, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6621047258377075\n",
      "Batch: 203 , Combined Loss: tensor(0.8168, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40580129623413086\n",
      "Batch: 204 , Combined Loss: tensor(0.6425, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9023406505584717\n",
      "Batch: 205 , Combined Loss: tensor(0.8171, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23477423191070557\n",
      "Batch: 206 , Combined Loss: tensor(0.6509, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9107993841171265\n",
      "Batch: 207 , Combined Loss: tensor(0.7091, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7728432416915894\n",
      "Batch: 208 , Combined Loss: tensor(0.6097, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7172483205795288\n",
      "Batch: 209 , Combined Loss: tensor(0.6899, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1315484642982483\n",
      "Batch: 210 , Combined Loss: tensor(0.6902, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44051098823547363\n",
      "Batch: 211 , Combined Loss: tensor(0.7961, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8146119117736816\n",
      "Batch: 212 , Combined Loss: tensor(0.7046, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2694045305252075\n",
      "Batch: 213 , Combined Loss: tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.007351994514465332\n",
      "Batch: 214 , Combined Loss: tensor(0.7634, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4961928129196167\n",
      "Batch: 215 , Combined Loss: tensor(0.6160, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7636464834213257\n",
      "Batch: 216 , Combined Loss: tensor(0.5645, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30853402614593506\n",
      "Batch: 217 , Combined Loss: tensor(0.7582, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.695327639579773\n",
      "Batch: 218 , Combined Loss: tensor(0.7489, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23382198810577393\n",
      "Batch: 219 , Combined Loss: tensor(0.9309, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8165712356567383\n",
      "Batch: 220 , Combined Loss: tensor(0.5948, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32669317722320557\n",
      "Batch: 221 , Combined Loss: tensor(0.8610, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08006727695465088\n",
      "Batch: 222 , Combined Loss: tensor(0.8761, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2565704584121704\n",
      "Batch: 223 , Combined Loss: tensor(0.9813, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.061241865158081055\n",
      "Batch: 224 , Combined Loss: tensor(0.7649, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3970133066177368\n",
      "Batch: 225 , Combined Loss: tensor(0.7223, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07438725233078003\n",
      "Batch: 226 , Combined Loss: tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.430919885635376\n",
      "Batch: 227 , Combined Loss: tensor(0.6706, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6071922779083252\n",
      "Batch: 228 , Combined Loss: tensor(0.7581, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.31069183349609375\n",
      "Batch: 229 , Combined Loss: tensor(0.6681, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8194440603256226\n",
      "Batch: 230 , Combined Loss: tensor(0.6572, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9597460031509399\n",
      "Batch: 231 , Combined Loss: tensor(0.8453, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2664541006088257\n",
      "Batch: 232 , Combined Loss: tensor(0.6024, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44899141788482666\n",
      "Batch: 233 , Combined Loss: tensor(0.6259, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7149531841278076\n",
      "Batch: 234 , Combined Loss: tensor(0.7749, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5605834722518921\n",
      "Batch: 235 , Combined Loss: tensor(0.6433, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4897632598876953\n",
      "Batch: 236 , Combined Loss: tensor(0.6919, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2350483536720276\n",
      "Batch: 237 , Combined Loss: tensor(0.9740, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7518614530563354\n",
      "Batch: 238 , Combined Loss: tensor(0.6613, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09354507923126221\n",
      "Batch: 239 , Combined Loss: tensor(0.6209, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9216010570526123\n",
      "Batch: 240 , Combined Loss: tensor(0.6795, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3609117269515991\n",
      "Batch: 241 , Combined Loss: tensor(0.6753, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.012169599533081\n",
      "Batch: 242 , Combined Loss: tensor(0.8079, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5453126430511475\n",
      "Batch: 243 , Combined Loss: tensor(0.7238, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0846917629241943\n",
      "Batch: 244 , Combined Loss: tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.007406830787658691\n",
      "Batch: 245 , Combined Loss: tensor(0.7273, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4439525604248047\n",
      "Batch: 246 , Combined Loss: tensor(0.6052, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7931673526763916\n",
      "Batch: 247 , Combined Loss: tensor(0.7052, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8931868076324463\n",
      "Batch: 248 , Combined Loss: tensor(0.7021, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.519980788230896\n",
      "Batch: 249 , Combined Loss: tensor(0.6714, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6132586002349854\n",
      "Batch: 250 , Combined Loss: tensor(0.7746, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9660978317260742\n",
      "Batch: 251 , Combined Loss: tensor(0.7108, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7071691751480103\n",
      "Batch: 252 , Combined Loss: tensor(0.6824, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9419548511505127\n",
      "Batch: 253 , Combined Loss: tensor(0.7973, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18007934093475342\n",
      "Batch: 254 , Combined Loss: tensor(0.7596, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22749114036560059\n",
      "Batch: 255 , Combined Loss: tensor(0.6859, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3104146718978882\n",
      "Batch: 256 , Combined Loss: tensor(0.6587, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0334694385528564\n",
      "Batch: 257 , Combined Loss: tensor(0.8992, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9834924936294556\n",
      "Batch: 258 , Combined Loss: tensor(0.7444, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37457430362701416\n",
      "Batch: 259 , Combined Loss: tensor(0.7297, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5552459955215454\n",
      "Batch: 260 , Combined Loss: tensor(0.7001, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9716475009918213\n",
      "Batch: 261 , Combined Loss: tensor(1.0004, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3618776798248291\n",
      "Batch: 262 , Combined Loss: tensor(0.6793, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9573682546615601\n",
      "Batch: 263 , Combined Loss: tensor(0.6808, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0206334590911865\n",
      "Batch: 264 , Combined Loss: tensor(0.6737, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7926002740859985\n",
      "Batch: 265 , Combined Loss: tensor(0.6974, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.16263312101364136\n",
      "Batch: 266 , Combined Loss: tensor(0.7102, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06661689281463623\n",
      "Batch: 267 , Combined Loss: tensor(0.6803, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.725846529006958\n",
      "Batch: 268 , Combined Loss: tensor(0.6889, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0431499481201172\n",
      "Batch: 269 , Combined Loss: tensor(0.7654, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8791096210479736\n",
      "Batch: 270 , Combined Loss: tensor(0.6146, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.814651370048523\n",
      "Batch: 271 , Combined Loss: tensor(0.5991, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7002894878387451\n",
      "Batch: 272 , Combined Loss: tensor(0.5829, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8121461868286133\n",
      "Batch: 273 , Combined Loss: tensor(0.6412, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5012381076812744\n",
      "Batch: 274 , Combined Loss: tensor(0.7087, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5652235746383667\n",
      "Batch: 275 , Combined Loss: tensor(0.7081, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3371535539627075\n",
      "Batch: 276 , Combined Loss: tensor(0.6560, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9976208209991455\n",
      "Batch: 277 , Combined Loss: tensor(0.7464, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3691796064376831\n",
      "Batch: 278 , Combined Loss: tensor(0.6855, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8498321771621704\n",
      "Batch: 279 , Combined Loss: tensor(0.8389, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05259889364242554\n",
      "Batch: 280 , Combined Loss: tensor(0.6841, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10490012168884277\n",
      "Batch: 281 , Combined Loss: tensor(0.6858, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3101005554199219\n",
      "Batch: 282 , Combined Loss: tensor(0.7216, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1138277053833008\n",
      "Batch: 283 , Combined Loss: tensor(0.6290, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8828988075256348\n",
      "Batch: 284 , Combined Loss: tensor(0.6629, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7065081596374512\n",
      "Batch: 285 , Combined Loss: tensor(0.7438, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5742627382278442\n",
      "Batch: 286 , Combined Loss: tensor(0.6717, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.817400336265564\n",
      "Batch: 287 , Combined Loss: tensor(0.6898, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1804614067077637\n",
      "Batch: 288 , Combined Loss: tensor(0.6955, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4025542736053467\n",
      "Batch: 289 , Combined Loss: tensor(0.6588, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8736284971237183\n",
      "Batch: 290 , Combined Loss: tensor(0.7225, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9560238122940063\n",
      "Batch: 291 , Combined Loss: tensor(0.7183, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9388824701309204\n",
      "Batch: 292 , Combined Loss: tensor(0.8324, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.311065673828125\n",
      "Batch: 293 , Combined Loss: tensor(0.6613, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5888864994049072\n",
      "Batch: 294 , Combined Loss: tensor(0.6274, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6859157085418701\n",
      "Batch: 295 , Combined Loss: tensor(0.7371, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0059502124786377\n",
      "Batch: 296 , Combined Loss: tensor(0.6250, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8787205219268799\n",
      "Batch: 297 , Combined Loss: tensor(0.8145, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6234326362609863\n",
      "Batch: 298 , Combined Loss: tensor(0.6166, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.719403862953186\n",
      "Batch: 299 , Combined Loss: tensor(0.8279, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8686619997024536\n",
      "Batch: 300 , Combined Loss: tensor(0.6414, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05358469486236572\n",
      "Batch: 301 , Combined Loss: tensor(0.7766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7173938751220703\n",
      "Batch: 302 , Combined Loss: tensor(0.7198, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5682698488235474\n",
      "Batch: 303 , Combined Loss: tensor(0.6027, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8509722948074341\n",
      "Batch: 304 , Combined Loss: tensor(0.6527, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8114564418792725\n",
      "Batch: 305 , Combined Loss: tensor(0.7835, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0046141147613525\n",
      "Batch: 306 , Combined Loss: tensor(0.6514, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9664806127548218\n",
      "Batch: 307 , Combined Loss: tensor(0.6211, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0422616004943848\n",
      "Batch: 308 , Combined Loss: tensor(0.6705, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0310752391815186\n",
      "Batch: 309 , Combined Loss: tensor(0.6337, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03899383544921875\n",
      "Batch: 310 , Combined Loss: tensor(0.6819, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8019430637359619\n",
      "Batch: 311 , Combined Loss: tensor(0.7832, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4382387399673462\n",
      "Batch: 312 , Combined Loss: tensor(0.6448, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5851157903671265\n",
      "Batch: 313 , Combined Loss: tensor(0.6595, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.25926798582077026\n",
      "Batch: 314 , Combined Loss: tensor(0.8887, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5706373453140259\n",
      "Batch: 315 , Combined Loss: tensor(0.8897, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21593964099884033\n",
      "Batch: 316 , Combined Loss: tensor(0.6395, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1280243396759033\n",
      "Batch: 317 , Combined Loss: tensor(0.8547, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6887619495391846\n",
      "Batch: 318 , Combined Loss: tensor(0.8070, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9415571689605713\n",
      "Batch: 319 , Combined Loss: tensor(0.6492, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15708684921264648\n",
      "Batch: 320 , Combined Loss: tensor(0.6262, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47274506092071533\n",
      "Batch: 321 , Combined Loss: tensor(0.8403, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4126415252685547\n",
      "Batch: 322 , Combined Loss: tensor(0.8067, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21859389543533325\n",
      "Batch: 323 , Combined Loss: tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39331841468811035\n",
      "Batch: 324 , Combined Loss: tensor(0.9210, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.134407639503479\n",
      "Batch: 325 , Combined Loss: tensor(0.6501, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34453296661376953\n",
      "Batch: 326 , Combined Loss: tensor(0.6091, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0673000812530518\n",
      "Batch: 327 , Combined Loss: tensor(0.7088, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8567198514938354\n",
      "Batch: 328 , Combined Loss: tensor(0.9031, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6006555557250977\n",
      "Batch: 329 , Combined Loss: tensor(0.6574, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3414876461029053\n",
      "Batch: 330 , Combined Loss: tensor(0.7045, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.242828130722046\n",
      "Batch: 331 , Combined Loss: tensor(0.7183, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8511425256729126\n",
      "Batch: 332 , Combined Loss: tensor(0.6470, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.117067575454712\n",
      "Batch: 333 , Combined Loss: tensor(0.7351, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6293988227844238\n",
      "Batch: 334 , Combined Loss: tensor(0.7299, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3497471809387207\n",
      "Batch: 335 , Combined Loss: tensor(0.7059, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7627617120742798\n",
      "Batch: 336 , Combined Loss: tensor(0.9209, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0446643829345703\n",
      "Batch: 337 , Combined Loss: tensor(0.8683, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10600757598876953\n",
      "Batch: 338 , Combined Loss: tensor(0.8898, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6111727952957153\n",
      "Batch: 339 , Combined Loss: tensor(0.6025, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6593285799026489\n",
      "Batch: 340 , Combined Loss: tensor(0.9279, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07921844720840454\n",
      "Batch: 341 , Combined Loss: tensor(0.7059, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9129234552383423\n",
      "Batch: 342 , Combined Loss: tensor(1.1092, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41131043434143066\n",
      "Batch: 343 , Combined Loss: tensor(0.6142, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4113481044769287\n",
      "Batch: 344 , Combined Loss: tensor(0.8168, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6316795349121094\n",
      "Batch: 345 , Combined Loss: tensor(0.7197, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8427585363388062\n",
      "Batch: 346 , Combined Loss: tensor(0.6294, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7825609445571899\n",
      "Batch: 347 , Combined Loss: tensor(0.6915, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8406611680984497\n",
      "Batch: 348 , Combined Loss: tensor(0.7044, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6706558465957642\n",
      "Batch: 349 , Combined Loss: tensor(0.6421, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5867986679077148\n",
      "Batch: 350 , Combined Loss: tensor(0.6347, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7527657747268677\n",
      "Batch: 351 , Combined Loss: tensor(0.6426, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10703182220458984\n",
      "Batch: 352 , Combined Loss: tensor(0.9222, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8916621208190918\n",
      "Batch: 353 , Combined Loss: tensor(0.7686, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7085011005401611\n",
      "Batch: 354 , Combined Loss: tensor(0.7649, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39760422706604004\n",
      "Batch: 355 , Combined Loss: tensor(0.7446, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2840597629547119\n",
      "Batch: 356 , Combined Loss: tensor(0.6892, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34011733531951904\n",
      "Batch: 357 , Combined Loss: tensor(0.7714, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10699105262756348\n",
      "Batch: 358 , Combined Loss: tensor(0.7342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1572137475013733\n",
      "Batch: 359 , Combined Loss: tensor(0.7323, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6753784418106079\n",
      "Batch: 360 , Combined Loss: tensor(0.6797, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4719655513763428\n",
      "Batch: 361 , Combined Loss: tensor(0.6359, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1828749179840088\n",
      "Batch: 362 , Combined Loss: tensor(0.7337, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1721886396408081\n",
      "Batch: 363 , Combined Loss: tensor(0.8501, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2689831852912903\n",
      "Batch: 364 , Combined Loss: tensor(0.6619, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4460587501525879\n",
      "Batch: 365 , Combined Loss: tensor(0.6835, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8698525428771973\n",
      "Batch: 366 , Combined Loss: tensor(0.8983, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9032926559448242\n",
      "Batch: 367 , Combined Loss: tensor(0.6656, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31674468517303467\n",
      "Batch: 368 , Combined Loss: tensor(0.7596, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4751734137535095\n",
      "Batch: 369 , Combined Loss: tensor(0.7937, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6704182624816895\n",
      "Batch: 370 , Combined Loss: tensor(1.1687, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.881821870803833\n",
      "Batch: 371 , Combined Loss: tensor(0.7253, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7826939821243286\n",
      "Batch: 372 , Combined Loss: tensor(0.6545, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5932434797286987\n",
      "Batch: 373 , Combined Loss: tensor(0.6593, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22443509101867676\n",
      "Batch: 374 , Combined Loss: tensor(0.7518, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5767056941986084\n",
      "Batch: 375 , Combined Loss: tensor(0.7262, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43984055519104004\n",
      "Batch: 376 , Combined Loss: tensor(0.5956, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.750137209892273\n",
      "Batch: 377 , Combined Loss: tensor(0.6765, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9196343421936035\n",
      "Batch: 378 , Combined Loss: tensor(0.7707, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15506374835968018\n",
      "Batch: 379 , Combined Loss: tensor(0.6387, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.555884599685669\n",
      "Batch: 380 , Combined Loss: tensor(0.7074, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.005659639835357666\n",
      "Batch: 381 , Combined Loss: tensor(0.7118, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8083838224411011\n",
      "Batch: 382 , Combined Loss: tensor(0.6993, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9528859853744507\n",
      "Batch: 383 , Combined Loss: tensor(1.0602, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3714115619659424\n",
      "Batch: 384 , Combined Loss: tensor(0.6620, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7742964029312134\n",
      "Batch: 385 , Combined Loss: tensor(0.6819, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8793220520019531\n",
      "Batch: 386 , Combined Loss: tensor(0.6734, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45956385135650635\n",
      "Batch: 387 , Combined Loss: tensor(0.7657, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3056114912033081\n",
      "Batch: 388 , Combined Loss: tensor(0.7067, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.290771484375\n",
      "Batch: 389 , Combined Loss: tensor(0.7019, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5043723583221436\n",
      "Batch: 390 , Combined Loss: tensor(0.7117, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5333964824676514\n",
      "Batch: 391 , Combined Loss: tensor(0.8009, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6581591367721558\n",
      "Batch: 392 , Combined Loss: tensor(0.7806, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20242798328399658\n",
      "Batch: 393 , Combined Loss: tensor(0.7398, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6334842443466187\n",
      "Batch: 394 , Combined Loss: tensor(0.8117, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35649120807647705\n",
      "Batch: 395 , Combined Loss: tensor(0.6736, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5213618278503418\n",
      "Batch: 396 , Combined Loss: tensor(0.6961, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6846835613250732\n",
      "Batch: 397 , Combined Loss: tensor(0.8987, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7904911041259766\n",
      "Batch: 398 , Combined Loss: tensor(0.7515, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5840582847595215\n",
      "Batch: 399 , Combined Loss: tensor(0.6808, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3358036279678345\n",
      "Batch: 400 , Combined Loss: tensor(0.6414, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5781407356262207\n",
      "Batch: 401 , Combined Loss: tensor(0.7783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43421924114227295\n",
      "Batch: 402 , Combined Loss: tensor(0.7504, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3474576473236084\n",
      "Batch: 403 , Combined Loss: tensor(0.7866, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2482762336730957\n",
      "Batch: 404 , Combined Loss: tensor(0.7761, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3731956481933594\n",
      "Batch: 405 , Combined Loss: tensor(0.7850, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.014666736125946045\n",
      "Batch: 406 , Combined Loss: tensor(0.7551, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4367203712463379\n",
      "Batch: 407 , Combined Loss: tensor(0.6552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6344220638275146\n",
      "Batch: 408 , Combined Loss: tensor(0.6661, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6365189552307129\n",
      "Batch: 409 , Combined Loss: tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6664350032806396\n",
      "Batch: 410 , Combined Loss: tensor(0.9272, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8240811824798584\n",
      "Batch: 411 , Combined Loss: tensor(0.6913, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7956141233444214\n",
      "Batch: 412 , Combined Loss: tensor(0.6196, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2666987180709839\n",
      "Batch: 413 , Combined Loss: tensor(0.8728, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1464042067527771\n",
      "Batch: 414 , Combined Loss: tensor(0.7083, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8819868564605713\n",
      "Batch: 415 , Combined Loss: tensor(0.6499, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.617887020111084\n",
      "Batch: 416 , Combined Loss: tensor(0.7089, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.252038836479187\n",
      "Batch: 417 , Combined Loss: tensor(0.6144, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7623236179351807\n",
      "Batch: 418 , Combined Loss: tensor(0.8161, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32447361946105957\n",
      "Batch: 419 , Combined Loss: tensor(0.6303, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.729272723197937\n",
      "Batch: 420 , Combined Loss: tensor(0.6361, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8952178955078125\n",
      "Batch: 421 , Combined Loss: tensor(0.6138, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3722257614135742\n",
      "Batch: 422 , Combined Loss: tensor(0.6414, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9377551078796387\n",
      "Batch: 423 , Combined Loss: tensor(0.6970, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.098999261856079\n",
      "Batch: 424 , Combined Loss: tensor(0.7106, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19827866554260254\n",
      "Batch: 425 , Combined Loss: tensor(0.6361, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22023212909698486\n",
      "Batch: 426 , Combined Loss: tensor(0.6938, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04283267259597778\n",
      "Batch: 427 , Combined Loss: tensor(0.6649, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.005111396312713623\n",
      "Batch: 428 , Combined Loss: tensor(0.5757, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5226526260375977\n",
      "Batch: 429 , Combined Loss: tensor(0.6582, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8348692655563354\n",
      "Batch: 430 , Combined Loss: tensor(0.8207, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9358015060424805\n",
      "Batch: 431 , Combined Loss: tensor(0.7550, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6895856857299805\n",
      "Batch: 432 , Combined Loss: tensor(0.6940, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6887950897216797\n",
      "Batch: 433 , Combined Loss: tensor(0.7347, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26983559131622314\n",
      "Batch: 434 , Combined Loss: tensor(0.6843, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17439472675323486\n",
      "Batch: 435 , Combined Loss: tensor(0.7447, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19008231163024902\n",
      "Batch: 436 , Combined Loss: tensor(0.7702, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8461601734161377\n",
      "Batch: 437 , Combined Loss: tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6885637044906616\n",
      "Batch: 438 , Combined Loss: tensor(0.6640, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.015380620956421\n",
      "Batch: 439 , Combined Loss: tensor(0.7442, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35845887660980225\n",
      "Batch: 440 , Combined Loss: tensor(0.6392, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7964386940002441\n",
      "Batch: 441 , Combined Loss: tensor(0.6515, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0830883979797363\n",
      "Batch: 442 , Combined Loss: tensor(0.8763, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5325218439102173\n",
      "Batch: 443 , Combined Loss: tensor(0.9070, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3766012191772461\n",
      "Batch: 444 , Combined Loss: tensor(0.7250, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0333571434020996\n",
      "Batch: 445 , Combined Loss: tensor(0.6496, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15659546852111816\n",
      "Batch: 446 , Combined Loss: tensor(0.6757, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9550151824951172\n",
      "Batch: 447 , Combined Loss: tensor(0.7121, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6624082326889038\n",
      "Batch: 448 , Combined Loss: tensor(0.6505, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6064882278442383\n",
      "Batch: 449 , Combined Loss: tensor(0.6299, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8167963027954102\n",
      "Batch: 450 , Combined Loss: tensor(0.7089, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7226200103759766\n",
      "Batch: 451 , Combined Loss: tensor(0.8371, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7401535511016846\n",
      "Batch: 452 , Combined Loss: tensor(0.5603, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13496029376983643\n",
      "Batch: 453 , Combined Loss: tensor(0.6675, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6193510293960571\n",
      "Batch: 454 , Combined Loss: tensor(0.8080, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9055122137069702\n",
      "Batch: 455 , Combined Loss: tensor(0.7055, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0861706733703613\n",
      "Batch: 456 , Combined Loss: tensor(0.6180, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5183590650558472\n",
      "Batch: 457 , Combined Loss: tensor(0.6733, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6093436479568481\n",
      "Batch: 458 , Combined Loss: tensor(0.6561, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8171384334564209\n",
      "Batch: 459 , Combined Loss: tensor(0.6818, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9658172130584717\n",
      "Batch: 460 , Combined Loss: tensor(0.7473, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4532485008239746\n",
      "Batch: 461 , Combined Loss: tensor(0.9065, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6273434162139893\n",
      "Batch: 462 , Combined Loss: tensor(0.6588, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3308584690093994\n",
      "Batch: 463 , Combined Loss: tensor(0.7380, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10231459140777588\n",
      "Batch: 464 , Combined Loss: tensor(0.6804, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8910789489746094\n",
      "Batch: 465 , Combined Loss: tensor(0.7413, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5154813528060913\n",
      "Batch: 466 , Combined Loss: tensor(0.9501, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6079280376434326\n",
      "Batch: 467 , Combined Loss: tensor(0.8500, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13849008083343506\n",
      "Batch: 468 , Combined Loss: tensor(0.6656, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.511649489402771\n",
      "Batch: 469 , Combined Loss: tensor(0.7757, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8348721265792847\n",
      "Batch: 470 , Combined Loss: tensor(0.6960, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11503750085830688\n",
      "Batch: 471 , Combined Loss: tensor(0.7374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0434904098510742\n",
      "Batch: 472 , Combined Loss: tensor(0.8007, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6666920185089111\n",
      "Batch: 473 , Combined Loss: tensor(0.7061, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7334246635437012\n",
      "Batch: 474 , Combined Loss: tensor(0.6890, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2860182523727417\n",
      "Batch: 475 , Combined Loss: tensor(0.6149, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.739450216293335\n",
      "Batch: 476 , Combined Loss: tensor(0.5945, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34566736221313477\n",
      "Batch: 477 , Combined Loss: tensor(0.6721, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7275876998901367\n",
      "Batch: 478 , Combined Loss: tensor(0.7998, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5625443458557129\n",
      "Batch: 479 , Combined Loss: tensor(0.6740, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19733589887619019\n",
      "Batch: 480 , Combined Loss: tensor(0.8184, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5680198669433594\n",
      "Batch: 481 , Combined Loss: tensor(0.7371, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8011360168457031\n",
      "Batch: 482 , Combined Loss: tensor(0.6652, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.693392276763916\n",
      "Batch: 483 , Combined Loss: tensor(0.6369, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31485533714294434\n",
      "Batch: 484 , Combined Loss: tensor(0.7445, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0176239013671875\n",
      "Batch: 485 , Combined Loss: tensor(1.1558, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21551263332366943\n",
      "Batch: 486 , Combined Loss: tensor(0.7302, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23311376571655273\n",
      "Batch: 487 , Combined Loss: tensor(0.6844, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8443074226379395\n",
      "Batch: 488 , Combined Loss: tensor(0.6364, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04340159893035889\n",
      "Batch: 489 , Combined Loss: tensor(0.7606, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7401533126831055\n",
      "Batch: 490 , Combined Loss: tensor(0.6762, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9700744152069092\n",
      "Batch: 491 , Combined Loss: tensor(0.6159, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18810665607452393\n",
      "Batch: 492 , Combined Loss: tensor(0.8131, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7952898740768433\n",
      "Batch: 493 , Combined Loss: tensor(0.7196, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7594929933547974\n",
      "Batch: 494 , Combined Loss: tensor(0.8825, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11769771575927734\n",
      "Batch: 495 , Combined Loss: tensor(0.6758, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6764490604400635\n",
      "Batch: 496 , Combined Loss: tensor(0.9822, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5379228591918945\n",
      "Batch: 497 , Combined Loss: tensor(0.7016, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7261948585510254\n",
      "Batch: 498 , Combined Loss: tensor(0.6570, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.796850323677063\n",
      "Batch: 499 , Combined Loss: tensor(0.7383, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9396802186965942\n",
      "Batch: 500 , Combined Loss: tensor(0.8194, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.276195764541626\n",
      "Batch: 501 , Combined Loss: tensor(0.6432, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0451350212097168\n",
      "Batch: 502 , Combined Loss: tensor(0.6065, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4130587577819824\n",
      "Batch: 503 , Combined Loss: tensor(0.7347, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0042389631271362305\n",
      "Batch: 504 , Combined Loss: tensor(0.8719, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.34617340564727783\n",
      "Batch: 505 , Combined Loss: tensor(0.6582, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1279528141021729\n",
      "Batch: 506 , Combined Loss: tensor(1.0361, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5424907207489014\n",
      "Batch: 507 , Combined Loss: tensor(0.7269, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44979989528656006\n",
      "Batch: 508 , Combined Loss: tensor(0.7206, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9196354150772095\n",
      "Batch: 509 , Combined Loss: tensor(0.7049, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37040627002716064\n",
      "Batch: 510 , Combined Loss: tensor(0.8178, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8220261335372925\n",
      "Batch: 511 , Combined Loss: tensor(0.8371, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.532035231590271\n",
      "Batch: 512 , Combined Loss: tensor(0.7245, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8343485593795776\n",
      "Batch: 513 , Combined Loss: tensor(0.7681, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6292053461074829\n",
      "Batch: 514 , Combined Loss: tensor(0.7030, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9938502311706543\n",
      "Batch: 515 , Combined Loss: tensor(0.6503, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.145233154296875\n",
      "Batch: 516 , Combined Loss: tensor(1.0769, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20721828937530518\n",
      "Batch: 517 , Combined Loss: tensor(0.6180, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8571852445602417\n",
      "Batch: 518 , Combined Loss: tensor(0.9177, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25103044509887695\n",
      "Batch: 519 , Combined Loss: tensor(0.6107, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1100032329559326\n",
      "Batch: 520 , Combined Loss: tensor(0.5563, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4338836669921875\n",
      "Batch: 521 , Combined Loss: tensor(0.9054, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1072320938110352\n",
      "Batch: 522 , Combined Loss: tensor(0.8714, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8647595643997192\n",
      "Batch: 523 , Combined Loss: tensor(0.7930, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6185106039047241\n",
      "Batch: 524 , Combined Loss: tensor(0.6443, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1712438464164734\n",
      "Batch: 525 , Combined Loss: tensor(0.8658, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7922641038894653\n",
      "Batch: 526 , Combined Loss: tensor(0.6677, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8425877094268799\n",
      "Batch: 527 , Combined Loss: tensor(0.9914, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6736437082290649\n",
      "Batch: 528 , Combined Loss: tensor(0.9129, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5111044645309448\n",
      "Batch: 529 , Combined Loss: tensor(0.8155, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20377862453460693\n",
      "Batch: 530 , Combined Loss: tensor(0.8738, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4913339614868164\n",
      "Batch: 531 , Combined Loss: tensor(0.8031, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20779919624328613\n",
      "Batch: 532 , Combined Loss: tensor(0.7809, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.033165693283081\n",
      "Batch: 533 , Combined Loss: tensor(0.6870, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8951621055603027\n",
      "Batch: 534 , Combined Loss: tensor(1.3389, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5457767248153687\n",
      "Batch: 535 , Combined Loss: tensor(0.7528, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.00015854835510253906\n",
      "Batch: 536 , Combined Loss: tensor(0.6768, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5719391107559204\n",
      "Batch: 537 , Combined Loss: tensor(0.7793, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4959428310394287\n",
      "Batch: 538 , Combined Loss: tensor(1.0365, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5071142911911011\n",
      "Batch: 539 , Combined Loss: tensor(0.7313, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8170686960220337\n",
      "Batch: 540 , Combined Loss: tensor(0.6879, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7533401250839233\n",
      "Batch: 541 , Combined Loss: tensor(0.8345, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8895953893661499\n",
      "Batch: 542 , Combined Loss: tensor(0.6848, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8679118156433105\n",
      "Batch: 543 , Combined Loss: tensor(0.6783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9490294456481934\n",
      "Batch: 544 , Combined Loss: tensor(0.6707, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7465531826019287\n",
      "Batch: 545 , Combined Loss: tensor(0.7511, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9316953420639038\n",
      "Batch: 546 , Combined Loss: tensor(0.7083, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5048716068267822\n",
      "Batch: 547 , Combined Loss: tensor(0.6432, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7245625257492065\n",
      "Batch: 548 , Combined Loss: tensor(0.6788, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2859996557235718\n",
      "Batch: 549 , Combined Loss: tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7178572416305542\n",
      "Batch: 550 , Combined Loss: tensor(0.6476, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.005633533000946045\n",
      "Batch: 551 , Combined Loss: tensor(0.8182, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8287568092346191\n",
      "Batch: 552 , Combined Loss: tensor(0.7461, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20440173149108887\n",
      "Batch: 553 , Combined Loss: tensor(0.8193, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9776260852813721\n",
      "Batch: 554 , Combined Loss: tensor(0.7058, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23514318466186523\n",
      "Batch: 555 , Combined Loss: tensor(0.7473, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8972628116607666\n",
      "Batch: 556 , Combined Loss: tensor(0.7202, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7351244688034058\n",
      "Batch: 557 , Combined Loss: tensor(0.5902, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4867112636566162\n",
      "Batch: 558 , Combined Loss: tensor(0.6630, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24078291654586792\n",
      "Batch: 559 , Combined Loss: tensor(0.8556, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24869036674499512\n",
      "Batch: 560 , Combined Loss: tensor(0.7624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.680932879447937\n",
      "Batch: 561 , Combined Loss: tensor(0.6137, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7750526666641235\n",
      "Batch: 562 , Combined Loss: tensor(0.7200, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10052597522735596\n",
      "Batch: 563 , Combined Loss: tensor(0.6682, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4596583843231201\n",
      "Batch: 564 , Combined Loss: tensor(0.6354, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9024204015731812\n",
      "Batch: 565 , Combined Loss: tensor(0.7512, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9254225492477417\n",
      "Batch: 566 , Combined Loss: tensor(0.6491, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8933422565460205\n",
      "Batch: 567 , Combined Loss: tensor(0.8442, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.422792911529541\n",
      "Batch: 568 , Combined Loss: tensor(0.7207, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8123595714569092\n",
      "Batch: 569 , Combined Loss: tensor(0.6083, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7122420072555542\n",
      "Batch: 570 , Combined Loss: tensor(0.7191, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.047814130783081\n",
      "Batch: 571 , Combined Loss: tensor(0.6947, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42673957347869873\n",
      "Batch: 572 , Combined Loss: tensor(0.7668, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6757688522338867\n",
      "Batch: 573 , Combined Loss: tensor(0.6666, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9578393697738647\n",
      "Batch: 574 , Combined Loss: tensor(0.6332, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5059596300125122\n",
      "Batch: 575 , Combined Loss: tensor(0.6471, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.462666392326355\n",
      "Batch: 576 , Combined Loss: tensor(0.7099, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41220736503601074\n",
      "Batch: 577 , Combined Loss: tensor(0.6169, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9566483497619629\n",
      "Batch: 578 , Combined Loss: tensor(0.7881, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8146179914474487\n",
      "Batch: 579 , Combined Loss: tensor(0.6939, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8722634315490723\n",
      "Batch: 580 , Combined Loss: tensor(0.7744, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6131919622421265\n",
      "Batch: 581 , Combined Loss: tensor(0.6532, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.327877402305603\n",
      "Batch: 582 , Combined Loss: tensor(0.7033, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07906866073608398\n",
      "Batch: 583 , Combined Loss: tensor(0.6807, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7182590961456299\n",
      "Batch: 584 , Combined Loss: tensor(0.7371, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8740495443344116\n",
      "Batch: 585 , Combined Loss: tensor(0.7619, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8665863275527954\n",
      "Batch: 586 , Combined Loss: tensor(0.7064, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21112722158432007\n",
      "Batch: 587 , Combined Loss: tensor(0.7500, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6557737588882446\n",
      "Batch: 588 , Combined Loss: tensor(0.6164, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8771967887878418\n",
      "Batch: 589 , Combined Loss: tensor(0.7703, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3246893882751465\n",
      "Batch: 590 , Combined Loss: tensor(0.7348, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15217262506484985\n",
      "Batch: 591 , Combined Loss: tensor(0.6768, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3962365388870239\n",
      "Batch: 592 , Combined Loss: tensor(0.7060, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.988959789276123\n",
      "Batch: 593 , Combined Loss: tensor(0.6599, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6571571826934814\n",
      "Batch: 594 , Combined Loss: tensor(0.6573, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7490712404251099\n",
      "Batch: 595 , Combined Loss: tensor(0.6457, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9722317457199097\n",
      "Batch: 596 , Combined Loss: tensor(0.9965, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7147570848464966\n",
      "Batch: 597 , Combined Loss: tensor(0.7887, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7173280715942383\n",
      "Batch: 598 , Combined Loss: tensor(0.7352, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9310733079910278\n",
      "Batch: 599 , Combined Loss: tensor(0.6154, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7569047212600708\n",
      "Batch: 600 , Combined Loss: tensor(0.7893, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7687731981277466\n",
      "Batch: 601 , Combined Loss: tensor(0.6307, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.696174144744873\n",
      "Batch: 602 , Combined Loss: tensor(0.7064, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4733138084411621\n",
      "Batch: 603 , Combined Loss: tensor(0.7120, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6785637140274048\n",
      "Batch: 604 , Combined Loss: tensor(0.6982, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17597156763076782\n",
      "Batch: 605 , Combined Loss: tensor(0.6864, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8084719181060791\n",
      "Batch: 606 , Combined Loss: tensor(0.6681, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7577892541885376\n",
      "Batch: 607 , Combined Loss: tensor(0.6193, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4061305522918701\n",
      "Batch: 608 , Combined Loss: tensor(0.7473, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9021741151809692\n",
      "Batch: 609 , Combined Loss: tensor(0.9394, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6338902711868286\n",
      "Batch: 610 , Combined Loss: tensor(0.8251, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5470947027206421\n",
      "Batch: 611 , Combined Loss: tensor(0.6595, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6648035049438477\n",
      "Batch: 612 , Combined Loss: tensor(0.7265, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3720889687538147\n",
      "Batch: 613 , Combined Loss: tensor(0.6814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43298041820526123\n",
      "Batch: 614 , Combined Loss: tensor(0.9458, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7655291557312012\n",
      "Batch: 615 , Combined Loss: tensor(0.7450, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6160972118377686\n",
      "Batch: 616 , Combined Loss: tensor(0.7484, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9054007530212402\n",
      "Batch: 617 , Combined Loss: tensor(0.6059, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45617246627807617\n",
      "Batch: 618 , Combined Loss: tensor(0.6705, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6011753082275391\n",
      "Batch: 619 , Combined Loss: tensor(0.8291, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.834381103515625\n",
      "Batch: 620 , Combined Loss: tensor(0.7941, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8889508247375488\n",
      "Batch: 621 , Combined Loss: tensor(0.6382, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.18902474641799927\n",
      "Batch: 622 , Combined Loss: tensor(0.9597, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4610253572463989\n",
      "Batch: 623 , Combined Loss: tensor(0.6452, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0811352729797363\n",
      "Batch: 624 , Combined Loss: tensor(0.6983, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7252484560012817\n",
      "Batch: 625 , Combined Loss: tensor(0.7759, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37643563747406006\n",
      "Batch: 626 , Combined Loss: tensor(0.6694, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8355592489242554\n",
      "Batch: 627 , Combined Loss: tensor(0.8041, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9454073905944824\n",
      "Batch: 628 , Combined Loss: tensor(0.7404, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8337290287017822\n",
      "----------Epoch 14, Loss: 0.7283276045644606, Accuracy: 0.9566751322420299, Dice Coef: [0.9799135919595182, 0.5151454195397509, 0.5489934538430687, 0.641599881896955], Dice Coef Necrotic: 0.9248261037386365, Dice Coef Edema: 0.9259089961284687, Dice Coef Enhancing: 0.8756068102364959, Sensitivity: [0.9623375503740175, 0.7129992896599165, 0.8539988255462889, 0.8629226174993242], Specificity: [0.9719511387079054, 0.9963661760139162, 0.9678306084937625, 0.993062874281539], Precision: [0.9983103783217826, 0.4825505316893458, 0.43689194051848207, 0.5558384611127515]\n",
      "Saving without nn.DataParallel\n",
      "Batch: 0 , Combined Loss: tensor(0.7740, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15463948249816895\n",
      "Batch: 1 , Combined Loss: tensor(0.8059, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8378328084945679\n",
      "Batch: 2 , Combined Loss: tensor(0.5860, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5306365489959717\n",
      "Batch: 3 , Combined Loss: tensor(0.6744, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8925323486328125\n",
      "Batch: 4 , Combined Loss: tensor(0.7075, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5885311365127563\n",
      "Batch: 5 , Combined Loss: tensor(0.6411, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8670988082885742\n",
      "Batch: 6 , Combined Loss: tensor(0.6292, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5542274713516235\n",
      "Batch: 7 , Combined Loss: tensor(0.7312, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46730661392211914\n",
      "Batch: 8 , Combined Loss: tensor(0.6752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7472833395004272\n",
      "Batch: 9 , Combined Loss: tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17635703086853027\n",
      "Batch: 10 , Combined Loss: tensor(0.8447, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5445529222488403\n",
      "Batch: 11 , Combined Loss: tensor(0.6679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8885847330093384\n",
      "Batch: 12 , Combined Loss: tensor(0.6919, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9762972593307495\n",
      "Batch: 13 , Combined Loss: tensor(0.7970, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9093341827392578\n",
      "Batch: 14 , Combined Loss: tensor(0.6459, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8379806280136108\n",
      "Batch: 15 , Combined Loss: tensor(0.7923, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8045433759689331\n",
      "Batch: 16 , Combined Loss: tensor(0.6899, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21104294061660767\n",
      "Batch: 17 , Combined Loss: tensor(0.8769, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.752596378326416\n",
      "Batch: 18 , Combined Loss: tensor(0.7081, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9137104749679565\n",
      "Batch: 19 , Combined Loss: tensor(0.9077, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8194267749786377\n",
      "Batch: 20 , Combined Loss: tensor(0.7368, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8593961000442505\n",
      "Batch: 21 , Combined Loss: tensor(0.7278, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9464367628097534\n",
      "Batch: 22 , Combined Loss: tensor(0.6642, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8004437685012817\n",
      "Batch: 23 , Combined Loss: tensor(0.6276, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5114153623580933\n",
      "Batch: 24 , Combined Loss: tensor(0.6971, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2732580900192261\n",
      "Batch: 25 , Combined Loss: tensor(0.6860, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9338741302490234\n",
      "Batch: 26 , Combined Loss: tensor(0.7345, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8604222536087036\n",
      "Batch: 27 , Combined Loss: tensor(0.6545, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9200444221496582\n",
      "Batch: 28 , Combined Loss: tensor(0.7048, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5289216041564941\n",
      "Batch: 29 , Combined Loss: tensor(0.7084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1431647539138794\n",
      "Batch: 30 , Combined Loss: tensor(0.7667, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0141282081604004\n",
      "Batch: 31 , Combined Loss: tensor(0.6548, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3731266260147095\n",
      "Batch: 32 , Combined Loss: tensor(0.6631, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7532801628112793\n",
      "Batch: 33 , Combined Loss: tensor(0.7228, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.243967056274414\n",
      "Batch: 34 , Combined Loss: tensor(0.7855, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7453500032424927\n",
      "Batch: 35 , Combined Loss: tensor(0.9604, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4590491056442261\n",
      "Batch: 36 , Combined Loss: tensor(0.8671, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9346864223480225\n",
      "Batch: 37 , Combined Loss: tensor(0.7463, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9770164489746094\n",
      "Batch: 38 , Combined Loss: tensor(0.7775, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26789987087249756\n",
      "Batch: 39 , Combined Loss: tensor(0.7610, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.340149462223053\n",
      "Batch: 40 , Combined Loss: tensor(0.5937, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43283212184906006\n",
      "Batch: 41 , Combined Loss: tensor(0.6149, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7704591751098633\n",
      "Batch: 42 , Combined Loss: tensor(0.6665, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0294783115386963\n",
      "Batch: 43 , Combined Loss: tensor(0.6614, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.634140133857727\n",
      "Batch: 44 , Combined Loss: tensor(0.6890, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.019054174423217773\n",
      "Batch: 45 , Combined Loss: tensor(0.7900, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9586416482925415\n",
      "Batch: 46 , Combined Loss: tensor(0.6985, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5678091049194336\n",
      "Batch: 47 , Combined Loss: tensor(0.7623, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7912640571594238\n",
      "Batch: 48 , Combined Loss: tensor(0.6383, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1044793128967285\n",
      "Batch: 49 , Combined Loss: tensor(0.6881, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.808082103729248\n",
      "Batch: 50 , Combined Loss: tensor(0.6568, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0041327476501465\n",
      "Batch: 51 , Combined Loss: tensor(0.5904, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.806289553642273\n",
      "Batch: 52 , Combined Loss: tensor(0.8531, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4914062023162842\n",
      "Batch: 53 , Combined Loss: tensor(0.6974, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.882099986076355\n",
      "Batch: 54 , Combined Loss: tensor(0.9681, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30388784408569336\n",
      "Batch: 55 , Combined Loss: tensor(0.7249, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8809546232223511\n",
      "Batch: 56 , Combined Loss: tensor(0.6161, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7192732095718384\n",
      "Batch: 57 , Combined Loss: tensor(0.7083, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5692518949508667\n",
      "Batch: 58 , Combined Loss: tensor(0.7253, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10763883590698242\n",
      "Batch: 59 , Combined Loss: tensor(0.7372, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1998559832572937\n",
      "Batch: 60 , Combined Loss: tensor(0.7835, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2665684223175049\n",
      "Batch: 61 , Combined Loss: tensor(0.8348, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1041831374168396\n",
      "Batch: 62 , Combined Loss: tensor(0.6994, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6990487575531006\n",
      "Batch: 63 , Combined Loss: tensor(0.7092, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7576462030410767\n",
      "Batch: 64 , Combined Loss: tensor(0.7373, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9755208492279053\n",
      "Batch: 65 , Combined Loss: tensor(0.7240, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6276053190231323\n",
      "Batch: 66 , Combined Loss: tensor(1.0536, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.665848970413208\n",
      "Batch: 67 , Combined Loss: tensor(0.7068, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1858842968940735\n",
      "Batch: 68 , Combined Loss: tensor(0.7697, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6920583248138428\n",
      "Batch: 69 , Combined Loss: tensor(0.6671, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7884436845779419\n",
      "Batch: 70 , Combined Loss: tensor(0.7847, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34411323070526123\n",
      "Batch: 71 , Combined Loss: tensor(0.6657, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09887278079986572\n",
      "Batch: 72 , Combined Loss: tensor(0.6559, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7973815202713013\n",
      "Batch: 73 , Combined Loss: tensor(0.7048, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7958419322967529\n",
      "Batch: 74 , Combined Loss: tensor(0.6921, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.076812505722046\n",
      "Batch: 75 , Combined Loss: tensor(0.6748, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7023805379867554\n",
      "Batch: 76 , Combined Loss: tensor(0.6687, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7988733053207397\n",
      "Batch: 77 , Combined Loss: tensor(0.7576, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25883233547210693\n",
      "Batch: 78 , Combined Loss: tensor(0.7683, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8710129261016846\n",
      "Batch: 79 , Combined Loss: tensor(0.6747, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3172518014907837\n",
      "Batch: 80 , Combined Loss: tensor(0.6918, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41576218605041504\n",
      "Batch: 81 , Combined Loss: tensor(0.7038, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3768397569656372\n",
      "Batch: 82 , Combined Loss: tensor(0.6788, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7570376396179199\n",
      "Batch: 83 , Combined Loss: tensor(0.6833, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0059728622436523\n",
      "Batch: 84 , Combined Loss: tensor(0.6824, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46720635890960693\n",
      "Batch: 85 , Combined Loss: tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3720734119415283\n",
      "Batch: 86 , Combined Loss: tensor(0.7082, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1063628196716309\n",
      "Batch: 87 , Combined Loss: tensor(0.7469, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5777283906936646\n",
      "Batch: 88 , Combined Loss: tensor(0.6981, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6636788845062256\n",
      "Batch: 89 , Combined Loss: tensor(0.7712, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7493411302566528\n",
      "Batch: 90 , Combined Loss: tensor(0.6198, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1326725482940674\n",
      "Batch: 91 , Combined Loss: tensor(0.9848, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7232447862625122\n",
      "Batch: 92 , Combined Loss: tensor(0.7395, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25426769256591797\n",
      "Batch: 93 , Combined Loss: tensor(0.6958, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09804975986480713\n",
      "Batch: 94 , Combined Loss: tensor(0.6767, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0818915367126465\n",
      "Batch: 95 , Combined Loss: tensor(0.6830, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.656909704208374\n",
      "Batch: 96 , Combined Loss: tensor(0.6224, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1034135818481445\n",
      "Batch: 97 , Combined Loss: tensor(0.9220, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5565077066421509\n",
      "Batch: 98 , Combined Loss: tensor(0.7100, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5828322172164917\n",
      "Batch: 99 , Combined Loss: tensor(0.6934, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0617804527282715\n",
      "Batch: 100 , Combined Loss: tensor(0.6720, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1369950771331787\n",
      "Batch: 101 , Combined Loss: tensor(0.7484, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6783972978591919\n",
      "Batch: 102 , Combined Loss: tensor(0.7478, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7004470825195312\n",
      "Batch: 103 , Combined Loss: tensor(0.6022, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6502130031585693\n",
      "Batch: 104 , Combined Loss: tensor(1.1277, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6376348733901978\n",
      "Batch: 105 , Combined Loss: tensor(0.6311, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7993944883346558\n",
      "Batch: 106 , Combined Loss: tensor(0.7496, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7259637117385864\n",
      "Batch: 107 , Combined Loss: tensor(0.8580, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5576187372207642\n",
      "Batch: 108 , Combined Loss: tensor(0.6388, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5918653011322021\n",
      "Batch: 109 , Combined Loss: tensor(0.6457, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15415120124816895\n",
      "Batch: 110 , Combined Loss: tensor(0.6133, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.46009957790374756\n",
      "Batch: 111 , Combined Loss: tensor(0.7203, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14884352684020996\n",
      "Batch: 112 , Combined Loss: tensor(0.7418, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6934518814086914\n",
      "Batch: 113 , Combined Loss: tensor(0.6851, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1769835352897644\n",
      "Batch: 114 , Combined Loss: tensor(0.6812, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39364945888519287\n",
      "Batch: 115 , Combined Loss: tensor(0.9402, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2729642391204834\n",
      "Batch: 116 , Combined Loss: tensor(0.6929, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6950333118438721\n",
      "Batch: 117 , Combined Loss: tensor(0.6089, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33467555046081543\n",
      "Batch: 118 , Combined Loss: tensor(0.6385, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20051878690719604\n",
      "Batch: 119 , Combined Loss: tensor(0.7639, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9749382734298706\n",
      "Batch: 120 , Combined Loss: tensor(0.7264, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.43220531940460205\n",
      "Batch: 121 , Combined Loss: tensor(0.6169, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6759636402130127\n",
      "Batch: 122 , Combined Loss: tensor(0.6231, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.696343183517456\n",
      "Batch: 123 , Combined Loss: tensor(0.6969, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8181710243225098\n",
      "Batch: 124 , Combined Loss: tensor(0.6150, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8122444152832031\n",
      "Batch: 125 , Combined Loss: tensor(0.6591, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0205607414245605\n",
      "Batch: 126 , Combined Loss: tensor(0.8039, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17974019050598145\n",
      "Batch: 127 , Combined Loss: tensor(0.6677, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21326732635498047\n",
      "Batch: 128 , Combined Loss: tensor(0.8958, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5869534015655518\n",
      "Batch: 129 , Combined Loss: tensor(0.6858, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5685429573059082\n",
      "Batch: 130 , Combined Loss: tensor(0.7020, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9796414375305176\n",
      "Batch: 131 , Combined Loss: tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7033035755157471\n",
      "Batch: 132 , Combined Loss: tensor(0.6592, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14231407642364502\n",
      "Batch: 133 , Combined Loss: tensor(0.6939, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.794277548789978\n",
      "Batch: 134 , Combined Loss: tensor(0.8143, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.691009521484375\n",
      "Batch: 135 , Combined Loss: tensor(0.8768, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6300724744796753\n",
      "Batch: 136 , Combined Loss: tensor(0.6415, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14970189332962036\n",
      "Batch: 137 , Combined Loss: tensor(0.6319, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6256934404373169\n",
      "Batch: 138 , Combined Loss: tensor(0.6884, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9608111381530762\n",
      "Batch: 139 , Combined Loss: tensor(0.6987, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.891598105430603\n",
      "Batch: 140 , Combined Loss: tensor(0.6971, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6056313514709473\n",
      "Batch: 141 , Combined Loss: tensor(0.6570, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4268585443496704\n",
      "Batch: 142 , Combined Loss: tensor(0.6474, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11751377582550049\n",
      "Batch: 143 , Combined Loss: tensor(0.6469, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16339313983917236\n",
      "Batch: 144 , Combined Loss: tensor(0.7991, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5717594623565674\n",
      "Batch: 145 , Combined Loss: tensor(0.6917, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4479740262031555\n",
      "Batch: 146 , Combined Loss: tensor(0.8519, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16542303562164307\n",
      "Batch: 147 , Combined Loss: tensor(0.6014, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3930400609970093\n",
      "Batch: 148 , Combined Loss: tensor(1.2016, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39298534393310547\n",
      "Batch: 149 , Combined Loss: tensor(0.7274, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.31017005443573\n",
      "Batch: 150 , Combined Loss: tensor(0.8881, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25242912769317627\n",
      "Batch: 151 , Combined Loss: tensor(0.7704, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8204180002212524\n",
      "Batch: 152 , Combined Loss: tensor(0.7676, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2670692205429077\n",
      "Batch: 153 , Combined Loss: tensor(0.6621, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1351628303527832\n",
      "Batch: 154 , Combined Loss: tensor(0.6756, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17093193531036377\n",
      "Batch: 155 , Combined Loss: tensor(0.6409, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5700986385345459\n",
      "Batch: 156 , Combined Loss: tensor(0.6579, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9281502962112427\n",
      "Batch: 157 , Combined Loss: tensor(0.6643, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31329429149627686\n",
      "Batch: 158 , Combined Loss: tensor(0.6661, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7669979333877563\n",
      "Batch: 159 , Combined Loss: tensor(0.8162, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.841742753982544\n",
      "Batch: 160 , Combined Loss: tensor(0.6805, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6648293733596802\n",
      "Batch: 161 , Combined Loss: tensor(0.7436, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.008111715316772461\n",
      "Batch: 162 , Combined Loss: tensor(0.6464, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5886775255203247\n",
      "Batch: 163 , Combined Loss: tensor(0.6855, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0020644664764404\n",
      "Batch: 164 , Combined Loss: tensor(0.6432, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8289891481399536\n",
      "Batch: 165 , Combined Loss: tensor(0.7863, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43759286403656006\n",
      "Batch: 166 , Combined Loss: tensor(0.6390, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3466256856918335\n",
      "Batch: 167 , Combined Loss: tensor(0.6661, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.025854110717773438\n",
      "Batch: 168 , Combined Loss: tensor(0.6841, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7690695524215698\n",
      "Batch: 169 , Combined Loss: tensor(0.6176, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0797679424285889\n",
      "Batch: 170 , Combined Loss: tensor(0.6581, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.461775541305542\n",
      "Batch: 171 , Combined Loss: tensor(0.7233, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28683531284332275\n",
      "Batch: 172 , Combined Loss: tensor(0.6607, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0254344940185547\n",
      "Batch: 173 , Combined Loss: tensor(0.6802, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7821447849273682\n",
      "Batch: 174 , Combined Loss: tensor(0.6997, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.259635865688324\n",
      "Batch: 175 , Combined Loss: tensor(0.8060, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3446308374404907\n",
      "Batch: 176 , Combined Loss: tensor(0.7445, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0494792461395264\n",
      "Batch: 177 , Combined Loss: tensor(0.6072, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8531960248947144\n",
      "Batch: 178 , Combined Loss: tensor(0.6157, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5796389579772949\n",
      "Batch: 179 , Combined Loss: tensor(0.7204, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6960945129394531\n",
      "Batch: 180 , Combined Loss: tensor(0.7474, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9139740467071533\n",
      "Batch: 181 , Combined Loss: tensor(0.6722, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7675081491470337\n",
      "Batch: 182 , Combined Loss: tensor(0.6979, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12156140804290771\n",
      "Batch: 183 , Combined Loss: tensor(0.6816, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5151461362838745\n",
      "Batch: 184 , Combined Loss: tensor(0.6614, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27753281593322754\n",
      "Batch: 185 , Combined Loss: tensor(0.7997, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.570701003074646\n",
      "Batch: 186 , Combined Loss: tensor(0.6399, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05908322334289551\n",
      "Batch: 187 , Combined Loss: tensor(0.7126, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.394789457321167\n",
      "Batch: 188 , Combined Loss: tensor(0.7379, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5989240407943726\n",
      "Batch: 189 , Combined Loss: tensor(0.6147, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9351271390914917\n",
      "Batch: 190 , Combined Loss: tensor(0.6972, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7679870128631592\n",
      "Batch: 191 , Combined Loss: tensor(0.7383, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7620213031768799\n",
      "Batch: 192 , Combined Loss: tensor(0.6350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39930737018585205\n",
      "Batch: 193 , Combined Loss: tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1944807767868042\n",
      "Batch: 194 , Combined Loss: tensor(0.7603, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35593247413635254\n",
      "Batch: 195 , Combined Loss: tensor(0.8295, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1015286445617676\n",
      "Batch: 196 , Combined Loss: tensor(0.6373, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6422692537307739\n",
      "Batch: 197 , Combined Loss: tensor(0.7835, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14945459365844727\n",
      "Batch: 198 , Combined Loss: tensor(0.6156, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.005211234092712402\n",
      "Batch: 199 , Combined Loss: tensor(0.6472, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.060610413551330566\n",
      "Batch: 200 , Combined Loss: tensor(0.8901, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0191986560821533\n",
      "Batch: 201 , Combined Loss: tensor(0.7617, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3829383850097656\n",
      "Batch: 202 , Combined Loss: tensor(0.8570, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9688209295272827\n",
      "Batch: 203 , Combined Loss: tensor(0.9191, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1880435347557068\n",
      "Batch: 204 , Combined Loss: tensor(0.9196, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8240768909454346\n",
      "Batch: 205 , Combined Loss: tensor(0.7248, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8772550821304321\n",
      "Batch: 206 , Combined Loss: tensor(0.7267, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3069990873336792\n",
      "Batch: 207 , Combined Loss: tensor(0.7410, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.826870322227478\n",
      "Batch: 208 , Combined Loss: tensor(0.6462, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1241860389709473\n",
      "Batch: 209 , Combined Loss: tensor(0.7028, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7616690397262573\n",
      "Batch: 210 , Combined Loss: tensor(0.5697, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8970128297805786\n",
      "Batch: 211 , Combined Loss: tensor(0.7380, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7979311943054199\n",
      "Batch: 212 , Combined Loss: tensor(0.7436, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18021154403686523\n",
      "Batch: 213 , Combined Loss: tensor(0.7255, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7083914279937744\n",
      "Batch: 214 , Combined Loss: tensor(0.7951, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7061489820480347\n",
      "Batch: 215 , Combined Loss: tensor(0.7936, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7779204845428467\n",
      "Batch: 216 , Combined Loss: tensor(0.7670, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7115683555603027\n",
      "Batch: 217 , Combined Loss: tensor(0.6939, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9018459320068359\n",
      "Batch: 218 , Combined Loss: tensor(0.6204, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0552699565887451\n",
      "Batch: 219 , Combined Loss: tensor(0.6990, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1186068058013916\n",
      "Batch: 220 , Combined Loss: tensor(0.6449, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2405000925064087\n",
      "Batch: 221 , Combined Loss: tensor(0.6448, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6632429361343384\n",
      "Batch: 222 , Combined Loss: tensor(0.6542, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8539458513259888\n",
      "Batch: 223 , Combined Loss: tensor(0.8202, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9472447633743286\n",
      "Batch: 224 , Combined Loss: tensor(0.6339, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6269893646240234\n",
      "Batch: 225 , Combined Loss: tensor(0.8132, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9584197998046875\n",
      "Batch: 226 , Combined Loss: tensor(0.8112, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17272460460662842\n",
      "Batch: 227 , Combined Loss: tensor(0.6285, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1917780637741089\n",
      "Batch: 228 , Combined Loss: tensor(0.6375, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4339801073074341\n",
      "Batch: 229 , Combined Loss: tensor(0.8369, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6487188339233398\n",
      "Batch: 230 , Combined Loss: tensor(0.6861, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7771382331848145\n",
      "Batch: 231 , Combined Loss: tensor(0.7816, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.935094952583313\n",
      "Batch: 232 , Combined Loss: tensor(0.6831, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6608262062072754\n",
      "Batch: 233 , Combined Loss: tensor(0.6104, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6565659046173096\n",
      "Batch: 234 , Combined Loss: tensor(0.6811, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1582934856414795\n",
      "Batch: 235 , Combined Loss: tensor(0.6373, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9776872396469116\n",
      "Batch: 236 , Combined Loss: tensor(0.7099, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2443714141845703\n",
      "Batch: 237 , Combined Loss: tensor(0.8313, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.511733889579773\n",
      "Batch: 238 , Combined Loss: tensor(0.6348, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9911686182022095\n",
      "Batch: 239 , Combined Loss: tensor(0.6511, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7783010005950928\n",
      "Batch: 240 , Combined Loss: tensor(0.6492, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7266808748245239\n",
      "Batch: 241 , Combined Loss: tensor(0.7705, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13601791858673096\n",
      "Batch: 242 , Combined Loss: tensor(0.7799, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5535751581192017\n",
      "Batch: 243 , Combined Loss: tensor(0.6748, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26806390285491943\n",
      "Batch: 244 , Combined Loss: tensor(0.5509, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14208519458770752\n",
      "Batch: 245 , Combined Loss: tensor(0.6156, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7853187322616577\n",
      "Batch: 246 , Combined Loss: tensor(0.6172, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9239087104797363\n",
      "Batch: 247 , Combined Loss: tensor(0.6394, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7815577983856201\n",
      "Batch: 248 , Combined Loss: tensor(0.6804, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6559908390045166\n",
      "Batch: 249 , Combined Loss: tensor(0.7188, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12251126766204834\n",
      "Batch: 250 , Combined Loss: tensor(0.7430, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5200705528259277\n",
      "Batch: 251 , Combined Loss: tensor(0.6845, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7862639427185059\n",
      "Batch: 252 , Combined Loss: tensor(0.6738, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8086037635803223\n",
      "Batch: 253 , Combined Loss: tensor(0.5681, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08192455768585205\n",
      "Batch: 254 , Combined Loss: tensor(0.8142, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9142303466796875\n",
      "Batch: 255 , Combined Loss: tensor(0.7761, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3380727767944336\n",
      "Batch: 256 , Combined Loss: tensor(0.6197, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7962778806686401\n",
      "Batch: 257 , Combined Loss: tensor(0.6318, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9996699094772339\n",
      "Batch: 258 , Combined Loss: tensor(0.6366, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6619648933410645\n",
      "Batch: 259 , Combined Loss: tensor(0.6211, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.060565829277038574\n",
      "Batch: 260 , Combined Loss: tensor(0.9024, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6133460998535156\n",
      "Batch: 261 , Combined Loss: tensor(0.7528, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0487616062164307\n",
      "Batch: 262 , Combined Loss: tensor(0.8478, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.009497642517089844\n",
      "Batch: 263 , Combined Loss: tensor(0.6656, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6641136407852173\n",
      "Batch: 264 , Combined Loss: tensor(0.6458, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9880855083465576\n",
      "Batch: 265 , Combined Loss: tensor(0.6635, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0922918319702148\n",
      "Batch: 266 , Combined Loss: tensor(0.7943, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43455004692077637\n",
      "Batch: 267 , Combined Loss: tensor(0.7078, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3006722927093506\n",
      "Batch: 268 , Combined Loss: tensor(0.7778, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6338223218917847\n",
      "Batch: 269 , Combined Loss: tensor(0.7218, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5395023822784424\n",
      "Batch: 270 , Combined Loss: tensor(0.9400, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6708093881607056\n",
      "Batch: 271 , Combined Loss: tensor(0.7435, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0177264213562012\n",
      "Batch: 272 , Combined Loss: tensor(0.7128, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2502143383026123\n",
      "Batch: 273 , Combined Loss: tensor(0.6783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6948646306991577\n",
      "Batch: 274 , Combined Loss: tensor(0.8692, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3242220878601074\n",
      "Batch: 275 , Combined Loss: tensor(0.6062, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7521060705184937\n",
      "Batch: 276 , Combined Loss: tensor(0.7517, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9961581230163574\n",
      "Batch: 277 , Combined Loss: tensor(0.5284, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17369532585144043\n",
      "Batch: 278 , Combined Loss: tensor(0.9146, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7109178304672241\n",
      "Batch: 279 , Combined Loss: tensor(0.6456, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8549038171768188\n",
      "Batch: 280 , Combined Loss: tensor(0.7453, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6630616188049316\n",
      "Batch: 281 , Combined Loss: tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7622383832931519\n",
      "Batch: 282 , Combined Loss: tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9146509170532227\n",
      "Batch: 283 , Combined Loss: tensor(0.9089, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5813746452331543\n",
      "Batch: 284 , Combined Loss: tensor(1.1057, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5298906564712524\n",
      "Batch: 285 , Combined Loss: tensor(0.6275, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5726234912872314\n",
      "Batch: 286 , Combined Loss: tensor(0.8306, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04235434532165527\n",
      "Batch: 287 , Combined Loss: tensor(0.6759, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8965246677398682\n",
      "Batch: 288 , Combined Loss: tensor(0.6809, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30653536319732666\n",
      "Batch: 289 , Combined Loss: tensor(0.9066, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6298384666442871\n",
      "Batch: 290 , Combined Loss: tensor(0.6612, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5700664520263672\n",
      "Batch: 291 , Combined Loss: tensor(0.6298, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9813705682754517\n",
      "Batch: 292 , Combined Loss: tensor(0.6820, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8717213869094849\n",
      "Batch: 293 , Combined Loss: tensor(0.7362, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9148389101028442\n",
      "Batch: 294 , Combined Loss: tensor(0.6390, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7505029439926147\n",
      "Batch: 295 , Combined Loss: tensor(0.6556, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.618249773979187\n",
      "Batch: 296 , Combined Loss: tensor(0.7684, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7947906255722046\n",
      "Batch: 297 , Combined Loss: tensor(0.5888, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7225140333175659\n",
      "Batch: 298 , Combined Loss: tensor(0.8401, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.577153205871582\n",
      "Batch: 299 , Combined Loss: tensor(0.7042, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08308041095733643\n",
      "Batch: 300 , Combined Loss: tensor(0.5996, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09795111417770386\n",
      "Batch: 301 , Combined Loss: tensor(0.8236, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5996699333190918\n",
      "Batch: 302 , Combined Loss: tensor(0.6630, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21273034811019897\n",
      "Batch: 303 , Combined Loss: tensor(0.6611, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9001245498657227\n",
      "Batch: 304 , Combined Loss: tensor(0.6571, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5093642473220825\n",
      "Batch: 305 , Combined Loss: tensor(0.6367, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6293528079986572\n",
      "Batch: 306 , Combined Loss: tensor(0.9167, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11524879932403564\n",
      "Batch: 307 , Combined Loss: tensor(0.8567, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16819441318511963\n",
      "Batch: 308 , Combined Loss: tensor(0.6592, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43548738956451416\n",
      "Batch: 309 , Combined Loss: tensor(0.8578, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.161049485206604\n",
      "Batch: 310 , Combined Loss: tensor(0.7351, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5366150140762329\n",
      "Batch: 311 , Combined Loss: tensor(0.7496, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27720820903778076\n",
      "Batch: 312 , Combined Loss: tensor(0.6230, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.41769981384277344\n",
      "Batch: 313 , Combined Loss: tensor(0.6323, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.700381875038147\n",
      "Batch: 314 , Combined Loss: tensor(0.7121, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7608299255371094\n",
      "Batch: 315 , Combined Loss: tensor(0.6557, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9094367027282715\n",
      "Batch: 316 , Combined Loss: tensor(0.6838, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.33606773614883423\n",
      "Batch: 317 , Combined Loss: tensor(0.7508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8667469024658203\n",
      "Batch: 318 , Combined Loss: tensor(0.6930, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3085745573043823\n",
      "Batch: 319 , Combined Loss: tensor(0.7703, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7811368703842163\n",
      "Batch: 320 , Combined Loss: tensor(0.6224, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08617472648620605\n",
      "Batch: 321 , Combined Loss: tensor(0.7507, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9956750869750977\n",
      "Batch: 322 , Combined Loss: tensor(0.8565, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2444441318511963\n",
      "Batch: 323 , Combined Loss: tensor(0.7097, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8011816740036011\n",
      "Batch: 324 , Combined Loss: tensor(0.6832, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.030708789825439453\n",
      "Batch: 325 , Combined Loss: tensor(0.6213, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5897163152694702\n",
      "Batch: 326 , Combined Loss: tensor(0.6369, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9047600030899048\n",
      "Batch: 327 , Combined Loss: tensor(0.6037, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9487862586975098\n",
      "Batch: 328 , Combined Loss: tensor(0.6636, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7829993963241577\n",
      "Batch: 329 , Combined Loss: tensor(0.6507, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8720329999923706\n",
      "Batch: 330 , Combined Loss: tensor(0.6647, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.72673499584198\n",
      "Batch: 331 , Combined Loss: tensor(0.6758, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7911444902420044\n",
      "Batch: 332 , Combined Loss: tensor(0.7105, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9339951276779175\n",
      "Batch: 333 , Combined Loss: tensor(0.6540, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9560015201568604\n",
      "Batch: 334 , Combined Loss: tensor(0.6745, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0644464492797852\n",
      "Batch: 335 , Combined Loss: tensor(0.6192, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4121028780937195\n",
      "Batch: 336 , Combined Loss: tensor(0.7261, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07715195417404175\n",
      "Batch: 337 , Combined Loss: tensor(0.7931, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.383914589881897\n",
      "Batch: 338 , Combined Loss: tensor(0.7281, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09674656391143799\n",
      "Batch: 339 , Combined Loss: tensor(0.7981, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6001827716827393\n",
      "Batch: 340 , Combined Loss: tensor(0.8120, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5063167810440063\n",
      "Batch: 341 , Combined Loss: tensor(0.6273, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2803112268447876\n",
      "Batch: 342 , Combined Loss: tensor(0.7407, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18731939792633057\n",
      "Batch: 343 , Combined Loss: tensor(0.6692, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9599676132202148\n",
      "Batch: 344 , Combined Loss: tensor(0.6741, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7780367136001587\n",
      "Batch: 345 , Combined Loss: tensor(0.7550, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7107981443405151\n",
      "Batch: 346 , Combined Loss: tensor(0.7005, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8924708366394043\n",
      "Batch: 347 , Combined Loss: tensor(0.6467, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1813291311264038\n",
      "Batch: 348 , Combined Loss: tensor(0.7742, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9149130582809448\n",
      "Batch: 349 , Combined Loss: tensor(0.7968, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29016125202178955\n",
      "Batch: 350 , Combined Loss: tensor(0.7355, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9541645050048828\n",
      "Batch: 351 , Combined Loss: tensor(0.8009, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2650488615036011\n",
      "Batch: 352 , Combined Loss: tensor(0.6398, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.046799659729004\n",
      "Batch: 353 , Combined Loss: tensor(0.7283, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7801810503005981\n",
      "Batch: 354 , Combined Loss: tensor(0.7609, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.32405757904052734\n",
      "Batch: 355 , Combined Loss: tensor(0.6915, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.835060715675354\n",
      "Batch: 356 , Combined Loss: tensor(0.6736, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9757202863693237\n",
      "Batch: 357 , Combined Loss: tensor(0.5926, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8734548091888428\n",
      "Batch: 358 , Combined Loss: tensor(0.6225, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.341724157333374\n",
      "Batch: 359 , Combined Loss: tensor(0.7478, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20006346702575684\n",
      "Batch: 360 , Combined Loss: tensor(0.6279, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4448953866958618\n",
      "Batch: 361 , Combined Loss: tensor(0.8124, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07846492528915405\n",
      "Batch: 362 , Combined Loss: tensor(0.7069, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38213443756103516\n",
      "Batch: 363 , Combined Loss: tensor(0.6997, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7518419027328491\n",
      "Batch: 364 , Combined Loss: tensor(0.6794, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6740612983703613\n",
      "Batch: 365 , Combined Loss: tensor(0.8317, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15258002281188965\n",
      "Batch: 366 , Combined Loss: tensor(0.8207, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3706326484680176\n",
      "Batch: 367 , Combined Loss: tensor(0.6614, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.025547266006469727\n",
      "Batch: 368 , Combined Loss: tensor(0.8327, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3009183406829834\n",
      "Batch: 369 , Combined Loss: tensor(0.9163, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0474519729614258\n",
      "Batch: 370 , Combined Loss: tensor(0.6714, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9252719879150391\n",
      "Batch: 371 , Combined Loss: tensor(0.6314, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3539806604385376\n",
      "Batch: 372 , Combined Loss: tensor(0.6799, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7770980596542358\n",
      "Batch: 373 , Combined Loss: tensor(0.6491, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4268134832382202\n",
      "Batch: 374 , Combined Loss: tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30351412296295166\n",
      "Batch: 375 , Combined Loss: tensor(0.6533, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6465334892272949\n",
      "Batch: 376 , Combined Loss: tensor(0.7641, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8678257465362549\n",
      "Batch: 377 , Combined Loss: tensor(0.6127, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8680022954940796\n",
      "Batch: 378 , Combined Loss: tensor(0.6143, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.770698070526123\n",
      "Batch: 379 , Combined Loss: tensor(0.6621, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03643155097961426\n",
      "Batch: 380 , Combined Loss: tensor(0.6391, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1992020606994629\n",
      "Batch: 381 , Combined Loss: tensor(0.9225, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9923346042633057\n",
      "Batch: 382 , Combined Loss: tensor(0.6626, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1130852699279785\n",
      "Batch: 383 , Combined Loss: tensor(0.6659, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08423197269439697\n",
      "Batch: 384 , Combined Loss: tensor(0.7596, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4955340623855591\n",
      "Batch: 385 , Combined Loss: tensor(0.6788, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6048232316970825\n",
      "Batch: 386 , Combined Loss: tensor(0.6707, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7074836492538452\n",
      "Batch: 387 , Combined Loss: tensor(0.8904, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.018884778022766113\n",
      "Batch: 388 , Combined Loss: tensor(0.7203, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6319338083267212\n",
      "Batch: 389 , Combined Loss: tensor(0.7442, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8506523370742798\n",
      "Batch: 390 , Combined Loss: tensor(0.7569, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2624105215072632\n",
      "Batch: 391 , Combined Loss: tensor(0.7809, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21774840354919434\n",
      "Batch: 392 , Combined Loss: tensor(0.8053, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7792142629623413\n",
      "Batch: 393 , Combined Loss: tensor(0.7022, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8438329696655273\n",
      "Batch: 394 , Combined Loss: tensor(0.7462, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8191196918487549\n",
      "Batch: 395 , Combined Loss: tensor(0.7251, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.02519357204437256\n",
      "Batch: 396 , Combined Loss: tensor(0.6144, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7283267974853516\n",
      "Batch: 397 , Combined Loss: tensor(0.7016, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8126413822174072\n",
      "Batch: 398 , Combined Loss: tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9013780355453491\n",
      "Batch: 399 , Combined Loss: tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9017757177352905\n",
      "Batch: 400 , Combined Loss: tensor(0.6325, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16133761405944824\n",
      "Batch: 401 , Combined Loss: tensor(0.6710, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6628949642181396\n",
      "Batch: 402 , Combined Loss: tensor(0.6896, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0749974250793457\n",
      "Batch: 403 , Combined Loss: tensor(0.6576, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3714640140533447\n",
      "Batch: 404 , Combined Loss: tensor(0.7315, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6456899642944336\n",
      "Batch: 405 , Combined Loss: tensor(0.8584, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2385246753692627\n",
      "Batch: 406 , Combined Loss: tensor(0.7359, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04518842697143555\n",
      "Batch: 407 , Combined Loss: tensor(0.7229, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.676676869392395\n",
      "Batch: 408 , Combined Loss: tensor(0.7245, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5694218873977661\n",
      "Batch: 409 , Combined Loss: tensor(1.0229, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.484882116317749\n",
      "Batch: 410 , Combined Loss: tensor(0.6738, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6782776117324829\n",
      "Batch: 411 , Combined Loss: tensor(0.6295, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6362490653991699\n",
      "Batch: 412 , Combined Loss: tensor(0.6519, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4619302749633789\n",
      "Batch: 413 , Combined Loss: tensor(0.7712, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6267400979995728\n",
      "Batch: 414 , Combined Loss: tensor(0.7878, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4311051368713379\n",
      "Batch: 415 , Combined Loss: tensor(0.7420, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2643086910247803\n",
      "Batch: 416 , Combined Loss: tensor(0.7100, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7271562814712524\n",
      "Batch: 417 , Combined Loss: tensor(0.6701, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4358307123184204\n",
      "Batch: 418 , Combined Loss: tensor(0.6248, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0264618396759033\n",
      "Batch: 419 , Combined Loss: tensor(0.6925, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9553443193435669\n",
      "Batch: 420 , Combined Loss: tensor(0.7524, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7470684051513672\n",
      "Batch: 421 , Combined Loss: tensor(0.6840, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20143473148345947\n",
      "Batch: 422 , Combined Loss: tensor(0.7223, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6577850580215454\n",
      "Batch: 423 , Combined Loss: tensor(0.6611, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.548012375831604\n",
      "Batch: 424 , Combined Loss: tensor(0.6985, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7087498903274536\n",
      "Batch: 425 , Combined Loss: tensor(0.7749, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39075231552124023\n",
      "Batch: 426 , Combined Loss: tensor(0.5833, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21949172019958496\n",
      "Batch: 427 , Combined Loss: tensor(0.7125, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7416841983795166\n",
      "Batch: 428 , Combined Loss: tensor(0.9307, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39844727516174316\n",
      "Batch: 429 , Combined Loss: tensor(0.6451, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2859588861465454\n",
      "Batch: 430 , Combined Loss: tensor(0.7972, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5527188777923584\n",
      "Batch: 431 , Combined Loss: tensor(0.8504, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6593177318572998\n",
      "Batch: 432 , Combined Loss: tensor(0.6743, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8922855854034424\n",
      "Batch: 433 , Combined Loss: tensor(0.7371, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.028744876384735107\n",
      "Batch: 434 , Combined Loss: tensor(0.7383, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36282575130462646\n",
      "Batch: 435 , Combined Loss: tensor(0.7081, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20863795280456543\n",
      "Batch: 436 , Combined Loss: tensor(0.7577, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7228208780288696\n",
      "Batch: 437 , Combined Loss: tensor(0.7783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22205126285552979\n",
      "Batch: 438 , Combined Loss: tensor(0.6147, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05681204795837402\n",
      "Batch: 439 , Combined Loss: tensor(0.6839, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2582581043243408\n",
      "Batch: 440 , Combined Loss: tensor(0.7051, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7885102033615112\n",
      "Batch: 441 , Combined Loss: tensor(0.6532, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0363686084747314\n",
      "Batch: 442 , Combined Loss: tensor(0.7358, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8091531991958618\n",
      "Batch: 443 , Combined Loss: tensor(0.7179, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9418904781341553\n",
      "Batch: 444 , Combined Loss: tensor(0.6977, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.45206743478775024\n",
      "Batch: 445 , Combined Loss: tensor(0.6665, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9062502384185791\n",
      "Batch: 446 , Combined Loss: tensor(0.7020, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17487597465515137\n",
      "Batch: 447 , Combined Loss: tensor(0.8511, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26593315601348877\n",
      "Batch: 448 , Combined Loss: tensor(0.7070, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6500163078308105\n",
      "Batch: 449 , Combined Loss: tensor(0.6669, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2560596466064453\n",
      "Batch: 450 , Combined Loss: tensor(0.6017, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3208409547805786\n",
      "Batch: 451 , Combined Loss: tensor(0.7054, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3784703016281128\n",
      "Batch: 452 , Combined Loss: tensor(0.8495, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08989346027374268\n",
      "Batch: 453 , Combined Loss: tensor(0.7783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05091959238052368\n",
      "Batch: 454 , Combined Loss: tensor(0.7931, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.998713493347168\n",
      "Batch: 455 , Combined Loss: tensor(0.6813, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.507964015007019\n",
      "Batch: 456 , Combined Loss: tensor(0.6331, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8970577716827393\n",
      "Batch: 457 , Combined Loss: tensor(0.6517, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8659439086914062\n",
      "Batch: 458 , Combined Loss: tensor(0.6804, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05776643753051758\n",
      "Batch: 459 , Combined Loss: tensor(0.8071, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34455418586730957\n",
      "Batch: 460 , Combined Loss: tensor(0.7226, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.539391040802002\n",
      "Batch: 461 , Combined Loss: tensor(0.6158, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.01965498924255371\n",
      "Batch: 462 , Combined Loss: tensor(0.6974, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.565438985824585\n",
      "Batch: 463 , Combined Loss: tensor(0.6011, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.070425033569336\n",
      "Batch: 464 , Combined Loss: tensor(0.6073, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4173926115036011\n",
      "Batch: 465 , Combined Loss: tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5637550354003906\n",
      "Batch: 466 , Combined Loss: tensor(0.6879, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13600623607635498\n",
      "Batch: 467 , Combined Loss: tensor(0.6252, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5358908176422119\n",
      "Batch: 468 , Combined Loss: tensor(0.5968, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8030276298522949\n",
      "Batch: 469 , Combined Loss: tensor(0.7096, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9403959512710571\n",
      "Batch: 470 , Combined Loss: tensor(0.6466, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5358362197875977\n",
      "Batch: 471 , Combined Loss: tensor(0.7542, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4664219617843628\n",
      "Batch: 472 , Combined Loss: tensor(0.7036, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05697596073150635\n",
      "Batch: 473 , Combined Loss: tensor(1.2415, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4077751636505127\n",
      "Batch: 474 , Combined Loss: tensor(0.7447, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4633152484893799\n",
      "Batch: 475 , Combined Loss: tensor(0.6214, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39017319679260254\n",
      "Batch: 476 , Combined Loss: tensor(0.7530, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.706000804901123\n",
      "Batch: 477 , Combined Loss: tensor(0.6905, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38748621940612793\n",
      "Batch: 478 , Combined Loss: tensor(0.7318, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6084680557250977\n",
      "Batch: 479 , Combined Loss: tensor(0.7457, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0732964277267456\n",
      "Batch: 480 , Combined Loss: tensor(0.7090, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6317967176437378\n",
      "Batch: 481 , Combined Loss: tensor(0.6273, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8179609775543213\n",
      "Batch: 482 , Combined Loss: tensor(0.7102, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.31787967681884766\n",
      "Batch: 483 , Combined Loss: tensor(0.8026, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6009423732757568\n",
      "Batch: 484 , Combined Loss: tensor(0.6899, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22732722759246826\n",
      "Batch: 485 , Combined Loss: tensor(0.8174, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8384643793106079\n",
      "Batch: 486 , Combined Loss: tensor(0.7974, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27669060230255127\n",
      "Batch: 487 , Combined Loss: tensor(0.5974, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.679547905921936\n",
      "Batch: 488 , Combined Loss: tensor(0.7710, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.257948637008667\n",
      "Batch: 489 , Combined Loss: tensor(0.8025, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9308770895004272\n",
      "Batch: 490 , Combined Loss: tensor(0.6335, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.627017617225647\n",
      "Batch: 491 , Combined Loss: tensor(0.6220, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41759419441223145\n",
      "Batch: 492 , Combined Loss: tensor(0.7874, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22218573093414307\n",
      "Batch: 493 , Combined Loss: tensor(0.6302, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9410687685012817\n",
      "Batch: 494 , Combined Loss: tensor(0.5885, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5486742258071899\n",
      "Batch: 495 , Combined Loss: tensor(0.7906, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.314802885055542\n",
      "Batch: 496 , Combined Loss: tensor(0.7362, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8088352680206299\n",
      "Batch: 497 , Combined Loss: tensor(0.6746, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5081959962844849\n",
      "Batch: 498 , Combined Loss: tensor(0.7886, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38332438468933105\n",
      "Batch: 499 , Combined Loss: tensor(0.6770, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8762168884277344\n",
      "Batch: 500 , Combined Loss: tensor(0.8401, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23908138275146484\n",
      "Batch: 501 , Combined Loss: tensor(0.6492, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.47910696268081665\n",
      "Batch: 502 , Combined Loss: tensor(0.7099, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9611339569091797\n",
      "Batch: 503 , Combined Loss: tensor(0.7013, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34704434871673584\n",
      "Batch: 504 , Combined Loss: tensor(0.6622, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9590812921524048\n",
      "Batch: 505 , Combined Loss: tensor(0.6584, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8790730237960815\n",
      "Batch: 506 , Combined Loss: tensor(0.6930, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5076130628585815\n",
      "Batch: 507 , Combined Loss: tensor(0.9899, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.024605751037597656\n",
      "Batch: 508 , Combined Loss: tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4662553071975708\n",
      "Batch: 509 , Combined Loss: tensor(0.6342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.232961654663086\n",
      "Batch: 510 , Combined Loss: tensor(0.6865, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.879820704460144\n",
      "Batch: 511 , Combined Loss: tensor(0.6081, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8717323541641235\n",
      "Batch: 512 , Combined Loss: tensor(0.5925, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7712982892990112\n",
      "Batch: 513 , Combined Loss: tensor(0.6452, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5040445327758789\n",
      "Batch: 514 , Combined Loss: tensor(0.6527, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9823706150054932\n",
      "Batch: 515 , Combined Loss: tensor(0.7208, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0074021816253662\n",
      "Batch: 516 , Combined Loss: tensor(0.6996, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3689078688621521\n",
      "Batch: 517 , Combined Loss: tensor(0.8758, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.996706485748291\n",
      "Batch: 518 , Combined Loss: tensor(0.6666, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21026504039764404\n",
      "Batch: 519 , Combined Loss: tensor(0.6444, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23227572441101074\n",
      "Batch: 520 , Combined Loss: tensor(0.6764, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7369160652160645\n",
      "Batch: 521 , Combined Loss: tensor(0.8350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4581853151321411\n",
      "Batch: 522 , Combined Loss: tensor(0.8267, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6727973222732544\n",
      "Batch: 523 , Combined Loss: tensor(0.7329, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4536125659942627\n",
      "Batch: 524 , Combined Loss: tensor(1.0275, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24248921871185303\n",
      "Batch: 525 , Combined Loss: tensor(0.5813, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46261298656463623\n",
      "Batch: 526 , Combined Loss: tensor(0.6160, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9127795696258545\n",
      "Batch: 527 , Combined Loss: tensor(0.7887, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4196857810020447\n",
      "Batch: 528 , Combined Loss: tensor(0.7638, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6282813549041748\n",
      "Batch: 529 , Combined Loss: tensor(0.6223, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6057783365249634\n",
      "Batch: 530 , Combined Loss: tensor(0.6732, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.483556866645813\n",
      "Batch: 531 , Combined Loss: tensor(0.7446, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38055479526519775\n",
      "Batch: 532 , Combined Loss: tensor(0.7033, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5062977075576782\n",
      "Batch: 533 , Combined Loss: tensor(0.7000, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7873016595840454\n",
      "Batch: 534 , Combined Loss: tensor(0.8812, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35393857955932617\n",
      "Batch: 535 , Combined Loss: tensor(0.6590, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35910069942474365\n",
      "Batch: 536 , Combined Loss: tensor(0.7508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8910696506500244\n",
      "Batch: 537 , Combined Loss: tensor(0.8051, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6365138292312622\n",
      "Batch: 538 , Combined Loss: tensor(0.6816, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7475086450576782\n",
      "Batch: 539 , Combined Loss: tensor(0.7411, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6162034273147583\n",
      "Batch: 540 , Combined Loss: tensor(0.7099, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08361494541168213\n",
      "Batch: 541 , Combined Loss: tensor(0.7689, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7027938365936279\n",
      "Batch: 542 , Combined Loss: tensor(0.6983, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9652658700942993\n",
      "Batch: 543 , Combined Loss: tensor(0.7487, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6560207605361938\n",
      "Batch: 544 , Combined Loss: tensor(0.6548, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6217488050460815\n",
      "Batch: 545 , Combined Loss: tensor(0.7341, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41495180130004883\n",
      "Batch: 546 , Combined Loss: tensor(0.9092, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7567884922027588\n",
      "Batch: 547 , Combined Loss: tensor(0.7373, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8065841197967529\n",
      "Batch: 548 , Combined Loss: tensor(0.7265, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5001206398010254\n",
      "Batch: 549 , Combined Loss: tensor(0.7694, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.457749605178833\n",
      "Batch: 550 , Combined Loss: tensor(0.8315, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.13158106803894043\n",
      "Batch: 551 , Combined Loss: tensor(0.7650, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.02986353635787964\n",
      "Batch: 552 , Combined Loss: tensor(0.6535, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23731768131256104\n",
      "Batch: 553 , Combined Loss: tensor(0.9056, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4430586099624634\n",
      "Batch: 554 , Combined Loss: tensor(0.7596, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7752586603164673\n",
      "Batch: 555 , Combined Loss: tensor(0.6706, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5740015506744385\n",
      "Batch: 556 , Combined Loss: tensor(0.7953, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4577559232711792\n",
      "Batch: 557 , Combined Loss: tensor(0.7482, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6986136436462402\n",
      "Batch: 558 , Combined Loss: tensor(0.7639, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8703869581222534\n",
      "Batch: 559 , Combined Loss: tensor(0.6738, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49621474742889404\n",
      "Batch: 560 , Combined Loss: tensor(0.6138, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.914762020111084\n",
      "Batch: 561 , Combined Loss: tensor(0.6690, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6532617807388306\n",
      "Batch: 562 , Combined Loss: tensor(0.6923, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33953118324279785\n",
      "Batch: 563 , Combined Loss: tensor(0.7217, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8412563800811768\n",
      "Batch: 564 , Combined Loss: tensor(0.6067, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7680231332778931\n",
      "Batch: 565 , Combined Loss: tensor(0.8652, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5572106838226318\n",
      "Batch: 566 , Combined Loss: tensor(0.8876, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4928913116455078\n",
      "Batch: 567 , Combined Loss: tensor(0.7126, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40527188777923584\n",
      "Batch: 568 , Combined Loss: tensor(0.7769, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20647436380386353\n",
      "Batch: 569 , Combined Loss: tensor(0.6931, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7070889472961426\n",
      "Batch: 570 , Combined Loss: tensor(0.6962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3612639904022217\n",
      "Batch: 571 , Combined Loss: tensor(0.8323, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.006111800670623779\n",
      "Batch: 572 , Combined Loss: tensor(0.6558, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4885721206665039\n",
      "Batch: 573 , Combined Loss: tensor(0.6656, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09760576486587524\n",
      "Batch: 574 , Combined Loss: tensor(0.6909, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.033003568649292\n",
      "Batch: 575 , Combined Loss: tensor(0.8038, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.718308687210083\n",
      "Batch: 576 , Combined Loss: tensor(0.7409, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8776546716690063\n",
      "Batch: 577 , Combined Loss: tensor(0.6325, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8060208559036255\n",
      "Batch: 578 , Combined Loss: tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3816176652908325\n",
      "Batch: 579 , Combined Loss: tensor(0.7388, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3253873586654663\n",
      "Batch: 580 , Combined Loss: tensor(0.6524, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7305284738540649\n",
      "Batch: 581 , Combined Loss: tensor(0.6247, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9436664581298828\n",
      "Batch: 582 , Combined Loss: tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8889856338500977\n",
      "Batch: 583 , Combined Loss: tensor(0.7247, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8839186429977417\n",
      "Batch: 584 , Combined Loss: tensor(0.7058, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4558292627334595\n",
      "Batch: 585 , Combined Loss: tensor(0.8386, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6952990293502808\n",
      "Batch: 586 , Combined Loss: tensor(0.7943, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2209787368774414\n",
      "Batch: 587 , Combined Loss: tensor(0.6224, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9363831281661987\n",
      "Batch: 588 , Combined Loss: tensor(0.7422, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8787969350814819\n",
      "Batch: 589 , Combined Loss: tensor(1.2377, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06992363929748535\n",
      "Batch: 590 , Combined Loss: tensor(0.6838, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1701582670211792\n",
      "Batch: 591 , Combined Loss: tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.523070216178894\n",
      "Batch: 592 , Combined Loss: tensor(0.6432, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8772114515304565\n",
      "Batch: 593 , Combined Loss: tensor(0.6851, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8525301218032837\n",
      "Batch: 594 , Combined Loss: tensor(0.6409, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2559291124343872\n",
      "Batch: 595 , Combined Loss: tensor(0.8485, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9599944353103638\n",
      "Batch: 596 , Combined Loss: tensor(0.6979, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7216744422912598\n",
      "Batch: 597 , Combined Loss: tensor(0.6457, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12473034858703613\n",
      "Batch: 598 , Combined Loss: tensor(0.6494, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10503125190734863\n",
      "Batch: 599 , Combined Loss: tensor(0.7700, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3062167167663574\n",
      "Batch: 600 , Combined Loss: tensor(1.1611, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8846958875656128\n",
      "Batch: 601 , Combined Loss: tensor(0.8762, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4395226240158081\n",
      "Batch: 602 , Combined Loss: tensor(0.6680, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.838991641998291\n",
      "Batch: 603 , Combined Loss: tensor(0.7362, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41083669662475586\n",
      "Batch: 604 , Combined Loss: tensor(0.7627, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36461782455444336\n",
      "Batch: 605 , Combined Loss: tensor(0.6286, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7797491550445557\n",
      "Batch: 606 , Combined Loss: tensor(0.9420, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5563640594482422\n",
      "Batch: 607 , Combined Loss: tensor(0.7192, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8126592636108398\n",
      "Batch: 608 , Combined Loss: tensor(0.6773, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0512194633483887\n",
      "Batch: 609 , Combined Loss: tensor(0.7547, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.052828311920166\n",
      "Batch: 610 , Combined Loss: tensor(0.6946, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16081547737121582\n",
      "Batch: 611 , Combined Loss: tensor(0.6501, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.856290340423584\n",
      "Batch: 612 , Combined Loss: tensor(0.5608, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2216867208480835\n",
      "Batch: 613 , Combined Loss: tensor(0.6692, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3630635738372803\n",
      "Batch: 614 , Combined Loss: tensor(0.7484, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0942208766937256\n",
      "Batch: 615 , Combined Loss: tensor(0.7550, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6521203517913818\n",
      "Batch: 616 , Combined Loss: tensor(0.6249, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3739675283432007\n",
      "Batch: 617 , Combined Loss: tensor(0.9388, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1269015073776245\n",
      "Batch: 618 , Combined Loss: tensor(0.6876, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8859944343566895\n",
      "Batch: 619 , Combined Loss: tensor(0.6357, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.000823974609375\n",
      "Batch: 620 , Combined Loss: tensor(1.0136, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.691797137260437\n",
      "Batch: 621 , Combined Loss: tensor(0.7593, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0925602912902832\n",
      "Batch: 622 , Combined Loss: tensor(0.6836, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8558318614959717\n",
      "Batch: 623 , Combined Loss: tensor(0.7205, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3609682321548462\n",
      "Batch: 624 , Combined Loss: tensor(0.6668, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9861830472946167\n",
      "Batch: 625 , Combined Loss: tensor(0.7067, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7643314599990845\n",
      "Batch: 626 , Combined Loss: tensor(0.7354, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7192115783691406\n",
      "Batch: 627 , Combined Loss: tensor(0.6531, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8369213342666626\n",
      "Batch: 628 , Combined Loss: tensor(0.8984, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4330097436904907\n",
      "----------Epoch 15, Loss: 0.720649461583227, Accuracy: 0.9595330599192027, Dice Coef: [0.9814419009158646, 0.5125235567631466, 0.5675997498878717, 0.639128812174657], Dice Coef Necrotic: 0.9571144010414182, Dice Coef Edema: 0.9558366210713171, Dice Coef Enhancing: 0.9341629885753604, Sensitivity: [0.9654051141253716, 0.7133863065932212, 0.8467854450683336, 0.866315243365939], Specificity: [0.9697610281988244, 0.9959890100459415, 0.9716921313199406, 0.9926649367108065], Precision: [0.9981694087883627, 0.4732435606701651, 0.4595980769964917, 0.5500448559497303]\n",
      "Saving without nn.DataParallel\n",
      "Batch: 0 , Combined Loss: tensor(0.6249, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7129980325698853\n",
      "Batch: 1 , Combined Loss: tensor(0.6826, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8943489789962769\n",
      "Batch: 2 , Combined Loss: tensor(0.7573, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1870124340057373\n",
      "Batch: 3 , Combined Loss: tensor(0.6492, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4291989803314209\n",
      "Batch: 4 , Combined Loss: tensor(0.8437, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6730999946594238\n",
      "Batch: 5 , Combined Loss: tensor(0.6811, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6254830360412598\n",
      "Batch: 6 , Combined Loss: tensor(0.8124, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9481784105300903\n",
      "Batch: 7 , Combined Loss: tensor(0.7571, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.824081301689148\n",
      "Batch: 8 , Combined Loss: tensor(0.7077, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12859892845153809\n",
      "Batch: 9 , Combined Loss: tensor(0.7323, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07210433483123779\n",
      "Batch: 10 , Combined Loss: tensor(0.7294, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7967402935028076\n",
      "Batch: 11 , Combined Loss: tensor(0.6454, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5224733352661133\n",
      "Batch: 12 , Combined Loss: tensor(1.0447, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6755446195602417\n",
      "Batch: 13 , Combined Loss: tensor(0.8151, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07465475797653198\n",
      "Batch: 14 , Combined Loss: tensor(0.8175, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8783191442489624\n",
      "Batch: 15 , Combined Loss: tensor(0.6994, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8863215446472168\n",
      "Batch: 16 , Combined Loss: tensor(0.7131, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.673474907875061\n",
      "Batch: 17 , Combined Loss: tensor(0.7098, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4341529607772827\n",
      "Batch: 18 , Combined Loss: tensor(0.6858, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9008046388626099\n",
      "Batch: 19 , Combined Loss: tensor(0.7136, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0160393714904785\n",
      "Batch: 20 , Combined Loss: tensor(0.8814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6432995200157166\n",
      "Batch: 21 , Combined Loss: tensor(0.6885, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9700479507446289\n",
      "Batch: 22 , Combined Loss: tensor(0.7273, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.294913649559021\n",
      "Batch: 23 , Combined Loss: tensor(0.6762, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9449423551559448\n",
      "Batch: 24 , Combined Loss: tensor(0.6718, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8851945400238037\n",
      "Batch: 25 , Combined Loss: tensor(0.9399, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3614281415939331\n",
      "Batch: 26 , Combined Loss: tensor(0.7465, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7413557767868042\n",
      "Batch: 27 , Combined Loss: tensor(0.6190, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7451188564300537\n",
      "Batch: 28 , Combined Loss: tensor(0.8662, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.4216997623443604\n",
      "Batch: 29 , Combined Loss: tensor(0.7024, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8588451147079468\n",
      "Batch: 30 , Combined Loss: tensor(0.7336, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7154369354248047\n",
      "Batch: 31 , Combined Loss: tensor(0.6818, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5698026418685913\n",
      "Batch: 32 , Combined Loss: tensor(0.6349, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8750579357147217\n",
      "Batch: 33 , Combined Loss: tensor(0.7514, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28995418548583984\n",
      "Batch: 34 , Combined Loss: tensor(0.6738, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36648130416870117\n",
      "Batch: 35 , Combined Loss: tensor(0.7476, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7904694080352783\n",
      "Batch: 36 , Combined Loss: tensor(0.6950, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9124913215637207\n",
      "Batch: 37 , Combined Loss: tensor(0.6945, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7149385213851929\n",
      "Batch: 38 , Combined Loss: tensor(0.6690, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.792434573173523\n",
      "Batch: 39 , Combined Loss: tensor(0.7092, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8703751564025879\n",
      "Batch: 40 , Combined Loss: tensor(0.6665, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09096837043762207\n",
      "Batch: 41 , Combined Loss: tensor(0.6541, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4547395706176758\n",
      "Batch: 42 , Combined Loss: tensor(0.6321, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9588632583618164\n",
      "Batch: 43 , Combined Loss: tensor(0.7704, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13264036178588867\n",
      "Batch: 44 , Combined Loss: tensor(0.7079, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4119429588317871\n",
      "Batch: 45 , Combined Loss: tensor(0.7612, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3583875894546509\n",
      "Batch: 46 , Combined Loss: tensor(0.6520, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7944024801254272\n",
      "Batch: 47 , Combined Loss: tensor(0.7288, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9415031671524048\n",
      "Batch: 48 , Combined Loss: tensor(0.7211, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.036304354667663574\n",
      "Batch: 49 , Combined Loss: tensor(0.7975, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6940796375274658\n",
      "Batch: 50 , Combined Loss: tensor(0.6611, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0661778450012207\n",
      "Batch: 51 , Combined Loss: tensor(0.6856, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44349348545074463\n",
      "Batch: 52 , Combined Loss: tensor(0.7890, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7634983062744141\n",
      "Batch: 53 , Combined Loss: tensor(0.7960, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09666025638580322\n",
      "Batch: 54 , Combined Loss: tensor(0.6907, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.02416139841079712\n",
      "Batch: 55 , Combined Loss: tensor(0.6957, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9480295181274414\n",
      "Batch: 56 , Combined Loss: tensor(0.6089, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3652409315109253\n",
      "Batch: 57 , Combined Loss: tensor(0.7064, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7264523506164551\n",
      "Batch: 58 , Combined Loss: tensor(0.6494, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22136276960372925\n",
      "Batch: 59 , Combined Loss: tensor(0.6938, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4615057706832886\n",
      "Batch: 60 , Combined Loss: tensor(0.8119, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3105412721633911\n",
      "Batch: 61 , Combined Loss: tensor(0.6159, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9470300674438477\n",
      "Batch: 62 , Combined Loss: tensor(0.6599, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7673556804656982\n",
      "Batch: 63 , Combined Loss: tensor(0.7010, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3732178211212158\n",
      "Batch: 64 , Combined Loss: tensor(0.9270, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.671562671661377\n",
      "Batch: 65 , Combined Loss: tensor(0.6463, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09666919708251953\n",
      "Batch: 66 , Combined Loss: tensor(0.6651, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.741909384727478\n",
      "Batch: 67 , Combined Loss: tensor(0.6126, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3468974828720093\n",
      "Batch: 68 , Combined Loss: tensor(0.7072, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8947856426239014\n",
      "Batch: 69 , Combined Loss: tensor(0.8128, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.035362303256988525\n",
      "Batch: 70 , Combined Loss: tensor(0.6474, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.150705099105835\n",
      "Batch: 71 , Combined Loss: tensor(0.6570, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.934402346611023\n",
      "Batch: 72 , Combined Loss: tensor(0.8688, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36257123947143555\n",
      "Batch: 73 , Combined Loss: tensor(0.6681, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07254296541213989\n",
      "Batch: 74 , Combined Loss: tensor(0.7638, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.885440468788147\n",
      "Batch: 75 , Combined Loss: tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8990606069564819\n",
      "Batch: 76 , Combined Loss: tensor(0.7336, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7822532653808594\n",
      "Batch: 77 , Combined Loss: tensor(0.7181, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8660190105438232\n",
      "Batch: 78 , Combined Loss: tensor(0.6684, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5030828714370728\n",
      "Batch: 79 , Combined Loss: tensor(0.7629, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.669482946395874\n",
      "Batch: 80 , Combined Loss: tensor(0.6782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6406874656677246\n",
      "Batch: 81 , Combined Loss: tensor(0.6290, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2461777925491333\n",
      "Batch: 82 , Combined Loss: tensor(0.6826, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12207138538360596\n",
      "Batch: 83 , Combined Loss: tensor(0.6513, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7053985595703125\n",
      "Batch: 84 , Combined Loss: tensor(0.6309, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7893166542053223\n",
      "Batch: 85 , Combined Loss: tensor(0.8746, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5305172204971313\n",
      "Batch: 86 , Combined Loss: tensor(0.6678, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.411800742149353\n",
      "Batch: 87 , Combined Loss: tensor(0.9165, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8099806308746338\n",
      "Batch: 88 , Combined Loss: tensor(0.7054, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0390639305114746\n",
      "Batch: 89 , Combined Loss: tensor(0.7492, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.38016921281814575\n",
      "Batch: 90 , Combined Loss: tensor(0.7242, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9898439645767212\n",
      "Batch: 91 , Combined Loss: tensor(0.7892, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4257059097290039\n",
      "Batch: 92 , Combined Loss: tensor(0.6161, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30446767807006836\n",
      "Batch: 93 , Combined Loss: tensor(0.8136, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46818506717681885\n",
      "Batch: 94 , Combined Loss: tensor(0.7395, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20886445045471191\n",
      "Batch: 95 , Combined Loss: tensor(0.7228, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9343580007553101\n",
      "Batch: 96 , Combined Loss: tensor(0.7668, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22978490591049194\n",
      "Batch: 97 , Combined Loss: tensor(0.6410, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5211199522018433\n",
      "Batch: 98 , Combined Loss: tensor(0.7406, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5874534845352173\n",
      "Batch: 99 , Combined Loss: tensor(0.7799, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7033380270004272\n",
      "Batch: 100 , Combined Loss: tensor(0.6807, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7419933080673218\n",
      "Batch: 101 , Combined Loss: tensor(0.7181, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9240679740905762\n",
      "Batch: 102 , Combined Loss: tensor(0.6852, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9390852451324463\n",
      "Batch: 103 , Combined Loss: tensor(0.7661, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7459076642990112\n",
      "Batch: 104 , Combined Loss: tensor(0.6357, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7762976884841919\n",
      "Batch: 105 , Combined Loss: tensor(0.7277, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6100039482116699\n",
      "Batch: 106 , Combined Loss: tensor(0.8233, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2806053161621094\n",
      "Batch: 107 , Combined Loss: tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7570714950561523\n",
      "Batch: 108 , Combined Loss: tensor(0.6143, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.176774263381958\n",
      "Batch: 109 , Combined Loss: tensor(0.7354, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8551445007324219\n",
      "Batch: 110 , Combined Loss: tensor(0.6961, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8353743553161621\n",
      "Batch: 111 , Combined Loss: tensor(0.6324, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6989529132843018\n",
      "Batch: 112 , Combined Loss: tensor(1.1714, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03252685070037842\n",
      "Batch: 113 , Combined Loss: tensor(0.7112, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3158597946166992\n",
      "Batch: 114 , Combined Loss: tensor(1.0603, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8382402658462524\n",
      "Batch: 115 , Combined Loss: tensor(0.6897, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8805714845657349\n",
      "Batch: 116 , Combined Loss: tensor(0.8400, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9279204607009888\n",
      "Batch: 117 , Combined Loss: tensor(0.6278, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05194294452667236\n",
      "Batch: 118 , Combined Loss: tensor(0.6414, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8630416393280029\n",
      "Batch: 119 , Combined Loss: tensor(0.6669, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5574983358383179\n",
      "Batch: 120 , Combined Loss: tensor(0.6276, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22433233261108398\n",
      "Batch: 121 , Combined Loss: tensor(0.7763, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4126828908920288\n",
      "Batch: 122 , Combined Loss: tensor(0.7331, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43939220905303955\n",
      "Batch: 123 , Combined Loss: tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3836820125579834\n",
      "Batch: 124 , Combined Loss: tensor(0.7239, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0186383724212646\n",
      "Batch: 125 , Combined Loss: tensor(0.7384, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.052879810333252\n",
      "Batch: 126 , Combined Loss: tensor(0.7031, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8930588960647583\n",
      "Batch: 127 , Combined Loss: tensor(0.6707, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.823122501373291\n",
      "Batch: 128 , Combined Loss: tensor(0.8115, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7792736291885376\n",
      "Batch: 129 , Combined Loss: tensor(0.6533, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13434946537017822\n",
      "Batch: 130 , Combined Loss: tensor(0.6895, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7417179346084595\n",
      "Batch: 131 , Combined Loss: tensor(0.7961, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.34189873933792114\n",
      "Batch: 132 , Combined Loss: tensor(0.6263, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33211541175842285\n",
      "Batch: 133 , Combined Loss: tensor(0.7394, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0602731704711914\n",
      "Batch: 134 , Combined Loss: tensor(0.7057, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6026252508163452\n",
      "Batch: 135 , Combined Loss: tensor(0.7378, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1212131977081299\n",
      "Batch: 136 , Combined Loss: tensor(0.6424, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6643842458724976\n",
      "Batch: 137 , Combined Loss: tensor(0.6243, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21307682991027832\n",
      "Batch: 138 , Combined Loss: tensor(0.7506, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3813823461532593\n",
      "Batch: 139 , Combined Loss: tensor(0.6441, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9792778491973877\n",
      "Batch: 140 , Combined Loss: tensor(0.6307, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5392187833786011\n",
      "Batch: 141 , Combined Loss: tensor(0.6714, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7176655530929565\n",
      "Batch: 142 , Combined Loss: tensor(0.6721, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1171808242797852\n",
      "Batch: 143 , Combined Loss: tensor(0.6912, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0355956554412842\n",
      "Batch: 144 , Combined Loss: tensor(0.7015, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8114043474197388\n",
      "Batch: 145 , Combined Loss: tensor(0.6958, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7310972213745117\n",
      "Batch: 146 , Combined Loss: tensor(0.7074, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.984611988067627\n",
      "Batch: 147 , Combined Loss: tensor(0.6906, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43332183361053467\n",
      "Batch: 148 , Combined Loss: tensor(0.7346, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8962666988372803\n",
      "Batch: 149 , Combined Loss: tensor(0.7860, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3889195919036865\n",
      "Batch: 150 , Combined Loss: tensor(0.6954, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9495143890380859\n",
      "Batch: 151 , Combined Loss: tensor(0.7181, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4209713935852051\n",
      "Batch: 152 , Combined Loss: tensor(0.5936, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8285346031188965\n",
      "Batch: 153 , Combined Loss: tensor(0.6815, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5212156772613525\n",
      "Batch: 154 , Combined Loss: tensor(0.6890, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6095958948135376\n",
      "Batch: 155 , Combined Loss: tensor(0.6525, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7830694913864136\n",
      "Batch: 156 , Combined Loss: tensor(0.6106, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8134565353393555\n",
      "Batch: 157 , Combined Loss: tensor(0.6354, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8069539070129395\n",
      "Batch: 158 , Combined Loss: tensor(0.6445, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5098998546600342\n",
      "Batch: 159 , Combined Loss: tensor(0.7533, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.01495361328125\n",
      "Batch: 160 , Combined Loss: tensor(0.6888, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.772132396697998\n",
      "Batch: 161 , Combined Loss: tensor(0.6814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8674303293228149\n",
      "Batch: 162 , Combined Loss: tensor(0.7237, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0117700099945068\n",
      "Batch: 163 , Combined Loss: tensor(0.6721, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18438255786895752\n",
      "Batch: 164 , Combined Loss: tensor(0.7059, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.80592942237854\n",
      "Batch: 165 , Combined Loss: tensor(0.6054, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7424421310424805\n",
      "Batch: 166 , Combined Loss: tensor(0.6505, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9003722667694092\n",
      "Batch: 167 , Combined Loss: tensor(0.6980, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27211129665374756\n",
      "Batch: 168 , Combined Loss: tensor(0.8310, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31205737590789795\n",
      "Batch: 169 , Combined Loss: tensor(0.6656, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9839009046554565\n",
      "Batch: 170 , Combined Loss: tensor(0.8264, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09146946668624878\n",
      "Batch: 171 , Combined Loss: tensor(0.6885, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5203202962875366\n",
      "Batch: 172 , Combined Loss: tensor(0.9940, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4585607051849365\n",
      "Batch: 173 , Combined Loss: tensor(0.8941, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11319154500961304\n",
      "Batch: 174 , Combined Loss: tensor(0.6048, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34992218017578125\n",
      "Batch: 175 , Combined Loss: tensor(0.5938, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.675823450088501\n",
      "Batch: 176 , Combined Loss: tensor(0.7287, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9427438974380493\n",
      "Batch: 177 , Combined Loss: tensor(0.6789, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0556104183197021\n",
      "Batch: 178 , Combined Loss: tensor(0.6572, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7631480693817139\n",
      "Batch: 179 , Combined Loss: tensor(0.7203, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7497379779815674\n",
      "Batch: 180 , Combined Loss: tensor(0.8027, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2730398178100586\n",
      "Batch: 181 , Combined Loss: tensor(0.6302, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8115227222442627\n",
      "Batch: 182 , Combined Loss: tensor(0.6040, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3972177505493164\n",
      "Batch: 183 , Combined Loss: tensor(0.7907, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5680229663848877\n",
      "Batch: 184 , Combined Loss: tensor(0.6323, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7739789485931396\n",
      "Batch: 185 , Combined Loss: tensor(0.6089, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.160239577293396\n",
      "Batch: 186 , Combined Loss: tensor(0.7830, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7218066453933716\n",
      "Batch: 187 , Combined Loss: tensor(0.6756, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9284723997116089\n",
      "Batch: 188 , Combined Loss: tensor(0.5733, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5673090219497681\n",
      "Batch: 189 , Combined Loss: tensor(0.6384, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6517322063446045\n",
      "Batch: 190 , Combined Loss: tensor(0.6522, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.822253942489624\n",
      "Batch: 191 , Combined Loss: tensor(0.7604, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5248274803161621\n",
      "Batch: 192 , Combined Loss: tensor(0.6928, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3694443702697754\n",
      "Batch: 193 , Combined Loss: tensor(0.6552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1096446514129639\n",
      "Batch: 194 , Combined Loss: tensor(0.7408, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3225208520889282\n",
      "Batch: 195 , Combined Loss: tensor(0.7695, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8813278675079346\n",
      "Batch: 196 , Combined Loss: tensor(0.6036, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7067161798477173\n",
      "Batch: 197 , Combined Loss: tensor(0.7882, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9479895830154419\n",
      "Batch: 198 , Combined Loss: tensor(0.6455, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6913411617279053\n",
      "Batch: 199 , Combined Loss: tensor(0.6977, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16141021251678467\n",
      "Batch: 200 , Combined Loss: tensor(1.0737, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4458875060081482\n",
      "Batch: 201 , Combined Loss: tensor(0.6208, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7537614107131958\n",
      "Batch: 202 , Combined Loss: tensor(0.6388, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4719010591506958\n",
      "Batch: 203 , Combined Loss: tensor(0.7021, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.871170163154602\n",
      "Batch: 204 , Combined Loss: tensor(0.7081, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06145834922790527\n",
      "Batch: 205 , Combined Loss: tensor(0.6533, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8921680450439453\n",
      "Batch: 206 , Combined Loss: tensor(0.9227, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9145877361297607\n",
      "Batch: 207 , Combined Loss: tensor(0.7241, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7941954135894775\n",
      "Batch: 208 , Combined Loss: tensor(0.6407, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7291649580001831\n",
      "Batch: 209 , Combined Loss: tensor(0.8001, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37838196754455566\n",
      "Batch: 210 , Combined Loss: tensor(0.6546, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.620872974395752\n",
      "Batch: 211 , Combined Loss: tensor(0.6495, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6780437231063843\n",
      "Batch: 212 , Combined Loss: tensor(0.6739, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3009045124053955\n",
      "Batch: 213 , Combined Loss: tensor(0.7718, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6523692607879639\n",
      "Batch: 214 , Combined Loss: tensor(0.5809, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9231009483337402\n",
      "Batch: 215 , Combined Loss: tensor(0.6432, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7219976186752319\n",
      "Batch: 216 , Combined Loss: tensor(0.6808, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32293593883514404\n",
      "Batch: 217 , Combined Loss: tensor(0.6788, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8658210039138794\n",
      "Batch: 218 , Combined Loss: tensor(0.6099, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0315322875976562\n",
      "Batch: 219 , Combined Loss: tensor(1.2283, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7562336921691895\n",
      "Batch: 220 , Combined Loss: tensor(0.6885, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0819270610809326\n",
      "Batch: 221 , Combined Loss: tensor(0.6030, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.858675479888916\n",
      "Batch: 222 , Combined Loss: tensor(0.6408, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0423367023468018\n",
      "Batch: 223 , Combined Loss: tensor(0.6901, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4399299621582031\n",
      "Batch: 224 , Combined Loss: tensor(0.7033, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31335294246673584\n",
      "Batch: 225 , Combined Loss: tensor(0.6201, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0134499073028564\n",
      "Batch: 226 , Combined Loss: tensor(0.5972, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.755286693572998\n",
      "Batch: 227 , Combined Loss: tensor(0.6005, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1210963726043701\n",
      "Batch: 228 , Combined Loss: tensor(0.6504, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9253619909286499\n",
      "Batch: 229 , Combined Loss: tensor(0.6567, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.991657018661499\n",
      "Batch: 230 , Combined Loss: tensor(0.6743, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2997838258743286\n",
      "Batch: 231 , Combined Loss: tensor(0.6272, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9466779232025146\n",
      "Batch: 232 , Combined Loss: tensor(0.6732, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8235222101211548\n",
      "Batch: 233 , Combined Loss: tensor(0.6476, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1197497844696045\n",
      "Batch: 234 , Combined Loss: tensor(0.6645, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1795291900634766\n",
      "Batch: 235 , Combined Loss: tensor(0.6502, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9371095895767212\n",
      "Batch: 236 , Combined Loss: tensor(0.5815, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5582664012908936\n",
      "Batch: 237 , Combined Loss: tensor(0.7267, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7763113975524902\n",
      "Batch: 238 , Combined Loss: tensor(0.6260, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.017406702041626\n",
      "Batch: 239 , Combined Loss: tensor(0.7627, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8342504501342773\n",
      "Batch: 240 , Combined Loss: tensor(0.6091, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0057640075683594\n",
      "Batch: 241 , Combined Loss: tensor(0.7614, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7233641147613525\n",
      "Batch: 242 , Combined Loss: tensor(0.5915, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8331925868988037\n",
      "Batch: 243 , Combined Loss: tensor(0.7268, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9510151147842407\n",
      "Batch: 244 , Combined Loss: tensor(0.6831, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6056473255157471\n",
      "Batch: 245 , Combined Loss: tensor(0.7071, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9930739402770996\n",
      "Batch: 246 , Combined Loss: tensor(0.6875, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0230998992919922\n",
      "Batch: 247 , Combined Loss: tensor(0.7606, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8081670999526978\n",
      "Batch: 248 , Combined Loss: tensor(0.6559, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9055455923080444\n",
      "Batch: 249 , Combined Loss: tensor(0.6639, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2861851453781128\n",
      "Batch: 250 , Combined Loss: tensor(0.7178, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8909265995025635\n",
      "Batch: 251 , Combined Loss: tensor(0.5832, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7943629026412964\n",
      "Batch: 252 , Combined Loss: tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7828686237335205\n",
      "Batch: 253 , Combined Loss: tensor(0.6939, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9597560167312622\n",
      "Batch: 254 , Combined Loss: tensor(0.7058, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7048770189285278\n",
      "Batch: 255 , Combined Loss: tensor(0.7677, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7741559743881226\n",
      "Batch: 256 , Combined Loss: tensor(0.6821, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7524079084396362\n",
      "Batch: 257 , Combined Loss: tensor(0.6904, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0952434539794922\n",
      "Batch: 258 , Combined Loss: tensor(0.8527, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35411250591278076\n",
      "Batch: 259 , Combined Loss: tensor(0.6371, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7317999601364136\n",
      "Batch: 260 , Combined Loss: tensor(0.6647, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9980322122573853\n",
      "Batch: 261 , Combined Loss: tensor(0.8832, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2937428951263428\n",
      "Batch: 262 , Combined Loss: tensor(0.8367, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2149139642715454\n",
      "Batch: 263 , Combined Loss: tensor(0.6969, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5393390655517578\n",
      "Batch: 264 , Combined Loss: tensor(0.7541, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42517101764678955\n",
      "Batch: 265 , Combined Loss: tensor(0.8242, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.157647967338562\n",
      "Batch: 266 , Combined Loss: tensor(0.6818, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05796152353286743\n",
      "Batch: 267 , Combined Loss: tensor(0.8099, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3948066234588623\n",
      "Batch: 268 , Combined Loss: tensor(0.6011, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9665172100067139\n",
      "Batch: 269 , Combined Loss: tensor(0.6217, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5520116090774536\n",
      "Batch: 270 , Combined Loss: tensor(0.7622, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8424785137176514\n",
      "Batch: 271 , Combined Loss: tensor(0.6929, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7585227489471436\n",
      "Batch: 272 , Combined Loss: tensor(0.6702, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9974863529205322\n",
      "Batch: 273 , Combined Loss: tensor(0.6827, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05505478382110596\n",
      "Batch: 274 , Combined Loss: tensor(0.6707, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5649129152297974\n",
      "Batch: 275 , Combined Loss: tensor(0.6279, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3780055046081543\n",
      "Batch: 276 , Combined Loss: tensor(0.7237, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5252593755722046\n",
      "Batch: 277 , Combined Loss: tensor(0.7748, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13247263431549072\n",
      "Batch: 278 , Combined Loss: tensor(0.6354, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21319884061813354\n",
      "Batch: 279 , Combined Loss: tensor(0.7632, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6300418376922607\n",
      "Batch: 280 , Combined Loss: tensor(0.8448, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40017807483673096\n",
      "Batch: 281 , Combined Loss: tensor(0.6070, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3091914653778076\n",
      "Batch: 282 , Combined Loss: tensor(0.6765, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.069530963897705\n",
      "Batch: 283 , Combined Loss: tensor(0.6909, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7216200828552246\n",
      "Batch: 284 , Combined Loss: tensor(0.9214, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4988875389099121\n",
      "Batch: 285 , Combined Loss: tensor(0.6467, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07060205936431885\n",
      "Batch: 286 , Combined Loss: tensor(0.6798, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.616287112236023\n",
      "Batch: 287 , Combined Loss: tensor(0.6850, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5958343744277954\n",
      "Batch: 288 , Combined Loss: tensor(0.8739, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12477558851242065\n",
      "Batch: 289 , Combined Loss: tensor(0.6727, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12902188301086426\n",
      "Batch: 290 , Combined Loss: tensor(0.6310, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.00515592098236084\n",
      "Batch: 291 , Combined Loss: tensor(0.7263, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8756026029586792\n",
      "Batch: 292 , Combined Loss: tensor(0.6827, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7018463611602783\n",
      "Batch: 293 , Combined Loss: tensor(0.7496, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9415959119796753\n",
      "Batch: 294 , Combined Loss: tensor(0.7825, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6500101089477539\n",
      "Batch: 295 , Combined Loss: tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6235429048538208\n",
      "Batch: 296 , Combined Loss: tensor(0.6025, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5300334692001343\n",
      "Batch: 297 , Combined Loss: tensor(0.6206, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.938490629196167\n",
      "Batch: 298 , Combined Loss: tensor(0.8102, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5873229503631592\n",
      "Batch: 299 , Combined Loss: tensor(0.8086, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3401062488555908\n",
      "Batch: 300 , Combined Loss: tensor(0.7617, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4852660894393921\n",
      "Batch: 301 , Combined Loss: tensor(0.6338, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7988883256912231\n",
      "Batch: 302 , Combined Loss: tensor(0.9310, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6312456130981445\n",
      "Batch: 303 , Combined Loss: tensor(0.6432, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9818605184555054\n",
      "Batch: 304 , Combined Loss: tensor(0.6459, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9364844560623169\n",
      "Batch: 305 , Combined Loss: tensor(0.9647, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39435702562332153\n",
      "Batch: 306 , Combined Loss: tensor(0.6318, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7073782682418823\n",
      "Batch: 307 , Combined Loss: tensor(0.7620, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3992922306060791\n",
      "Batch: 308 , Combined Loss: tensor(0.8273, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0141758918762207\n",
      "Batch: 309 , Combined Loss: tensor(0.8294, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3820425271987915\n",
      "Batch: 310 , Combined Loss: tensor(0.6403, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03942513465881348\n",
      "Batch: 311 , Combined Loss: tensor(0.6573, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7641662359237671\n",
      "Batch: 312 , Combined Loss: tensor(0.7454, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7853977680206299\n",
      "Batch: 313 , Combined Loss: tensor(0.7697, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33256685733795166\n",
      "Batch: 314 , Combined Loss: tensor(0.6991, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0929030179977417\n",
      "Batch: 315 , Combined Loss: tensor(0.6441, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9355158805847168\n",
      "Batch: 316 , Combined Loss: tensor(0.7438, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07921123504638672\n",
      "Batch: 317 , Combined Loss: tensor(0.7263, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7804406881332397\n",
      "Batch: 318 , Combined Loss: tensor(0.7333, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.853440523147583\n",
      "Batch: 319 , Combined Loss: tensor(0.6741, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9270881414413452\n",
      "Batch: 320 , Combined Loss: tensor(0.6870, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7393944263458252\n",
      "Batch: 321 , Combined Loss: tensor(0.6976, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9003838300704956\n",
      "Batch: 322 , Combined Loss: tensor(0.6812, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49175333976745605\n",
      "Batch: 323 , Combined Loss: tensor(0.6082, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.13168185949325562\n",
      "Batch: 324 , Combined Loss: tensor(0.8283, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.761911153793335\n",
      "Batch: 325 , Combined Loss: tensor(0.7851, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6713086366653442\n",
      "Batch: 326 , Combined Loss: tensor(0.6198, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8958077430725098\n",
      "Batch: 327 , Combined Loss: tensor(0.7567, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21957612037658691\n",
      "Batch: 328 , Combined Loss: tensor(0.6206, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.40156930685043335\n",
      "Batch: 329 , Combined Loss: tensor(0.7798, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7154921293258667\n",
      "Batch: 330 , Combined Loss: tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3550935983657837\n",
      "Batch: 331 , Combined Loss: tensor(0.8510, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5894877910614014\n",
      "Batch: 332 , Combined Loss: tensor(0.6783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.49954694509506226\n",
      "Batch: 333 , Combined Loss: tensor(0.6206, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23590481281280518\n",
      "Batch: 334 , Combined Loss: tensor(0.6894, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.599801778793335\n",
      "Batch: 335 , Combined Loss: tensor(0.6728, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31217753887176514\n",
      "Batch: 336 , Combined Loss: tensor(0.7331, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9030842781066895\n",
      "Batch: 337 , Combined Loss: tensor(0.6075, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4924737215042114\n",
      "Batch: 338 , Combined Loss: tensor(0.6265, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0258524417877197\n",
      "Batch: 339 , Combined Loss: tensor(0.6763, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7918984889984131\n",
      "Batch: 340 , Combined Loss: tensor(0.6123, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7854799032211304\n",
      "Batch: 341 , Combined Loss: tensor(0.6793, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5202635526657104\n",
      "Batch: 342 , Combined Loss: tensor(0.7288, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2643929123878479\n",
      "Batch: 343 , Combined Loss: tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3797358274459839\n",
      "Batch: 344 , Combined Loss: tensor(0.8066, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24781548976898193\n",
      "Batch: 345 , Combined Loss: tensor(0.7494, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20686471462249756\n",
      "Batch: 346 , Combined Loss: tensor(0.7185, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4016897678375244\n",
      "Batch: 347 , Combined Loss: tensor(0.7403, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6141740083694458\n",
      "Batch: 348 , Combined Loss: tensor(0.8166, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5240615606307983\n",
      "Batch: 349 , Combined Loss: tensor(0.8357, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.589587926864624\n",
      "Batch: 350 , Combined Loss: tensor(0.6844, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26788997650146484\n",
      "Batch: 351 , Combined Loss: tensor(0.7532, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24722230434417725\n",
      "Batch: 352 , Combined Loss: tensor(0.6600, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7633317708969116\n",
      "Batch: 353 , Combined Loss: tensor(0.6260, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48285138607025146\n",
      "Batch: 354 , Combined Loss: tensor(0.6516, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42026209831237793\n",
      "Batch: 355 , Combined Loss: tensor(0.8211, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.02412015199661255\n",
      "Batch: 356 , Combined Loss: tensor(0.7690, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7222515344619751\n",
      "Batch: 357 , Combined Loss: tensor(0.6391, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0000171661376953\n",
      "Batch: 358 , Combined Loss: tensor(0.7041, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5104063749313354\n",
      "Batch: 359 , Combined Loss: tensor(0.6763, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8665852546691895\n",
      "Batch: 360 , Combined Loss: tensor(0.7644, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.38821715116500854\n",
      "Batch: 361 , Combined Loss: tensor(0.8664, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1599363088607788\n",
      "Batch: 362 , Combined Loss: tensor(0.8095, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7306251525878906\n",
      "Batch: 363 , Combined Loss: tensor(0.7461, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3443169593811035\n",
      "Batch: 364 , Combined Loss: tensor(0.9899, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1100088357925415\n",
      "Batch: 365 , Combined Loss: tensor(0.7043, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6608223915100098\n",
      "Batch: 366 , Combined Loss: tensor(0.8520, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1810154914855957\n",
      "Batch: 367 , Combined Loss: tensor(0.7559, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.788092851638794\n",
      "Batch: 368 , Combined Loss: tensor(0.7401, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.827118992805481\n",
      "Batch: 369 , Combined Loss: tensor(0.7034, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7092138528823853\n",
      "Batch: 370 , Combined Loss: tensor(0.6938, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2445923089981079\n",
      "Batch: 371 , Combined Loss: tensor(0.7214, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0639348030090332\n",
      "Batch: 372 , Combined Loss: tensor(0.6248, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.784559965133667\n",
      "Batch: 373 , Combined Loss: tensor(0.6872, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1445404291152954\n",
      "Batch: 374 , Combined Loss: tensor(0.7315, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6123027801513672\n",
      "Batch: 375 , Combined Loss: tensor(0.6624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5294197797775269\n",
      "Batch: 376 , Combined Loss: tensor(0.6934, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.42658907175064087\n",
      "Batch: 377 , Combined Loss: tensor(0.6830, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.18737667798995972\n",
      "Batch: 378 , Combined Loss: tensor(0.8598, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6371021270751953\n",
      "Batch: 379 , Combined Loss: tensor(0.7750, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.632521390914917\n",
      "Batch: 380 , Combined Loss: tensor(0.9615, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5433899164199829\n",
      "Batch: 381 , Combined Loss: tensor(0.6680, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3960413932800293\n",
      "Batch: 382 , Combined Loss: tensor(0.6721, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5028561353683472\n",
      "Batch: 383 , Combined Loss: tensor(0.6905, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5860595703125\n",
      "Batch: 384 , Combined Loss: tensor(0.7015, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22195422649383545\n",
      "Batch: 385 , Combined Loss: tensor(0.7012, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0214130878448486\n",
      "Batch: 386 , Combined Loss: tensor(1.1876, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4733484983444214\n",
      "Batch: 387 , Combined Loss: tensor(0.6596, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1428449153900146\n",
      "Batch: 388 , Combined Loss: tensor(0.8085, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46648383140563965\n",
      "Batch: 389 , Combined Loss: tensor(0.7243, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37204062938690186\n",
      "Batch: 390 , Combined Loss: tensor(0.6751, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9303348064422607\n",
      "Batch: 391 , Combined Loss: tensor(0.8077, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44988954067230225\n",
      "Batch: 392 , Combined Loss: tensor(0.6718, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4878506660461426\n",
      "Batch: 393 , Combined Loss: tensor(0.7070, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9070863723754883\n",
      "Batch: 394 , Combined Loss: tensor(0.7211, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7347959280014038\n",
      "Batch: 395 , Combined Loss: tensor(0.9278, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28458499908447266\n",
      "Batch: 396 , Combined Loss: tensor(0.7071, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9745748043060303\n",
      "Batch: 397 , Combined Loss: tensor(0.7098, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.027898311614990234\n",
      "Batch: 398 , Combined Loss: tensor(0.6079, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7416013479232788\n",
      "Batch: 399 , Combined Loss: tensor(0.7186, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49390339851379395\n",
      "Batch: 400 , Combined Loss: tensor(0.8484, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6016935110092163\n",
      "Batch: 401 , Combined Loss: tensor(0.7843, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.703711748123169\n",
      "Batch: 402 , Combined Loss: tensor(0.7496, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0138964653015137\n",
      "Batch: 403 , Combined Loss: tensor(0.6461, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6568732261657715\n",
      "Batch: 404 , Combined Loss: tensor(0.8280, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5837135314941406\n",
      "Batch: 405 , Combined Loss: tensor(0.7602, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36566221714019775\n",
      "Batch: 406 , Combined Loss: tensor(0.6132, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9378576278686523\n",
      "Batch: 407 , Combined Loss: tensor(0.8329, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6163002252578735\n",
      "Batch: 408 , Combined Loss: tensor(0.7039, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6421641111373901\n",
      "Batch: 409 , Combined Loss: tensor(0.7324, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8019256591796875\n",
      "Batch: 410 , Combined Loss: tensor(0.8742, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1019931435585022\n",
      "Batch: 411 , Combined Loss: tensor(0.6532, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48463189601898193\n",
      "Batch: 412 , Combined Loss: tensor(0.5975, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9092828035354614\n",
      "Batch: 413 , Combined Loss: tensor(0.6455, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.014617741107940674\n",
      "Batch: 414 , Combined Loss: tensor(0.8601, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.983739972114563\n",
      "Batch: 415 , Combined Loss: tensor(0.6773, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7242496013641357\n",
      "Batch: 416 , Combined Loss: tensor(0.7382, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.810510516166687\n",
      "Batch: 417 , Combined Loss: tensor(0.8308, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6141576766967773\n",
      "Batch: 418 , Combined Loss: tensor(0.5682, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12741446495056152\n",
      "Batch: 419 , Combined Loss: tensor(0.6878, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3269331455230713\n",
      "Batch: 420 , Combined Loss: tensor(0.6466, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38278043270111084\n",
      "Batch: 421 , Combined Loss: tensor(0.7230, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3301506042480469\n",
      "Batch: 422 , Combined Loss: tensor(0.7017, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.049411773681640625\n",
      "Batch: 423 , Combined Loss: tensor(0.8853, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41626405715942383\n",
      "Batch: 424 , Combined Loss: tensor(0.6958, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.847722053527832\n",
      "Batch: 425 , Combined Loss: tensor(0.7057, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3496914505958557\n",
      "Batch: 426 , Combined Loss: tensor(0.6837, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4684426784515381\n",
      "Batch: 427 , Combined Loss: tensor(0.7073, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6732833385467529\n",
      "Batch: 428 , Combined Loss: tensor(0.7693, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8997793197631836\n",
      "Batch: 429 , Combined Loss: tensor(0.7354, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8106406927108765\n",
      "Batch: 430 , Combined Loss: tensor(0.6308, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7980824708938599\n",
      "Batch: 431 , Combined Loss: tensor(0.6523, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37560558319091797\n",
      "Batch: 432 , Combined Loss: tensor(0.6804, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6690256595611572\n",
      "Batch: 433 , Combined Loss: tensor(0.7866, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8412272930145264\n",
      "Batch: 434 , Combined Loss: tensor(0.5841, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8602548837661743\n",
      "Batch: 435 , Combined Loss: tensor(0.6694, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8334726095199585\n",
      "Batch: 436 , Combined Loss: tensor(0.6180, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3323162794113159\n",
      "Batch: 437 , Combined Loss: tensor(0.7440, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43058013916015625\n",
      "Batch: 438 , Combined Loss: tensor(0.9483, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42164361476898193\n",
      "Batch: 439 , Combined Loss: tensor(0.7938, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7590622901916504\n",
      "Batch: 440 , Combined Loss: tensor(0.6039, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0878009796142578\n",
      "Batch: 441 , Combined Loss: tensor(0.6644, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6813596487045288\n",
      "Batch: 442 , Combined Loss: tensor(0.6407, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7498403787612915\n",
      "Batch: 443 , Combined Loss: tensor(0.6634, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7307476997375488\n",
      "Batch: 444 , Combined Loss: tensor(0.6963, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9539124965667725\n",
      "Batch: 445 , Combined Loss: tensor(0.6587, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6457189321517944\n",
      "Batch: 446 , Combined Loss: tensor(0.6831, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8223007917404175\n",
      "Batch: 447 , Combined Loss: tensor(0.6552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6186076402664185\n",
      "Batch: 448 , Combined Loss: tensor(0.6943, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9032100439071655\n",
      "Batch: 449 , Combined Loss: tensor(0.6828, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42123281955718994\n",
      "Batch: 450 , Combined Loss: tensor(0.6005, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.770220160484314\n",
      "Batch: 451 , Combined Loss: tensor(0.6760, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2551411986351013\n",
      "Batch: 452 , Combined Loss: tensor(0.7266, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19202518463134766\n",
      "Batch: 453 , Combined Loss: tensor(0.7282, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0050463080406188965\n",
      "Batch: 454 , Combined Loss: tensor(0.7253, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6128883361816406\n",
      "Batch: 455 , Combined Loss: tensor(0.8074, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28348827362060547\n",
      "Batch: 456 , Combined Loss: tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7405294179916382\n",
      "Batch: 457 , Combined Loss: tensor(0.8585, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.032064437866211\n",
      "Batch: 458 , Combined Loss: tensor(0.6958, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6756308078765869\n",
      "Batch: 459 , Combined Loss: tensor(0.7678, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.977096438407898\n",
      "Batch: 460 , Combined Loss: tensor(0.6243, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7845813035964966\n",
      "Batch: 461 , Combined Loss: tensor(0.6604, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1949601173400879\n",
      "Batch: 462 , Combined Loss: tensor(0.6601, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.003983736038208\n",
      "Batch: 463 , Combined Loss: tensor(0.6319, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.464214563369751\n",
      "Batch: 464 , Combined Loss: tensor(0.6555, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6944156885147095\n",
      "Batch: 465 , Combined Loss: tensor(0.6943, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.910893440246582\n",
      "Batch: 466 , Combined Loss: tensor(0.6786, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0217792987823486\n",
      "Batch: 467 , Combined Loss: tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9013935327529907\n",
      "Batch: 468 , Combined Loss: tensor(0.8376, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7799849510192871\n",
      "Batch: 469 , Combined Loss: tensor(0.6440, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08137941360473633\n",
      "Batch: 470 , Combined Loss: tensor(0.7070, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.00676119327545166\n",
      "Batch: 471 , Combined Loss: tensor(0.6188, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6927703619003296\n",
      "Batch: 472 , Combined Loss: tensor(0.6944, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9051332473754883\n",
      "Batch: 473 , Combined Loss: tensor(0.6936, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6449495553970337\n",
      "Batch: 474 , Combined Loss: tensor(0.6368, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8633582592010498\n",
      "Batch: 475 , Combined Loss: tensor(0.5433, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28116142749786377\n",
      "Batch: 476 , Combined Loss: tensor(0.6432, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7374007701873779\n",
      "Batch: 477 , Combined Loss: tensor(0.7343, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6242709159851074\n",
      "Batch: 478 , Combined Loss: tensor(0.6558, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2783442735671997\n",
      "Batch: 479 , Combined Loss: tensor(0.6493, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.019899070262908936\n",
      "Batch: 480 , Combined Loss: tensor(0.6770, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0941321849822998\n",
      "Batch: 481 , Combined Loss: tensor(0.6268, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4012448787689209\n",
      "Batch: 482 , Combined Loss: tensor(0.8424, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9986196756362915\n",
      "Batch: 483 , Combined Loss: tensor(0.8193, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9329131841659546\n",
      "Batch: 484 , Combined Loss: tensor(0.6413, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0690746307373047\n",
      "Batch: 485 , Combined Loss: tensor(0.6500, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8277038335800171\n",
      "Batch: 486 , Combined Loss: tensor(0.7105, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5776649713516235\n",
      "Batch: 487 , Combined Loss: tensor(0.6708, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8412601947784424\n",
      "Batch: 488 , Combined Loss: tensor(0.7862, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8149827718734741\n",
      "Batch: 489 , Combined Loss: tensor(0.7029, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2357230186462402\n",
      "Batch: 490 , Combined Loss: tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.132878303527832\n",
      "Batch: 491 , Combined Loss: tensor(0.6600, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0085523128509521\n",
      "Batch: 492 , Combined Loss: tensor(0.6318, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7177779674530029\n",
      "Batch: 493 , Combined Loss: tensor(0.6479, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7514982223510742\n",
      "Batch: 494 , Combined Loss: tensor(0.7435, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6514683961868286\n",
      "Batch: 495 , Combined Loss: tensor(0.6572, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9110931158065796\n",
      "Batch: 496 , Combined Loss: tensor(0.6533, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.104233980178833\n",
      "Batch: 497 , Combined Loss: tensor(0.7568, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.680917501449585\n",
      "Batch: 498 , Combined Loss: tensor(0.5875, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9704610109329224\n",
      "Batch: 499 , Combined Loss: tensor(0.7228, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32472097873687744\n",
      "Batch: 500 , Combined Loss: tensor(0.6828, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48594677448272705\n",
      "Batch: 501 , Combined Loss: tensor(0.6846, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8019808530807495\n",
      "Batch: 502 , Combined Loss: tensor(0.9083, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22923731803894043\n",
      "Batch: 503 , Combined Loss: tensor(0.9120, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9591419696807861\n",
      "Batch: 504 , Combined Loss: tensor(0.6575, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9410300254821777\n",
      "Batch: 505 , Combined Loss: tensor(0.7090, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4686983823776245\n",
      "Batch: 506 , Combined Loss: tensor(0.8250, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6167458295822144\n",
      "Batch: 507 , Combined Loss: tensor(0.5942, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6233006715774536\n",
      "Batch: 508 , Combined Loss: tensor(0.6136, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2256250381469727\n",
      "Batch: 509 , Combined Loss: tensor(0.8127, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5393393039703369\n",
      "Batch: 510 , Combined Loss: tensor(0.6650, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29175734519958496\n",
      "Batch: 511 , Combined Loss: tensor(0.7444, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9092258214950562\n",
      "Batch: 512 , Combined Loss: tensor(0.7518, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0469458103179932\n",
      "Batch: 513 , Combined Loss: tensor(0.6834, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8554044961929321\n",
      "Batch: 514 , Combined Loss: tensor(0.6757, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9726506471633911\n",
      "Batch: 515 , Combined Loss: tensor(0.7125, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4329659938812256\n",
      "Batch: 516 , Combined Loss: tensor(0.6287, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7752038240432739\n",
      "Batch: 517 , Combined Loss: tensor(0.7340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2198241949081421\n",
      "Batch: 518 , Combined Loss: tensor(0.7635, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8646787405014038\n",
      "Batch: 519 , Combined Loss: tensor(0.6760, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0250067710876465\n",
      "Batch: 520 , Combined Loss: tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8416885137557983\n",
      "Batch: 521 , Combined Loss: tensor(0.7714, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9500830173492432\n",
      "Batch: 522 , Combined Loss: tensor(0.7934, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5783624649047852\n",
      "Batch: 523 , Combined Loss: tensor(0.6809, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7917988300323486\n",
      "Batch: 524 , Combined Loss: tensor(0.8012, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06524467468261719\n",
      "Batch: 525 , Combined Loss: tensor(0.6722, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7980540990829468\n",
      "Batch: 526 , Combined Loss: tensor(0.7455, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.091965913772583\n",
      "Batch: 527 , Combined Loss: tensor(0.6774, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8299609422683716\n",
      "Batch: 528 , Combined Loss: tensor(0.5551, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6289564371109009\n",
      "Batch: 529 , Combined Loss: tensor(0.7846, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8885366916656494\n",
      "Batch: 530 , Combined Loss: tensor(0.6915, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6864306926727295\n",
      "Batch: 531 , Combined Loss: tensor(0.9465, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11651813983917236\n",
      "Batch: 532 , Combined Loss: tensor(0.6560, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8504214286804199\n",
      "Batch: 533 , Combined Loss: tensor(0.6768, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0681507587432861\n",
      "Batch: 534 , Combined Loss: tensor(0.7572, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10143846273422241\n",
      "Batch: 535 , Combined Loss: tensor(0.6274, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07807230949401855\n",
      "Batch: 536 , Combined Loss: tensor(0.6758, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.694200873374939\n",
      "Batch: 537 , Combined Loss: tensor(0.6876, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34783828258514404\n",
      "Batch: 538 , Combined Loss: tensor(0.7032, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9599562883377075\n",
      "Batch: 539 , Combined Loss: tensor(0.8922, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7170358896255493\n",
      "Batch: 540 , Combined Loss: tensor(0.6730, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39875245094299316\n",
      "Batch: 541 , Combined Loss: tensor(0.6710, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.735028862953186\n",
      "Batch: 542 , Combined Loss: tensor(0.7988, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9345283508300781\n",
      "Batch: 543 , Combined Loss: tensor(0.5816, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5112332105636597\n",
      "Batch: 544 , Combined Loss: tensor(0.6967, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.873234748840332\n",
      "Batch: 545 , Combined Loss: tensor(0.6233, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11561977863311768\n",
      "Batch: 546 , Combined Loss: tensor(0.6471, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7113994359970093\n",
      "Batch: 547 , Combined Loss: tensor(0.5813, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7603049278259277\n",
      "Batch: 548 , Combined Loss: tensor(0.6150, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8848065137863159\n",
      "Batch: 549 , Combined Loss: tensor(0.6416, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8331269025802612\n",
      "Batch: 550 , Combined Loss: tensor(0.7103, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8513033390045166\n",
      "Batch: 551 , Combined Loss: tensor(0.6101, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.875519871711731\n",
      "Batch: 552 , Combined Loss: tensor(0.7637, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8422043323516846\n",
      "Batch: 553 , Combined Loss: tensor(0.7538, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3810628652572632\n",
      "Batch: 554 , Combined Loss: tensor(0.9260, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9891396760940552\n",
      "Batch: 555 , Combined Loss: tensor(0.7232, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5780432224273682\n",
      "Batch: 556 , Combined Loss: tensor(0.7680, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5310209393501282\n",
      "Batch: 557 , Combined Loss: tensor(0.7021, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0210940837860107\n",
      "Batch: 558 , Combined Loss: tensor(0.6280, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0012319087982178\n",
      "Batch: 559 , Combined Loss: tensor(0.6471, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8396613597869873\n",
      "Batch: 560 , Combined Loss: tensor(0.6593, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.694306492805481\n",
      "Batch: 561 , Combined Loss: tensor(0.6552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9608089923858643\n",
      "Batch: 562 , Combined Loss: tensor(0.6029, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6304464340209961\n",
      "Batch: 563 , Combined Loss: tensor(0.7103, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6285891532897949\n",
      "Batch: 564 , Combined Loss: tensor(0.6487, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1414954662322998\n",
      "Batch: 565 , Combined Loss: tensor(0.6057, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6365052461624146\n",
      "Batch: 566 , Combined Loss: tensor(0.7125, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0978879928588867\n",
      "Batch: 567 , Combined Loss: tensor(0.6219, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1528778076171875\n",
      "Batch: 568 , Combined Loss: tensor(0.6208, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.822723388671875\n",
      "Batch: 569 , Combined Loss: tensor(0.6782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10907822847366333\n",
      "Batch: 570 , Combined Loss: tensor(0.7848, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7290674448013306\n",
      "Batch: 571 , Combined Loss: tensor(0.5825, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11941039562225342\n",
      "Batch: 572 , Combined Loss: tensor(0.6390, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4216177463531494\n",
      "Batch: 573 , Combined Loss: tensor(0.8460, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7578936815261841\n",
      "Batch: 574 , Combined Loss: tensor(0.8263, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.328637957572937\n",
      "Batch: 575 , Combined Loss: tensor(0.7627, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5640313625335693\n",
      "Batch: 576 , Combined Loss: tensor(0.6927, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4236210584640503\n",
      "Batch: 577 , Combined Loss: tensor(0.5634, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2794431447982788\n",
      "Batch: 578 , Combined Loss: tensor(0.6786, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0286524295806885\n",
      "Batch: 579 , Combined Loss: tensor(0.7308, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2076805830001831\n",
      "Batch: 580 , Combined Loss: tensor(0.6340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.40511512756347656\n",
      "Batch: 581 , Combined Loss: tensor(0.8105, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1581511497497559\n",
      "Batch: 582 , Combined Loss: tensor(0.6361, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24263334274291992\n",
      "Batch: 583 , Combined Loss: tensor(0.7026, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08177334070205688\n",
      "Batch: 584 , Combined Loss: tensor(0.7542, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.004258692264556885\n",
      "Batch: 585 , Combined Loss: tensor(0.6904, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0648883581161499\n",
      "Batch: 586 , Combined Loss: tensor(0.6468, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06500589847564697\n",
      "Batch: 587 , Combined Loss: tensor(0.7121, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5598571300506592\n",
      "Batch: 588 , Combined Loss: tensor(0.7363, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.519487738609314\n",
      "Batch: 589 , Combined Loss: tensor(0.7552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5699481964111328\n",
      "Batch: 590 , Combined Loss: tensor(0.6988, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8382599353790283\n",
      "Batch: 591 , Combined Loss: tensor(0.6935, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2089598178863525\n",
      "Batch: 592 , Combined Loss: tensor(0.6869, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5140681266784668\n",
      "Batch: 593 , Combined Loss: tensor(0.6370, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03981500864028931\n",
      "Batch: 594 , Combined Loss: tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8522487878799438\n",
      "Batch: 595 , Combined Loss: tensor(0.7076, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9053158760070801\n",
      "Batch: 596 , Combined Loss: tensor(0.6010, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6833564043045044\n",
      "Batch: 597 , Combined Loss: tensor(0.6709, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8264548778533936\n",
      "Batch: 598 , Combined Loss: tensor(0.7984, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4104427099227905\n",
      "Batch: 599 , Combined Loss: tensor(0.6721, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2634791135787964\n",
      "Batch: 600 , Combined Loss: tensor(0.7905, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6833027601242065\n",
      "Batch: 601 , Combined Loss: tensor(0.7782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8335825204849243\n",
      "Batch: 602 , Combined Loss: tensor(0.7583, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6933821439743042\n",
      "Batch: 603 , Combined Loss: tensor(0.6287, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6381533145904541\n",
      "Batch: 604 , Combined Loss: tensor(0.6725, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9257179498672485\n",
      "Batch: 605 , Combined Loss: tensor(0.7506, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46702754497528076\n",
      "Batch: 606 , Combined Loss: tensor(0.6587, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8860582113265991\n",
      "Batch: 607 , Combined Loss: tensor(0.6164, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0856332778930664\n",
      "Batch: 608 , Combined Loss: tensor(0.6489, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9037370681762695\n",
      "Batch: 609 , Combined Loss: tensor(0.8228, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40892136096954346\n",
      "Batch: 610 , Combined Loss: tensor(0.8248, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5260446071624756\n",
      "Batch: 611 , Combined Loss: tensor(0.9155, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6669065952301025\n",
      "Batch: 612 , Combined Loss: tensor(0.7816, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3587498664855957\n",
      "Batch: 613 , Combined Loss: tensor(0.7394, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0100488662719727\n",
      "Batch: 614 , Combined Loss: tensor(0.6469, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8699647188186646\n",
      "Batch: 615 , Combined Loss: tensor(0.6581, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7073161602020264\n",
      "Batch: 616 , Combined Loss: tensor(0.6084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4005240201950073\n",
      "Batch: 617 , Combined Loss: tensor(0.8551, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6325148344039917\n",
      "Batch: 618 , Combined Loss: tensor(0.7657, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9484610557556152\n",
      "Batch: 619 , Combined Loss: tensor(0.7841, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14657878875732422\n",
      "Batch: 620 , Combined Loss: tensor(0.6705, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3098764419555664\n",
      "Batch: 621 , Combined Loss: tensor(0.7783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.016019701957702637\n",
      "Batch: 622 , Combined Loss: tensor(0.9700, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5479719638824463\n",
      "Batch: 623 , Combined Loss: tensor(0.8267, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21435511112213135\n",
      "Batch: 624 , Combined Loss: tensor(0.6633, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14990806579589844\n",
      "Batch: 625 , Combined Loss: tensor(0.6723, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0052430033683776855\n",
      "Batch: 626 , Combined Loss: tensor(0.6353, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9567098617553711\n",
      "Batch: 627 , Combined Loss: tensor(0.7533, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0520029067993164\n",
      "Batch: 628 , Combined Loss: tensor(0.6556, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1232664585113525\n",
      "----------Epoch 16, Loss: 0.712643733464288, Accuracy: 0.9636291631264983, Dice Coef: [0.9835748022425156, 0.5231356383393825, 0.5809492402740235, 0.6802453966800284], Dice Coef Necrotic: 0.9905722101467699, Dice Coef Edema: 0.9932529144704568, Dice Coef Enhancing: 0.9789506345580785, Sensitivity: [0.9696275489508442, 0.7436821650897282, 0.8444432930603315, 0.864526222804961], Specificity: [0.9675528863844697, 0.9961305141259452, 0.9737023804070271, 0.9948177087477547], Precision: [0.9980370909307265, 0.4728943467735311, 0.4762700436853141, 0.605419264714321]\n",
      "Saving without nn.DataParallel\n",
      "Batch: 0 , Combined Loss: tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9163875579833984\n",
      "Batch: 1 , Combined Loss: tensor(0.6127, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0779540538787842\n",
      "Batch: 2 , Combined Loss: tensor(0.6570, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8155362606048584\n",
      "Batch: 3 , Combined Loss: tensor(0.6637, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9782989025115967\n",
      "Batch: 4 , Combined Loss: tensor(0.6115, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3465833067893982\n",
      "Batch: 5 , Combined Loss: tensor(0.8427, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14768600463867188\n",
      "Batch: 6 , Combined Loss: tensor(0.6929, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9703420400619507\n",
      "Batch: 7 , Combined Loss: tensor(0.7068, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4997577667236328\n",
      "Batch: 8 , Combined Loss: tensor(0.6985, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7499761581420898\n",
      "Batch: 9 , Combined Loss: tensor(0.7350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9057797193527222\n",
      "Batch: 10 , Combined Loss: tensor(0.7077, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.822433590888977\n",
      "Batch: 11 , Combined Loss: tensor(0.7978, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0209014415740967\n",
      "Batch: 12 , Combined Loss: tensor(0.6862, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6370465755462646\n",
      "Batch: 13 , Combined Loss: tensor(0.7750, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4269982576370239\n",
      "Batch: 14 , Combined Loss: tensor(0.8382, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8703973293304443\n",
      "Batch: 15 , Combined Loss: tensor(0.8698, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28971195220947266\n",
      "Batch: 16 , Combined Loss: tensor(0.6800, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.346832513809204\n",
      "Batch: 17 , Combined Loss: tensor(0.6271, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6596790552139282\n",
      "Batch: 18 , Combined Loss: tensor(0.6965, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.32653236389160156\n",
      "Batch: 19 , Combined Loss: tensor(0.6602, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6613893508911133\n",
      "Batch: 20 , Combined Loss: tensor(0.6685, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4464532136917114\n",
      "Batch: 21 , Combined Loss: tensor(0.6661, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2186288833618164\n",
      "Batch: 22 , Combined Loss: tensor(0.7349, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4250563383102417\n",
      "Batch: 23 , Combined Loss: tensor(0.6162, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.90973961353302\n",
      "Batch: 24 , Combined Loss: tensor(0.7247, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9398834705352783\n",
      "Batch: 25 , Combined Loss: tensor(0.6192, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7631113529205322\n",
      "Batch: 26 , Combined Loss: tensor(0.6506, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8208054304122925\n",
      "Batch: 27 , Combined Loss: tensor(0.7217, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16329872608184814\n",
      "Batch: 28 , Combined Loss: tensor(0.8643, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0602543354034424\n",
      "Batch: 29 , Combined Loss: tensor(0.6729, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0404583215713501\n",
      "Batch: 30 , Combined Loss: tensor(0.6956, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6009082794189453\n",
      "Batch: 31 , Combined Loss: tensor(0.7444, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9330096244812012\n",
      "Batch: 32 , Combined Loss: tensor(0.7295, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9775058031082153\n",
      "Batch: 33 , Combined Loss: tensor(0.7088, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8521440029144287\n",
      "Batch: 34 , Combined Loss: tensor(0.8072, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7335401773452759\n",
      "Batch: 35 , Combined Loss: tensor(0.6623, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16555142402648926\n",
      "Batch: 36 , Combined Loss: tensor(0.6956, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10937631130218506\n",
      "Batch: 37 , Combined Loss: tensor(0.7672, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8772960901260376\n",
      "Batch: 38 , Combined Loss: tensor(0.7398, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1013000011444092\n",
      "Batch: 39 , Combined Loss: tensor(0.7922, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4848736524581909\n",
      "Batch: 40 , Combined Loss: tensor(0.6849, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5648140907287598\n",
      "Batch: 41 , Combined Loss: tensor(0.7045, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9553523063659668\n",
      "Batch: 42 , Combined Loss: tensor(0.7547, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.94801926612854\n",
      "Batch: 43 , Combined Loss: tensor(0.9893, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3858001232147217\n",
      "Batch: 44 , Combined Loss: tensor(0.7340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7127268314361572\n",
      "Batch: 45 , Combined Loss: tensor(0.7533, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7209650278091431\n",
      "Batch: 46 , Combined Loss: tensor(0.6143, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6619716882705688\n",
      "Batch: 47 , Combined Loss: tensor(0.7774, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1597597599029541\n",
      "Batch: 48 , Combined Loss: tensor(0.6534, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.17305588722229\n",
      "Batch: 49 , Combined Loss: tensor(0.6394, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5804406404495239\n",
      "Batch: 50 , Combined Loss: tensor(0.6462, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5352531671524048\n",
      "Batch: 51 , Combined Loss: tensor(0.6709, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9983056783676147\n",
      "Batch: 52 , Combined Loss: tensor(0.6879, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7826284170150757\n",
      "Batch: 53 , Combined Loss: tensor(0.7775, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03259652853012085\n",
      "Batch: 54 , Combined Loss: tensor(0.6848, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8140168190002441\n",
      "Batch: 55 , Combined Loss: tensor(0.8552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7076023817062378\n",
      "Batch: 56 , Combined Loss: tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38900482654571533\n",
      "Batch: 57 , Combined Loss: tensor(0.6827, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27352678775787354\n",
      "Batch: 58 , Combined Loss: tensor(0.7449, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.292789101600647\n",
      "Batch: 59 , Combined Loss: tensor(0.6935, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8054274320602417\n",
      "Batch: 60 , Combined Loss: tensor(0.6483, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.883438229560852\n",
      "Batch: 61 , Combined Loss: tensor(0.6238, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35803723335266113\n",
      "Batch: 62 , Combined Loss: tensor(0.7352, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3900214433670044\n",
      "Batch: 63 , Combined Loss: tensor(0.6323, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46043455600738525\n",
      "Batch: 64 , Combined Loss: tensor(0.6583, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5768086910247803\n",
      "Batch: 65 , Combined Loss: tensor(0.6658, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1024315357208252\n",
      "Batch: 66 , Combined Loss: tensor(0.6581, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40402114391326904\n",
      "Batch: 67 , Combined Loss: tensor(0.6099, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0000567436218262\n",
      "Batch: 68 , Combined Loss: tensor(0.6488, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8515363931655884\n",
      "Batch: 69 , Combined Loss: tensor(0.6541, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8932387828826904\n",
      "Batch: 70 , Combined Loss: tensor(0.7012, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7400727272033691\n",
      "Batch: 71 , Combined Loss: tensor(0.7428, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0902690887451172\n",
      "Batch: 72 , Combined Loss: tensor(0.7814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.801232099533081\n",
      "Batch: 73 , Combined Loss: tensor(0.6525, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7837029695510864\n",
      "Batch: 74 , Combined Loss: tensor(0.6508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8476953506469727\n",
      "Batch: 75 , Combined Loss: tensor(0.6856, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3507080078125\n",
      "Batch: 76 , Combined Loss: tensor(0.6528, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6786584854125977\n",
      "Batch: 77 , Combined Loss: tensor(0.5959, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8529618978500366\n",
      "Batch: 78 , Combined Loss: tensor(0.6821, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.585835337638855\n",
      "Batch: 79 , Combined Loss: tensor(0.6366, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0466954708099365\n",
      "Batch: 80 , Combined Loss: tensor(0.7961, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7647720575332642\n",
      "Batch: 81 , Combined Loss: tensor(0.6311, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24190592765808105\n",
      "Batch: 82 , Combined Loss: tensor(0.6109, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.028489351272583\n",
      "Batch: 83 , Combined Loss: tensor(0.7721, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9895223379135132\n",
      "Batch: 84 , Combined Loss: tensor(0.6705, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9472315311431885\n",
      "Batch: 85 , Combined Loss: tensor(0.6805, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6548837423324585\n",
      "Batch: 86 , Combined Loss: tensor(0.8256, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6475589275360107\n",
      "Batch: 87 , Combined Loss: tensor(0.6807, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5293422937393188\n",
      "Batch: 88 , Combined Loss: tensor(0.7526, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0212173461914062\n",
      "Batch: 89 , Combined Loss: tensor(0.6580, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9167169332504272\n",
      "Batch: 90 , Combined Loss: tensor(0.6508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6276156902313232\n",
      "Batch: 91 , Combined Loss: tensor(0.7637, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9192132949829102\n",
      "Batch: 92 , Combined Loss: tensor(0.6183, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0035779476165771\n",
      "Batch: 93 , Combined Loss: tensor(0.7416, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6739965677261353\n",
      "Batch: 94 , Combined Loss: tensor(0.9384, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09055006504058838\n",
      "Batch: 95 , Combined Loss: tensor(0.8454, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8000596761703491\n",
      "Batch: 96 , Combined Loss: tensor(0.8905, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5991002321243286\n",
      "Batch: 97 , Combined Loss: tensor(0.6618, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8274611234664917\n",
      "Batch: 98 , Combined Loss: tensor(0.6080, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4599428176879883\n",
      "Batch: 99 , Combined Loss: tensor(0.6433, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4701131582260132\n",
      "Batch: 100 , Combined Loss: tensor(0.8189, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.046571969985962\n",
      "Batch: 101 , Combined Loss: tensor(0.6210, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6542211771011353\n",
      "Batch: 102 , Combined Loss: tensor(0.5961, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5002948045730591\n",
      "Batch: 103 , Combined Loss: tensor(0.7695, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.954824686050415\n",
      "Batch: 104 , Combined Loss: tensor(0.6369, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5373095273971558\n",
      "Batch: 105 , Combined Loss: tensor(0.7678, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8773943185806274\n",
      "Batch: 106 , Combined Loss: tensor(0.7292, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1136503219604492\n",
      "Batch: 107 , Combined Loss: tensor(0.8102, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7020581960678101\n",
      "Batch: 108 , Combined Loss: tensor(0.6720, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9758538007736206\n",
      "Batch: 109 , Combined Loss: tensor(0.7574, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.546630859375\n",
      "Batch: 110 , Combined Loss: tensor(0.6440, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.635332465171814\n",
      "Batch: 111 , Combined Loss: tensor(0.7441, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1011495590209961\n",
      "Batch: 112 , Combined Loss: tensor(0.8828, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5861843824386597\n",
      "Batch: 113 , Combined Loss: tensor(0.6337, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.732563853263855\n",
      "Batch: 114 , Combined Loss: tensor(0.7683, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.869041919708252\n",
      "Batch: 115 , Combined Loss: tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6419156789779663\n",
      "Batch: 116 , Combined Loss: tensor(0.6281, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3590090870857239\n",
      "Batch: 117 , Combined Loss: tensor(0.8033, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06253588199615479\n",
      "Batch: 118 , Combined Loss: tensor(0.6265, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0238256454467773\n",
      "Batch: 119 , Combined Loss: tensor(0.6662, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9879709482192993\n",
      "Batch: 120 , Combined Loss: tensor(0.6200, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9743006229400635\n",
      "Batch: 121 , Combined Loss: tensor(0.6276, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.644526481628418\n",
      "Batch: 122 , Combined Loss: tensor(0.7074, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7274763584136963\n",
      "Batch: 123 , Combined Loss: tensor(0.8600, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.13736408948898315\n",
      "Batch: 124 , Combined Loss: tensor(0.6931, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11012375354766846\n",
      "Batch: 125 , Combined Loss: tensor(0.7366, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9922226667404175\n",
      "Batch: 126 , Combined Loss: tensor(0.7025, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.252702534198761\n",
      "Batch: 127 , Combined Loss: tensor(0.6350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17280900478363037\n",
      "Batch: 128 , Combined Loss: tensor(0.6995, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.79456627368927\n",
      "Batch: 129 , Combined Loss: tensor(0.6401, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3529040813446045\n",
      "Batch: 130 , Combined Loss: tensor(0.6675, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0519673824310303\n",
      "Batch: 131 , Combined Loss: tensor(0.7111, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0495562553405762\n",
      "Batch: 132 , Combined Loss: tensor(0.6765, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6860260963439941\n",
      "Batch: 133 , Combined Loss: tensor(0.6202, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1074481010437012\n",
      "Batch: 134 , Combined Loss: tensor(0.6610, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4480304718017578\n",
      "Batch: 135 , Combined Loss: tensor(0.6483, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8297513723373413\n",
      "Batch: 136 , Combined Loss: tensor(0.9382, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17513442039489746\n",
      "Batch: 137 , Combined Loss: tensor(0.6470, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7610654830932617\n",
      "Batch: 138 , Combined Loss: tensor(0.8879, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1674962043762207\n",
      "Batch: 139 , Combined Loss: tensor(0.7414, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5077462196350098\n",
      "Batch: 140 , Combined Loss: tensor(0.6833, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6379772424697876\n",
      "Batch: 141 , Combined Loss: tensor(0.7380, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9371670484542847\n",
      "Batch: 142 , Combined Loss: tensor(0.6720, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9080857038497925\n",
      "Batch: 143 , Combined Loss: tensor(0.7369, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09922873973846436\n",
      "Batch: 144 , Combined Loss: tensor(0.7030, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0785210132598877\n",
      "Batch: 145 , Combined Loss: tensor(0.7001, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7717146873474121\n",
      "Batch: 146 , Combined Loss: tensor(0.6731, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7417348623275757\n",
      "Batch: 147 , Combined Loss: tensor(0.8011, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.157301425933838\n",
      "Batch: 148 , Combined Loss: tensor(0.6682, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.727219820022583\n",
      "Batch: 149 , Combined Loss: tensor(0.8038, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06446093320846558\n",
      "Batch: 150 , Combined Loss: tensor(0.8410, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9195914268493652\n",
      "Batch: 151 , Combined Loss: tensor(0.7031, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.59404456615448\n",
      "Batch: 152 , Combined Loss: tensor(0.7179, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9116013050079346\n",
      "Batch: 153 , Combined Loss: tensor(0.7557, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9595385789871216\n",
      "Batch: 154 , Combined Loss: tensor(0.7608, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04290783405303955\n",
      "Batch: 155 , Combined Loss: tensor(0.6952, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8547303676605225\n",
      "Batch: 156 , Combined Loss: tensor(0.6061, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7156397104263306\n",
      "Batch: 157 , Combined Loss: tensor(0.6121, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27511048316955566\n",
      "Batch: 158 , Combined Loss: tensor(0.6924, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7763445377349854\n",
      "Batch: 159 , Combined Loss: tensor(0.6719, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0013759136199951\n",
      "Batch: 160 , Combined Loss: tensor(0.9101, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7874526977539062\n",
      "Batch: 161 , Combined Loss: tensor(0.6880, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04060971736907959\n",
      "Batch: 162 , Combined Loss: tensor(0.6922, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1201103925704956\n",
      "Batch: 163 , Combined Loss: tensor(0.6547, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9046859741210938\n",
      "Batch: 164 , Combined Loss: tensor(0.7742, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6792187690734863\n",
      "Batch: 165 , Combined Loss: tensor(0.6848, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6856623888015747\n",
      "Batch: 166 , Combined Loss: tensor(0.9416, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.056507229804992676\n",
      "Batch: 167 , Combined Loss: tensor(0.6226, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7163093090057373\n",
      "Batch: 168 , Combined Loss: tensor(0.6916, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34616732597351074\n",
      "Batch: 169 , Combined Loss: tensor(0.6338, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24654269218444824\n",
      "Batch: 170 , Combined Loss: tensor(0.6675, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6733951568603516\n",
      "Batch: 171 , Combined Loss: tensor(0.7463, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9613046646118164\n",
      "Batch: 172 , Combined Loss: tensor(0.7639, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8244928121566772\n",
      "Batch: 173 , Combined Loss: tensor(0.7694, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.991135835647583\n",
      "Batch: 174 , Combined Loss: tensor(0.6345, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8964049816131592\n",
      "Batch: 175 , Combined Loss: tensor(0.6592, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8626199960708618\n",
      "Batch: 176 , Combined Loss: tensor(0.6451, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.762365460395813\n",
      "Batch: 177 , Combined Loss: tensor(0.6177, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09053778648376465\n",
      "Batch: 178 , Combined Loss: tensor(0.7502, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21451294422149658\n",
      "Batch: 179 , Combined Loss: tensor(0.7179, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8449009656906128\n",
      "Batch: 180 , Combined Loss: tensor(0.6219, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6815688610076904\n",
      "Batch: 181 , Combined Loss: tensor(0.6789, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49935054779052734\n",
      "Batch: 182 , Combined Loss: tensor(0.6638, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2718579173088074\n",
      "Batch: 183 , Combined Loss: tensor(0.6651, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.044322848320007324\n",
      "Batch: 184 , Combined Loss: tensor(0.7374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.030799031257629395\n",
      "Batch: 185 , Combined Loss: tensor(0.6087, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7702407836914062\n",
      "Batch: 186 , Combined Loss: tensor(0.8171, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6970227956771851\n",
      "Batch: 187 , Combined Loss: tensor(0.6934, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5630420446395874\n",
      "Batch: 188 , Combined Loss: tensor(0.8965, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6105080842971802\n",
      "Batch: 189 , Combined Loss: tensor(0.6397, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0324301719665527\n",
      "Batch: 190 , Combined Loss: tensor(0.6108, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34806978702545166\n",
      "Batch: 191 , Combined Loss: tensor(0.8722, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.877373456954956\n",
      "Batch: 192 , Combined Loss: tensor(0.6506, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.877611517906189\n",
      "Batch: 193 , Combined Loss: tensor(0.8250, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.336618423461914\n",
      "Batch: 194 , Combined Loss: tensor(0.8281, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27683115005493164\n",
      "Batch: 195 , Combined Loss: tensor(0.6528, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.941602349281311\n",
      "Batch: 196 , Combined Loss: tensor(0.7380, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.833295464515686\n",
      "Batch: 197 , Combined Loss: tensor(0.9217, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.055680751800537\n",
      "Batch: 198 , Combined Loss: tensor(0.5867, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7707920074462891\n",
      "Batch: 199 , Combined Loss: tensor(0.6088, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7267956733703613\n",
      "Batch: 200 , Combined Loss: tensor(0.6831, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.780298113822937\n",
      "Batch: 201 , Combined Loss: tensor(0.6589, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6197041273117065\n",
      "Batch: 202 , Combined Loss: tensor(0.6950, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9806041717529297\n",
      "Batch: 203 , Combined Loss: tensor(0.6428, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.899608850479126\n",
      "Batch: 204 , Combined Loss: tensor(0.5853, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8240270614624023\n",
      "Batch: 205 , Combined Loss: tensor(0.5590, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5200889110565186\n",
      "Batch: 206 , Combined Loss: tensor(0.7985, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8358267545700073\n",
      "Batch: 207 , Combined Loss: tensor(0.6010, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3595418930053711\n",
      "Batch: 208 , Combined Loss: tensor(0.7005, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0797326564788818\n",
      "Batch: 209 , Combined Loss: tensor(0.7768, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9580531120300293\n",
      "Batch: 210 , Combined Loss: tensor(0.9442, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8491740226745605\n",
      "Batch: 211 , Combined Loss: tensor(0.6174, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0135433673858643\n",
      "Batch: 212 , Combined Loss: tensor(0.6166, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30254530906677246\n",
      "Batch: 213 , Combined Loss: tensor(1.0592, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3695538640022278\n",
      "Batch: 214 , Combined Loss: tensor(0.6559, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3614926338195801\n",
      "Batch: 215 , Combined Loss: tensor(0.6556, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7516379356384277\n",
      "Batch: 216 , Combined Loss: tensor(0.5623, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.797703742980957\n",
      "Batch: 217 , Combined Loss: tensor(0.7691, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7528179883956909\n",
      "Batch: 218 , Combined Loss: tensor(0.7601, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9156594276428223\n",
      "Batch: 219 , Combined Loss: tensor(0.7666, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6029174327850342\n",
      "Batch: 220 , Combined Loss: tensor(0.7031, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8927669525146484\n",
      "Batch: 221 , Combined Loss: tensor(0.6207, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4552806615829468\n",
      "Batch: 222 , Combined Loss: tensor(0.6532, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7351549863815308\n",
      "Batch: 223 , Combined Loss: tensor(0.6636, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0595498085021973\n",
      "Batch: 224 , Combined Loss: tensor(0.6149, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4686774015426636\n",
      "Batch: 225 , Combined Loss: tensor(0.7508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2683819532394409\n",
      "Batch: 226 , Combined Loss: tensor(0.6622, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8892966508865356\n",
      "Batch: 227 , Combined Loss: tensor(0.6756, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1228516101837158\n",
      "Batch: 228 , Combined Loss: tensor(0.7656, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3806748390197754\n",
      "Batch: 229 , Combined Loss: tensor(0.7629, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0692975521087646\n",
      "Batch: 230 , Combined Loss: tensor(0.6133, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9548431634902954\n",
      "Batch: 231 , Combined Loss: tensor(0.6264, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6726909875869751\n",
      "Batch: 232 , Combined Loss: tensor(0.5961, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8704169988632202\n",
      "Batch: 233 , Combined Loss: tensor(0.6469, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.048948049545288\n",
      "Batch: 234 , Combined Loss: tensor(0.6175, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6198145151138306\n",
      "Batch: 235 , Combined Loss: tensor(0.5948, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9443573951721191\n",
      "Batch: 236 , Combined Loss: tensor(0.6335, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9103829860687256\n",
      "Batch: 237 , Combined Loss: tensor(0.6689, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8493978977203369\n",
      "Batch: 238 , Combined Loss: tensor(0.6206, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7648016214370728\n",
      "Batch: 239 , Combined Loss: tensor(0.6433, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9581547975540161\n",
      "Batch: 240 , Combined Loss: tensor(0.7785, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6022309064865112\n",
      "Batch: 241 , Combined Loss: tensor(0.5839, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40060412883758545\n",
      "Batch: 242 , Combined Loss: tensor(0.7107, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.087942123413086\n",
      "Batch: 243 , Combined Loss: tensor(0.6158, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6250357627868652\n",
      "Batch: 244 , Combined Loss: tensor(0.7970, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9704383611679077\n",
      "Batch: 245 , Combined Loss: tensor(0.6432, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0573101043701172\n",
      "Batch: 246 , Combined Loss: tensor(0.6762, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.440720796585083\n",
      "Batch: 247 , Combined Loss: tensor(0.7491, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8427207469940186\n",
      "Batch: 248 , Combined Loss: tensor(0.6848, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1072604656219482\n",
      "Batch: 249 , Combined Loss: tensor(0.6870, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.278295636177063\n",
      "Batch: 250 , Combined Loss: tensor(0.7945, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6003638505935669\n",
      "Batch: 251 , Combined Loss: tensor(0.6978, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0301942825317383\n",
      "Batch: 252 , Combined Loss: tensor(0.6756, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08861243724822998\n",
      "Batch: 253 , Combined Loss: tensor(0.7061, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9680783748626709\n",
      "Batch: 254 , Combined Loss: tensor(0.7417, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7114070653915405\n",
      "Batch: 255 , Combined Loss: tensor(0.6485, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7144931554794312\n",
      "Batch: 256 , Combined Loss: tensor(0.6470, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8893154859542847\n",
      "Batch: 257 , Combined Loss: tensor(0.6222, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6765614748001099\n",
      "Batch: 258 , Combined Loss: tensor(0.6383, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0279455184936523\n",
      "Batch: 259 , Combined Loss: tensor(0.6880, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7522295713424683\n",
      "Batch: 260 , Combined Loss: tensor(0.6399, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48109495639801025\n",
      "Batch: 261 , Combined Loss: tensor(0.7020, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5415151119232178\n",
      "Batch: 262 , Combined Loss: tensor(0.6990, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3054637908935547\n",
      "Batch: 263 , Combined Loss: tensor(0.7354, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6151025295257568\n",
      "Batch: 264 , Combined Loss: tensor(0.6791, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46028923988342285\n",
      "Batch: 265 , Combined Loss: tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8223530054092407\n",
      "Batch: 266 , Combined Loss: tensor(0.6296, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8045578002929688\n",
      "Batch: 267 , Combined Loss: tensor(0.6961, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7021503448486328\n",
      "Batch: 268 , Combined Loss: tensor(0.7103, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6745858192443848\n",
      "Batch: 269 , Combined Loss: tensor(0.7134, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2618911266326904\n",
      "Batch: 270 , Combined Loss: tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07168728113174438\n",
      "Batch: 271 , Combined Loss: tensor(0.7760, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5360766649246216\n",
      "Batch: 272 , Combined Loss: tensor(0.7532, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8743839263916016\n",
      "Batch: 273 , Combined Loss: tensor(0.6032, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9758524894714355\n",
      "Batch: 274 , Combined Loss: tensor(0.6731, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.562798261642456\n",
      "Batch: 275 , Combined Loss: tensor(0.6861, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0807597637176514\n",
      "Batch: 276 , Combined Loss: tensor(0.8660, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7247872352600098\n",
      "Batch: 277 , Combined Loss: tensor(0.6416, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.253354549407959\n",
      "Batch: 278 , Combined Loss: tensor(0.6796, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6836106777191162\n",
      "Batch: 279 , Combined Loss: tensor(0.8202, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30209898948669434\n",
      "Batch: 280 , Combined Loss: tensor(0.6813, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8418328762054443\n",
      "Batch: 281 , Combined Loss: tensor(0.6597, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0226175785064697\n",
      "Batch: 282 , Combined Loss: tensor(0.8262, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4144587516784668\n",
      "Batch: 283 , Combined Loss: tensor(0.6612, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7399985790252686\n",
      "Batch: 284 , Combined Loss: tensor(0.9351, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.978712797164917\n",
      "Batch: 285 , Combined Loss: tensor(0.8072, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8503545522689819\n",
      "Batch: 286 , Combined Loss: tensor(0.5945, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5470900535583496\n",
      "Batch: 287 , Combined Loss: tensor(0.6008, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.994067907333374\n",
      "Batch: 288 , Combined Loss: tensor(0.8334, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0284359455108643\n",
      "Batch: 289 , Combined Loss: tensor(0.7535, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7695720195770264\n",
      "Batch: 290 , Combined Loss: tensor(0.9608, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6212130784988403\n",
      "Batch: 291 , Combined Loss: tensor(0.7296, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8066047430038452\n",
      "Batch: 292 , Combined Loss: tensor(0.5869, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6385854482650757\n",
      "Batch: 293 , Combined Loss: tensor(0.6653, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.006859540939331\n",
      "Batch: 294 , Combined Loss: tensor(0.9368, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4781816005706787\n",
      "Batch: 295 , Combined Loss: tensor(0.6371, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8679640293121338\n",
      "Batch: 296 , Combined Loss: tensor(0.8077, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0080924034118652\n",
      "Batch: 297 , Combined Loss: tensor(0.5510, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.326435923576355\n",
      "Batch: 298 , Combined Loss: tensor(0.6883, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25374698638916016\n",
      "Batch: 299 , Combined Loss: tensor(0.8441, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6042174100875854\n",
      "Batch: 300 , Combined Loss: tensor(0.8536, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46006035804748535\n",
      "Batch: 301 , Combined Loss: tensor(0.5695, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6339923143386841\n",
      "Batch: 302 , Combined Loss: tensor(0.6765, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8518692255020142\n",
      "Batch: 303 , Combined Loss: tensor(0.6057, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9385643005371094\n",
      "Batch: 304 , Combined Loss: tensor(0.6279, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7153276205062866\n",
      "Batch: 305 , Combined Loss: tensor(0.6668, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09840703010559082\n",
      "Batch: 306 , Combined Loss: tensor(0.7927, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7224758863449097\n",
      "Batch: 307 , Combined Loss: tensor(0.7255, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9084064960479736\n",
      "Batch: 308 , Combined Loss: tensor(0.7669, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6181310415267944\n",
      "Batch: 309 , Combined Loss: tensor(0.6703, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9015076160430908\n",
      "Batch: 310 , Combined Loss: tensor(0.6720, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25961434841156006\n",
      "Batch: 311 , Combined Loss: tensor(0.7135, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0220417976379395\n",
      "Batch: 312 , Combined Loss: tensor(0.6446, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1143903732299805\n",
      "Batch: 313 , Combined Loss: tensor(0.6969, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39853811264038086\n",
      "Batch: 314 , Combined Loss: tensor(0.6310, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.942943811416626\n",
      "Batch: 315 , Combined Loss: tensor(0.6424, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7868373394012451\n",
      "Batch: 316 , Combined Loss: tensor(0.6484, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7861453294754028\n",
      "Batch: 317 , Combined Loss: tensor(0.7744, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7449034452438354\n",
      "Batch: 318 , Combined Loss: tensor(0.8717, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6198180913925171\n",
      "Batch: 319 , Combined Loss: tensor(0.6146, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12174129486083984\n",
      "Batch: 320 , Combined Loss: tensor(0.6983, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9438461065292358\n",
      "Batch: 321 , Combined Loss: tensor(0.6299, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1356768608093262\n",
      "Batch: 322 , Combined Loss: tensor(0.6784, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.836456298828125\n",
      "Batch: 323 , Combined Loss: tensor(0.6669, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1592588424682617\n",
      "Batch: 324 , Combined Loss: tensor(0.6896, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8018186092376709\n",
      "Batch: 325 , Combined Loss: tensor(0.6365, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0983235836029053\n",
      "Batch: 326 , Combined Loss: tensor(0.7348, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09020006656646729\n",
      "Batch: 327 , Combined Loss: tensor(0.5892, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7862240076065063\n",
      "Batch: 328 , Combined Loss: tensor(0.6599, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9508088827133179\n",
      "Batch: 329 , Combined Loss: tensor(0.6359, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2689124345779419\n",
      "Batch: 330 , Combined Loss: tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0154623985290527\n",
      "Batch: 331 , Combined Loss: tensor(0.6360, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8875494003295898\n",
      "Batch: 332 , Combined Loss: tensor(0.6258, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.018956422805786133\n",
      "Batch: 333 , Combined Loss: tensor(0.7396, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05897784233093262\n",
      "Batch: 334 , Combined Loss: tensor(0.6833, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9982173442840576\n",
      "Batch: 335 , Combined Loss: tensor(0.6039, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8631083965301514\n",
      "Batch: 336 , Combined Loss: tensor(0.6506, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7570631504058838\n",
      "Batch: 337 , Combined Loss: tensor(0.6172, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2647169828414917\n",
      "Batch: 338 , Combined Loss: tensor(0.5723, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2515636682510376\n",
      "Batch: 339 , Combined Loss: tensor(0.7596, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9548066854476929\n",
      "Batch: 340 , Combined Loss: tensor(0.6267, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1014649868011475\n",
      "Batch: 341 , Combined Loss: tensor(0.6316, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5667979717254639\n",
      "Batch: 342 , Combined Loss: tensor(0.7872, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2813657522201538\n",
      "Batch: 343 , Combined Loss: tensor(1.0719, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.592078685760498\n",
      "Batch: 344 , Combined Loss: tensor(0.8401, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9164060354232788\n",
      "Batch: 345 , Combined Loss: tensor(0.7265, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32620906829833984\n",
      "Batch: 346 , Combined Loss: tensor(0.8199, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5367470979690552\n",
      "Batch: 347 , Combined Loss: tensor(0.6583, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8005518913269043\n",
      "Batch: 348 , Combined Loss: tensor(0.6598, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9768935441970825\n",
      "Batch: 349 , Combined Loss: tensor(0.6895, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8168631792068481\n",
      "Batch: 350 , Combined Loss: tensor(0.6348, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4713459014892578\n",
      "Batch: 351 , Combined Loss: tensor(0.6478, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6890673637390137\n",
      "Batch: 352 , Combined Loss: tensor(0.6986, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3225240707397461\n",
      "Batch: 353 , Combined Loss: tensor(0.5487, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8306541442871094\n",
      "Batch: 354 , Combined Loss: tensor(0.6285, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0520827770233154\n",
      "Batch: 355 , Combined Loss: tensor(0.7252, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8286216259002686\n",
      "Batch: 356 , Combined Loss: tensor(0.6316, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8509304523468018\n",
      "Batch: 357 , Combined Loss: tensor(0.5440, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.668094277381897\n",
      "Batch: 358 , Combined Loss: tensor(0.6384, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3892216682434082\n",
      "Batch: 359 , Combined Loss: tensor(0.6244, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9907412528991699\n",
      "Batch: 360 , Combined Loss: tensor(0.6759, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9605034589767456\n",
      "Batch: 361 , Combined Loss: tensor(0.8254, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42176830768585205\n",
      "Batch: 362 , Combined Loss: tensor(0.6415, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9919363260269165\n",
      "Batch: 363 , Combined Loss: tensor(0.6603, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8604209423065186\n",
      "Batch: 364 , Combined Loss: tensor(0.6150, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0699307918548584\n",
      "Batch: 365 , Combined Loss: tensor(0.6378, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6487178802490234\n",
      "Batch: 366 , Combined Loss: tensor(0.6260, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3194591999053955\n",
      "Batch: 367 , Combined Loss: tensor(0.6179, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6837434768676758\n",
      "Batch: 368 , Combined Loss: tensor(0.6651, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9434887170791626\n",
      "Batch: 369 , Combined Loss: tensor(0.7508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04261672496795654\n",
      "Batch: 370 , Combined Loss: tensor(0.5449, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3150343894958496\n",
      "Batch: 371 , Combined Loss: tensor(0.6297, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07410228252410889\n",
      "Batch: 372 , Combined Loss: tensor(0.6849, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15388935804367065\n",
      "Batch: 373 , Combined Loss: tensor(0.6578, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9610915184020996\n",
      "Batch: 374 , Combined Loss: tensor(0.5804, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5355676412582397\n",
      "Batch: 375 , Combined Loss: tensor(0.6369, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8155126571655273\n",
      "Batch: 376 , Combined Loss: tensor(0.7484, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6416652202606201\n",
      "Batch: 377 , Combined Loss: tensor(1.1917, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4799422025680542\n",
      "Batch: 378 , Combined Loss: tensor(0.7110, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.89406418800354\n",
      "Batch: 379 , Combined Loss: tensor(0.6316, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.174504280090332\n",
      "Batch: 380 , Combined Loss: tensor(0.7283, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.043026089668273926\n",
      "Batch: 381 , Combined Loss: tensor(0.8155, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0363924503326416\n",
      "Batch: 382 , Combined Loss: tensor(0.8830, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4256402254104614\n",
      "Batch: 383 , Combined Loss: tensor(0.6097, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7556726932525635\n",
      "Batch: 384 , Combined Loss: tensor(0.5806, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9730366468429565\n",
      "Batch: 385 , Combined Loss: tensor(0.8951, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.830406665802002\n",
      "Batch: 386 , Combined Loss: tensor(0.8183, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24028289318084717\n",
      "Batch: 387 , Combined Loss: tensor(0.7858, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4543722867965698\n",
      "Batch: 388 , Combined Loss: tensor(0.7268, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32004213333129883\n",
      "Batch: 389 , Combined Loss: tensor(0.7207, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9006143808364868\n",
      "Batch: 390 , Combined Loss: tensor(0.5995, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0112090110778809\n",
      "Batch: 391 , Combined Loss: tensor(0.5826, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7988636493682861\n",
      "Batch: 392 , Combined Loss: tensor(0.6940, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0721862316131592\n",
      "Batch: 393 , Combined Loss: tensor(0.6548, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05864208936691284\n",
      "Batch: 394 , Combined Loss: tensor(0.6892, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7639906406402588\n",
      "Batch: 395 , Combined Loss: tensor(0.9010, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2874964475631714\n",
      "Batch: 396 , Combined Loss: tensor(0.7215, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.014827311038970947\n",
      "Batch: 397 , Combined Loss: tensor(0.6071, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44005250930786133\n",
      "Batch: 398 , Combined Loss: tensor(0.6789, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1153838634490967\n",
      "Batch: 399 , Combined Loss: tensor(0.7423, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2749975919723511\n",
      "Batch: 400 , Combined Loss: tensor(0.5933, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8223353624343872\n",
      "Batch: 401 , Combined Loss: tensor(0.7254, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9045853614807129\n",
      "Batch: 402 , Combined Loss: tensor(0.7271, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7351711988449097\n",
      "Batch: 403 , Combined Loss: tensor(1.1184, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7495317459106445\n",
      "Batch: 404 , Combined Loss: tensor(0.6629, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9850318431854248\n",
      "Batch: 405 , Combined Loss: tensor(0.6729, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0054032802581787\n",
      "Batch: 406 , Combined Loss: tensor(0.6082, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8913203477859497\n",
      "Batch: 407 , Combined Loss: tensor(0.6336, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4749222993850708\n",
      "Batch: 408 , Combined Loss: tensor(0.6915, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9194067716598511\n",
      "Batch: 409 , Combined Loss: tensor(0.6913, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6737051010131836\n",
      "Batch: 410 , Combined Loss: tensor(0.6448, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0560173988342285\n",
      "Batch: 411 , Combined Loss: tensor(0.6551, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7998210191726685\n",
      "Batch: 412 , Combined Loss: tensor(0.7284, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0552048683166504\n",
      "Batch: 413 , Combined Loss: tensor(0.7374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5298479795455933\n",
      "Batch: 414 , Combined Loss: tensor(0.7640, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7650256156921387\n",
      "Batch: 415 , Combined Loss: tensor(0.7481, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8134690523147583\n",
      "Batch: 416 , Combined Loss: tensor(0.8618, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9913240671157837\n",
      "Batch: 417 , Combined Loss: tensor(0.8010, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9655866622924805\n",
      "Batch: 418 , Combined Loss: tensor(0.6407, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9912351369857788\n",
      "Batch: 419 , Combined Loss: tensor(0.6718, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9978584051132202\n",
      "Batch: 420 , Combined Loss: tensor(0.6464, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1652655601501465\n",
      "Batch: 421 , Combined Loss: tensor(0.8527, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0373492240905762\n",
      "Batch: 422 , Combined Loss: tensor(0.7461, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5040786266326904\n",
      "Batch: 423 , Combined Loss: tensor(1.1899, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4646608829498291\n",
      "Batch: 424 , Combined Loss: tensor(0.7373, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8440824747085571\n",
      "Batch: 425 , Combined Loss: tensor(0.6104, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8577896356582642\n",
      "Batch: 426 , Combined Loss: tensor(0.6177, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9686317443847656\n",
      "Batch: 427 , Combined Loss: tensor(0.7224, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7079282999038696\n",
      "Batch: 428 , Combined Loss: tensor(0.5778, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9339016675949097\n",
      "Batch: 429 , Combined Loss: tensor(0.7114, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5758382081985474\n",
      "Batch: 430 , Combined Loss: tensor(0.5969, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2554457187652588\n",
      "Batch: 431 , Combined Loss: tensor(0.8478, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.746371865272522\n",
      "Batch: 432 , Combined Loss: tensor(0.7940, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6760600805282593\n",
      "Batch: 433 , Combined Loss: tensor(0.7393, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.553881049156189\n",
      "Batch: 434 , Combined Loss: tensor(0.6868, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9005299806594849\n",
      "Batch: 435 , Combined Loss: tensor(0.6293, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8863719701766968\n",
      "Batch: 436 , Combined Loss: tensor(0.6644, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2542848587036133\n",
      "Batch: 437 , Combined Loss: tensor(0.5961, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8972723484039307\n",
      "Batch: 438 , Combined Loss: tensor(0.7268, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15623915195465088\n",
      "Batch: 439 , Combined Loss: tensor(0.7001, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7673619985580444\n",
      "Batch: 440 , Combined Loss: tensor(0.6504, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9287829399108887\n",
      "Batch: 441 , Combined Loss: tensor(0.7096, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0515105724334717\n",
      "Batch: 442 , Combined Loss: tensor(0.6400, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.960330605506897\n",
      "Batch: 443 , Combined Loss: tensor(0.7932, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1664649248123169\n",
      "Batch: 444 , Combined Loss: tensor(0.6754, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5252095460891724\n",
      "Batch: 445 , Combined Loss: tensor(0.6502, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.58141028881073\n",
      "Batch: 446 , Combined Loss: tensor(1.1026, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7762657403945923\n",
      "Batch: 447 , Combined Loss: tensor(0.8319, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07154852151870728\n",
      "Batch: 448 , Combined Loss: tensor(0.6450, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8823155164718628\n",
      "Batch: 449 , Combined Loss: tensor(0.7706, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30586671829223633\n",
      "Batch: 450 , Combined Loss: tensor(0.7553, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43148088455200195\n",
      "Batch: 451 , Combined Loss: tensor(0.6800, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.703783392906189\n",
      "Batch: 452 , Combined Loss: tensor(0.6957, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21800744533538818\n",
      "Batch: 453 , Combined Loss: tensor(0.6469, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2386212348937988\n",
      "Batch: 454 , Combined Loss: tensor(0.7301, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3455166816711426\n",
      "Batch: 455 , Combined Loss: tensor(0.6590, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45197153091430664\n",
      "Batch: 456 , Combined Loss: tensor(0.6347, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7199171781539917\n",
      "Batch: 457 , Combined Loss: tensor(0.6725, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6095888614654541\n",
      "Batch: 458 , Combined Loss: tensor(0.6561, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5970053672790527\n",
      "Batch: 459 , Combined Loss: tensor(0.6986, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7661275863647461\n",
      "Batch: 460 , Combined Loss: tensor(0.7550, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9187088012695312\n",
      "Batch: 461 , Combined Loss: tensor(0.7396, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8038082122802734\n",
      "Batch: 462 , Combined Loss: tensor(0.7237, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8912477493286133\n",
      "Batch: 463 , Combined Loss: tensor(0.8852, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9509272575378418\n",
      "Batch: 464 , Combined Loss: tensor(0.6876, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8163285255432129\n",
      "Batch: 465 , Combined Loss: tensor(0.7751, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9057071208953857\n",
      "Batch: 466 , Combined Loss: tensor(0.7732, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6602797508239746\n",
      "Batch: 467 , Combined Loss: tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5816235542297363\n",
      "Batch: 468 , Combined Loss: tensor(0.6271, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0809950828552246\n",
      "Batch: 469 , Combined Loss: tensor(0.7373, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45295774936676025\n",
      "Batch: 470 , Combined Loss: tensor(0.7092, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9699355363845825\n",
      "Batch: 471 , Combined Loss: tensor(0.7908, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.020702838897705\n",
      "Batch: 472 , Combined Loss: tensor(0.6911, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0858221054077148\n",
      "Batch: 473 , Combined Loss: tensor(0.6729, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8181668519973755\n",
      "Batch: 474 , Combined Loss: tensor(0.7694, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4919050931930542\n",
      "Batch: 475 , Combined Loss: tensor(0.6452, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4811490774154663\n",
      "Batch: 476 , Combined Loss: tensor(0.6805, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5139970779418945\n",
      "Batch: 477 , Combined Loss: tensor(0.6243, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3900442123413086\n",
      "Batch: 478 , Combined Loss: tensor(0.7298, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9741635322570801\n",
      "Batch: 479 , Combined Loss: tensor(0.6976, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.021599650382995605\n",
      "Batch: 480 , Combined Loss: tensor(0.7180, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7503683567047119\n",
      "Batch: 481 , Combined Loss: tensor(0.6903, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8758975267410278\n",
      "Batch: 482 , Combined Loss: tensor(1.0165, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23887968063354492\n",
      "Batch: 483 , Combined Loss: tensor(0.6881, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.052391529083252\n",
      "Batch: 484 , Combined Loss: tensor(0.7101, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12487179040908813\n",
      "Batch: 485 , Combined Loss: tensor(1.0684, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8345680236816406\n",
      "Batch: 486 , Combined Loss: tensor(0.7991, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25678396224975586\n",
      "Batch: 487 , Combined Loss: tensor(0.5932, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3023284077644348\n",
      "Batch: 488 , Combined Loss: tensor(0.7595, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7139712572097778\n",
      "Batch: 489 , Combined Loss: tensor(0.7610, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30519044399261475\n",
      "Batch: 490 , Combined Loss: tensor(0.6000, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03747689723968506\n",
      "Batch: 491 , Combined Loss: tensor(0.6524, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9034203290939331\n",
      "Batch: 492 , Combined Loss: tensor(0.6801, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14417463541030884\n",
      "Batch: 493 , Combined Loss: tensor(0.6926, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9823952913284302\n",
      "Batch: 494 , Combined Loss: tensor(0.6288, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8292220830917358\n",
      "Batch: 495 , Combined Loss: tensor(0.8309, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8470218181610107\n",
      "Batch: 496 , Combined Loss: tensor(0.6810, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7489033937454224\n",
      "Batch: 497 , Combined Loss: tensor(0.6827, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8708548545837402\n",
      "Batch: 498 , Combined Loss: tensor(0.6424, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.03452467918396\n",
      "Batch: 499 , Combined Loss: tensor(0.6425, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8618624210357666\n",
      "Batch: 500 , Combined Loss: tensor(0.7754, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5404384136199951\n",
      "Batch: 501 , Combined Loss: tensor(0.8478, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7274472713470459\n",
      "Batch: 502 , Combined Loss: tensor(1.0901, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3043574094772339\n",
      "Batch: 503 , Combined Loss: tensor(0.7281, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2652796506881714\n",
      "Batch: 504 , Combined Loss: tensor(0.5319, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4817924499511719\n",
      "Batch: 505 , Combined Loss: tensor(0.6961, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1594457626342773\n",
      "Batch: 506 , Combined Loss: tensor(0.6550, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8170480728149414\n",
      "Batch: 507 , Combined Loss: tensor(0.6793, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6641570329666138\n",
      "Batch: 508 , Combined Loss: tensor(0.6287, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0543568134307861\n",
      "Batch: 509 , Combined Loss: tensor(0.6567, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9859604835510254\n",
      "Batch: 510 , Combined Loss: tensor(0.9638, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.745468020439148\n",
      "Batch: 511 , Combined Loss: tensor(0.7510, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.562578558921814\n",
      "Batch: 512 , Combined Loss: tensor(1.0016, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7027072906494141\n",
      "Batch: 513 , Combined Loss: tensor(0.6921, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8314534425735474\n",
      "Batch: 514 , Combined Loss: tensor(0.6171, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1336979866027832\n",
      "Batch: 515 , Combined Loss: tensor(0.6409, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0812723636627197\n",
      "Batch: 516 , Combined Loss: tensor(0.6431, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0900743007659912\n",
      "Batch: 517 , Combined Loss: tensor(0.6195, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1957782506942749\n",
      "Batch: 518 , Combined Loss: tensor(0.5929, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1415550708770752\n",
      "Batch: 519 , Combined Loss: tensor(0.6605, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8777288198471069\n",
      "Batch: 520 , Combined Loss: tensor(0.6408, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0878264904022217\n",
      "Batch: 521 , Combined Loss: tensor(0.7830, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30992817878723145\n",
      "Batch: 522 , Combined Loss: tensor(0.6060, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7997220754623413\n",
      "Batch: 523 , Combined Loss: tensor(0.6405, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6997123956680298\n",
      "Batch: 524 , Combined Loss: tensor(0.6565, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3082810640335083\n",
      "Batch: 525 , Combined Loss: tensor(0.8328, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.776329517364502\n",
      "Batch: 526 , Combined Loss: tensor(0.6693, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8199131488800049\n",
      "Batch: 527 , Combined Loss: tensor(0.6987, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7889107465744019\n",
      "Batch: 528 , Combined Loss: tensor(0.8025, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8283717632293701\n",
      "Batch: 529 , Combined Loss: tensor(0.9006, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5474715232849121\n",
      "Batch: 530 , Combined Loss: tensor(0.6786, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9167083501815796\n",
      "Batch: 531 , Combined Loss: tensor(0.8823, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9864500761032104\n",
      "Batch: 532 , Combined Loss: tensor(0.6041, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.838139533996582\n",
      "Batch: 533 , Combined Loss: tensor(0.6774, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7387683391571045\n",
      "Batch: 534 , Combined Loss: tensor(0.6768, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0039129257202148\n",
      "Batch: 535 , Combined Loss: tensor(0.5819, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6844972372055054\n",
      "Batch: 536 , Combined Loss: tensor(0.6548, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.125284194946289\n",
      "Batch: 537 , Combined Loss: tensor(0.7079, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8950952291488647\n",
      "Batch: 538 , Combined Loss: tensor(0.6143, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8163913488388062\n",
      "Batch: 539 , Combined Loss: tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3300372362136841\n",
      "Batch: 540 , Combined Loss: tensor(0.5731, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0517840385437012\n",
      "Batch: 541 , Combined Loss: tensor(0.6712, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9055010080337524\n",
      "Batch: 542 , Combined Loss: tensor(0.7315, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.886436939239502\n",
      "Batch: 543 , Combined Loss: tensor(0.6795, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7898387908935547\n",
      "Batch: 544 , Combined Loss: tensor(0.6233, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.681280255317688\n",
      "Batch: 545 , Combined Loss: tensor(0.7781, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.779271125793457\n",
      "Batch: 546 , Combined Loss: tensor(0.5895, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0425734519958496\n",
      "Batch: 547 , Combined Loss: tensor(0.6134, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6978024244308472\n",
      "Batch: 548 , Combined Loss: tensor(0.5912, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7988338470458984\n",
      "Batch: 549 , Combined Loss: tensor(0.5906, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17977052927017212\n",
      "Batch: 550 , Combined Loss: tensor(0.8063, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9177032709121704\n",
      "Batch: 551 , Combined Loss: tensor(0.7257, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.980431079864502\n",
      "Batch: 552 , Combined Loss: tensor(0.6947, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7287429571151733\n",
      "Batch: 553 , Combined Loss: tensor(0.6533, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9715880155563354\n",
      "Batch: 554 , Combined Loss: tensor(0.8274, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5757653713226318\n",
      "Batch: 555 , Combined Loss: tensor(0.6711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.047858715057373\n",
      "Batch: 556 , Combined Loss: tensor(0.5788, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.706550121307373\n",
      "Batch: 557 , Combined Loss: tensor(0.6774, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4306536912918091\n",
      "Batch: 558 , Combined Loss: tensor(0.7050, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.018297135829925537\n",
      "Batch: 559 , Combined Loss: tensor(0.5915, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3935903310775757\n",
      "Batch: 560 , Combined Loss: tensor(0.6034, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5705028772354126\n",
      "Batch: 561 , Combined Loss: tensor(0.6589, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.025986850261688232\n",
      "Batch: 562 , Combined Loss: tensor(0.6353, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6930594444274902\n",
      "Batch: 563 , Combined Loss: tensor(0.8118, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8638648986816406\n",
      "Batch: 564 , Combined Loss: tensor(0.6424, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4613196849822998\n",
      "Batch: 565 , Combined Loss: tensor(0.7770, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8590531349182129\n",
      "Batch: 566 , Combined Loss: tensor(0.6719, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.615181565284729\n",
      "Batch: 567 , Combined Loss: tensor(0.6971, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6116112470626831\n",
      "Batch: 568 , Combined Loss: tensor(0.7539, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.71183180809021\n",
      "Batch: 569 , Combined Loss: tensor(0.7562, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8921791315078735\n",
      "Batch: 570 , Combined Loss: tensor(0.6021, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07489174604415894\n",
      "Batch: 571 , Combined Loss: tensor(0.6715, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21351659297943115\n",
      "Batch: 572 , Combined Loss: tensor(0.6349, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0959632396697998\n",
      "Batch: 573 , Combined Loss: tensor(0.9248, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7338486909866333\n",
      "Batch: 574 , Combined Loss: tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9999172687530518\n",
      "Batch: 575 , Combined Loss: tensor(0.6196, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06931936740875244\n",
      "Batch: 576 , Combined Loss: tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8217545747756958\n",
      "Batch: 577 , Combined Loss: tensor(0.6033, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8224513530731201\n",
      "Batch: 578 , Combined Loss: tensor(0.5733, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5803089141845703\n",
      "Batch: 579 , Combined Loss: tensor(0.6908, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7361117601394653\n",
      "Batch: 580 , Combined Loss: tensor(0.6485, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6811113357543945\n",
      "Batch: 581 , Combined Loss: tensor(0.6458, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9789032936096191\n",
      "Batch: 582 , Combined Loss: tensor(0.6500, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8062626123428345\n",
      "Batch: 583 , Combined Loss: tensor(0.9195, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7868245840072632\n",
      "Batch: 584 , Combined Loss: tensor(0.6487, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8571822643280029\n",
      "Batch: 585 , Combined Loss: tensor(0.6280, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7014524936676025\n",
      "Batch: 586 , Combined Loss: tensor(0.6615, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8725768327713013\n",
      "Batch: 587 , Combined Loss: tensor(0.7027, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9431315660476685\n",
      "Batch: 588 , Combined Loss: tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6982954740524292\n",
      "Batch: 589 , Combined Loss: tensor(0.7924, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8957829475402832\n",
      "Batch: 590 , Combined Loss: tensor(0.7176, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23712754249572754\n",
      "Batch: 591 , Combined Loss: tensor(0.6850, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8578464984893799\n",
      "Batch: 592 , Combined Loss: tensor(0.6548, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0610158443450928\n",
      "Batch: 593 , Combined Loss: tensor(0.7591, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8320252895355225\n",
      "Batch: 594 , Combined Loss: tensor(0.6238, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8100594282150269\n",
      "Batch: 595 , Combined Loss: tensor(0.8619, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8516734838485718\n",
      "Batch: 596 , Combined Loss: tensor(0.6806, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19976842403411865\n",
      "Batch: 597 , Combined Loss: tensor(0.6829, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9060083627700806\n",
      "Batch: 598 , Combined Loss: tensor(0.7499, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9145680665969849\n",
      "Batch: 599 , Combined Loss: tensor(0.7878, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4895442724227905\n",
      "Batch: 600 , Combined Loss: tensor(0.7515, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9787555932998657\n",
      "Batch: 601 , Combined Loss: tensor(0.9457, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12424707412719727\n",
      "Batch: 602 , Combined Loss: tensor(0.7326, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9095817804336548\n",
      "Batch: 603 , Combined Loss: tensor(0.6736, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9411860704421997\n",
      "Batch: 604 , Combined Loss: tensor(0.5635, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.836838960647583\n",
      "Batch: 605 , Combined Loss: tensor(0.6448, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9557336568832397\n",
      "Batch: 606 , Combined Loss: tensor(0.6629, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6133276224136353\n",
      "Batch: 607 , Combined Loss: tensor(0.6005, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7830810546875\n",
      "Batch: 608 , Combined Loss: tensor(0.6148, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0822010040283203\n",
      "Batch: 609 , Combined Loss: tensor(0.7828, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09459090232849121\n",
      "Batch: 610 , Combined Loss: tensor(0.6995, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22643083333969116\n",
      "Batch: 611 , Combined Loss: tensor(0.9556, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2219821810722351\n",
      "Batch: 612 , Combined Loss: tensor(0.6846, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.306148886680603\n",
      "Batch: 613 , Combined Loss: tensor(0.5922, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8923459053039551\n",
      "Batch: 614 , Combined Loss: tensor(0.7573, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6224883794784546\n",
      "Batch: 615 , Combined Loss: tensor(0.8090, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7330845594406128\n",
      "Batch: 616 , Combined Loss: tensor(0.6950, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.988573431968689\n",
      "Batch: 617 , Combined Loss: tensor(0.6158, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.074906826019287\n",
      "Batch: 618 , Combined Loss: tensor(0.6299, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.944062352180481\n",
      "Batch: 619 , Combined Loss: tensor(0.7752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8657722473144531\n",
      "Batch: 620 , Combined Loss: tensor(0.7036, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8667064905166626\n",
      "Batch: 621 , Combined Loss: tensor(0.5832, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9717880487442017\n",
      "Batch: 622 , Combined Loss: tensor(0.5891, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9977188110351562\n",
      "Batch: 623 , Combined Loss: tensor(0.6727, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.694063663482666\n",
      "Batch: 624 , Combined Loss: tensor(0.7604, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8696810007095337\n",
      "Batch: 625 , Combined Loss: tensor(0.8678, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7085888385772705\n",
      "Batch: 626 , Combined Loss: tensor(0.7919, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8405115604400635\n",
      "Batch: 627 , Combined Loss: tensor(0.8773, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24270665645599365\n",
      "Batch: 628 , Combined Loss: tensor(0.8467, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23270463943481445\n",
      "----------Epoch 17, Loss: 0.7055224586746083, Accuracy: 0.969870154922073, Dice Coef: [0.9867554613061853, 0.5744520816107398, 0.6184820627994204, 0.6951259426974047], Dice Coef Necrotic: 1.0180999202195316, Dice Coef Edema: 1.0306600464104152, Dice Coef Enhancing: 1.0135362053567418, Sensitivity: [0.976139530089398, 0.7476051484292422, 0.8450864533551736, 0.8732203087445188], Specificity: [0.9627767068782558, 0.9972938656427902, 0.9789944719434353, 0.9950939755182009], Precision: [0.9976804738772503, 0.534245919528282, 0.5223257099283245, 0.6220591023942087]\n",
      "Saving without nn.DataParallel\n",
      "Batch: 0 , Combined Loss: tensor(0.5975, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2767707109451294\n",
      "Batch: 1 , Combined Loss: tensor(0.6056, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31657445430755615\n",
      "Batch: 2 , Combined Loss: tensor(0.6160, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7587897777557373\n",
      "Batch: 3 , Combined Loss: tensor(0.6654, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.023581743240356445\n",
      "Batch: 4 , Combined Loss: tensor(0.5889, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9177132844924927\n",
      "Batch: 5 , Combined Loss: tensor(0.6675, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6829771995544434\n",
      "Batch: 6 , Combined Loss: tensor(0.7221, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1134858131408691\n",
      "Batch: 7 , Combined Loss: tensor(0.6187, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09663999080657959\n",
      "Batch: 8 , Combined Loss: tensor(0.7454, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0376169681549072\n",
      "Batch: 9 , Combined Loss: tensor(0.7949, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.521903395652771\n",
      "Batch: 10 , Combined Loss: tensor(0.6936, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6765351295471191\n",
      "Batch: 11 , Combined Loss: tensor(0.5970, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5863839387893677\n",
      "Batch: 12 , Combined Loss: tensor(0.7654, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05207550525665283\n",
      "Batch: 13 , Combined Loss: tensor(0.6823, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7170875072479248\n",
      "Batch: 14 , Combined Loss: tensor(0.6174, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6737523078918457\n",
      "Batch: 15 , Combined Loss: tensor(0.6388, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.059043288230895996\n",
      "Batch: 16 , Combined Loss: tensor(0.6221, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.015474915504455566\n",
      "Batch: 17 , Combined Loss: tensor(0.5772, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6952803134918213\n",
      "Batch: 18 , Combined Loss: tensor(0.6303, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15339380502700806\n",
      "Batch: 19 , Combined Loss: tensor(0.5912, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7638341188430786\n",
      "Batch: 20 , Combined Loss: tensor(0.5774, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7393202781677246\n",
      "Batch: 21 , Combined Loss: tensor(0.7593, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9008132219314575\n",
      "Batch: 22 , Combined Loss: tensor(0.7075, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04397320747375488\n",
      "Batch: 23 , Combined Loss: tensor(0.6882, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6194703578948975\n",
      "Batch: 24 , Combined Loss: tensor(0.6154, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0989446640014648\n",
      "Batch: 25 , Combined Loss: tensor(0.6543, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4126167297363281\n",
      "Batch: 26 , Combined Loss: tensor(0.6646, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9581950902938843\n",
      "Batch: 27 , Combined Loss: tensor(0.6670, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8284554481506348\n",
      "Batch: 28 , Combined Loss: tensor(0.6743, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4287393093109131\n",
      "Batch: 29 , Combined Loss: tensor(0.6062, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6890579462051392\n",
      "Batch: 30 , Combined Loss: tensor(0.5833, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41382598876953125\n",
      "Batch: 31 , Combined Loss: tensor(0.6607, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4183170795440674\n",
      "Batch: 32 , Combined Loss: tensor(0.6136, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8379026651382446\n",
      "Batch: 33 , Combined Loss: tensor(0.7549, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7609550952911377\n",
      "Batch: 34 , Combined Loss: tensor(0.5990, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5755666494369507\n",
      "Batch: 35 , Combined Loss: tensor(0.6643, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18322861194610596\n",
      "Batch: 36 , Combined Loss: tensor(0.6747, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.92474365234375\n",
      "Batch: 37 , Combined Loss: tensor(0.6185, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11525702476501465\n",
      "Batch: 38 , Combined Loss: tensor(0.7334, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9447227716445923\n",
      "Batch: 39 , Combined Loss: tensor(0.6293, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36399948596954346\n",
      "Batch: 40 , Combined Loss: tensor(0.7218, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7995463609695435\n",
      "Batch: 41 , Combined Loss: tensor(0.8646, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6216733455657959\n",
      "Batch: 42 , Combined Loss: tensor(0.8623, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19982385635375977\n",
      "Batch: 43 , Combined Loss: tensor(0.6677, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.879791259765625\n",
      "Batch: 44 , Combined Loss: tensor(0.7193, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9241493940353394\n",
      "Batch: 45 , Combined Loss: tensor(0.5959, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7457045316696167\n",
      "Batch: 46 , Combined Loss: tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7151623964309692\n",
      "Batch: 47 , Combined Loss: tensor(0.7423, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8310848474502563\n",
      "Batch: 48 , Combined Loss: tensor(0.6265, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7343659400939941\n",
      "Batch: 49 , Combined Loss: tensor(0.7796, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9308258295059204\n",
      "Batch: 50 , Combined Loss: tensor(0.6345, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9102448225021362\n",
      "Batch: 51 , Combined Loss: tensor(0.6155, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1817549467086792\n",
      "Batch: 52 , Combined Loss: tensor(0.6660, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8388819694519043\n",
      "Batch: 53 , Combined Loss: tensor(0.6881, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5674790143966675\n",
      "Batch: 54 , Combined Loss: tensor(0.6231, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4012387990951538\n",
      "Batch: 55 , Combined Loss: tensor(0.6607, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0382511615753174\n",
      "Batch: 56 , Combined Loss: tensor(0.7806, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7528454065322876\n",
      "Batch: 57 , Combined Loss: tensor(0.6107, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0717799663543701\n",
      "Batch: 58 , Combined Loss: tensor(0.8064, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8775875568389893\n",
      "Batch: 59 , Combined Loss: tensor(0.7509, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9062477350234985\n",
      "Batch: 60 , Combined Loss: tensor(0.6805, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6477580070495605\n",
      "Batch: 61 , Combined Loss: tensor(0.7496, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7794281244277954\n",
      "Batch: 62 , Combined Loss: tensor(0.7488, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5802706480026245\n",
      "Batch: 63 , Combined Loss: tensor(0.6036, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44282543659210205\n",
      "Batch: 64 , Combined Loss: tensor(0.6300, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7499014139175415\n",
      "Batch: 65 , Combined Loss: tensor(0.8303, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6339226961135864\n",
      "Batch: 66 , Combined Loss: tensor(0.6958, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.717765212059021\n",
      "Batch: 67 , Combined Loss: tensor(0.7129, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5200388431549072\n",
      "Batch: 68 , Combined Loss: tensor(0.6958, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1226111650466919\n",
      "Batch: 69 , Combined Loss: tensor(1.0477, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2103029489517212\n",
      "Batch: 70 , Combined Loss: tensor(0.5759, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9235575199127197\n",
      "Batch: 71 , Combined Loss: tensor(0.6544, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.693291425704956\n",
      "Batch: 72 , Combined Loss: tensor(0.5975, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9643231630325317\n",
      "Batch: 73 , Combined Loss: tensor(0.6773, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46249401569366455\n",
      "Batch: 74 , Combined Loss: tensor(0.6193, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3719857931137085\n",
      "Batch: 75 , Combined Loss: tensor(0.6400, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.548264741897583\n",
      "Batch: 76 , Combined Loss: tensor(0.7260, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9772508144378662\n",
      "Batch: 77 , Combined Loss: tensor(0.8221, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.556303858757019\n",
      "Batch: 78 , Combined Loss: tensor(0.6294, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0794823169708252\n",
      "Batch: 79 , Combined Loss: tensor(0.6915, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9947776794433594\n",
      "Batch: 80 , Combined Loss: tensor(0.7062, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7220022678375244\n",
      "Batch: 81 , Combined Loss: tensor(0.6209, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5481168031692505\n",
      "Batch: 82 , Combined Loss: tensor(0.6799, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6917564868927002\n",
      "Batch: 83 , Combined Loss: tensor(0.7319, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6942517757415771\n",
      "Batch: 84 , Combined Loss: tensor(0.6082, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9496409893035889\n",
      "Batch: 85 , Combined Loss: tensor(0.7037, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46791374683380127\n",
      "Batch: 86 , Combined Loss: tensor(0.6419, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1276822090148926\n",
      "Batch: 87 , Combined Loss: tensor(0.6265, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7942562103271484\n",
      "Batch: 88 , Combined Loss: tensor(0.7974, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49019134044647217\n",
      "Batch: 89 , Combined Loss: tensor(0.6828, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32667577266693115\n",
      "Batch: 90 , Combined Loss: tensor(0.6505, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8743716478347778\n",
      "Batch: 91 , Combined Loss: tensor(0.7265, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09076350927352905\n",
      "Batch: 92 , Combined Loss: tensor(0.8309, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9516309499740601\n",
      "Batch: 93 , Combined Loss: tensor(0.6760, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49743354320526123\n",
      "Batch: 94 , Combined Loss: tensor(0.6995, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0165808200836182\n",
      "Batch: 95 , Combined Loss: tensor(0.8415, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37864720821380615\n",
      "Batch: 96 , Combined Loss: tensor(0.6475, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5629526376724243\n",
      "Batch: 97 , Combined Loss: tensor(0.7808, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22040003538131714\n",
      "Batch: 98 , Combined Loss: tensor(0.6674, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5065717697143555\n",
      "Batch: 99 , Combined Loss: tensor(0.6082, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3456137180328369\n",
      "Batch: 100 , Combined Loss: tensor(0.7662, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43499696254730225\n",
      "Batch: 101 , Combined Loss: tensor(0.6328, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6405017375946045\n",
      "Batch: 102 , Combined Loss: tensor(0.6545, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0994842052459717\n",
      "Batch: 103 , Combined Loss: tensor(0.7628, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3591722249984741\n",
      "Batch: 104 , Combined Loss: tensor(0.5988, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26185286045074463\n",
      "Batch: 105 , Combined Loss: tensor(0.7952, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5627090930938721\n",
      "Batch: 106 , Combined Loss: tensor(0.7316, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3917689323425293\n",
      "Batch: 107 , Combined Loss: tensor(0.6939, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7280163764953613\n",
      "Batch: 108 , Combined Loss: tensor(0.6696, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9539936780929565\n",
      "Batch: 109 , Combined Loss: tensor(0.7442, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9455373287200928\n",
      "Batch: 110 , Combined Loss: tensor(0.6007, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9343972206115723\n",
      "Batch: 111 , Combined Loss: tensor(0.6702, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8070539236068726\n",
      "Batch: 112 , Combined Loss: tensor(0.7571, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7539582252502441\n",
      "Batch: 113 , Combined Loss: tensor(0.7125, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6154665946960449\n",
      "Batch: 114 , Combined Loss: tensor(0.6731, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6207482814788818\n",
      "Batch: 115 , Combined Loss: tensor(0.7779, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3590071201324463\n",
      "Batch: 116 , Combined Loss: tensor(0.7106, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4484139680862427\n",
      "Batch: 117 , Combined Loss: tensor(0.6240, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1006379127502441\n",
      "Batch: 118 , Combined Loss: tensor(0.7185, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7038322687149048\n",
      "Batch: 119 , Combined Loss: tensor(0.7461, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8304327726364136\n",
      "Batch: 120 , Combined Loss: tensor(0.6266, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7915588617324829\n",
      "Batch: 121 , Combined Loss: tensor(0.6709, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0017919540405273\n",
      "Batch: 122 , Combined Loss: tensor(0.7976, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9032415151596069\n",
      "Batch: 123 , Combined Loss: tensor(0.6865, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8690042495727539\n",
      "Batch: 124 , Combined Loss: tensor(0.6739, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9776151180267334\n",
      "Batch: 125 , Combined Loss: tensor(0.8881, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2971203327178955\n",
      "Batch: 126 , Combined Loss: tensor(0.7529, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7929593324661255\n",
      "Batch: 127 , Combined Loss: tensor(0.7230, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5768662691116333\n",
      "Batch: 128 , Combined Loss: tensor(0.6298, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9841793775558472\n",
      "Batch: 129 , Combined Loss: tensor(0.6014, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.648597002029419\n",
      "Batch: 130 , Combined Loss: tensor(0.6436, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6089966297149658\n",
      "Batch: 131 , Combined Loss: tensor(0.7279, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9251207113265991\n",
      "Batch: 132 , Combined Loss: tensor(0.6757, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8768041133880615\n",
      "Batch: 133 , Combined Loss: tensor(0.6134, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10982811450958252\n",
      "Batch: 134 , Combined Loss: tensor(0.6548, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9176546335220337\n",
      "Batch: 135 , Combined Loss: tensor(0.7201, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36403894424438477\n",
      "Batch: 136 , Combined Loss: tensor(0.6380, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8612505197525024\n",
      "Batch: 137 , Combined Loss: tensor(0.6981, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.032076120376587\n",
      "Batch: 138 , Combined Loss: tensor(0.7054, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24325776100158691\n",
      "Batch: 139 , Combined Loss: tensor(0.7889, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.934118390083313\n",
      "Batch: 140 , Combined Loss: tensor(0.6524, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.89206862449646\n",
      "Batch: 141 , Combined Loss: tensor(0.7099, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9775114059448242\n",
      "Batch: 142 , Combined Loss: tensor(0.6119, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7629294395446777\n",
      "Batch: 143 , Combined Loss: tensor(0.6146, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8005695343017578\n",
      "Batch: 144 , Combined Loss: tensor(0.6715, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9997522830963135\n",
      "Batch: 145 , Combined Loss: tensor(0.5876, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18603038787841797\n",
      "Batch: 146 , Combined Loss: tensor(0.6334, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7201530933380127\n",
      "Batch: 147 , Combined Loss: tensor(0.7994, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8372900485992432\n",
      "Batch: 148 , Combined Loss: tensor(0.6635, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5178265571594238\n",
      "Batch: 149 , Combined Loss: tensor(1.0131, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2961078882217407\n",
      "Batch: 150 , Combined Loss: tensor(0.6988, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9374648332595825\n",
      "Batch: 151 , Combined Loss: tensor(0.6764, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8597625494003296\n",
      "Batch: 152 , Combined Loss: tensor(1.0279, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7261158227920532\n",
      "Batch: 153 , Combined Loss: tensor(0.5860, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.879993200302124\n",
      "Batch: 154 , Combined Loss: tensor(0.8935, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06027209758758545\n",
      "Batch: 155 , Combined Loss: tensor(0.6729, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.204911231994629\n",
      "Batch: 156 , Combined Loss: tensor(0.7060, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8583292961120605\n",
      "Batch: 157 , Combined Loss: tensor(0.8327, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2900567054748535\n",
      "Batch: 158 , Combined Loss: tensor(0.6335, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9666476249694824\n",
      "Batch: 159 , Combined Loss: tensor(0.6331, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8317708969116211\n",
      "Batch: 160 , Combined Loss: tensor(0.6180, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8914932012557983\n",
      "Batch: 161 , Combined Loss: tensor(0.6008, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0018233060836791992\n",
      "Batch: 162 , Combined Loss: tensor(0.6972, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0475947856903076\n",
      "Batch: 163 , Combined Loss: tensor(0.6460, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12134802341461182\n",
      "Batch: 164 , Combined Loss: tensor(0.6668, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9507650136947632\n",
      "Batch: 165 , Combined Loss: tensor(0.6457, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7726377248764038\n",
      "Batch: 166 , Combined Loss: tensor(0.6339, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3797905445098877\n",
      "Batch: 167 , Combined Loss: tensor(0.6724, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0729503631591797\n",
      "Batch: 168 , Combined Loss: tensor(0.8201, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8360961675643921\n",
      "Batch: 169 , Combined Loss: tensor(0.7929, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5136871337890625\n",
      "Batch: 170 , Combined Loss: tensor(0.6724, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22881346940994263\n",
      "Batch: 171 , Combined Loss: tensor(0.6384, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.050408244132995605\n",
      "Batch: 172 , Combined Loss: tensor(0.6341, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0008347034454346\n",
      "Batch: 173 , Combined Loss: tensor(0.8263, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9900021553039551\n",
      "Batch: 174 , Combined Loss: tensor(0.6341, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8658715486526489\n",
      "Batch: 175 , Combined Loss: tensor(0.5907, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6171011924743652\n",
      "Batch: 176 , Combined Loss: tensor(0.6738, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8167668581008911\n",
      "Batch: 177 , Combined Loss: tensor(0.6640, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4698317050933838\n",
      "Batch: 178 , Combined Loss: tensor(1.0243, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5713887214660645\n",
      "Batch: 179 , Combined Loss: tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2150644063949585\n",
      "Batch: 180 , Combined Loss: tensor(0.8975, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18123352527618408\n",
      "Batch: 181 , Combined Loss: tensor(0.7194, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7566680908203125\n",
      "Batch: 182 , Combined Loss: tensor(0.6917, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9882934093475342\n",
      "Batch: 183 , Combined Loss: tensor(0.5988, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9973304271697998\n",
      "Batch: 184 , Combined Loss: tensor(0.6024, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2242252826690674\n",
      "Batch: 185 , Combined Loss: tensor(0.6318, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5881719589233398\n",
      "Batch: 186 , Combined Loss: tensor(0.6488, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0976133346557617\n",
      "Batch: 187 , Combined Loss: tensor(0.6165, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8906350135803223\n",
      "Batch: 188 , Combined Loss: tensor(0.6374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8015687465667725\n",
      "Batch: 189 , Combined Loss: tensor(0.8458, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5777156352996826\n",
      "Batch: 190 , Combined Loss: tensor(0.6636, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05798459053039551\n",
      "Batch: 191 , Combined Loss: tensor(0.7422, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.45929813385009766\n",
      "Batch: 192 , Combined Loss: tensor(0.5834, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1307744979858398\n",
      "Batch: 193 , Combined Loss: tensor(0.6797, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9945075511932373\n",
      "Batch: 194 , Combined Loss: tensor(0.9371, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9990386962890625\n",
      "Batch: 195 , Combined Loss: tensor(0.7496, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.33686238527297974\n",
      "Batch: 196 , Combined Loss: tensor(0.6499, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.589879035949707\n",
      "Batch: 197 , Combined Loss: tensor(0.6766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34786558151245117\n",
      "Batch: 198 , Combined Loss: tensor(0.5672, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.425426721572876\n",
      "Batch: 199 , Combined Loss: tensor(0.6309, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8991485834121704\n",
      "Batch: 200 , Combined Loss: tensor(0.7668, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.32199954986572266\n",
      "Batch: 201 , Combined Loss: tensor(0.6470, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9153585433959961\n",
      "Batch: 202 , Combined Loss: tensor(0.6520, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.01275634765625\n",
      "Batch: 203 , Combined Loss: tensor(0.7265, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.402401864528656\n",
      "Batch: 204 , Combined Loss: tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.417444109916687\n",
      "Batch: 205 , Combined Loss: tensor(0.6468, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.994853138923645\n",
      "Batch: 206 , Combined Loss: tensor(0.5941, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5966241359710693\n",
      "Batch: 207 , Combined Loss: tensor(0.8121, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0129075050354004\n",
      "Batch: 208 , Combined Loss: tensor(0.5776, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4435018301010132\n",
      "Batch: 209 , Combined Loss: tensor(0.5739, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8901300430297852\n",
      "Batch: 210 , Combined Loss: tensor(0.5414, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5559686422348022\n",
      "Batch: 211 , Combined Loss: tensor(0.7006, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8874298334121704\n",
      "Batch: 212 , Combined Loss: tensor(0.6523, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.737326979637146\n",
      "Batch: 213 , Combined Loss: tensor(0.6678, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.734318733215332\n",
      "Batch: 214 , Combined Loss: tensor(0.7314, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7315555810928345\n",
      "Batch: 215 , Combined Loss: tensor(0.6101, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.087282657623291\n",
      "Batch: 216 , Combined Loss: tensor(0.7205, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9819371700286865\n",
      "Batch: 217 , Combined Loss: tensor(0.7598, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08438354730606079\n",
      "Batch: 218 , Combined Loss: tensor(0.7826, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.006256222724914551\n",
      "Batch: 219 , Combined Loss: tensor(0.5770, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4902440309524536\n",
      "Batch: 220 , Combined Loss: tensor(0.7483, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6645393371582031\n",
      "Batch: 221 , Combined Loss: tensor(0.6338, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5950919985771179\n",
      "Batch: 222 , Combined Loss: tensor(0.6954, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5676970481872559\n",
      "Batch: 223 , Combined Loss: tensor(0.9387, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49478769302368164\n",
      "Batch: 224 , Combined Loss: tensor(0.7009, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5941624641418457\n",
      "Batch: 225 , Combined Loss: tensor(0.8296, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6440634727478027\n",
      "Batch: 226 , Combined Loss: tensor(0.6420, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8763529062271118\n",
      "Batch: 227 , Combined Loss: tensor(0.5612, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5274462699890137\n",
      "Batch: 228 , Combined Loss: tensor(0.6978, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.30215227603912354\n",
      "Batch: 229 , Combined Loss: tensor(0.6448, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7803120613098145\n",
      "Batch: 230 , Combined Loss: tensor(0.6443, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7658838033676147\n",
      "Batch: 231 , Combined Loss: tensor(0.6519, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36968934535980225\n",
      "Batch: 232 , Combined Loss: tensor(0.5504, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09845268726348877\n",
      "Batch: 233 , Combined Loss: tensor(0.6927, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7774639129638672\n",
      "Batch: 234 , Combined Loss: tensor(0.8257, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19304168224334717\n",
      "Batch: 235 , Combined Loss: tensor(0.9731, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8768693208694458\n",
      "Batch: 236 , Combined Loss: tensor(0.7509, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6897268295288086\n",
      "Batch: 237 , Combined Loss: tensor(0.6414, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13613379001617432\n",
      "Batch: 238 , Combined Loss: tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6206918954849243\n",
      "Batch: 239 , Combined Loss: tensor(0.6130, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9422488212585449\n",
      "Batch: 240 , Combined Loss: tensor(0.6408, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6694566011428833\n",
      "Batch: 241 , Combined Loss: tensor(0.8850, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42666900157928467\n",
      "Batch: 242 , Combined Loss: tensor(0.6940, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08391809463500977\n",
      "Batch: 243 , Combined Loss: tensor(0.6340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7188690900802612\n",
      "Batch: 244 , Combined Loss: tensor(0.6801, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0260698795318604\n",
      "Batch: 245 , Combined Loss: tensor(0.6214, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9352574348449707\n",
      "Batch: 246 , Combined Loss: tensor(0.5978, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5912134647369385\n",
      "Batch: 247 , Combined Loss: tensor(0.6175, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.961173415184021\n",
      "Batch: 248 , Combined Loss: tensor(0.7057, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8325120210647583\n",
      "Batch: 249 , Combined Loss: tensor(0.7337, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15983915328979492\n",
      "Batch: 250 , Combined Loss: tensor(1.0879, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6066606640815735\n",
      "Batch: 251 , Combined Loss: tensor(0.6695, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2140836715698242\n",
      "Batch: 252 , Combined Loss: tensor(0.5589, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8141943216323853\n",
      "Batch: 253 , Combined Loss: tensor(0.5850, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5568742752075195\n",
      "Batch: 254 , Combined Loss: tensor(0.6607, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3523911237716675\n",
      "Batch: 255 , Combined Loss: tensor(0.6242, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42444419860839844\n",
      "Batch: 256 , Combined Loss: tensor(0.6234, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9127565622329712\n",
      "Batch: 257 , Combined Loss: tensor(0.8394, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2645207643508911\n",
      "Batch: 258 , Combined Loss: tensor(0.5980, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.483828067779541\n",
      "Batch: 259 , Combined Loss: tensor(0.8022, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5796205997467041\n",
      "Batch: 260 , Combined Loss: tensor(0.6213, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7778089046478271\n",
      "Batch: 261 , Combined Loss: tensor(0.6219, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.920051097869873\n",
      "Batch: 262 , Combined Loss: tensor(0.5936, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.992297887802124\n",
      "Batch: 263 , Combined Loss: tensor(0.6939, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8784335851669312\n",
      "Batch: 264 , Combined Loss: tensor(0.8500, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6980141401290894\n",
      "Batch: 265 , Combined Loss: tensor(0.5451, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19168031215667725\n",
      "Batch: 266 , Combined Loss: tensor(0.6560, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10993826389312744\n",
      "Batch: 267 , Combined Loss: tensor(0.6364, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24349820613861084\n",
      "Batch: 268 , Combined Loss: tensor(0.5744, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0462241172790527\n",
      "Batch: 269 , Combined Loss: tensor(0.6749, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09784257411956787\n",
      "Batch: 270 , Combined Loss: tensor(0.6782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5868585109710693\n",
      "Batch: 271 , Combined Loss: tensor(0.6892, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5432873964309692\n",
      "Batch: 272 , Combined Loss: tensor(0.6312, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6498228311538696\n",
      "Batch: 273 , Combined Loss: tensor(0.5878, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8634903430938721\n",
      "Batch: 274 , Combined Loss: tensor(0.8030, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6881287097930908\n",
      "Batch: 275 , Combined Loss: tensor(0.6131, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7884875535964966\n",
      "Batch: 276 , Combined Loss: tensor(0.6516, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0154051780700684\n",
      "Batch: 277 , Combined Loss: tensor(0.7431, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0450060367584229\n",
      "Batch: 278 , Combined Loss: tensor(0.7031, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.010031819343566895\n",
      "Batch: 279 , Combined Loss: tensor(0.7304, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9997134208679199\n",
      "Batch: 280 , Combined Loss: tensor(0.6680, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9269046783447266\n",
      "Batch: 281 , Combined Loss: tensor(0.6414, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5957666635513306\n",
      "Batch: 282 , Combined Loss: tensor(0.6475, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8359998464584351\n",
      "Batch: 283 , Combined Loss: tensor(0.9860, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3442186713218689\n",
      "Batch: 284 , Combined Loss: tensor(0.6359, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0111970901489258\n",
      "Batch: 285 , Combined Loss: tensor(0.6739, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23030173778533936\n",
      "Batch: 286 , Combined Loss: tensor(0.6761, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.119828701019287\n",
      "Batch: 287 , Combined Loss: tensor(0.7831, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7000654935836792\n",
      "Batch: 288 , Combined Loss: tensor(0.6419, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4503520727157593\n",
      "Batch: 289 , Combined Loss: tensor(0.8522, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9335178136825562\n",
      "Batch: 290 , Combined Loss: tensor(0.6590, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0405056476593018\n",
      "Batch: 291 , Combined Loss: tensor(0.6114, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0396220684051514\n",
      "Batch: 292 , Combined Loss: tensor(0.8155, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9591151475906372\n",
      "Batch: 293 , Combined Loss: tensor(0.8109, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44916701316833496\n",
      "Batch: 294 , Combined Loss: tensor(0.6581, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9514570236206055\n",
      "Batch: 295 , Combined Loss: tensor(0.6413, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8903093338012695\n",
      "Batch: 296 , Combined Loss: tensor(0.6447, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.16800981760025024\n",
      "Batch: 297 , Combined Loss: tensor(0.6820, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06593233346939087\n",
      "Batch: 298 , Combined Loss: tensor(0.6825, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3154031038284302\n",
      "Batch: 299 , Combined Loss: tensor(0.5808, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2004178762435913\n",
      "Batch: 300 , Combined Loss: tensor(0.7956, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6278413534164429\n",
      "Batch: 301 , Combined Loss: tensor(0.6092, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0801513195037842\n",
      "Batch: 302 , Combined Loss: tensor(0.6292, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.111220359802246\n",
      "Batch: 303 , Combined Loss: tensor(0.8964, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1214563846588135\n",
      "Batch: 304 , Combined Loss: tensor(0.6433, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9316929578781128\n",
      "Batch: 305 , Combined Loss: tensor(0.8847, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.820956826210022\n",
      "Batch: 306 , Combined Loss: tensor(0.7942, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3409634828567505\n",
      "Batch: 307 , Combined Loss: tensor(0.6333, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18966269493103027\n",
      "Batch: 308 , Combined Loss: tensor(0.6467, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0620927810668945\n",
      "Batch: 309 , Combined Loss: tensor(0.7451, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2785062789916992\n",
      "Batch: 310 , Combined Loss: tensor(0.6224, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9835753440856934\n",
      "Batch: 311 , Combined Loss: tensor(0.6348, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4443976879119873\n",
      "Batch: 312 , Combined Loss: tensor(0.6652, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8634636402130127\n",
      "Batch: 313 , Combined Loss: tensor(0.6463, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9921818971633911\n",
      "Batch: 314 , Combined Loss: tensor(0.7560, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8533589839935303\n",
      "Batch: 315 , Combined Loss: tensor(0.7070, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19230389595031738\n",
      "Batch: 316 , Combined Loss: tensor(0.7690, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1910591125488281\n",
      "Batch: 317 , Combined Loss: tensor(0.7389, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7010682821273804\n",
      "Batch: 318 , Combined Loss: tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.771795392036438\n",
      "Batch: 319 , Combined Loss: tensor(0.6652, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8158320188522339\n",
      "Batch: 320 , Combined Loss: tensor(0.6860, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14666420221328735\n",
      "Batch: 321 , Combined Loss: tensor(0.6301, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42296552658081055\n",
      "Batch: 322 , Combined Loss: tensor(0.5935, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8922054767608643\n",
      "Batch: 323 , Combined Loss: tensor(0.5805, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1434507369995117\n",
      "Batch: 324 , Combined Loss: tensor(0.7639, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.012845754623413\n",
      "Batch: 325 , Combined Loss: tensor(0.6484, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0991132259368896\n",
      "Batch: 326 , Combined Loss: tensor(0.6447, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9556915760040283\n",
      "Batch: 327 , Combined Loss: tensor(0.6680, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29839539527893066\n",
      "Batch: 328 , Combined Loss: tensor(0.7272, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7307913303375244\n",
      "Batch: 329 , Combined Loss: tensor(0.6824, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.029266595840454\n",
      "Batch: 330 , Combined Loss: tensor(0.6110, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8307434320449829\n",
      "Batch: 331 , Combined Loss: tensor(0.6320, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9826408624649048\n",
      "Batch: 332 , Combined Loss: tensor(0.6748, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1956455707550049\n",
      "Batch: 333 , Combined Loss: tensor(0.8146, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41055870056152344\n",
      "Batch: 334 , Combined Loss: tensor(0.5622, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.866134524345398\n",
      "Batch: 335 , Combined Loss: tensor(0.6550, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8481746912002563\n",
      "Batch: 336 , Combined Loss: tensor(0.7472, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0794575214385986\n",
      "Batch: 337 , Combined Loss: tensor(0.6843, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0488264560699463\n",
      "Batch: 338 , Combined Loss: tensor(0.6557, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28288841247558594\n",
      "Batch: 339 , Combined Loss: tensor(0.5920, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9636090993881226\n",
      "Batch: 340 , Combined Loss: tensor(0.7577, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0600430965423584\n",
      "Batch: 341 , Combined Loss: tensor(0.8364, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9922211170196533\n",
      "Batch: 342 , Combined Loss: tensor(0.7251, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9716882705688477\n",
      "Batch: 343 , Combined Loss: tensor(0.5984, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9375829696655273\n",
      "Batch: 344 , Combined Loss: tensor(0.6730, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43894946575164795\n",
      "Batch: 345 , Combined Loss: tensor(0.6513, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8170056343078613\n",
      "Batch: 346 , Combined Loss: tensor(0.6102, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.065417766571045\n",
      "Batch: 347 , Combined Loss: tensor(0.6738, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5077975988388062\n",
      "Batch: 348 , Combined Loss: tensor(0.6066, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42023181915283203\n",
      "Batch: 349 , Combined Loss: tensor(0.5903, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5128054618835449\n",
      "Batch: 350 , Combined Loss: tensor(0.6492, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.854393482208252\n",
      "Batch: 351 , Combined Loss: tensor(0.8531, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6041276454925537\n",
      "Batch: 352 , Combined Loss: tensor(0.5921, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7994527816772461\n",
      "Batch: 353 , Combined Loss: tensor(0.6191, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0565948486328125\n",
      "Batch: 354 , Combined Loss: tensor(0.7014, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9416751861572266\n",
      "Batch: 355 , Combined Loss: tensor(0.6530, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8975180387496948\n",
      "Batch: 356 , Combined Loss: tensor(0.6484, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.888202428817749\n",
      "Batch: 357 , Combined Loss: tensor(0.6569, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9724452495574951\n",
      "Batch: 358 , Combined Loss: tensor(0.7349, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5231494903564453\n",
      "Batch: 359 , Combined Loss: tensor(0.6136, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2613729238510132\n",
      "Batch: 360 , Combined Loss: tensor(0.7613, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0923302173614502\n",
      "Batch: 361 , Combined Loss: tensor(0.6887, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6324093341827393\n",
      "Batch: 362 , Combined Loss: tensor(0.6711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9891762733459473\n",
      "Batch: 363 , Combined Loss: tensor(0.9215, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.944870114326477\n",
      "Batch: 364 , Combined Loss: tensor(0.8355, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.049581289291381836\n",
      "Batch: 365 , Combined Loss: tensor(0.7575, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9304754734039307\n",
      "Batch: 366 , Combined Loss: tensor(0.6473, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1525652408599854\n",
      "Batch: 367 , Combined Loss: tensor(0.6121, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6628825664520264\n",
      "Batch: 368 , Combined Loss: tensor(0.8704, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5526604652404785\n",
      "Batch: 369 , Combined Loss: tensor(0.5922, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.823554277420044\n",
      "Batch: 370 , Combined Loss: tensor(0.9772, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9443191289901733\n",
      "Batch: 371 , Combined Loss: tensor(0.7936, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11494028568267822\n",
      "Batch: 372 , Combined Loss: tensor(0.6829, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8760889768600464\n",
      "Batch: 373 , Combined Loss: tensor(0.7841, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5496907234191895\n",
      "Batch: 374 , Combined Loss: tensor(0.5911, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9367902278900146\n",
      "Batch: 375 , Combined Loss: tensor(0.9420, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2974032163619995\n",
      "Batch: 376 , Combined Loss: tensor(0.7074, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8433318138122559\n",
      "Batch: 377 , Combined Loss: tensor(0.7368, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.060312271118164\n",
      "Batch: 378 , Combined Loss: tensor(0.6596, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8292243480682373\n",
      "Batch: 379 , Combined Loss: tensor(0.6016, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4060707092285156\n",
      "Batch: 380 , Combined Loss: tensor(0.9831, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8506731986999512\n",
      "Batch: 381 , Combined Loss: tensor(0.6303, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.867805004119873\n",
      "Batch: 382 , Combined Loss: tensor(0.6420, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0352709293365479\n",
      "Batch: 383 , Combined Loss: tensor(0.7983, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1103062629699707\n",
      "Batch: 384 , Combined Loss: tensor(0.6184, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.997456431388855\n",
      "Batch: 385 , Combined Loss: tensor(0.7450, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.911892294883728\n",
      "Batch: 386 , Combined Loss: tensor(0.8721, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7635353803634644\n",
      "Batch: 387 , Combined Loss: tensor(0.6197, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0787560939788818\n",
      "Batch: 388 , Combined Loss: tensor(0.6302, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8350925445556641\n",
      "Batch: 389 , Combined Loss: tensor(0.9257, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47071778774261475\n",
      "Batch: 390 , Combined Loss: tensor(0.5340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6355243921279907\n",
      "Batch: 391 , Combined Loss: tensor(0.6058, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.735159158706665\n",
      "Batch: 392 , Combined Loss: tensor(0.7014, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7315890789031982\n",
      "Batch: 393 , Combined Loss: tensor(0.7638, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9179960489273071\n",
      "Batch: 394 , Combined Loss: tensor(0.6838, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.637320876121521\n",
      "Batch: 395 , Combined Loss: tensor(0.5956, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8090351819992065\n",
      "Batch: 396 , Combined Loss: tensor(0.7887, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3757575750350952\n",
      "Batch: 397 , Combined Loss: tensor(0.7438, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2714037895202637\n",
      "Batch: 398 , Combined Loss: tensor(0.6085, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1760571002960205\n",
      "Batch: 399 , Combined Loss: tensor(0.6353, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9875717163085938\n",
      "Batch: 400 , Combined Loss: tensor(0.6936, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8196111917495728\n",
      "Batch: 401 , Combined Loss: tensor(0.6516, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5508025884628296\n",
      "Batch: 402 , Combined Loss: tensor(0.6969, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12160301208496094\n",
      "Batch: 403 , Combined Loss: tensor(0.5699, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6194419860839844\n",
      "Batch: 404 , Combined Loss: tensor(0.7040, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.021941065788269043\n",
      "Batch: 405 , Combined Loss: tensor(0.6598, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8494220972061157\n",
      "Batch: 406 , Combined Loss: tensor(0.6914, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6086156368255615\n",
      "Batch: 407 , Combined Loss: tensor(0.8041, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5201438665390015\n",
      "Batch: 408 , Combined Loss: tensor(0.7667, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5218456983566284\n",
      "Batch: 409 , Combined Loss: tensor(0.6615, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.91716468334198\n",
      "Batch: 410 , Combined Loss: tensor(0.7084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8424164056777954\n",
      "Batch: 411 , Combined Loss: tensor(0.6537, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8056225776672363\n",
      "Batch: 412 , Combined Loss: tensor(0.6099, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6939979791641235\n",
      "Batch: 413 , Combined Loss: tensor(0.6896, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8430145978927612\n",
      "Batch: 414 , Combined Loss: tensor(0.6975, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20339572429656982\n",
      "Batch: 415 , Combined Loss: tensor(0.6638, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4970417022705078\n",
      "Batch: 416 , Combined Loss: tensor(0.7325, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.583145260810852\n",
      "Batch: 417 , Combined Loss: tensor(0.6371, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0623948574066162\n",
      "Batch: 418 , Combined Loss: tensor(0.6641, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7880579233169556\n",
      "Batch: 419 , Combined Loss: tensor(0.5882, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9094101190567017\n",
      "Batch: 420 , Combined Loss: tensor(0.6061, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0202586650848389\n",
      "Batch: 421 , Combined Loss: tensor(0.7461, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45460236072540283\n",
      "Batch: 422 , Combined Loss: tensor(0.6160, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12009119987487793\n",
      "Batch: 423 , Combined Loss: tensor(0.6340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.953819751739502\n",
      "Batch: 424 , Combined Loss: tensor(0.5642, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3723580837249756\n",
      "Batch: 425 , Combined Loss: tensor(0.8176, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6698894500732422\n",
      "Batch: 426 , Combined Loss: tensor(0.7446, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4264662265777588\n",
      "Batch: 427 , Combined Loss: tensor(0.8774, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7711117267608643\n",
      "Batch: 428 , Combined Loss: tensor(0.6114, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4539991617202759\n",
      "Batch: 429 , Combined Loss: tensor(0.7455, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7498513460159302\n",
      "Batch: 430 , Combined Loss: tensor(0.6385, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0693321228027344\n",
      "Batch: 431 , Combined Loss: tensor(0.6157, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8521047830581665\n",
      "Batch: 432 , Combined Loss: tensor(0.6057, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44166290760040283\n",
      "Batch: 433 , Combined Loss: tensor(0.6648, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.111577033996582\n",
      "Batch: 434 , Combined Loss: tensor(0.6606, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.057260870933532715\n",
      "Batch: 435 , Combined Loss: tensor(0.6965, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1304948329925537\n",
      "Batch: 436 , Combined Loss: tensor(0.7522, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.005584955215454\n",
      "Batch: 437 , Combined Loss: tensor(0.7520, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9366459846496582\n",
      "Batch: 438 , Combined Loss: tensor(0.7884, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8939155340194702\n",
      "Batch: 439 , Combined Loss: tensor(0.8190, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7261489629745483\n",
      "Batch: 440 , Combined Loss: tensor(0.8234, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15777182579040527\n",
      "Batch: 441 , Combined Loss: tensor(0.9623, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6528643369674683\n",
      "Batch: 442 , Combined Loss: tensor(0.6276, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.237657070159912\n",
      "Batch: 443 , Combined Loss: tensor(0.5870, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0452468395233154\n",
      "Batch: 444 , Combined Loss: tensor(0.6048, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6784142255783081\n",
      "Batch: 445 , Combined Loss: tensor(1.1907, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4489341974258423\n",
      "Batch: 446 , Combined Loss: tensor(0.7016, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9455585479736328\n",
      "Batch: 447 , Combined Loss: tensor(0.7000, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.127729892730713\n",
      "Batch: 448 , Combined Loss: tensor(0.6604, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9302289485931396\n",
      "Batch: 449 , Combined Loss: tensor(0.7486, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.035691738128662\n",
      "Batch: 450 , Combined Loss: tensor(0.7951, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8472975492477417\n",
      "Batch: 451 , Combined Loss: tensor(0.6345, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2732701301574707\n",
      "Batch: 452 , Combined Loss: tensor(0.6766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8813902139663696\n",
      "Batch: 453 , Combined Loss: tensor(0.7332, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.804997444152832\n",
      "Batch: 454 , Combined Loss: tensor(0.5661, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9879523515701294\n",
      "Batch: 455 , Combined Loss: tensor(0.7036, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8671976327896118\n",
      "Batch: 456 , Combined Loss: tensor(0.7253, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7664848566055298\n",
      "Batch: 457 , Combined Loss: tensor(0.6807, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8615279197692871\n",
      "Batch: 458 , Combined Loss: tensor(0.7222, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6116689443588257\n",
      "Batch: 459 , Combined Loss: tensor(0.6062, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6142623424530029\n",
      "Batch: 460 , Combined Loss: tensor(0.6187, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9850988388061523\n",
      "Batch: 461 , Combined Loss: tensor(0.7480, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8894674777984619\n",
      "Batch: 462 , Combined Loss: tensor(0.8115, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8753495216369629\n",
      "Batch: 463 , Combined Loss: tensor(0.6273, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.670640230178833\n",
      "Batch: 464 , Combined Loss: tensor(0.6008, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5586053133010864\n",
      "Batch: 465 , Combined Loss: tensor(0.6501, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7586253881454468\n",
      "Batch: 466 , Combined Loss: tensor(0.6426, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8814481496810913\n",
      "Batch: 467 , Combined Loss: tensor(0.5015, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5378168821334839\n",
      "Batch: 468 , Combined Loss: tensor(0.6200, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9072785377502441\n",
      "Batch: 469 , Combined Loss: tensor(0.6402, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5067466497421265\n",
      "Batch: 470 , Combined Loss: tensor(0.6095, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.624503493309021\n",
      "Batch: 471 , Combined Loss: tensor(0.5943, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9121204614639282\n",
      "Batch: 472 , Combined Loss: tensor(0.7134, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9871494770050049\n",
      "Batch: 473 , Combined Loss: tensor(0.7754, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9230760335922241\n",
      "Batch: 474 , Combined Loss: tensor(0.7194, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0050387382507324\n",
      "Batch: 475 , Combined Loss: tensor(0.7016, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0700592994689941\n",
      "Batch: 476 , Combined Loss: tensor(0.5892, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.02791571617126465\n",
      "Batch: 477 , Combined Loss: tensor(0.6177, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6209896802902222\n",
      "Batch: 478 , Combined Loss: tensor(0.7284, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3984640836715698\n",
      "Batch: 479 , Combined Loss: tensor(0.6779, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8799805641174316\n",
      "Batch: 480 , Combined Loss: tensor(0.8092, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7785818576812744\n",
      "Batch: 481 , Combined Loss: tensor(0.7458, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1449350118637085\n",
      "Batch: 482 , Combined Loss: tensor(0.5640, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9689127206802368\n",
      "Batch: 483 , Combined Loss: tensor(0.6695, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0395445823669434\n",
      "Batch: 484 , Combined Loss: tensor(0.6838, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8226754665374756\n",
      "Batch: 485 , Combined Loss: tensor(0.8208, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7200576066970825\n",
      "Batch: 486 , Combined Loss: tensor(0.6472, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9461768865585327\n",
      "Batch: 487 , Combined Loss: tensor(0.8125, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5327554941177368\n",
      "Batch: 488 , Combined Loss: tensor(0.7066, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9688721895217896\n",
      "Batch: 489 , Combined Loss: tensor(0.6068, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1164863109588623\n",
      "Batch: 490 , Combined Loss: tensor(0.6411, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8240127563476562\n",
      "Batch: 491 , Combined Loss: tensor(0.6499, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9569944143295288\n",
      "Batch: 492 , Combined Loss: tensor(0.7278, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1793816089630127\n",
      "Batch: 493 , Combined Loss: tensor(0.9319, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3589669466018677\n",
      "Batch: 494 , Combined Loss: tensor(0.7465, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3601895570755005\n",
      "Batch: 495 , Combined Loss: tensor(0.7552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7891291379928589\n",
      "Batch: 496 , Combined Loss: tensor(0.6978, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5477396249771118\n",
      "Batch: 497 , Combined Loss: tensor(0.6492, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15879511833190918\n",
      "Batch: 498 , Combined Loss: tensor(0.7993, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0059442520141602\n",
      "Batch: 499 , Combined Loss: tensor(0.6968, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7138105630874634\n",
      "Batch: 500 , Combined Loss: tensor(0.6309, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8686816692352295\n",
      "Batch: 501 , Combined Loss: tensor(0.6626, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3263465166091919\n",
      "Batch: 502 , Combined Loss: tensor(0.6431, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9499919414520264\n",
      "Batch: 503 , Combined Loss: tensor(0.7288, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0621533393859863\n",
      "Batch: 504 , Combined Loss: tensor(0.6673, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8824989795684814\n",
      "Batch: 505 , Combined Loss: tensor(0.8212, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7714605331420898\n",
      "Batch: 506 , Combined Loss: tensor(0.7961, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9476398229598999\n",
      "Batch: 507 , Combined Loss: tensor(0.6625, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8974153995513916\n",
      "Batch: 508 , Combined Loss: tensor(0.6196, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8297263383865356\n",
      "Batch: 509 , Combined Loss: tensor(0.6429, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.792974591255188\n",
      "Batch: 510 , Combined Loss: tensor(0.7476, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8803398609161377\n",
      "Batch: 511 , Combined Loss: tensor(0.7000, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0341113805770874\n",
      "Batch: 512 , Combined Loss: tensor(0.5827, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0260396003723145\n",
      "Batch: 513 , Combined Loss: tensor(0.7837, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.020792007446289\n",
      "Batch: 514 , Combined Loss: tensor(0.6109, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8921424150466919\n",
      "Batch: 515 , Combined Loss: tensor(0.6548, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.037117600440979004\n",
      "Batch: 516 , Combined Loss: tensor(0.6891, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8531988859176636\n",
      "Batch: 517 , Combined Loss: tensor(0.6764, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9365576505661011\n",
      "Batch: 518 , Combined Loss: tensor(0.6219, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.601123571395874\n",
      "Batch: 519 , Combined Loss: tensor(0.6754, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1359167098999023\n",
      "Batch: 520 , Combined Loss: tensor(0.7057, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7822188138961792\n",
      "Batch: 521 , Combined Loss: tensor(0.7062, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0398409366607666\n",
      "Batch: 522 , Combined Loss: tensor(0.7045, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9967489242553711\n",
      "Batch: 523 , Combined Loss: tensor(0.5703, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11174964904785156\n",
      "Batch: 524 , Combined Loss: tensor(1.0317, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8700342178344727\n",
      "Batch: 525 , Combined Loss: tensor(0.6542, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4894498586654663\n",
      "Batch: 526 , Combined Loss: tensor(0.6579, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14718472957611084\n",
      "Batch: 527 , Combined Loss: tensor(0.6041, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9549897909164429\n",
      "Batch: 528 , Combined Loss: tensor(0.7577, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4630352258682251\n",
      "Batch: 529 , Combined Loss: tensor(0.5835, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0394155979156494\n",
      "Batch: 530 , Combined Loss: tensor(0.6884, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36155855655670166\n",
      "Batch: 531 , Combined Loss: tensor(0.8806, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3797339200973511\n",
      "Batch: 532 , Combined Loss: tensor(0.6911, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20170879364013672\n",
      "Batch: 533 , Combined Loss: tensor(0.6346, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7514117956161499\n",
      "Batch: 534 , Combined Loss: tensor(0.6238, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1292240619659424\n",
      "Batch: 535 , Combined Loss: tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9910250902175903\n",
      "Batch: 536 , Combined Loss: tensor(0.6941, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6783931255340576\n",
      "Batch: 537 , Combined Loss: tensor(0.6626, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6395795345306396\n",
      "Batch: 538 , Combined Loss: tensor(0.6207, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7855346202850342\n",
      "Batch: 539 , Combined Loss: tensor(0.5939, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0486631393432617\n",
      "Batch: 540 , Combined Loss: tensor(0.7254, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6035397052764893\n",
      "Batch: 541 , Combined Loss: tensor(0.7233, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7592719793319702\n",
      "Batch: 542 , Combined Loss: tensor(0.6897, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6523231267929077\n",
      "Batch: 543 , Combined Loss: tensor(0.6957, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8369839191436768\n",
      "Batch: 544 , Combined Loss: tensor(0.6322, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21291828155517578\n",
      "Batch: 545 , Combined Loss: tensor(0.7557, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26827991008758545\n",
      "Batch: 546 , Combined Loss: tensor(0.5852, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6594582796096802\n",
      "Batch: 547 , Combined Loss: tensor(0.6257, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5596915483474731\n",
      "Batch: 548 , Combined Loss: tensor(0.8865, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27605879306793213\n",
      "Batch: 549 , Combined Loss: tensor(0.7535, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8530261516571045\n",
      "Batch: 550 , Combined Loss: tensor(0.6007, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8935602903366089\n",
      "Batch: 551 , Combined Loss: tensor(0.7382, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17050516605377197\n",
      "Batch: 552 , Combined Loss: tensor(0.6275, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7086930274963379\n",
      "Batch: 553 , Combined Loss: tensor(1.0156, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3977471590042114\n",
      "Batch: 554 , Combined Loss: tensor(0.6591, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8978276252746582\n",
      "Batch: 555 , Combined Loss: tensor(0.8528, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3906230926513672\n",
      "Batch: 556 , Combined Loss: tensor(0.8150, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1339378356933594\n",
      "Batch: 557 , Combined Loss: tensor(0.6610, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7320775985717773\n",
      "Batch: 558 , Combined Loss: tensor(0.6601, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0665242671966553\n",
      "Batch: 559 , Combined Loss: tensor(0.5621, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.468278169631958\n",
      "Batch: 560 , Combined Loss: tensor(0.6401, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07195734977722168\n",
      "Batch: 561 , Combined Loss: tensor(0.6588, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7961276769638062\n",
      "Batch: 562 , Combined Loss: tensor(0.6730, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8563295602798462\n",
      "Batch: 563 , Combined Loss: tensor(0.5702, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9783226251602173\n",
      "Batch: 564 , Combined Loss: tensor(0.5636, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.799888014793396\n",
      "Batch: 565 , Combined Loss: tensor(0.6728, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.136101245880127\n",
      "Batch: 566 , Combined Loss: tensor(1.0167, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42830824851989746\n",
      "Batch: 567 , Combined Loss: tensor(0.5701, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7739627361297607\n",
      "Batch: 568 , Combined Loss: tensor(1.1457, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7267767190933228\n",
      "Batch: 569 , Combined Loss: tensor(0.6052, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09279370307922363\n",
      "Batch: 570 , Combined Loss: tensor(0.5770, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29401063919067383\n",
      "Batch: 571 , Combined Loss: tensor(0.6242, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6059964895248413\n",
      "Batch: 572 , Combined Loss: tensor(0.5943, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7147895097732544\n",
      "Batch: 573 , Combined Loss: tensor(0.5552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7913830280303955\n",
      "Batch: 574 , Combined Loss: tensor(0.6745, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.364429235458374\n",
      "Batch: 575 , Combined Loss: tensor(0.8065, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10836994647979736\n",
      "Batch: 576 , Combined Loss: tensor(0.6678, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9082072973251343\n",
      "Batch: 577 , Combined Loss: tensor(0.5927, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7281697988510132\n",
      "Batch: 578 , Combined Loss: tensor(0.7178, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0707347393035889\n",
      "Batch: 579 , Combined Loss: tensor(0.6765, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8206040859222412\n",
      "Batch: 580 , Combined Loss: tensor(0.7926, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9835352897644043\n",
      "Batch: 581 , Combined Loss: tensor(0.6167, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7984123229980469\n",
      "Batch: 582 , Combined Loss: tensor(0.6405, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9497233629226685\n",
      "Batch: 583 , Combined Loss: tensor(0.6137, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9185899496078491\n",
      "Batch: 584 , Combined Loss: tensor(0.6252, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8084704875946045\n",
      "Batch: 585 , Combined Loss: tensor(0.7505, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.128737211227417\n",
      "Batch: 586 , Combined Loss: tensor(0.5873, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6107385158538818\n",
      "Batch: 587 , Combined Loss: tensor(0.6285, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0805163383483887\n",
      "Batch: 588 , Combined Loss: tensor(0.6539, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0459253787994385\n",
      "Batch: 589 , Combined Loss: tensor(0.7683, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7718960046768188\n",
      "Batch: 590 , Combined Loss: tensor(0.7622, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5794914960861206\n",
      "Batch: 591 , Combined Loss: tensor(0.6879, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.553383469581604\n",
      "Batch: 592 , Combined Loss: tensor(0.7011, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8420631885528564\n",
      "Batch: 593 , Combined Loss: tensor(0.7880, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.701421856880188\n",
      "Batch: 594 , Combined Loss: tensor(0.8885, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8075051307678223\n",
      "Batch: 595 , Combined Loss: tensor(0.6678, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9973359107971191\n",
      "Batch: 596 , Combined Loss: tensor(0.8465, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.702399730682373\n",
      "Batch: 597 , Combined Loss: tensor(0.6276, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5721898078918457\n",
      "Batch: 598 , Combined Loss: tensor(0.6188, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5506168603897095\n",
      "Batch: 599 , Combined Loss: tensor(0.8784, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9001755714416504\n",
      "Batch: 600 , Combined Loss: tensor(0.6133, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9259157180786133\n",
      "Batch: 601 , Combined Loss: tensor(0.7396, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4514005184173584\n",
      "Batch: 602 , Combined Loss: tensor(0.6476, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7750749588012695\n",
      "Batch: 603 , Combined Loss: tensor(0.5760, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7653019428253174\n",
      "Batch: 604 , Combined Loss: tensor(0.5960, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9365800619125366\n",
      "Batch: 605 , Combined Loss: tensor(0.7336, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2247847318649292\n",
      "Batch: 606 , Combined Loss: tensor(1.1428, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6592833995819092\n",
      "Batch: 607 , Combined Loss: tensor(0.5933, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0230669975280762\n",
      "Batch: 608 , Combined Loss: tensor(0.6395, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8665927648544312\n",
      "Batch: 609 , Combined Loss: tensor(0.7066, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8479526042938232\n",
      "Batch: 610 , Combined Loss: tensor(0.6138, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8325448036193848\n",
      "Batch: 611 , Combined Loss: tensor(0.6352, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8031715154647827\n",
      "Batch: 612 , Combined Loss: tensor(0.6232, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.622046709060669\n",
      "Batch: 613 , Combined Loss: tensor(0.6514, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1706461906433105\n",
      "Batch: 614 , Combined Loss: tensor(0.7315, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6656074523925781\n",
      "Batch: 615 , Combined Loss: tensor(0.6885, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9081319570541382\n",
      "Batch: 616 , Combined Loss: tensor(0.7632, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7914707660675049\n",
      "Batch: 617 , Combined Loss: tensor(0.5620, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42054593563079834\n",
      "Batch: 618 , Combined Loss: tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21965348720550537\n",
      "Batch: 619 , Combined Loss: tensor(0.7202, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0251410007476807\n",
      "Batch: 620 , Combined Loss: tensor(0.7325, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7261577844619751\n",
      "Batch: 621 , Combined Loss: tensor(0.8752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7979111671447754\n",
      "Batch: 622 , Combined Loss: tensor(0.7691, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2425464391708374\n",
      "Batch: 623 , Combined Loss: tensor(0.6292, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1363790035247803\n",
      "Batch: 624 , Combined Loss: tensor(0.5616, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8170757293701172\n",
      "Batch: 625 , Combined Loss: tensor(0.6613, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8711787462234497\n",
      "Batch: 626 , Combined Loss: tensor(0.5787, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0025229454040527\n",
      "Batch: 627 , Combined Loss: tensor(0.6667, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0953011512756348\n",
      "Batch: 628 , Combined Loss: tensor(0.7282, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5616902112960815\n",
      "----------Epoch 18, Loss: 0.6925259385086205, Accuracy: 0.9690754948056559, Dice Coef: [0.9860996665560384, 0.5763564515529457, 0.6216935183906954, 0.6977268704868491], Dice Coef Necrotic: 1.0367320104678612, Dice Coef Edema: 1.0454864132873758, Dice Coef Enhancing: 1.0465032099071043, Sensitivity: [0.9747112457816666, 0.7606641831285866, 0.8623889899784507, 0.8696584275202598], Specificity: [0.9652084259994458, 0.9971509837384065, 0.9779325727438509, 0.9953020765595672], Precision: [0.9978650397071778, 0.5327153088241557, 0.5195286768887989, 0.6290841493648233]\n",
      "Saving without nn.DataParallel\n",
      "Batch: 0 , Combined Loss: tensor(0.5324, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4434152841567993\n",
      "Batch: 1 , Combined Loss: tensor(0.6518, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.35522544384002686\n",
      "Batch: 2 , Combined Loss: tensor(0.7594, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.01633596420288086\n",
      "Batch: 3 , Combined Loss: tensor(0.6984, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9628963470458984\n",
      "Batch: 4 , Combined Loss: tensor(0.6573, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.878292441368103\n",
      "Batch: 5 , Combined Loss: tensor(0.6659, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9199395179748535\n",
      "Batch: 6 , Combined Loss: tensor(0.5682, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7471423149108887\n",
      "Batch: 7 , Combined Loss: tensor(0.6679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1047861576080322\n",
      "Batch: 8 , Combined Loss: tensor(0.6693, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2812999486923218\n",
      "Batch: 9 , Combined Loss: tensor(0.6158, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8869569301605225\n",
      "Batch: 10 , Combined Loss: tensor(0.5619, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9262129068374634\n",
      "Batch: 11 , Combined Loss: tensor(0.6135, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8204096555709839\n",
      "Batch: 12 , Combined Loss: tensor(1.3890, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48423826694488525\n",
      "Batch: 13 , Combined Loss: tensor(0.6365, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8124467134475708\n",
      "Batch: 14 , Combined Loss: tensor(0.9349, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8460303544998169\n",
      "Batch: 15 , Combined Loss: tensor(0.6502, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9258266687393188\n",
      "Batch: 16 , Combined Loss: tensor(0.6362, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.037907361984253\n",
      "Batch: 17 , Combined Loss: tensor(0.7481, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8896641731262207\n",
      "Batch: 18 , Combined Loss: tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.913847804069519\n",
      "Batch: 19 , Combined Loss: tensor(0.6993, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8882709741592407\n",
      "Batch: 20 , Combined Loss: tensor(0.5774, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17377281188964844\n",
      "Batch: 21 , Combined Loss: tensor(0.9664, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6847267150878906\n",
      "Batch: 22 , Combined Loss: tensor(1.2536, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8096256256103516\n",
      "Batch: 23 , Combined Loss: tensor(0.6474, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4443047046661377\n",
      "Batch: 24 , Combined Loss: tensor(0.7792, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9620747566223145\n",
      "Batch: 25 , Combined Loss: tensor(0.7956, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9895334243774414\n",
      "Batch: 26 , Combined Loss: tensor(0.7393, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8269888162612915\n",
      "Batch: 27 , Combined Loss: tensor(0.5092, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8061050176620483\n",
      "Batch: 28 , Combined Loss: tensor(0.5951, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6802300214767456\n",
      "Batch: 29 , Combined Loss: tensor(0.7299, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0747296810150146\n",
      "Batch: 30 , Combined Loss: tensor(0.6503, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0102226734161377\n",
      "Batch: 31 , Combined Loss: tensor(0.7325, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7094690799713135\n",
      "Batch: 32 , Combined Loss: tensor(0.7072, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8208049535751343\n",
      "Batch: 33 , Combined Loss: tensor(0.8048, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9828016757965088\n",
      "Batch: 34 , Combined Loss: tensor(0.5609, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9768049716949463\n",
      "Batch: 35 , Combined Loss: tensor(0.8302, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7503829002380371\n",
      "Batch: 36 , Combined Loss: tensor(0.5538, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1882389783859253\n",
      "Batch: 37 , Combined Loss: tensor(0.6654, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0137228965759277\n",
      "Batch: 38 , Combined Loss: tensor(0.6720, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9333240985870361\n",
      "Batch: 39 , Combined Loss: tensor(0.6124, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.764329195022583\n",
      "Batch: 40 , Combined Loss: tensor(0.7242, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.380460262298584\n",
      "Batch: 41 , Combined Loss: tensor(0.5718, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9934706687927246\n",
      "Batch: 42 , Combined Loss: tensor(0.6772, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6942030191421509\n",
      "Batch: 43 , Combined Loss: tensor(0.6373, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7459225654602051\n",
      "Batch: 44 , Combined Loss: tensor(0.5798, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8360923528671265\n",
      "Batch: 45 , Combined Loss: tensor(0.7731, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4807572364807129\n",
      "Batch: 46 , Combined Loss: tensor(0.6268, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9528287649154663\n",
      "Batch: 47 , Combined Loss: tensor(0.6558, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9116275310516357\n",
      "Batch: 48 , Combined Loss: tensor(0.5954, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20681142807006836\n",
      "Batch: 49 , Combined Loss: tensor(0.6791, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42711496353149414\n",
      "Batch: 50 , Combined Loss: tensor(0.8389, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2641037702560425\n",
      "Batch: 51 , Combined Loss: tensor(0.7506, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9528888463973999\n",
      "Batch: 52 , Combined Loss: tensor(0.7315, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4627079963684082\n",
      "Batch: 53 , Combined Loss: tensor(0.8167, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.670557975769043\n",
      "Batch: 54 , Combined Loss: tensor(0.6033, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5716493129730225\n",
      "Batch: 55 , Combined Loss: tensor(0.6239, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12359261512756348\n",
      "Batch: 56 , Combined Loss: tensor(0.6877, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6646448373794556\n",
      "Batch: 57 , Combined Loss: tensor(0.7023, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.93278968334198\n",
      "Batch: 58 , Combined Loss: tensor(0.5821, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5539611577987671\n",
      "Batch: 59 , Combined Loss: tensor(0.6271, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9613398313522339\n",
      "Batch: 60 , Combined Loss: tensor(0.6373, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7939455509185791\n",
      "Batch: 61 , Combined Loss: tensor(0.7444, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4682135581970215\n",
      "Batch: 62 , Combined Loss: tensor(0.9708, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5881906747817993\n",
      "Batch: 63 , Combined Loss: tensor(0.5780, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6335320472717285\n",
      "Batch: 64 , Combined Loss: tensor(0.6385, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8919748067855835\n",
      "Batch: 65 , Combined Loss: tensor(0.6643, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0303843021392822\n",
      "Batch: 66 , Combined Loss: tensor(0.6053, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.049445629119873\n",
      "Batch: 67 , Combined Loss: tensor(0.6939, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9095019102096558\n",
      "Batch: 68 , Combined Loss: tensor(0.6502, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9868826866149902\n",
      "Batch: 69 , Combined Loss: tensor(0.7004, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7014638185501099\n",
      "Batch: 70 , Combined Loss: tensor(0.5707, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7896524667739868\n",
      "Batch: 71 , Combined Loss: tensor(0.5887, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.116145133972168\n",
      "Batch: 72 , Combined Loss: tensor(0.5712, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20339053869247437\n",
      "Batch: 73 , Combined Loss: tensor(0.8056, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31174659729003906\n",
      "Batch: 74 , Combined Loss: tensor(0.8015, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0274746417999268\n",
      "Batch: 75 , Combined Loss: tensor(0.6057, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8431979417800903\n",
      "Batch: 76 , Combined Loss: tensor(0.6203, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09438937902450562\n",
      "Batch: 77 , Combined Loss: tensor(0.5872, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3381696939468384\n",
      "Batch: 78 , Combined Loss: tensor(1.1678, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7304188013076782\n",
      "Batch: 79 , Combined Loss: tensor(0.6489, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9561958312988281\n",
      "Batch: 80 , Combined Loss: tensor(0.6467, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8661071062088013\n",
      "Batch: 81 , Combined Loss: tensor(0.5694, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6675819158554077\n",
      "Batch: 82 , Combined Loss: tensor(0.9135, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3760589361190796\n",
      "Batch: 83 , Combined Loss: tensor(0.8067, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.191901683807373\n",
      "Batch: 84 , Combined Loss: tensor(0.6969, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19646841287612915\n",
      "Batch: 85 , Combined Loss: tensor(0.6885, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9069629907608032\n",
      "Batch: 86 , Combined Loss: tensor(0.6472, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.065563678741455\n",
      "Batch: 87 , Combined Loss: tensor(0.6799, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5596283674240112\n",
      "Batch: 88 , Combined Loss: tensor(0.6814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.206791639328003\n",
      "Batch: 89 , Combined Loss: tensor(0.6364, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5273244380950928\n",
      "Batch: 90 , Combined Loss: tensor(0.6065, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6465251445770264\n",
      "Batch: 91 , Combined Loss: tensor(0.6307, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5032181739807129\n",
      "Batch: 92 , Combined Loss: tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7016415596008301\n",
      "Batch: 93 , Combined Loss: tensor(0.7010, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19316411018371582\n",
      "Batch: 94 , Combined Loss: tensor(0.8028, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6772987842559814\n",
      "Batch: 95 , Combined Loss: tensor(0.7318, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9308478832244873\n",
      "Batch: 96 , Combined Loss: tensor(0.5760, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8697611093521118\n",
      "Batch: 97 , Combined Loss: tensor(0.6643, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1593379974365234\n",
      "Batch: 98 , Combined Loss: tensor(0.7495, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8672574758529663\n",
      "Batch: 99 , Combined Loss: tensor(0.8125, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7699253559112549\n",
      "Batch: 100 , Combined Loss: tensor(0.5910, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1452889442443848\n",
      "Batch: 101 , Combined Loss: tensor(0.6988, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1935725212097168\n",
      "Batch: 102 , Combined Loss: tensor(0.5850, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0836071968078613\n",
      "Batch: 103 , Combined Loss: tensor(0.6263, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8478729724884033\n",
      "Batch: 104 , Combined Loss: tensor(0.5881, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4519350528717041\n",
      "Batch: 105 , Combined Loss: tensor(0.6794, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46732378005981445\n",
      "Batch: 106 , Combined Loss: tensor(0.7669, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5546556711196899\n",
      "Batch: 107 , Combined Loss: tensor(0.6246, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0920276641845703\n",
      "Batch: 108 , Combined Loss: tensor(0.8107, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6870663166046143\n",
      "Batch: 109 , Combined Loss: tensor(0.6486, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8239343166351318\n",
      "Batch: 110 , Combined Loss: tensor(0.6380, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16722023487091064\n",
      "Batch: 111 , Combined Loss: tensor(0.5864, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8535605669021606\n",
      "Batch: 112 , Combined Loss: tensor(0.7704, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8486006259918213\n",
      "Batch: 113 , Combined Loss: tensor(0.7985, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.616504430770874\n",
      "Batch: 114 , Combined Loss: tensor(0.6141, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0051977634429932\n",
      "Batch: 115 , Combined Loss: tensor(0.9006, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3660297989845276\n",
      "Batch: 116 , Combined Loss: tensor(0.7017, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8462216854095459\n",
      "Batch: 117 , Combined Loss: tensor(0.8355, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.00583815574646\n",
      "Batch: 118 , Combined Loss: tensor(0.5898, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0346078872680664\n",
      "Batch: 119 , Combined Loss: tensor(0.5907, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45221102237701416\n",
      "Batch: 120 , Combined Loss: tensor(0.6978, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7614810466766357\n",
      "Batch: 121 , Combined Loss: tensor(0.6936, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0047674179077148\n",
      "Batch: 122 , Combined Loss: tensor(0.6693, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9290766716003418\n",
      "Batch: 123 , Combined Loss: tensor(0.6050, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6529713869094849\n",
      "Batch: 124 , Combined Loss: tensor(0.6323, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9271681308746338\n",
      "Batch: 125 , Combined Loss: tensor(0.7879, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0656557083129883\n",
      "Batch: 126 , Combined Loss: tensor(0.8323, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5279653072357178\n",
      "Batch: 127 , Combined Loss: tensor(0.7042, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8394136428833008\n",
      "Batch: 128 , Combined Loss: tensor(0.6781, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8495767116546631\n",
      "Batch: 129 , Combined Loss: tensor(0.6364, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7243666648864746\n",
      "Batch: 130 , Combined Loss: tensor(0.6156, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9809019565582275\n",
      "Batch: 131 , Combined Loss: tensor(0.6038, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7851778268814087\n",
      "Batch: 132 , Combined Loss: tensor(0.6816, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7800732851028442\n",
      "Batch: 133 , Combined Loss: tensor(0.6206, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7079017162322998\n",
      "Batch: 134 , Combined Loss: tensor(0.6652, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8560969829559326\n",
      "Batch: 135 , Combined Loss: tensor(0.5796, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.575798749923706\n",
      "Batch: 136 , Combined Loss: tensor(0.5882, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8090161085128784\n",
      "Batch: 137 , Combined Loss: tensor(0.8307, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9718044996261597\n",
      "Batch: 138 , Combined Loss: tensor(0.6477, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9012458324432373\n",
      "Batch: 139 , Combined Loss: tensor(0.9218, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7800710201263428\n",
      "Batch: 140 , Combined Loss: tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6789122819900513\n",
      "Batch: 141 , Combined Loss: tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2766380310058594\n",
      "Batch: 142 , Combined Loss: tensor(0.6701, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6540669202804565\n",
      "Batch: 143 , Combined Loss: tensor(0.6160, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6318252086639404\n",
      "Batch: 144 , Combined Loss: tensor(0.6108, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0333213806152344\n",
      "Batch: 145 , Combined Loss: tensor(0.7291, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8401126861572266\n",
      "Batch: 146 , Combined Loss: tensor(0.5818, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0523626804351807\n",
      "Batch: 147 , Combined Loss: tensor(0.8429, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17731356620788574\n",
      "Batch: 148 , Combined Loss: tensor(0.7606, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.566493034362793\n",
      "Batch: 149 , Combined Loss: tensor(0.7500, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9706941843032837\n",
      "Batch: 150 , Combined Loss: tensor(0.7263, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44099295139312744\n",
      "Batch: 151 , Combined Loss: tensor(0.6291, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7901880741119385\n",
      "Batch: 152 , Combined Loss: tensor(0.5963, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8181158304214478\n",
      "Batch: 153 , Combined Loss: tensor(0.8022, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6362937688827515\n",
      "Batch: 154 , Combined Loss: tensor(0.6766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5462110042572021\n",
      "Batch: 155 , Combined Loss: tensor(0.6362, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7913174629211426\n",
      "Batch: 156 , Combined Loss: tensor(0.5830, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9775148630142212\n",
      "Batch: 157 , Combined Loss: tensor(0.7015, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36049163341522217\n",
      "Batch: 158 , Combined Loss: tensor(0.6547, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2694333791732788\n",
      "Batch: 159 , Combined Loss: tensor(0.6567, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1515681743621826\n",
      "Batch: 160 , Combined Loss: tensor(0.8263, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6883901357650757\n",
      "Batch: 161 , Combined Loss: tensor(0.7042, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6988261938095093\n",
      "Batch: 162 , Combined Loss: tensor(0.6808, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19506800174713135\n",
      "Batch: 163 , Combined Loss: tensor(0.7047, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4082984924316406\n",
      "Batch: 164 , Combined Loss: tensor(0.5617, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37354016304016113\n",
      "Batch: 165 , Combined Loss: tensor(0.6535, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0371274948120117\n",
      "Batch: 166 , Combined Loss: tensor(0.6500, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.087146520614624\n",
      "Batch: 167 , Combined Loss: tensor(0.7460, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8911827802658081\n",
      "Batch: 168 , Combined Loss: tensor(0.7237, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8710981607437134\n",
      "Batch: 169 , Combined Loss: tensor(0.7105, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8448996543884277\n",
      "Batch: 170 , Combined Loss: tensor(0.5964, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9188143014907837\n",
      "Batch: 171 , Combined Loss: tensor(0.6330, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7353973388671875\n",
      "Batch: 172 , Combined Loss: tensor(0.5500, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8808684349060059\n",
      "Batch: 173 , Combined Loss: tensor(0.6003, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27636563777923584\n",
      "Batch: 174 , Combined Loss: tensor(0.7342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.729224681854248\n",
      "Batch: 175 , Combined Loss: tensor(0.6691, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0103251934051514\n",
      "Batch: 176 , Combined Loss: tensor(0.7216, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8303239345550537\n",
      "Batch: 177 , Combined Loss: tensor(0.6317, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8835999965667725\n",
      "Batch: 178 , Combined Loss: tensor(0.5857, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9502813816070557\n",
      "Batch: 179 , Combined Loss: tensor(0.8012, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9581694602966309\n",
      "Batch: 180 , Combined Loss: tensor(0.6153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0040228366851807\n",
      "Batch: 181 , Combined Loss: tensor(0.5541, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5783029794692993\n",
      "Batch: 182 , Combined Loss: tensor(0.6170, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9710928201675415\n",
      "Batch: 183 , Combined Loss: tensor(0.6181, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.843401312828064\n",
      "Batch: 184 , Combined Loss: tensor(0.7266, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.124206781387329\n",
      "Batch: 185 , Combined Loss: tensor(0.7087, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20319795608520508\n",
      "Batch: 186 , Combined Loss: tensor(0.6120, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.190000057220459\n",
      "Batch: 187 , Combined Loss: tensor(0.8017, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17881786823272705\n",
      "Batch: 188 , Combined Loss: tensor(0.5853, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6590611934661865\n",
      "Batch: 189 , Combined Loss: tensor(0.8220, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8705013990402222\n",
      "Batch: 190 , Combined Loss: tensor(0.6679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8285858631134033\n",
      "Batch: 191 , Combined Loss: tensor(0.7200, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9230942726135254\n",
      "Batch: 192 , Combined Loss: tensor(0.6705, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7150247097015381\n",
      "Batch: 193 , Combined Loss: tensor(0.6188, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9360935688018799\n",
      "Batch: 194 , Combined Loss: tensor(0.7228, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7869104146957397\n",
      "Batch: 195 , Combined Loss: tensor(0.7457, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45174407958984375\n",
      "Batch: 196 , Combined Loss: tensor(0.5977, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9270346164703369\n",
      "Batch: 197 , Combined Loss: tensor(0.7026, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.981399655342102\n",
      "Batch: 198 , Combined Loss: tensor(0.6705, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8602782487869263\n",
      "Batch: 199 , Combined Loss: tensor(0.8595, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9626593589782715\n",
      "Batch: 200 , Combined Loss: tensor(0.6098, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9373147487640381\n",
      "Batch: 201 , Combined Loss: tensor(0.6496, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6092852354049683\n",
      "Batch: 202 , Combined Loss: tensor(0.6322, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1647388935089111\n",
      "Batch: 203 , Combined Loss: tensor(0.8668, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.498958945274353\n",
      "Batch: 204 , Combined Loss: tensor(0.7710, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9733814001083374\n",
      "Batch: 205 , Combined Loss: tensor(0.6224, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9047420024871826\n",
      "Batch: 206 , Combined Loss: tensor(0.7550, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.000497817993164\n",
      "Batch: 207 , Combined Loss: tensor(0.6764, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.367642879486084\n",
      "Batch: 208 , Combined Loss: tensor(0.6018, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9322081804275513\n",
      "Batch: 209 , Combined Loss: tensor(0.6734, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.111440896987915\n",
      "Batch: 210 , Combined Loss: tensor(0.5968, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0698432922363281\n",
      "Batch: 211 , Combined Loss: tensor(0.6188, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4193732738494873\n",
      "Batch: 212 , Combined Loss: tensor(0.7688, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2911849021911621\n",
      "Batch: 213 , Combined Loss: tensor(0.5709, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7957531213760376\n",
      "Batch: 214 , Combined Loss: tensor(0.6819, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.735668420791626\n",
      "Batch: 215 , Combined Loss: tensor(0.6011, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1432151794433594\n",
      "Batch: 216 , Combined Loss: tensor(0.6702, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9148002862930298\n",
      "Batch: 217 , Combined Loss: tensor(0.5999, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0370044708251953\n",
      "Batch: 218 , Combined Loss: tensor(0.5151, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46905648708343506\n",
      "Batch: 219 , Combined Loss: tensor(0.6565, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9633629322052002\n",
      "Batch: 220 , Combined Loss: tensor(0.8368, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8789095878601074\n",
      "Batch: 221 , Combined Loss: tensor(0.6156, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44142937660217285\n",
      "Batch: 222 , Combined Loss: tensor(0.7766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9583510160446167\n",
      "Batch: 223 , Combined Loss: tensor(0.7289, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2213332653045654\n",
      "Batch: 224 , Combined Loss: tensor(0.6723, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.397153377532959\n",
      "Batch: 225 , Combined Loss: tensor(0.7995, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8337322473526001\n",
      "Batch: 226 , Combined Loss: tensor(0.5623, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8328061103820801\n",
      "Batch: 227 , Combined Loss: tensor(0.6395, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9444204568862915\n",
      "Batch: 228 , Combined Loss: tensor(0.6193, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8757877349853516\n",
      "Batch: 229 , Combined Loss: tensor(0.6301, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5642865896224976\n",
      "Batch: 230 , Combined Loss: tensor(0.6340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7567373514175415\n",
      "Batch: 231 , Combined Loss: tensor(0.7343, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6460056304931641\n",
      "Batch: 232 , Combined Loss: tensor(0.6817, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0771090984344482\n",
      "Batch: 233 , Combined Loss: tensor(0.6180, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20050477981567383\n",
      "Batch: 234 , Combined Loss: tensor(0.6759, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2151119709014893\n",
      "Batch: 235 , Combined Loss: tensor(0.6490, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9233366250991821\n",
      "Batch: 236 , Combined Loss: tensor(0.6374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0561704635620117\n",
      "Batch: 237 , Combined Loss: tensor(0.6426, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19273966550827026\n",
      "Batch: 238 , Combined Loss: tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2932208776473999\n",
      "Batch: 239 , Combined Loss: tensor(0.6111, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18675768375396729\n",
      "Batch: 240 , Combined Loss: tensor(0.6821, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8212885856628418\n",
      "Batch: 241 , Combined Loss: tensor(0.7306, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5826364755630493\n",
      "Batch: 242 , Combined Loss: tensor(0.6823, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0531365871429443\n",
      "Batch: 243 , Combined Loss: tensor(0.6870, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6188406944274902\n",
      "Batch: 244 , Combined Loss: tensor(0.6441, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7599515914916992\n",
      "Batch: 245 , Combined Loss: tensor(0.6487, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8617020845413208\n",
      "Batch: 246 , Combined Loss: tensor(0.6876, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7758771181106567\n",
      "Batch: 247 , Combined Loss: tensor(0.6524, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49795031547546387\n",
      "Batch: 248 , Combined Loss: tensor(0.5677, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8846563100814819\n",
      "Batch: 249 , Combined Loss: tensor(0.6040, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9603817462921143\n",
      "Batch: 250 , Combined Loss: tensor(0.6071, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9717178344726562\n",
      "Batch: 251 , Combined Loss: tensor(0.9595, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9949231147766113\n",
      "Batch: 252 , Combined Loss: tensor(0.6448, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.009776711463928223\n",
      "Batch: 253 , Combined Loss: tensor(0.7240, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.599891185760498\n",
      "Batch: 254 , Combined Loss: tensor(0.7691, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0437126159667969\n",
      "Batch: 255 , Combined Loss: tensor(0.6766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9289460182189941\n",
      "Batch: 256 , Combined Loss: tensor(0.6648, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0252201557159424\n",
      "Batch: 257 , Combined Loss: tensor(0.6003, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8437228202819824\n",
      "Batch: 258 , Combined Loss: tensor(0.6729, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7031234502792358\n",
      "Batch: 259 , Combined Loss: tensor(0.5554, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44721949100494385\n",
      "Batch: 260 , Combined Loss: tensor(0.7982, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8803473711013794\n",
      "Batch: 261 , Combined Loss: tensor(0.6132, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.99672532081604\n",
      "Batch: 262 , Combined Loss: tensor(0.6435, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1282804012298584\n",
      "Batch: 263 , Combined Loss: tensor(0.6972, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03956866264343262\n",
      "Batch: 264 , Combined Loss: tensor(0.6838, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8872319459915161\n",
      "Batch: 265 , Combined Loss: tensor(0.6506, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9107552766799927\n",
      "Batch: 266 , Combined Loss: tensor(0.6859, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1208226680755615\n",
      "Batch: 267 , Combined Loss: tensor(0.5421, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6337203979492188\n",
      "Batch: 268 , Combined Loss: tensor(0.7867, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0288939476013184\n",
      "Batch: 269 , Combined Loss: tensor(0.6981, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8461685180664062\n",
      "Batch: 270 , Combined Loss: tensor(0.6696, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.019722163677215576\n",
      "Batch: 271 , Combined Loss: tensor(0.7378, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.920814037322998\n",
      "Batch: 272 , Combined Loss: tensor(0.6081, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9342617988586426\n",
      "Batch: 273 , Combined Loss: tensor(0.9640, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2739121913909912\n",
      "Batch: 274 , Combined Loss: tensor(0.6374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7692654132843018\n",
      "Batch: 275 , Combined Loss: tensor(0.5568, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9166202545166016\n",
      "Batch: 276 , Combined Loss: tensor(0.6167, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.038724422454834\n",
      "Batch: 277 , Combined Loss: tensor(0.7607, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36008667945861816\n",
      "Batch: 278 , Combined Loss: tensor(0.6701, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12424159049987793\n",
      "Batch: 279 , Combined Loss: tensor(0.5610, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6714099645614624\n",
      "Batch: 280 , Combined Loss: tensor(0.7047, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.01106858253479\n",
      "Batch: 281 , Combined Loss: tensor(0.6252, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8252812623977661\n",
      "Batch: 282 , Combined Loss: tensor(0.6491, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8074610233306885\n",
      "Batch: 283 , Combined Loss: tensor(0.6153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.732811450958252\n",
      "Batch: 284 , Combined Loss: tensor(0.9613, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9229985475540161\n",
      "Batch: 285 , Combined Loss: tensor(0.9262, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7595843076705933\n",
      "Batch: 286 , Combined Loss: tensor(0.6038, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7546719312667847\n",
      "Batch: 287 , Combined Loss: tensor(0.6693, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.095003604888916\n",
      "Batch: 288 , Combined Loss: tensor(0.6360, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37564778327941895\n",
      "Batch: 289 , Combined Loss: tensor(0.6033, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8347256183624268\n",
      "Batch: 290 , Combined Loss: tensor(0.6355, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9561725854873657\n",
      "Batch: 291 , Combined Loss: tensor(0.7254, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0900249481201172\n",
      "Batch: 292 , Combined Loss: tensor(0.6824, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4870504140853882\n",
      "Batch: 293 , Combined Loss: tensor(0.6195, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1376121044158936\n",
      "Batch: 294 , Combined Loss: tensor(0.6301, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9982658624649048\n",
      "Batch: 295 , Combined Loss: tensor(0.6534, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0154352188110352\n",
      "Batch: 296 , Combined Loss: tensor(0.6634, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0444397926330566\n",
      "Batch: 297 , Combined Loss: tensor(0.8177, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9625891447067261\n",
      "Batch: 298 , Combined Loss: tensor(0.6995, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8975472450256348\n",
      "Batch: 299 , Combined Loss: tensor(0.7033, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8352358341217041\n",
      "Batch: 300 , Combined Loss: tensor(0.7202, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9258630275726318\n",
      "Batch: 301 , Combined Loss: tensor(0.6981, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6886818408966064\n",
      "Batch: 302 , Combined Loss: tensor(0.6671, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0934784412384033\n",
      "Batch: 303 , Combined Loss: tensor(0.6994, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6306742429733276\n",
      "Batch: 304 , Combined Loss: tensor(0.6176, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0784623622894287\n",
      "Batch: 305 , Combined Loss: tensor(0.6219, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9725103378295898\n",
      "Batch: 306 , Combined Loss: tensor(0.5744, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8959351778030396\n",
      "Batch: 307 , Combined Loss: tensor(0.7020, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16033828258514404\n",
      "Batch: 308 , Combined Loss: tensor(0.5688, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7006672620773315\n",
      "Batch: 309 , Combined Loss: tensor(0.5475, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21419775485992432\n",
      "Batch: 310 , Combined Loss: tensor(0.5964, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.866459846496582\n",
      "Batch: 311 , Combined Loss: tensor(0.5894, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9645425081253052\n",
      "Batch: 312 , Combined Loss: tensor(0.6316, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9891852140426636\n",
      "Batch: 313 , Combined Loss: tensor(0.6397, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5714727640151978\n",
      "Batch: 314 , Combined Loss: tensor(0.6440, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6353987455368042\n",
      "Batch: 315 , Combined Loss: tensor(0.6684, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8434447050094604\n",
      "Batch: 316 , Combined Loss: tensor(0.8076, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0051610469818115\n",
      "Batch: 317 , Combined Loss: tensor(0.6954, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.043318986892700195\n",
      "Batch: 318 , Combined Loss: tensor(0.7323, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9170602560043335\n",
      "Batch: 319 , Combined Loss: tensor(0.6425, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05654430389404297\n",
      "Batch: 320 , Combined Loss: tensor(0.6687, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8690313100814819\n",
      "Batch: 321 , Combined Loss: tensor(0.7235, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41744983196258545\n",
      "Batch: 322 , Combined Loss: tensor(0.6698, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9835643768310547\n",
      "Batch: 323 , Combined Loss: tensor(0.6766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3182401657104492\n",
      "Batch: 324 , Combined Loss: tensor(0.8542, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4642406702041626\n",
      "Batch: 325 , Combined Loss: tensor(0.6610, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9718320369720459\n",
      "Batch: 326 , Combined Loss: tensor(0.6838, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7813674211502075\n",
      "Batch: 327 , Combined Loss: tensor(0.7539, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42394983768463135\n",
      "Batch: 328 , Combined Loss: tensor(0.6309, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3783000707626343\n",
      "Batch: 329 , Combined Loss: tensor(0.7312, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4073234796524048\n",
      "Batch: 330 , Combined Loss: tensor(0.7285, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6327488422393799\n",
      "Batch: 331 , Combined Loss: tensor(0.6244, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26883625984191895\n",
      "Batch: 332 , Combined Loss: tensor(0.6093, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1217045783996582\n",
      "Batch: 333 , Combined Loss: tensor(0.7296, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8738812208175659\n",
      "Batch: 334 , Combined Loss: tensor(0.7316, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6775140762329102\n",
      "Batch: 335 , Combined Loss: tensor(0.9029, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5165326595306396\n",
      "Batch: 336 , Combined Loss: tensor(0.6677, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8297964334487915\n",
      "Batch: 337 , Combined Loss: tensor(0.8131, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0312572717666626\n",
      "Batch: 338 , Combined Loss: tensor(0.6408, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3212411403656006\n",
      "Batch: 339 , Combined Loss: tensor(0.6753, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.027634620666504\n",
      "Batch: 340 , Combined Loss: tensor(0.6938, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6285302639007568\n",
      "Batch: 341 , Combined Loss: tensor(0.6604, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.789624810218811\n",
      "Batch: 342 , Combined Loss: tensor(0.7277, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5554283857345581\n",
      "Batch: 343 , Combined Loss: tensor(0.6390, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.790429949760437\n",
      "Batch: 344 , Combined Loss: tensor(0.8323, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9384034872055054\n",
      "Batch: 345 , Combined Loss: tensor(0.6063, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6163202524185181\n",
      "Batch: 346 , Combined Loss: tensor(0.5947, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.701971173286438\n",
      "Batch: 347 , Combined Loss: tensor(0.6710, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8518251180648804\n",
      "Batch: 348 , Combined Loss: tensor(0.7655, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3392667770385742\n",
      "Batch: 349 , Combined Loss: tensor(0.6367, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.01952075958251953\n",
      "Batch: 350 , Combined Loss: tensor(0.5982, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1977308988571167\n",
      "Batch: 351 , Combined Loss: tensor(0.7553, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8222618103027344\n",
      "Batch: 352 , Combined Loss: tensor(0.6758, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8052531480789185\n",
      "Batch: 353 , Combined Loss: tensor(0.6013, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5534764528274536\n",
      "Batch: 354 , Combined Loss: tensor(0.6234, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7575298547744751\n",
      "Batch: 355 , Combined Loss: tensor(0.5969, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5429520606994629\n",
      "Batch: 356 , Combined Loss: tensor(0.7594, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.597113847732544\n",
      "Batch: 357 , Combined Loss: tensor(0.5743, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.505501389503479\n",
      "Batch: 358 , Combined Loss: tensor(0.7812, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0048582553863525\n",
      "Batch: 359 , Combined Loss: tensor(0.6389, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8444467782974243\n",
      "Batch: 360 , Combined Loss: tensor(0.9900, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.004386603832244873\n",
      "Batch: 361 , Combined Loss: tensor(0.6292, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8183178901672363\n",
      "Batch: 362 , Combined Loss: tensor(0.5878, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6848186254501343\n",
      "Batch: 363 , Combined Loss: tensor(0.6283, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7270601987838745\n",
      "Batch: 364 , Combined Loss: tensor(0.6243, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09414243698120117\n",
      "Batch: 365 , Combined Loss: tensor(0.6203, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4636359214782715\n",
      "Batch: 366 , Combined Loss: tensor(0.6411, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6971127986907959\n",
      "Batch: 367 , Combined Loss: tensor(0.6342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8525052070617676\n",
      "Batch: 368 , Combined Loss: tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.003546476364135742\n",
      "Batch: 369 , Combined Loss: tensor(1.0084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5567446947097778\n",
      "Batch: 370 , Combined Loss: tensor(0.6292, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43666577339172363\n",
      "Batch: 371 , Combined Loss: tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4609220027923584\n",
      "Batch: 372 , Combined Loss: tensor(0.5960, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9329342842102051\n",
      "Batch: 373 , Combined Loss: tensor(0.5410, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12194621562957764\n",
      "Batch: 374 , Combined Loss: tensor(0.7820, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49816620349884033\n",
      "Batch: 375 , Combined Loss: tensor(0.7613, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8161435127258301\n",
      "Batch: 376 , Combined Loss: tensor(0.6067, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8724842071533203\n",
      "Batch: 377 , Combined Loss: tensor(0.8760, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10751104354858398\n",
      "Batch: 378 , Combined Loss: tensor(0.8424, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8662139177322388\n",
      "Batch: 379 , Combined Loss: tensor(0.8676, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44990503787994385\n",
      "Batch: 380 , Combined Loss: tensor(0.8167, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6583267450332642\n",
      "Batch: 381 , Combined Loss: tensor(0.5596, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7397303581237793\n",
      "Batch: 382 , Combined Loss: tensor(0.7020, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.724176287651062\n",
      "Batch: 383 , Combined Loss: tensor(0.6228, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6366747617721558\n",
      "Batch: 384 , Combined Loss: tensor(0.7862, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4228670597076416\n",
      "Batch: 385 , Combined Loss: tensor(0.7696, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8240665197372437\n",
      "Batch: 386 , Combined Loss: tensor(0.8283, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2555060386657715\n",
      "Batch: 387 , Combined Loss: tensor(0.6213, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5685007572174072\n",
      "Batch: 388 , Combined Loss: tensor(0.7154, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6287362575531006\n",
      "Batch: 389 , Combined Loss: tensor(0.6861, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9926353693008423\n",
      "Batch: 390 , Combined Loss: tensor(0.6271, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1471869945526123\n",
      "Batch: 391 , Combined Loss: tensor(0.5700, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.973675012588501\n",
      "Batch: 392 , Combined Loss: tensor(0.6454, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.869921088218689\n",
      "Batch: 393 , Combined Loss: tensor(0.7371, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03552806377410889\n",
      "Batch: 394 , Combined Loss: tensor(0.6139, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6719086170196533\n",
      "Batch: 395 , Combined Loss: tensor(0.7856, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2672090530395508\n",
      "Batch: 396 , Combined Loss: tensor(0.8459, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0188202857971191\n",
      "Batch: 397 , Combined Loss: tensor(0.6437, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7748554944992065\n",
      "Batch: 398 , Combined Loss: tensor(0.6496, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1794365644454956\n",
      "Batch: 399 , Combined Loss: tensor(0.6300, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15881139039993286\n",
      "Batch: 400 , Combined Loss: tensor(0.7234, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9030647277832031\n",
      "Batch: 401 , Combined Loss: tensor(0.6843, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7893503904342651\n",
      "Batch: 402 , Combined Loss: tensor(0.5389, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5833567380905151\n",
      "Batch: 403 , Combined Loss: tensor(0.6699, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06193429231643677\n",
      "Batch: 404 , Combined Loss: tensor(0.6622, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9676686525344849\n",
      "Batch: 405 , Combined Loss: tensor(0.7525, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07846653461456299\n",
      "Batch: 406 , Combined Loss: tensor(0.7319, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3707925081253052\n",
      "Batch: 407 , Combined Loss: tensor(0.5696, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8739888668060303\n",
      "Batch: 408 , Combined Loss: tensor(0.7288, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7994451522827148\n",
      "Batch: 409 , Combined Loss: tensor(0.6852, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11294114589691162\n",
      "Batch: 410 , Combined Loss: tensor(0.6832, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9149316549301147\n",
      "Batch: 411 , Combined Loss: tensor(0.7605, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3858158588409424\n",
      "Batch: 412 , Combined Loss: tensor(0.6213, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8949699401855469\n",
      "Batch: 413 , Combined Loss: tensor(0.6015, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44411206245422363\n",
      "Batch: 414 , Combined Loss: tensor(0.6974, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7181146144866943\n",
      "Batch: 415 , Combined Loss: tensor(0.5556, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5517401695251465\n",
      "Batch: 416 , Combined Loss: tensor(0.5858, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22346729040145874\n",
      "Batch: 417 , Combined Loss: tensor(0.6549, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8814829587936401\n",
      "Batch: 418 , Combined Loss: tensor(0.6494, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0706050395965576\n",
      "Batch: 419 , Combined Loss: tensor(0.8484, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.18519151210784912\n",
      "Batch: 420 , Combined Loss: tensor(0.6043, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8628828525543213\n",
      "Batch: 421 , Combined Loss: tensor(0.6227, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.851945161819458\n",
      "Batch: 422 , Combined Loss: tensor(0.6323, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9735115766525269\n",
      "Batch: 423 , Combined Loss: tensor(0.6516, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8353786468505859\n",
      "Batch: 424 , Combined Loss: tensor(0.5942, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39710068702697754\n",
      "Batch: 425 , Combined Loss: tensor(0.6986, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7346957921981812\n",
      "Batch: 426 , Combined Loss: tensor(0.6227, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0220646858215332\n",
      "Batch: 427 , Combined Loss: tensor(0.6827, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6341619491577148\n",
      "Batch: 428 , Combined Loss: tensor(0.6946, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6528408527374268\n",
      "Batch: 429 , Combined Loss: tensor(0.6784, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.964465856552124\n",
      "Batch: 430 , Combined Loss: tensor(0.6405, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8183090686798096\n",
      "Batch: 431 , Combined Loss: tensor(0.6655, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0395135879516602\n",
      "Batch: 432 , Combined Loss: tensor(0.6202, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7291884422302246\n",
      "Batch: 433 , Combined Loss: tensor(0.6182, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9450187683105469\n",
      "Batch: 434 , Combined Loss: tensor(0.8104, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6636916399002075\n",
      "Batch: 435 , Combined Loss: tensor(0.6594, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11661666631698608\n",
      "Batch: 436 , Combined Loss: tensor(0.8695, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.155922532081604\n",
      "Batch: 437 , Combined Loss: tensor(0.6988, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5531405210494995\n",
      "Batch: 438 , Combined Loss: tensor(0.5951, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7111117839813232\n",
      "Batch: 439 , Combined Loss: tensor(0.6754, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0652060508728027\n",
      "Batch: 440 , Combined Loss: tensor(0.7193, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8643664121627808\n",
      "Batch: 441 , Combined Loss: tensor(0.6803, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0615947246551514\n",
      "Batch: 442 , Combined Loss: tensor(0.6824, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8676707744598389\n",
      "Batch: 443 , Combined Loss: tensor(0.7718, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.42007583379745483\n",
      "Batch: 444 , Combined Loss: tensor(0.6079, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7181627750396729\n",
      "Batch: 445 , Combined Loss: tensor(0.6433, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49990415573120117\n",
      "Batch: 446 , Combined Loss: tensor(0.6409, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9754214286804199\n",
      "Batch: 447 , Combined Loss: tensor(0.7384, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8154398202896118\n",
      "Batch: 448 , Combined Loss: tensor(0.6408, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9549612998962402\n",
      "Batch: 449 , Combined Loss: tensor(0.6396, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0259768962860107\n",
      "Batch: 450 , Combined Loss: tensor(0.7007, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09730362892150879\n",
      "Batch: 451 , Combined Loss: tensor(0.6346, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32102835178375244\n",
      "Batch: 452 , Combined Loss: tensor(0.7450, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1598440408706665\n",
      "Batch: 453 , Combined Loss: tensor(0.7003, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9159796237945557\n",
      "Batch: 454 , Combined Loss: tensor(0.7109, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6520146131515503\n",
      "Batch: 455 , Combined Loss: tensor(0.6205, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8128173351287842\n",
      "Batch: 456 , Combined Loss: tensor(0.6457, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04059755802154541\n",
      "Batch: 457 , Combined Loss: tensor(0.6867, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7812315225601196\n",
      "Batch: 458 , Combined Loss: tensor(0.6065, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2025673389434814\n",
      "Batch: 459 , Combined Loss: tensor(0.6259, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7054134607315063\n",
      "Batch: 460 , Combined Loss: tensor(0.6405, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36741089820861816\n",
      "Batch: 461 , Combined Loss: tensor(0.5921, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7213594913482666\n",
      "Batch: 462 , Combined Loss: tensor(0.6308, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5243974924087524\n",
      "Batch: 463 , Combined Loss: tensor(0.6477, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9714967012405396\n",
      "Batch: 464 , Combined Loss: tensor(0.6727, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18514132499694824\n",
      "Batch: 465 , Combined Loss: tensor(0.6587, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7044862508773804\n",
      "Batch: 466 , Combined Loss: tensor(0.7797, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31192100048065186\n",
      "Batch: 467 , Combined Loss: tensor(0.7082, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9525271654129028\n",
      "Batch: 468 , Combined Loss: tensor(0.6504, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3331620693206787\n",
      "Batch: 469 , Combined Loss: tensor(0.5762, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41258227825164795\n",
      "Batch: 470 , Combined Loss: tensor(0.8059, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.66819167137146\n",
      "Batch: 471 , Combined Loss: tensor(0.6157, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8519104719161987\n",
      "Batch: 472 , Combined Loss: tensor(0.6768, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18880689144134521\n",
      "Batch: 473 , Combined Loss: tensor(0.6792, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0609399676322937\n",
      "Batch: 474 , Combined Loss: tensor(0.8053, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.783491849899292\n",
      "Batch: 475 , Combined Loss: tensor(0.6845, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12499809265136719\n",
      "Batch: 476 , Combined Loss: tensor(0.6781, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.133885383605957\n",
      "Batch: 477 , Combined Loss: tensor(0.5886, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.74700927734375\n",
      "Batch: 478 , Combined Loss: tensor(0.7320, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22876054048538208\n",
      "Batch: 479 , Combined Loss: tensor(0.6371, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8017932176589966\n",
      "Batch: 480 , Combined Loss: tensor(0.6975, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04166889190673828\n",
      "Batch: 481 , Combined Loss: tensor(1.0399, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40327560901641846\n",
      "Batch: 482 , Combined Loss: tensor(0.5962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.060124158859253\n",
      "Batch: 483 , Combined Loss: tensor(0.6797, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4478302001953125\n",
      "Batch: 484 , Combined Loss: tensor(0.7293, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3332710266113281\n",
      "Batch: 485 , Combined Loss: tensor(0.7086, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09138429164886475\n",
      "Batch: 486 , Combined Loss: tensor(0.9914, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23734569549560547\n",
      "Batch: 487 , Combined Loss: tensor(0.6537, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5250099897384644\n",
      "Batch: 488 , Combined Loss: tensor(0.7256, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0074076652526855\n",
      "Batch: 489 , Combined Loss: tensor(0.6014, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30225837230682373\n",
      "Batch: 490 , Combined Loss: tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8444967269897461\n",
      "Batch: 491 , Combined Loss: tensor(1.1710, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6485917568206787\n",
      "Batch: 492 , Combined Loss: tensor(0.7086, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8610813617706299\n",
      "Batch: 493 , Combined Loss: tensor(0.6797, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8126193284988403\n",
      "Batch: 494 , Combined Loss: tensor(0.7982, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5593658685684204\n",
      "Batch: 495 , Combined Loss: tensor(0.6859, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8743259906768799\n",
      "Batch: 496 , Combined Loss: tensor(0.6212, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5299038887023926\n",
      "Batch: 497 , Combined Loss: tensor(0.6894, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0245318412780762\n",
      "Batch: 498 , Combined Loss: tensor(0.6520, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5063151121139526\n",
      "Batch: 499 , Combined Loss: tensor(0.6503, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9890813827514648\n",
      "Batch: 500 , Combined Loss: tensor(0.5925, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8428354263305664\n",
      "Batch: 501 , Combined Loss: tensor(0.5622, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8056735992431641\n",
      "Batch: 502 , Combined Loss: tensor(0.6889, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36639952659606934\n",
      "Batch: 503 , Combined Loss: tensor(0.7050, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8690837621688843\n",
      "Batch: 504 , Combined Loss: tensor(0.8147, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6402190923690796\n",
      "Batch: 505 , Combined Loss: tensor(0.6002, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7071954011917114\n",
      "Batch: 506 , Combined Loss: tensor(0.6021, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.658318042755127\n",
      "Batch: 507 , Combined Loss: tensor(0.6287, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6936191320419312\n",
      "Batch: 508 , Combined Loss: tensor(0.6463, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7555481195449829\n",
      "Batch: 509 , Combined Loss: tensor(0.5815, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8228325843811035\n",
      "Batch: 510 , Combined Loss: tensor(0.8831, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5346817970275879\n",
      "Batch: 511 , Combined Loss: tensor(0.7252, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5674867630004883\n",
      "Batch: 512 , Combined Loss: tensor(0.7521, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9582188129425049\n",
      "Batch: 513 , Combined Loss: tensor(0.7231, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06829965114593506\n",
      "Batch: 514 , Combined Loss: tensor(0.6199, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9333257675170898\n",
      "Batch: 515 , Combined Loss: tensor(0.5320, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8041397333145142\n",
      "Batch: 516 , Combined Loss: tensor(0.8223, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2942899465560913\n",
      "Batch: 517 , Combined Loss: tensor(0.8448, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24185681343078613\n",
      "Batch: 518 , Combined Loss: tensor(0.7592, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7219947576522827\n",
      "Batch: 519 , Combined Loss: tensor(0.6644, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3911386728286743\n",
      "Batch: 520 , Combined Loss: tensor(0.8230, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0675945281982422\n",
      "Batch: 521 , Combined Loss: tensor(0.6408, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.779769778251648\n",
      "Batch: 522 , Combined Loss: tensor(0.6356, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0886404514312744\n",
      "Batch: 523 , Combined Loss: tensor(0.7478, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.00706326961517334\n",
      "Batch: 524 , Combined Loss: tensor(0.6550, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6128509044647217\n",
      "Batch: 525 , Combined Loss: tensor(0.6841, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7104531526565552\n",
      "Batch: 526 , Combined Loss: tensor(0.7410, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.609339714050293\n",
      "Batch: 527 , Combined Loss: tensor(0.6020, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.140357494354248\n",
      "Batch: 528 , Combined Loss: tensor(0.5994, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9811849594116211\n",
      "Batch: 529 , Combined Loss: tensor(0.7452, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6102914810180664\n",
      "Batch: 530 , Combined Loss: tensor(0.7390, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7499016523361206\n",
      "Batch: 531 , Combined Loss: tensor(0.7564, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.553827166557312\n",
      "Batch: 532 , Combined Loss: tensor(0.5989, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1063573360443115\n",
      "Batch: 533 , Combined Loss: tensor(0.6522, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08480215072631836\n",
      "Batch: 534 , Combined Loss: tensor(0.5683, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7795239686965942\n",
      "Batch: 535 , Combined Loss: tensor(0.5699, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1008706092834473\n",
      "Batch: 536 , Combined Loss: tensor(0.5939, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0808846950531006\n",
      "Batch: 537 , Combined Loss: tensor(0.8308, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7836761474609375\n",
      "Batch: 538 , Combined Loss: tensor(0.6311, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.801176905632019\n",
      "Batch: 539 , Combined Loss: tensor(0.6200, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0333919525146484\n",
      "Batch: 540 , Combined Loss: tensor(0.6750, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8192740678787231\n",
      "Batch: 541 , Combined Loss: tensor(0.5709, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.028273105621338\n",
      "Batch: 542 , Combined Loss: tensor(0.6631, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.168834924697876\n",
      "Batch: 543 , Combined Loss: tensor(0.5638, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9389643669128418\n",
      "Batch: 544 , Combined Loss: tensor(0.6292, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6681069135665894\n",
      "Batch: 545 , Combined Loss: tensor(0.8263, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43342816829681396\n",
      "Batch: 546 , Combined Loss: tensor(0.7859, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0006439685821533\n",
      "Batch: 547 , Combined Loss: tensor(0.7093, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34745967388153076\n",
      "Batch: 548 , Combined Loss: tensor(0.6710, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7359970808029175\n",
      "Batch: 549 , Combined Loss: tensor(0.6265, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.917082667350769\n",
      "Batch: 550 , Combined Loss: tensor(0.6878, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0125823020935059\n",
      "Batch: 551 , Combined Loss: tensor(0.6619, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9239873886108398\n",
      "Batch: 552 , Combined Loss: tensor(0.6736, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0001335144042969\n",
      "Batch: 553 , Combined Loss: tensor(0.6357, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3118807077407837\n",
      "Batch: 554 , Combined Loss: tensor(0.7023, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22402215003967285\n",
      "Batch: 555 , Combined Loss: tensor(0.6363, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8126803636550903\n",
      "Batch: 556 , Combined Loss: tensor(0.7033, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0269875526428223\n",
      "Batch: 557 , Combined Loss: tensor(0.6129, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8498179912567139\n",
      "Batch: 558 , Combined Loss: tensor(0.6242, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1378037929534912\n",
      "Batch: 559 , Combined Loss: tensor(0.7083, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1015183925628662\n",
      "Batch: 560 , Combined Loss: tensor(0.6837, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9069913625717163\n",
      "Batch: 561 , Combined Loss: tensor(0.8332, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3175501823425293\n",
      "Batch: 562 , Combined Loss: tensor(0.7401, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3985649347305298\n",
      "Batch: 563 , Combined Loss: tensor(0.7318, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0102057456970215\n",
      "Batch: 564 , Combined Loss: tensor(0.6036, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6307005882263184\n",
      "Batch: 565 , Combined Loss: tensor(0.6328, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44157958030700684\n",
      "Batch: 566 , Combined Loss: tensor(0.6047, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5684820413589478\n",
      "Batch: 567 , Combined Loss: tensor(0.7189, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.010717332363128662\n",
      "Batch: 568 , Combined Loss: tensor(0.6627, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7248226404190063\n",
      "Batch: 569 , Combined Loss: tensor(0.5954, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6714085340499878\n",
      "Batch: 570 , Combined Loss: tensor(0.6634, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8820348978042603\n",
      "Batch: 571 , Combined Loss: tensor(0.6225, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1675245761871338\n",
      "Batch: 572 , Combined Loss: tensor(0.9204, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26297664642333984\n",
      "Batch: 573 , Combined Loss: tensor(0.6146, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1652789115905762\n",
      "Batch: 574 , Combined Loss: tensor(0.7345, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9159466028213501\n",
      "Batch: 575 , Combined Loss: tensor(0.6071, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0348260402679443\n",
      "Batch: 576 , Combined Loss: tensor(0.5863, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8117227554321289\n",
      "Batch: 577 , Combined Loss: tensor(0.8345, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3574697971343994\n",
      "Batch: 578 , Combined Loss: tensor(0.7520, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0286903381347656\n",
      "Batch: 579 , Combined Loss: tensor(0.7907, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8497152328491211\n",
      "Batch: 580 , Combined Loss: tensor(0.8137, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6697613000869751\n",
      "Batch: 581 , Combined Loss: tensor(0.5883, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5227304697036743\n",
      "Batch: 582 , Combined Loss: tensor(0.7740, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7515383958816528\n",
      "Batch: 583 , Combined Loss: tensor(0.7443, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.085141658782959\n",
      "Batch: 584 , Combined Loss: tensor(0.6497, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09449160099029541\n",
      "Batch: 585 , Combined Loss: tensor(0.6663, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2426619529724121\n",
      "Batch: 586 , Combined Loss: tensor(0.7432, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6740603446960449\n",
      "Batch: 587 , Combined Loss: tensor(0.6398, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2387547492980957\n",
      "Batch: 588 , Combined Loss: tensor(0.6079, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7053743600845337\n",
      "Batch: 589 , Combined Loss: tensor(0.7185, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1494812965393066\n",
      "Batch: 590 , Combined Loss: tensor(0.7265, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6253589391708374\n",
      "Batch: 591 , Combined Loss: tensor(0.5830, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7038701772689819\n",
      "Batch: 592 , Combined Loss: tensor(0.7476, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.022473454475402832\n",
      "Batch: 593 , Combined Loss: tensor(0.5982, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9726544618606567\n",
      "Batch: 594 , Combined Loss: tensor(0.8193, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8726016283035278\n",
      "Batch: 595 , Combined Loss: tensor(0.6806, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.148857831954956\n",
      "Batch: 596 , Combined Loss: tensor(0.7334, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4208611249923706\n",
      "Batch: 597 , Combined Loss: tensor(0.6568, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5916399955749512\n",
      "Batch: 598 , Combined Loss: tensor(0.5904, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7270877361297607\n",
      "Batch: 599 , Combined Loss: tensor(0.6602, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7225298881530762\n",
      "Batch: 600 , Combined Loss: tensor(0.5673, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9475376605987549\n",
      "Batch: 601 , Combined Loss: tensor(0.5480, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8950554132461548\n",
      "Batch: 602 , Combined Loss: tensor(0.7532, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9628280401229858\n",
      "Batch: 603 , Combined Loss: tensor(0.5993, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47158074378967285\n",
      "Batch: 604 , Combined Loss: tensor(0.6300, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5617743730545044\n",
      "Batch: 605 , Combined Loss: tensor(0.6726, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3433055877685547\n",
      "Batch: 606 , Combined Loss: tensor(0.6973, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7923530340194702\n",
      "Batch: 607 , Combined Loss: tensor(0.7046, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8350367546081543\n",
      "Batch: 608 , Combined Loss: tensor(0.6528, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7675933837890625\n",
      "Batch: 609 , Combined Loss: tensor(0.6675, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7928986549377441\n",
      "Batch: 610 , Combined Loss: tensor(0.6661, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.015828192234039307\n",
      "Batch: 611 , Combined Loss: tensor(0.7657, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.962709903717041\n",
      "Batch: 612 , Combined Loss: tensor(0.5927, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.825178861618042\n",
      "Batch: 613 , Combined Loss: tensor(0.5957, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0112783908843994\n",
      "Batch: 614 , Combined Loss: tensor(0.6731, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8492015600204468\n",
      "Batch: 615 , Combined Loss: tensor(0.5915, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9349188804626465\n",
      "Batch: 616 , Combined Loss: tensor(0.6242, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.257946252822876\n",
      "Batch: 617 , Combined Loss: tensor(0.9439, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4730799198150635\n",
      "Batch: 618 , Combined Loss: tensor(0.8338, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7145662307739258\n",
      "Batch: 619 , Combined Loss: tensor(0.6568, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0143204927444458\n",
      "Batch: 620 , Combined Loss: tensor(0.7093, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9384034872055054\n",
      "Batch: 621 , Combined Loss: tensor(0.7798, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4269903898239136\n",
      "Batch: 622 , Combined Loss: tensor(0.6058, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8396425247192383\n",
      "Batch: 623 , Combined Loss: tensor(0.6258, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9742217063903809\n",
      "Batch: 624 , Combined Loss: tensor(0.5950, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9448800086975098\n",
      "Batch: 625 , Combined Loss: tensor(0.7009, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1849437952041626\n",
      "Batch: 626 , Combined Loss: tensor(0.6865, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7072652578353882\n",
      "Batch: 627 , Combined Loss: tensor(0.7074, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8536499738693237\n",
      "Batch: 628 , Combined Loss: tensor(0.7019, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8586121797561646\n",
      "----------Epoch 19, Loss: 0.6842294809170103, Accuracy: 0.9708365772411062, Dice Coef: [0.9870247918585336, 0.5826910658605304, 0.6329199662645842, 0.7076775710625496], Dice Coef Necrotic: 1.0436487136999122, Dice Coef Edema: 1.0585156872265513, Dice Coef Enhancing: 1.0468847861903514, Sensitivity: [0.9763013970681328, 0.7654538503190982, 0.8678729156052933, 0.8625258586068885], Specificity: [0.9672034493690455, 0.997199424783831, 0.979035085828202, 0.995746024841345], Precision: [0.9980666176882381, 0.5376670830811252, 0.5294037665880288, 0.6466184438867731]\n",
      "Saving without nn.DataParallel\n",
      "Batch: 0 , Combined Loss: tensor(0.5823, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8190631866455078\n",
      "Batch: 1 , Combined Loss: tensor(0.6686, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0703577995300293\n",
      "Batch: 2 , Combined Loss: tensor(0.6980, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7811408042907715\n",
      "Batch: 3 , Combined Loss: tensor(0.6853, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1928820610046387\n",
      "Batch: 4 , Combined Loss: tensor(0.6392, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7370390892028809\n",
      "Batch: 5 , Combined Loss: tensor(0.6190, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5573570728302002\n",
      "Batch: 6 , Combined Loss: tensor(0.6991, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7228896617889404\n",
      "Batch: 7 , Combined Loss: tensor(0.6878, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0543897151947021\n",
      "Batch: 8 , Combined Loss: tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6314791440963745\n",
      "Batch: 9 , Combined Loss: tensor(0.6988, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8789976835250854\n",
      "Batch: 10 , Combined Loss: tensor(0.8682, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.901576042175293\n",
      "Batch: 11 , Combined Loss: tensor(0.9203, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17441803216934204\n",
      "Batch: 12 , Combined Loss: tensor(0.9276, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1928701400756836\n",
      "Batch: 13 , Combined Loss: tensor(0.6465, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0742691159248352\n",
      "Batch: 14 , Combined Loss: tensor(0.5614, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7878588438034058\n",
      "Batch: 15 , Combined Loss: tensor(0.6372, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9769318103790283\n",
      "Batch: 16 , Combined Loss: tensor(0.7444, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8286325931549072\n",
      "Batch: 17 , Combined Loss: tensor(0.6281, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06938517093658447\n",
      "Batch: 18 , Combined Loss: tensor(0.6897, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.031903743743896484\n",
      "Batch: 19 , Combined Loss: tensor(0.6905, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6581506729125977\n",
      "Batch: 20 , Combined Loss: tensor(0.7338, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.972394585609436\n",
      "Batch: 21 , Combined Loss: tensor(0.6230, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20214426517486572\n",
      "Batch: 22 , Combined Loss: tensor(0.7821, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.18358808755874634\n",
      "Batch: 23 , Combined Loss: tensor(0.6501, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3198423385620117\n",
      "Batch: 24 , Combined Loss: tensor(0.7981, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1576223373413086\n",
      "Batch: 25 , Combined Loss: tensor(0.7223, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06373429298400879\n",
      "Batch: 26 , Combined Loss: tensor(0.5803, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0590293407440186\n",
      "Batch: 27 , Combined Loss: tensor(0.6493, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07293498516082764\n",
      "Batch: 28 , Combined Loss: tensor(0.7475, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7485326528549194\n",
      "Batch: 29 , Combined Loss: tensor(0.5399, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3858093023300171\n",
      "Batch: 30 , Combined Loss: tensor(0.7085, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0387580394744873\n",
      "Batch: 31 , Combined Loss: tensor(0.6982, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7103725671768188\n",
      "Batch: 32 , Combined Loss: tensor(0.6009, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5720276832580566\n",
      "Batch: 33 , Combined Loss: tensor(0.7420, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2567509412765503\n",
      "Batch: 34 , Combined Loss: tensor(0.5975, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31348204612731934\n",
      "Batch: 35 , Combined Loss: tensor(0.7827, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22687828540802002\n",
      "Batch: 36 , Combined Loss: tensor(0.6882, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8820395469665527\n",
      "Batch: 37 , Combined Loss: tensor(0.6229, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26834726333618164\n",
      "Batch: 38 , Combined Loss: tensor(0.6460, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0511744022369385\n",
      "Batch: 39 , Combined Loss: tensor(0.6722, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6505162715911865\n",
      "Batch: 40 , Combined Loss: tensor(0.7285, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44365572929382324\n",
      "Batch: 41 , Combined Loss: tensor(0.6760, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3551797866821289\n",
      "Batch: 42 , Combined Loss: tensor(0.7352, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5860246419906616\n",
      "Batch: 43 , Combined Loss: tensor(0.5987, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.017508864402770996\n",
      "Batch: 44 , Combined Loss: tensor(0.6358, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9438499212265015\n",
      "Batch: 45 , Combined Loss: tensor(0.7381, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8896108865737915\n",
      "Batch: 46 , Combined Loss: tensor(0.7587, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8663852214813232\n",
      "Batch: 47 , Combined Loss: tensor(0.6885, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7192568778991699\n",
      "Batch: 48 , Combined Loss: tensor(0.6848, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.127081036567688\n",
      "Batch: 49 , Combined Loss: tensor(1.0415, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17943155765533447\n",
      "Batch: 50 , Combined Loss: tensor(0.7184, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.603085994720459\n",
      "Batch: 51 , Combined Loss: tensor(0.6740, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.125650405883789\n",
      "Batch: 52 , Combined Loss: tensor(0.6458, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9255136251449585\n",
      "Batch: 53 , Combined Loss: tensor(0.7051, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3919109106063843\n",
      "Batch: 54 , Combined Loss: tensor(0.6099, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10651576519012451\n",
      "Batch: 55 , Combined Loss: tensor(0.7708, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7840452194213867\n",
      "Batch: 56 , Combined Loss: tensor(1.4585, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49037277698516846\n",
      "Batch: 57 , Combined Loss: tensor(0.6963, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9960294961929321\n",
      "Batch: 58 , Combined Loss: tensor(0.5853, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.046750783920288\n",
      "Batch: 59 , Combined Loss: tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0181324481964111\n",
      "Batch: 60 , Combined Loss: tensor(0.6931, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8819124698638916\n",
      "Batch: 61 , Combined Loss: tensor(0.7029, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6559939384460449\n",
      "Batch: 62 , Combined Loss: tensor(0.8016, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6780718564987183\n",
      "Batch: 63 , Combined Loss: tensor(0.6261, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0751516819000244\n",
      "Batch: 64 , Combined Loss: tensor(0.5900, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6709203720092773\n",
      "Batch: 65 , Combined Loss: tensor(0.5973, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.825068473815918\n",
      "Batch: 66 , Combined Loss: tensor(0.5767, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7868232727050781\n",
      "Batch: 67 , Combined Loss: tensor(0.6206, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8612315654754639\n",
      "Batch: 68 , Combined Loss: tensor(0.7958, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0634992122650146\n",
      "Batch: 69 , Combined Loss: tensor(0.6370, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6936531066894531\n",
      "Batch: 70 , Combined Loss: tensor(0.7344, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6780785322189331\n",
      "Batch: 71 , Combined Loss: tensor(0.6288, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7251218557357788\n",
      "Batch: 72 , Combined Loss: tensor(0.6376, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0862526893615723\n",
      "Batch: 73 , Combined Loss: tensor(0.6301, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.037283182144165\n",
      "Batch: 74 , Combined Loss: tensor(0.7934, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16783356666564941\n",
      "Batch: 75 , Combined Loss: tensor(0.5838, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.944665789604187\n",
      "Batch: 76 , Combined Loss: tensor(0.6160, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8024545907974243\n",
      "Batch: 77 , Combined Loss: tensor(1.0073, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40681231021881104\n",
      "Batch: 78 , Combined Loss: tensor(0.6068, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1451542377471924\n",
      "Batch: 79 , Combined Loss: tensor(0.7483, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9904327392578125\n",
      "Batch: 80 , Combined Loss: tensor(0.6699, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9424960613250732\n",
      "Batch: 81 , Combined Loss: tensor(0.6327, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9803051948547363\n",
      "Batch: 82 , Combined Loss: tensor(0.7811, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1924266815185547\n",
      "Batch: 83 , Combined Loss: tensor(0.6356, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.388733148574829\n",
      "Batch: 84 , Combined Loss: tensor(0.8779, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9325369596481323\n",
      "Batch: 85 , Combined Loss: tensor(0.6559, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.926027774810791\n",
      "Batch: 86 , Combined Loss: tensor(0.6271, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9694061279296875\n",
      "Batch: 87 , Combined Loss: tensor(0.8067, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6295093297958374\n",
      "Batch: 88 , Combined Loss: tensor(0.6259, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0932049751281738\n",
      "Batch: 89 , Combined Loss: tensor(0.6500, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2232661247253418\n",
      "Batch: 90 , Combined Loss: tensor(0.6931, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9711198806762695\n",
      "Batch: 91 , Combined Loss: tensor(0.8408, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9604986906051636\n",
      "Batch: 92 , Combined Loss: tensor(0.6848, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8154529333114624\n",
      "Batch: 93 , Combined Loss: tensor(0.6860, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0681555271148682\n",
      "Batch: 94 , Combined Loss: tensor(0.6571, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7000820636749268\n",
      "Batch: 95 , Combined Loss: tensor(0.8247, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7696049213409424\n",
      "Batch: 96 , Combined Loss: tensor(0.6844, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0663728713989258\n",
      "Batch: 97 , Combined Loss: tensor(0.7033, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4219592809677124\n",
      "Batch: 98 , Combined Loss: tensor(0.6182, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0468950271606445\n",
      "Batch: 99 , Combined Loss: tensor(0.6039, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.953954815864563\n",
      "Batch: 100 , Combined Loss: tensor(0.6308, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.746553897857666\n",
      "Batch: 101 , Combined Loss: tensor(0.6733, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9125596284866333\n",
      "Batch: 102 , Combined Loss: tensor(0.6836, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.904534101486206\n",
      "Batch: 103 , Combined Loss: tensor(0.7558, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0694100856781006\n",
      "Batch: 104 , Combined Loss: tensor(0.6194, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.996631383895874\n",
      "Batch: 105 , Combined Loss: tensor(0.5501, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9382195472717285\n",
      "Batch: 106 , Combined Loss: tensor(0.5641, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.964024543762207\n",
      "Batch: 107 , Combined Loss: tensor(0.6033, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0781328678131104\n",
      "Batch: 108 , Combined Loss: tensor(0.7620, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9936579465866089\n",
      "Batch: 109 , Combined Loss: tensor(0.9564, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.036200523376464844\n",
      "Batch: 110 , Combined Loss: tensor(0.7633, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20828843116760254\n",
      "Batch: 111 , Combined Loss: tensor(0.6312, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3845326900482178\n",
      "Batch: 112 , Combined Loss: tensor(0.6167, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9757465124130249\n",
      "Batch: 113 , Combined Loss: tensor(0.5979, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9777858257293701\n",
      "Batch: 114 , Combined Loss: tensor(0.5566, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8316526412963867\n",
      "Batch: 115 , Combined Loss: tensor(0.8732, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0302138328552246\n",
      "Batch: 116 , Combined Loss: tensor(0.6421, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5807729959487915\n",
      "Batch: 117 , Combined Loss: tensor(0.5857, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7535785436630249\n",
      "Batch: 118 , Combined Loss: tensor(0.6766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49204933643341064\n",
      "Batch: 119 , Combined Loss: tensor(0.7917, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6288769245147705\n",
      "Batch: 120 , Combined Loss: tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7670485973358154\n",
      "Batch: 121 , Combined Loss: tensor(0.7482, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23193466663360596\n",
      "Batch: 122 , Combined Loss: tensor(1.0425, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07436555624008179\n",
      "Batch: 123 , Combined Loss: tensor(0.5696, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.117473840713501\n",
      "Batch: 124 , Combined Loss: tensor(0.8289, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0616657733917236\n",
      "Batch: 125 , Combined Loss: tensor(0.7298, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7870892286300659\n",
      "Batch: 126 , Combined Loss: tensor(0.6940, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5805474519729614\n",
      "Batch: 127 , Combined Loss: tensor(0.7205, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7025192975997925\n",
      "Batch: 128 , Combined Loss: tensor(0.5916, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9672186374664307\n",
      "Batch: 129 , Combined Loss: tensor(0.7191, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.513131856918335\n",
      "Batch: 130 , Combined Loss: tensor(0.7214, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8081141710281372\n",
      "Batch: 131 , Combined Loss: tensor(0.7248, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6917978525161743\n",
      "Batch: 132 , Combined Loss: tensor(0.6218, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8663414716720581\n",
      "Batch: 133 , Combined Loss: tensor(0.5819, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8994959592819214\n",
      "Batch: 134 , Combined Loss: tensor(0.7128, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9571114778518677\n",
      "Batch: 135 , Combined Loss: tensor(0.6946, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7811909914016724\n",
      "Batch: 136 , Combined Loss: tensor(0.7543, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9183001518249512\n",
      "Batch: 137 , Combined Loss: tensor(0.6835, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9450981616973877\n",
      "Batch: 138 , Combined Loss: tensor(0.7365, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7723598480224609\n",
      "Batch: 139 , Combined Loss: tensor(0.5507, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.781480073928833\n",
      "Batch: 140 , Combined Loss: tensor(0.6424, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5309666395187378\n",
      "Batch: 141 , Combined Loss: tensor(0.7543, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11126542091369629\n",
      "Batch: 142 , Combined Loss: tensor(0.7324, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7087092399597168\n",
      "Batch: 143 , Combined Loss: tensor(0.9159, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4638112783432007\n",
      "Batch: 144 , Combined Loss: tensor(0.7644, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9317280054092407\n",
      "Batch: 145 , Combined Loss: tensor(0.7750, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9892281293869019\n",
      "Batch: 146 , Combined Loss: tensor(0.6283, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8918559551239014\n",
      "Batch: 147 , Combined Loss: tensor(0.7676, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08001840114593506\n",
      "Batch: 148 , Combined Loss: tensor(0.6993, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0671977996826172\n",
      "Batch: 149 , Combined Loss: tensor(0.7262, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.05397629737854\n",
      "Batch: 150 , Combined Loss: tensor(0.6828, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0688591003417969\n",
      "Batch: 151 , Combined Loss: tensor(0.6775, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4798022508621216\n",
      "Batch: 152 , Combined Loss: tensor(0.6445, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5657200813293457\n",
      "Batch: 153 , Combined Loss: tensor(0.7658, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4371802806854248\n",
      "Batch: 154 , Combined Loss: tensor(0.6094, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1909390687942505\n",
      "Batch: 155 , Combined Loss: tensor(0.6395, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8424974679946899\n",
      "Batch: 156 , Combined Loss: tensor(0.7192, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2081131935119629\n",
      "Batch: 157 , Combined Loss: tensor(0.6424, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7765763998031616\n",
      "Batch: 158 , Combined Loss: tensor(0.8305, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.713787317276001\n",
      "Batch: 159 , Combined Loss: tensor(0.7040, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8655586242675781\n",
      "Batch: 160 , Combined Loss: tensor(0.6524, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8505953550338745\n",
      "Batch: 161 , Combined Loss: tensor(0.6723, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8271980285644531\n",
      "Batch: 162 , Combined Loss: tensor(0.5831, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8161303997039795\n",
      "Batch: 163 , Combined Loss: tensor(0.6393, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7498478889465332\n",
      "Batch: 164 , Combined Loss: tensor(0.7433, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5312937498092651\n",
      "Batch: 165 , Combined Loss: tensor(0.7783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.02491128444671631\n",
      "Batch: 166 , Combined Loss: tensor(0.5589, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33455681800842285\n",
      "Batch: 167 , Combined Loss: tensor(0.6421, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3425741195678711\n",
      "Batch: 168 , Combined Loss: tensor(0.6347, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1621930599212646\n",
      "Batch: 169 , Combined Loss: tensor(0.6364, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1964690685272217\n",
      "Batch: 170 , Combined Loss: tensor(0.7544, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9882373809814453\n",
      "Batch: 171 , Combined Loss: tensor(0.5731, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3216519355773926\n",
      "Batch: 172 , Combined Loss: tensor(0.5786, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9430313110351562\n",
      "Batch: 173 , Combined Loss: tensor(0.6724, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7915840148925781\n",
      "Batch: 174 , Combined Loss: tensor(0.8317, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.328066349029541\n",
      "Batch: 175 , Combined Loss: tensor(0.7130, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8958142995834351\n",
      "Batch: 176 , Combined Loss: tensor(0.6176, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8830188512802124\n",
      "Batch: 177 , Combined Loss: tensor(0.6741, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18965590000152588\n",
      "Batch: 178 , Combined Loss: tensor(0.7043, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23532474040985107\n",
      "Batch: 179 , Combined Loss: tensor(0.6077, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.757927417755127\n",
      "Batch: 180 , Combined Loss: tensor(0.6806, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6812468767166138\n",
      "Batch: 181 , Combined Loss: tensor(0.6848, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.778113842010498\n",
      "Batch: 182 , Combined Loss: tensor(0.6596, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9502097368240356\n",
      "Batch: 183 , Combined Loss: tensor(0.6819, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9009783267974854\n",
      "Batch: 184 , Combined Loss: tensor(0.6061, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0419554710388184\n",
      "Batch: 185 , Combined Loss: tensor(0.5745, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5214003324508667\n",
      "Batch: 186 , Combined Loss: tensor(0.7207, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38399839401245117\n",
      "Batch: 187 , Combined Loss: tensor(0.6692, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7558039426803589\n",
      "Batch: 188 , Combined Loss: tensor(0.6149, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41675102710723877\n",
      "Batch: 189 , Combined Loss: tensor(0.6721, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.018112778663635254\n",
      "Batch: 190 , Combined Loss: tensor(0.6385, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5679779052734375\n",
      "Batch: 191 , Combined Loss: tensor(0.5923, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9198158979415894\n",
      "Batch: 192 , Combined Loss: tensor(0.7035, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6988404989242554\n",
      "Batch: 193 , Combined Loss: tensor(0.7076, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2135080099105835\n",
      "Batch: 194 , Combined Loss: tensor(0.5985, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38964664936065674\n",
      "Batch: 195 , Combined Loss: tensor(0.6299, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9088821411132812\n",
      "Batch: 196 , Combined Loss: tensor(0.8180, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0991222858428955\n",
      "Batch: 197 , Combined Loss: tensor(0.6211, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9750642776489258\n",
      "Batch: 198 , Combined Loss: tensor(0.7353, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7208024263381958\n",
      "Batch: 199 , Combined Loss: tensor(0.6748, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9178996086120605\n",
      "Batch: 200 , Combined Loss: tensor(0.6401, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9238659143447876\n",
      "Batch: 201 , Combined Loss: tensor(0.5472, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6656335592269897\n",
      "Batch: 202 , Combined Loss: tensor(0.6319, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9788508415222168\n",
      "Batch: 203 , Combined Loss: tensor(0.6840, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8818773031234741\n",
      "Batch: 204 , Combined Loss: tensor(0.6825, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5388925075531006\n",
      "Batch: 205 , Combined Loss: tensor(0.7362, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9304131269454956\n",
      "Batch: 206 , Combined Loss: tensor(0.6850, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47386765480041504\n",
      "Batch: 207 , Combined Loss: tensor(0.8157, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8086651563644409\n",
      "Batch: 208 , Combined Loss: tensor(0.7497, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8291313648223877\n",
      "Batch: 209 , Combined Loss: tensor(0.5927, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5691369771957397\n",
      "Batch: 210 , Combined Loss: tensor(0.7437, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.081918716430664\n",
      "Batch: 211 , Combined Loss: tensor(0.7220, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0338430404663086\n",
      "Batch: 212 , Combined Loss: tensor(0.7529, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7825675010681152\n",
      "Batch: 213 , Combined Loss: tensor(0.6175, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30530571937561035\n",
      "Batch: 214 , Combined Loss: tensor(0.6243, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1299552917480469\n",
      "Batch: 215 , Combined Loss: tensor(0.5600, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5283834934234619\n",
      "Batch: 216 , Combined Loss: tensor(0.6775, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9293828010559082\n",
      "Batch: 217 , Combined Loss: tensor(0.6156, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8847934007644653\n",
      "Batch: 218 , Combined Loss: tensor(0.6124, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0929598808288574\n",
      "Batch: 219 , Combined Loss: tensor(0.7200, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.046825885772705\n",
      "Batch: 220 , Combined Loss: tensor(0.6217, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.016772329807281494\n",
      "Batch: 221 , Combined Loss: tensor(0.6914, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0184509754180908\n",
      "Batch: 222 , Combined Loss: tensor(0.6450, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1589125394821167\n",
      "Batch: 223 , Combined Loss: tensor(0.5813, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7727576494216919\n",
      "Batch: 224 , Combined Loss: tensor(1.0435, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.478259801864624\n",
      "Batch: 225 , Combined Loss: tensor(0.7297, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9770076274871826\n",
      "Batch: 226 , Combined Loss: tensor(0.5322, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7221022844314575\n",
      "Batch: 227 , Combined Loss: tensor(0.7669, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.036222219467163\n",
      "Batch: 228 , Combined Loss: tensor(0.6678, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2004331350326538\n",
      "Batch: 229 , Combined Loss: tensor(0.7397, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.120469331741333\n",
      "Batch: 230 , Combined Loss: tensor(0.6065, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1021225452423096\n",
      "Batch: 231 , Combined Loss: tensor(0.7445, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.052193641662597656\n",
      "Batch: 232 , Combined Loss: tensor(0.6314, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8636223077774048\n",
      "Batch: 233 , Combined Loss: tensor(0.6031, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9361305236816406\n",
      "Batch: 234 , Combined Loss: tensor(0.7071, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.712053656578064\n",
      "Batch: 235 , Combined Loss: tensor(0.6967, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9617408514022827\n",
      "Batch: 236 , Combined Loss: tensor(0.5679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8150893449783325\n",
      "Batch: 237 , Combined Loss: tensor(0.6727, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8910741806030273\n",
      "Batch: 238 , Combined Loss: tensor(0.6274, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.034914255142211914\n",
      "Batch: 239 , Combined Loss: tensor(0.7339, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3492501974105835\n",
      "Batch: 240 , Combined Loss: tensor(0.5741, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9856433868408203\n",
      "Batch: 241 , Combined Loss: tensor(0.6449, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8924678564071655\n",
      "Batch: 242 , Combined Loss: tensor(0.6905, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.758427619934082\n",
      "Batch: 243 , Combined Loss: tensor(0.7360, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.978630542755127\n",
      "Batch: 244 , Combined Loss: tensor(0.8685, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2969193458557129\n",
      "Batch: 245 , Combined Loss: tensor(0.6813, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.992343544960022\n",
      "Batch: 246 , Combined Loss: tensor(0.6897, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3329041004180908\n",
      "Batch: 247 , Combined Loss: tensor(0.6489, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8158478736877441\n",
      "Batch: 248 , Combined Loss: tensor(0.7591, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9555697441101074\n",
      "Batch: 249 , Combined Loss: tensor(0.6825, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04777324199676514\n",
      "Batch: 250 , Combined Loss: tensor(0.5927, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5190634727478027\n",
      "Batch: 251 , Combined Loss: tensor(0.6161, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6898130178451538\n",
      "Batch: 252 , Combined Loss: tensor(0.6882, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7859905958175659\n",
      "Batch: 253 , Combined Loss: tensor(0.6827, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3428138494491577\n",
      "Batch: 254 , Combined Loss: tensor(0.7452, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7282137870788574\n",
      "Batch: 255 , Combined Loss: tensor(0.6541, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9649754762649536\n",
      "Batch: 256 , Combined Loss: tensor(0.7051, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8477516174316406\n",
      "Batch: 257 , Combined Loss: tensor(0.6543, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8970236778259277\n",
      "Batch: 258 , Combined Loss: tensor(0.6647, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0895776748657227\n",
      "Batch: 259 , Combined Loss: tensor(0.6755, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6739242076873779\n",
      "Batch: 260 , Combined Loss: tensor(0.7239, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33086133003234863\n",
      "Batch: 261 , Combined Loss: tensor(0.6831, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1515871286392212\n",
      "Batch: 262 , Combined Loss: tensor(0.5808, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8353173732757568\n",
      "Batch: 263 , Combined Loss: tensor(0.8000, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7618793249130249\n",
      "Batch: 264 , Combined Loss: tensor(0.6307, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0046181678771973\n",
      "Batch: 265 , Combined Loss: tensor(0.6014, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9539015293121338\n",
      "Batch: 266 , Combined Loss: tensor(0.6347, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8580312728881836\n",
      "Batch: 267 , Combined Loss: tensor(0.6714, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9013137817382812\n",
      "Batch: 268 , Combined Loss: tensor(0.6109, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.620193600654602\n",
      "Batch: 269 , Combined Loss: tensor(0.7559, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4165041446685791\n",
      "Batch: 270 , Combined Loss: tensor(0.7409, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6198139190673828\n",
      "Batch: 271 , Combined Loss: tensor(0.6559, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8881109952926636\n",
      "Batch: 272 , Combined Loss: tensor(0.6891, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.755002498626709\n",
      "Batch: 273 , Combined Loss: tensor(0.7206, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.868099570274353\n",
      "Batch: 274 , Combined Loss: tensor(0.6818, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6703329086303711\n",
      "Batch: 275 , Combined Loss: tensor(0.7217, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.933273196220398\n",
      "Batch: 276 , Combined Loss: tensor(0.8346, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.006564974784851074\n",
      "Batch: 277 , Combined Loss: tensor(0.7754, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.861261248588562\n",
      "Batch: 278 , Combined Loss: tensor(0.6560, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3165629506111145\n",
      "Batch: 279 , Combined Loss: tensor(0.6777, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0405004024505615\n",
      "Batch: 280 , Combined Loss: tensor(0.6185, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7494335174560547\n",
      "Batch: 281 , Combined Loss: tensor(0.7433, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8526654243469238\n",
      "Batch: 282 , Combined Loss: tensor(0.8687, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22220885753631592\n",
      "Batch: 283 , Combined Loss: tensor(0.7616, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12989473342895508\n",
      "Batch: 284 , Combined Loss: tensor(0.7127, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47947824001312256\n",
      "Batch: 285 , Combined Loss: tensor(0.7974, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35739803314208984\n",
      "Batch: 286 , Combined Loss: tensor(0.6351, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.832079291343689\n",
      "Batch: 287 , Combined Loss: tensor(0.6309, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9713406562805176\n",
      "Batch: 288 , Combined Loss: tensor(0.5920, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7484488487243652\n",
      "Batch: 289 , Combined Loss: tensor(0.6040, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7460416555404663\n",
      "Batch: 290 , Combined Loss: tensor(0.6708, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43147265911102295\n",
      "Batch: 291 , Combined Loss: tensor(0.6262, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10902762413024902\n",
      "Batch: 292 , Combined Loss: tensor(0.6279, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1296732425689697\n",
      "Batch: 293 , Combined Loss: tensor(0.7207, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7276941537857056\n",
      "Batch: 294 , Combined Loss: tensor(0.5807, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1132209300994873\n",
      "Batch: 295 , Combined Loss: tensor(0.6924, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9076758623123169\n",
      "Batch: 296 , Combined Loss: tensor(0.7646, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9359253644943237\n",
      "Batch: 297 , Combined Loss: tensor(0.7908, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46964406967163086\n",
      "Batch: 298 , Combined Loss: tensor(0.7695, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0616440773010254\n",
      "Batch: 299 , Combined Loss: tensor(0.6371, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7776530981063843\n",
      "Batch: 300 , Combined Loss: tensor(0.6825, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9528275728225708\n",
      "Batch: 301 , Combined Loss: tensor(0.5866, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0721468925476074\n",
      "Batch: 302 , Combined Loss: tensor(0.7023, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6260391473770142\n",
      "Batch: 303 , Combined Loss: tensor(0.5915, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20648235082626343\n",
      "Batch: 304 , Combined Loss: tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38017988204956055\n",
      "Batch: 305 , Combined Loss: tensor(0.6202, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7709693908691406\n",
      "Batch: 306 , Combined Loss: tensor(0.6508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9044806957244873\n",
      "Batch: 307 , Combined Loss: tensor(0.6174, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.149087905883789\n",
      "Batch: 308 , Combined Loss: tensor(0.8861, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7971256971359253\n",
      "Batch: 309 , Combined Loss: tensor(0.5983, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7126349210739136\n",
      "Batch: 310 , Combined Loss: tensor(0.6631, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17924129962921143\n",
      "Batch: 311 , Combined Loss: tensor(0.7470, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6375067234039307\n",
      "Batch: 312 , Combined Loss: tensor(0.8064, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8664615154266357\n",
      "Batch: 313 , Combined Loss: tensor(0.6027, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1334736347198486\n",
      "Batch: 314 , Combined Loss: tensor(0.6762, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.16791534423828125\n",
      "Batch: 315 , Combined Loss: tensor(0.9555, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6702396869659424\n",
      "Batch: 316 , Combined Loss: tensor(0.5969, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.462063193321228\n",
      "Batch: 317 , Combined Loss: tensor(0.6613, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.019719123840332\n",
      "Batch: 318 , Combined Loss: tensor(0.6335, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.36197447776794434\n",
      "Batch: 319 , Combined Loss: tensor(0.6110, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8744720220565796\n",
      "Batch: 320 , Combined Loss: tensor(0.6307, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4716033935546875\n",
      "Batch: 321 , Combined Loss: tensor(0.5956, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.004023790359497\n",
      "Batch: 322 , Combined Loss: tensor(0.6365, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8048367500305176\n",
      "Batch: 323 , Combined Loss: tensor(0.7009, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9603438377380371\n",
      "Batch: 324 , Combined Loss: tensor(0.7935, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35823237895965576\n",
      "Batch: 325 , Combined Loss: tensor(0.5650, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.025531291961669922\n",
      "Batch: 326 , Combined Loss: tensor(0.6278, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25945448875427246\n",
      "Batch: 327 , Combined Loss: tensor(0.5934, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.283998966217041\n",
      "Batch: 328 , Combined Loss: tensor(0.6354, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5205254554748535\n",
      "Batch: 329 , Combined Loss: tensor(0.8451, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7353405952453613\n",
      "Batch: 330 , Combined Loss: tensor(0.6914, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9676439762115479\n",
      "Batch: 331 , Combined Loss: tensor(0.8076, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9779011011123657\n",
      "Batch: 332 , Combined Loss: tensor(0.6288, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7978025674819946\n",
      "Batch: 333 , Combined Loss: tensor(0.8012, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9467991590499878\n",
      "Batch: 334 , Combined Loss: tensor(0.5822, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9786190986633301\n",
      "Batch: 335 , Combined Loss: tensor(0.6311, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8157390356063843\n",
      "Batch: 336 , Combined Loss: tensor(0.5731, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.824203372001648\n",
      "Batch: 337 , Combined Loss: tensor(0.7345, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6184920072555542\n",
      "Batch: 338 , Combined Loss: tensor(0.7535, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.129565715789795\n",
      "Batch: 339 , Combined Loss: tensor(0.7856, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4311025142669678\n",
      "Batch: 340 , Combined Loss: tensor(0.5903, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.238882064819336\n",
      "Batch: 341 , Combined Loss: tensor(0.5938, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3370530605316162\n",
      "Batch: 342 , Combined Loss: tensor(0.6817, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1166496276855469\n",
      "Batch: 343 , Combined Loss: tensor(0.7461, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43374598026275635\n",
      "Batch: 344 , Combined Loss: tensor(0.6771, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9644496440887451\n",
      "Batch: 345 , Combined Loss: tensor(0.6049, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0267281532287598\n",
      "Batch: 346 , Combined Loss: tensor(0.7332, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9253876209259033\n",
      "Batch: 347 , Combined Loss: tensor(0.7501, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8996957540512085\n",
      "Batch: 348 , Combined Loss: tensor(0.6510, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8482962846755981\n",
      "Batch: 349 , Combined Loss: tensor(0.6187, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9636745452880859\n",
      "Batch: 350 , Combined Loss: tensor(0.6884, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.552327036857605\n",
      "Batch: 351 , Combined Loss: tensor(0.9186, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1299607753753662\n",
      "Batch: 352 , Combined Loss: tensor(1.0826, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7393704652786255\n",
      "Batch: 353 , Combined Loss: tensor(0.5957, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0034053325653076\n",
      "Batch: 354 , Combined Loss: tensor(0.6966, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.013860225677490234\n",
      "Batch: 355 , Combined Loss: tensor(0.7600, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6566163301467896\n",
      "Batch: 356 , Combined Loss: tensor(0.6171, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.675443172454834\n",
      "Batch: 357 , Combined Loss: tensor(0.6108, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8388789892196655\n",
      "Batch: 358 , Combined Loss: tensor(0.7038, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9758893251419067\n",
      "Batch: 359 , Combined Loss: tensor(0.6242, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5341230630874634\n",
      "Batch: 360 , Combined Loss: tensor(0.6093, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0726666450500488\n",
      "Batch: 361 , Combined Loss: tensor(0.5549, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6184933185577393\n",
      "Batch: 362 , Combined Loss: tensor(0.6553, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0015606880187988\n",
      "Batch: 363 , Combined Loss: tensor(0.6346, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0009641647338867\n",
      "Batch: 364 , Combined Loss: tensor(0.6226, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1381659507751465\n",
      "Batch: 365 , Combined Loss: tensor(0.9916, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5470072031021118\n",
      "Batch: 366 , Combined Loss: tensor(0.6398, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.240378737449646\n",
      "Batch: 367 , Combined Loss: tensor(0.8246, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6508820056915283\n",
      "Batch: 368 , Combined Loss: tensor(0.6440, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0146076679229736\n",
      "Batch: 369 , Combined Loss: tensor(0.5642, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.680106520652771\n",
      "Batch: 370 , Combined Loss: tensor(0.7684, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3240586519241333\n",
      "Batch: 371 , Combined Loss: tensor(0.6613, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6802947521209717\n",
      "Batch: 372 , Combined Loss: tensor(0.7394, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3161592483520508\n",
      "Batch: 373 , Combined Loss: tensor(0.6804, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.046732306480407715\n",
      "Batch: 374 , Combined Loss: tensor(1.0173, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07089269161224365\n",
      "Batch: 375 , Combined Loss: tensor(0.6266, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6499248743057251\n",
      "Batch: 376 , Combined Loss: tensor(0.7507, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8340095281600952\n",
      "Batch: 377 , Combined Loss: tensor(0.5962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1561410427093506\n",
      "Batch: 378 , Combined Loss: tensor(0.6698, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9027172327041626\n",
      "Batch: 379 , Combined Loss: tensor(0.6333, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8520025014877319\n",
      "Batch: 380 , Combined Loss: tensor(0.6653, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7507940530776978\n",
      "Batch: 381 , Combined Loss: tensor(0.6115, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8855481147766113\n",
      "Batch: 382 , Combined Loss: tensor(0.6655, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0795905590057373\n",
      "Batch: 383 , Combined Loss: tensor(0.8642, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12436336278915405\n",
      "Batch: 384 , Combined Loss: tensor(0.7021, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0036439895629883\n",
      "Batch: 385 , Combined Loss: tensor(0.7227, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1914684772491455\n",
      "Batch: 386 , Combined Loss: tensor(0.6335, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5772719383239746\n",
      "Batch: 387 , Combined Loss: tensor(0.5947, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9142566919326782\n",
      "Batch: 388 , Combined Loss: tensor(0.6277, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8742774724960327\n",
      "Batch: 389 , Combined Loss: tensor(0.6734, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.927310585975647\n",
      "Batch: 390 , Combined Loss: tensor(0.6377, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8840867280960083\n",
      "Batch: 391 , Combined Loss: tensor(0.6508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38496339321136475\n",
      "Batch: 392 , Combined Loss: tensor(0.6339, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.543886661529541\n",
      "Batch: 393 , Combined Loss: tensor(0.4901, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5749012231826782\n",
      "Batch: 394 , Combined Loss: tensor(0.7936, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7779011726379395\n",
      "Batch: 395 , Combined Loss: tensor(0.6430, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0813789367675781\n",
      "Batch: 396 , Combined Loss: tensor(0.6933, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9206565618515015\n",
      "Batch: 397 , Combined Loss: tensor(0.7440, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.011017441749572754\n",
      "Batch: 398 , Combined Loss: tensor(0.6169, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8820927143096924\n",
      "Batch: 399 , Combined Loss: tensor(0.6167, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9614372253417969\n",
      "Batch: 400 , Combined Loss: tensor(0.6507, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.132878303527832\n",
      "Batch: 401 , Combined Loss: tensor(0.6442, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2147015929222107\n",
      "Batch: 402 , Combined Loss: tensor(0.8536, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3266803026199341\n",
      "Batch: 403 , Combined Loss: tensor(0.5958, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5934698581695557\n",
      "Batch: 404 , Combined Loss: tensor(0.8381, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8571451902389526\n",
      "Batch: 405 , Combined Loss: tensor(0.5880, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0069036483764648\n",
      "Batch: 406 , Combined Loss: tensor(0.7129, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6582674980163574\n",
      "Batch: 407 , Combined Loss: tensor(0.6981, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8181343078613281\n",
      "Batch: 408 , Combined Loss: tensor(1.2069, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.783339262008667\n",
      "Batch: 409 , Combined Loss: tensor(0.5615, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30246973037719727\n",
      "Batch: 410 , Combined Loss: tensor(0.7939, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5675681829452515\n",
      "Batch: 411 , Combined Loss: tensor(0.7359, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9683160781860352\n",
      "Batch: 412 , Combined Loss: tensor(0.5915, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.967078685760498\n",
      "Batch: 413 , Combined Loss: tensor(0.6132, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9240052700042725\n",
      "Batch: 414 , Combined Loss: tensor(0.5696, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10204315185546875\n",
      "Batch: 415 , Combined Loss: tensor(0.6531, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41424083709716797\n",
      "Batch: 416 , Combined Loss: tensor(0.6417, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0900945663452148\n",
      "Batch: 417 , Combined Loss: tensor(0.6097, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8615938425064087\n",
      "Batch: 418 , Combined Loss: tensor(0.5672, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.32844454050064087\n",
      "Batch: 419 , Combined Loss: tensor(0.6376, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21969473361968994\n",
      "Batch: 420 , Combined Loss: tensor(0.6178, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7782164812088013\n",
      "Batch: 421 , Combined Loss: tensor(0.8159, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.37808966636657715\n",
      "Batch: 422 , Combined Loss: tensor(0.5916, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1717579364776611\n",
      "Batch: 423 , Combined Loss: tensor(0.7837, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7872588634490967\n",
      "Batch: 424 , Combined Loss: tensor(0.6239, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1719883680343628\n",
      "Batch: 425 , Combined Loss: tensor(0.8603, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.798151969909668\n",
      "Batch: 426 , Combined Loss: tensor(0.7661, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1246154308319092\n",
      "Batch: 427 , Combined Loss: tensor(0.5456, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8983414173126221\n",
      "Batch: 428 , Combined Loss: tensor(0.6123, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.879520058631897\n",
      "Batch: 429 , Combined Loss: tensor(0.5174, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9378641843795776\n",
      "Batch: 430 , Combined Loss: tensor(0.7598, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24254578351974487\n",
      "Batch: 431 , Combined Loss: tensor(0.6576, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0174915790557861\n",
      "Batch: 432 , Combined Loss: tensor(0.6609, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.238729476928711\n",
      "Batch: 433 , Combined Loss: tensor(0.6808, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1608119010925293\n",
      "Batch: 434 , Combined Loss: tensor(0.6429, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24411815404891968\n",
      "Batch: 435 , Combined Loss: tensor(0.5720, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8829660415649414\n",
      "Batch: 436 , Combined Loss: tensor(0.7942, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7975773811340332\n",
      "Batch: 437 , Combined Loss: tensor(0.6203, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1082329750061035\n",
      "Batch: 438 , Combined Loss: tensor(0.5637, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7274670600891113\n",
      "Batch: 439 , Combined Loss: tensor(0.7216, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0224919319152832\n",
      "Batch: 440 , Combined Loss: tensor(0.6797, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1329715251922607\n",
      "Batch: 441 , Combined Loss: tensor(0.7380, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9242285490036011\n",
      "Batch: 442 , Combined Loss: tensor(0.5979, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.423407793045044\n",
      "Batch: 443 , Combined Loss: tensor(0.9800, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4250626564025879\n",
      "Batch: 444 , Combined Loss: tensor(0.8099, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.050363540649414\n",
      "Batch: 445 , Combined Loss: tensor(0.6462, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8604826927185059\n",
      "Batch: 446 , Combined Loss: tensor(0.6196, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9454896450042725\n",
      "Batch: 447 , Combined Loss: tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8082146644592285\n",
      "Batch: 448 , Combined Loss: tensor(0.7892, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.736342191696167\n",
      "Batch: 449 , Combined Loss: tensor(0.6602, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9423999786376953\n",
      "Batch: 450 , Combined Loss: tensor(0.5475, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.075270652770996\n",
      "Batch: 451 , Combined Loss: tensor(0.6861, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1040606498718262\n",
      "Batch: 452 , Combined Loss: tensor(0.5970, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.662934422492981\n",
      "Batch: 453 , Combined Loss: tensor(0.7563, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9397211074829102\n",
      "Batch: 454 , Combined Loss: tensor(0.5907, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7230590581893921\n",
      "Batch: 455 , Combined Loss: tensor(0.6551, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0029003620147705\n",
      "Batch: 456 , Combined Loss: tensor(0.6783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1094684600830078\n",
      "Batch: 457 , Combined Loss: tensor(0.6800, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6992461681365967\n",
      "Batch: 458 , Combined Loss: tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.056335210800171\n",
      "Batch: 459 , Combined Loss: tensor(0.9037, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4564324617385864\n",
      "Batch: 460 , Combined Loss: tensor(0.7460, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0154895782470703\n",
      "Batch: 461 , Combined Loss: tensor(0.6630, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8909026384353638\n",
      "Batch: 462 , Combined Loss: tensor(0.9228, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9834353923797607\n",
      "Batch: 463 , Combined Loss: tensor(0.9542, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.617272138595581\n",
      "Batch: 464 , Combined Loss: tensor(0.6526, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9356834888458252\n",
      "Batch: 465 , Combined Loss: tensor(0.6787, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9222569465637207\n",
      "Batch: 466 , Combined Loss: tensor(0.6151, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.123384952545166\n",
      "Batch: 467 , Combined Loss: tensor(0.6687, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.042733907699585\n",
      "Batch: 468 , Combined Loss: tensor(0.6795, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6294875144958496\n",
      "Batch: 469 , Combined Loss: tensor(0.5855, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7311575412750244\n",
      "Batch: 470 , Combined Loss: tensor(0.8233, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41184496879577637\n",
      "Batch: 471 , Combined Loss: tensor(0.6047, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.020521640777588\n",
      "Batch: 472 , Combined Loss: tensor(0.6340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1055254936218262\n",
      "Batch: 473 , Combined Loss: tensor(0.6354, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9818264245986938\n",
      "Batch: 474 , Combined Loss: tensor(0.6392, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8332663774490356\n",
      "Batch: 475 , Combined Loss: tensor(0.7577, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5000025033950806\n",
      "Batch: 476 , Combined Loss: tensor(0.5863, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7660908699035645\n",
      "Batch: 477 , Combined Loss: tensor(0.7051, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22271126508712769\n",
      "Batch: 478 , Combined Loss: tensor(0.7266, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2108997106552124\n",
      "Batch: 479 , Combined Loss: tensor(0.7324, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.755631685256958\n",
      "Batch: 480 , Combined Loss: tensor(0.6025, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9758785963058472\n",
      "Batch: 481 , Combined Loss: tensor(0.7982, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17096281051635742\n",
      "Batch: 482 , Combined Loss: tensor(0.7082, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7714372873306274\n",
      "Batch: 483 , Combined Loss: tensor(0.6394, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.566329836845398\n",
      "Batch: 484 , Combined Loss: tensor(0.7851, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5353223085403442\n",
      "Batch: 485 , Combined Loss: tensor(0.6979, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7945950031280518\n",
      "Batch: 486 , Combined Loss: tensor(0.6532, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0184447765350342\n",
      "Batch: 487 , Combined Loss: tensor(0.6253, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.003303050994873047\n",
      "Batch: 488 , Combined Loss: tensor(0.7031, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14050734043121338\n",
      "Batch: 489 , Combined Loss: tensor(0.6744, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8678425550460815\n",
      "Batch: 490 , Combined Loss: tensor(0.6665, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20393985509872437\n",
      "Batch: 491 , Combined Loss: tensor(0.6331, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.727213978767395\n",
      "Batch: 492 , Combined Loss: tensor(0.6394, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7155579328536987\n",
      "Batch: 493 , Combined Loss: tensor(1.0419, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27175605297088623\n",
      "Batch: 494 , Combined Loss: tensor(0.6539, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25784575939178467\n",
      "Batch: 495 , Combined Loss: tensor(0.6457, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0163342952728271\n",
      "Batch: 496 , Combined Loss: tensor(1.1015, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8904491662979126\n",
      "Batch: 497 , Combined Loss: tensor(0.6574, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7559763193130493\n",
      "Batch: 498 , Combined Loss: tensor(0.6332, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5700277090072632\n",
      "Batch: 499 , Combined Loss: tensor(0.6616, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1409070491790771\n",
      "Batch: 500 , Combined Loss: tensor(0.6043, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9440244436264038\n",
      "Batch: 501 , Combined Loss: tensor(0.7815, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9536948204040527\n",
      "Batch: 502 , Combined Loss: tensor(0.6679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18195652961730957\n",
      "Batch: 503 , Combined Loss: tensor(0.8161, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9627190828323364\n",
      "Batch: 504 , Combined Loss: tensor(0.6031, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.096374273300171\n",
      "Batch: 505 , Combined Loss: tensor(0.6234, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5447959899902344\n",
      "Batch: 506 , Combined Loss: tensor(0.6135, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11172890663146973\n",
      "Batch: 507 , Combined Loss: tensor(0.6329, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8181660175323486\n",
      "Batch: 508 , Combined Loss: tensor(0.6975, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4637984037399292\n",
      "Batch: 509 , Combined Loss: tensor(0.8411, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37182044982910156\n",
      "Batch: 510 , Combined Loss: tensor(0.6261, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6056013107299805\n",
      "Batch: 511 , Combined Loss: tensor(0.5829, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6221233606338501\n",
      "Batch: 512 , Combined Loss: tensor(0.6961, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.780830979347229\n",
      "Batch: 513 , Combined Loss: tensor(0.6379, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5254696607589722\n",
      "Batch: 514 , Combined Loss: tensor(0.5551, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.706710934638977\n",
      "Batch: 515 , Combined Loss: tensor(0.7587, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1545262336730957\n",
      "Batch: 516 , Combined Loss: tensor(0.6980, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0858389139175415\n",
      "Batch: 517 , Combined Loss: tensor(0.6640, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26386749744415283\n",
      "Batch: 518 , Combined Loss: tensor(0.6430, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.068866491317749\n",
      "Batch: 519 , Combined Loss: tensor(0.6503, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7831707000732422\n",
      "Batch: 520 , Combined Loss: tensor(0.5539, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5020788908004761\n",
      "Batch: 521 , Combined Loss: tensor(0.6083, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9859318733215332\n",
      "Batch: 522 , Combined Loss: tensor(0.8142, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6377776861190796\n",
      "Batch: 523 , Combined Loss: tensor(0.6418, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.024370551109313965\n",
      "Batch: 524 , Combined Loss: tensor(0.5471, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9928939342498779\n",
      "Batch: 525 , Combined Loss: tensor(0.5638, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8003509044647217\n",
      "Batch: 526 , Combined Loss: tensor(0.5783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7249281406402588\n",
      "Batch: 527 , Combined Loss: tensor(0.6518, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0287716388702393\n",
      "Batch: 528 , Combined Loss: tensor(0.6805, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1228865385055542\n",
      "Batch: 529 , Combined Loss: tensor(0.6155, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37006914615631104\n",
      "Batch: 530 , Combined Loss: tensor(0.8105, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7602092027664185\n",
      "Batch: 531 , Combined Loss: tensor(0.6692, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0641000270843506\n",
      "Batch: 532 , Combined Loss: tensor(0.6895, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0093369483947754\n",
      "Batch: 533 , Combined Loss: tensor(0.7598, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03779977560043335\n",
      "Batch: 534 , Combined Loss: tensor(0.6664, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0421245098114014\n",
      "Batch: 535 , Combined Loss: tensor(0.6049, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0077435970306396\n",
      "Batch: 536 , Combined Loss: tensor(0.5965, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7141050100326538\n",
      "Batch: 537 , Combined Loss: tensor(0.8363, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3450174331665039\n",
      "Batch: 538 , Combined Loss: tensor(0.7571, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3378363847732544\n",
      "Batch: 539 , Combined Loss: tensor(0.7675, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8604936599731445\n",
      "Batch: 540 , Combined Loss: tensor(0.6236, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0136573314666748\n",
      "Batch: 541 , Combined Loss: tensor(0.8178, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19920384883880615\n",
      "Batch: 542 , Combined Loss: tensor(0.6754, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7642127275466919\n",
      "Batch: 543 , Combined Loss: tensor(0.6135, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8312156200408936\n",
      "Batch: 544 , Combined Loss: tensor(0.6357, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5386899709701538\n",
      "Batch: 545 , Combined Loss: tensor(0.6426, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49719762802124023\n",
      "Batch: 546 , Combined Loss: tensor(0.6196, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1548397541046143\n",
      "Batch: 547 , Combined Loss: tensor(0.8998, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.750495433807373\n",
      "Batch: 548 , Combined Loss: tensor(0.8777, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37485766410827637\n",
      "Batch: 549 , Combined Loss: tensor(0.6613, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8583551645278931\n",
      "Batch: 550 , Combined Loss: tensor(0.6392, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9918161630630493\n",
      "Batch: 551 , Combined Loss: tensor(0.5915, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6976591348648071\n",
      "Batch: 552 , Combined Loss: tensor(0.6221, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2015368938446045\n",
      "Batch: 553 , Combined Loss: tensor(0.6781, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9396195411682129\n",
      "Batch: 554 , Combined Loss: tensor(0.7016, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5443778038024902\n",
      "Batch: 555 , Combined Loss: tensor(0.6155, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9117257595062256\n",
      "Batch: 556 , Combined Loss: tensor(0.5676, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7688020467758179\n",
      "Batch: 557 , Combined Loss: tensor(0.9988, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6425048112869263\n",
      "Batch: 558 , Combined Loss: tensor(0.6113, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32970917224884033\n",
      "Batch: 559 , Combined Loss: tensor(0.7081, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2475331425666809\n",
      "Batch: 560 , Combined Loss: tensor(0.6267, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8711038827896118\n",
      "Batch: 561 , Combined Loss: tensor(0.8553, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6940861940383911\n",
      "Batch: 562 , Combined Loss: tensor(0.6694, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0223970413208008\n",
      "Batch: 563 , Combined Loss: tensor(0.6190, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8171422481536865\n",
      "Batch: 564 , Combined Loss: tensor(0.6824, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2582178115844727\n",
      "Batch: 565 , Combined Loss: tensor(0.6058, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9338160753250122\n",
      "Batch: 566 , Combined Loss: tensor(0.6059, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8597841262817383\n",
      "Batch: 567 , Combined Loss: tensor(0.6187, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0288927555084229\n",
      "Batch: 568 , Combined Loss: tensor(0.6114, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6653866767883301\n",
      "Batch: 569 , Combined Loss: tensor(0.9343, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.060595035552978516\n",
      "Batch: 570 , Combined Loss: tensor(0.6027, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1369574069976807\n",
      "Batch: 571 , Combined Loss: tensor(0.5820, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5565376281738281\n",
      "Batch: 572 , Combined Loss: tensor(0.6511, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8048267364501953\n",
      "Batch: 573 , Combined Loss: tensor(0.5854, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4020422697067261\n",
      "Batch: 574 , Combined Loss: tensor(0.5734, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6589207649230957\n",
      "Batch: 575 , Combined Loss: tensor(0.7786, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6977475881576538\n",
      "Batch: 576 , Combined Loss: tensor(0.7566, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27780187129974365\n",
      "Batch: 577 , Combined Loss: tensor(0.6418, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1839996576309204\n",
      "Batch: 578 , Combined Loss: tensor(0.6336, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6905041933059692\n",
      "Batch: 579 , Combined Loss: tensor(0.6830, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7913482189178467\n",
      "Batch: 580 , Combined Loss: tensor(0.5960, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6198259592056274\n",
      "Batch: 581 , Combined Loss: tensor(0.5959, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5969794988632202\n",
      "Batch: 582 , Combined Loss: tensor(0.5947, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5332961082458496\n",
      "Batch: 583 , Combined Loss: tensor(0.7684, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16900920867919922\n",
      "Batch: 584 , Combined Loss: tensor(0.6921, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.039627790451049805\n",
      "Batch: 585 , Combined Loss: tensor(0.7697, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6700727939605713\n",
      "Batch: 586 , Combined Loss: tensor(0.7074, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.755345344543457\n",
      "Batch: 587 , Combined Loss: tensor(0.7799, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9927685260772705\n",
      "Batch: 588 , Combined Loss: tensor(0.5842, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9847995042800903\n",
      "Batch: 589 , Combined Loss: tensor(0.8580, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7300091981887817\n",
      "Batch: 590 , Combined Loss: tensor(0.6530, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3800743818283081\n",
      "Batch: 591 , Combined Loss: tensor(0.6230, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38471341133117676\n",
      "Batch: 592 , Combined Loss: tensor(0.6604, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5547641515731812\n",
      "Batch: 593 , Combined Loss: tensor(0.5714, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7639714479446411\n",
      "Batch: 594 , Combined Loss: tensor(0.7863, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38913285732269287\n",
      "Batch: 595 , Combined Loss: tensor(0.6912, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8736262321472168\n",
      "Batch: 596 , Combined Loss: tensor(0.7249, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3422234058380127\n",
      "Batch: 597 , Combined Loss: tensor(0.5632, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7660350799560547\n",
      "Batch: 598 , Combined Loss: tensor(0.6318, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8765530586242676\n",
      "Batch: 599 , Combined Loss: tensor(0.6002, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8247355222702026\n",
      "Batch: 600 , Combined Loss: tensor(0.5782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9015755653381348\n",
      "Batch: 601 , Combined Loss: tensor(0.5603, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5698821544647217\n",
      "Batch: 602 , Combined Loss: tensor(0.5409, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4877849817276001\n",
      "Batch: 603 , Combined Loss: tensor(0.6032, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0420277118682861\n",
      "Batch: 604 , Combined Loss: tensor(0.6460, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9583818912506104\n",
      "Batch: 605 , Combined Loss: tensor(0.6959, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6884928941726685\n",
      "Batch: 606 , Combined Loss: tensor(0.6957, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0233778953552246\n",
      "Batch: 607 , Combined Loss: tensor(0.5840, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0841128826141357\n",
      "Batch: 608 , Combined Loss: tensor(1.2452, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5149868726730347\n",
      "Batch: 609 , Combined Loss: tensor(0.5684, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8473381996154785\n",
      "Batch: 610 , Combined Loss: tensor(0.7172, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4258601665496826\n",
      "Batch: 611 , Combined Loss: tensor(0.5609, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9336121082305908\n",
      "Batch: 612 , Combined Loss: tensor(0.7859, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8156827688217163\n",
      "Batch: 613 , Combined Loss: tensor(0.6916, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8144456148147583\n",
      "Batch: 614 , Combined Loss: tensor(0.6135, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7237335443496704\n",
      "Batch: 615 , Combined Loss: tensor(0.7037, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6865063905715942\n",
      "Batch: 616 , Combined Loss: tensor(0.5960, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0312535762786865\n",
      "Batch: 617 , Combined Loss: tensor(0.8209, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9423977136611938\n",
      "Batch: 618 , Combined Loss: tensor(0.6303, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9234992265701294\n",
      "Batch: 619 , Combined Loss: tensor(0.7782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8492544889450073\n",
      "Batch: 620 , Combined Loss: tensor(0.7216, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8451757431030273\n",
      "Batch: 621 , Combined Loss: tensor(0.6930, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6872227191925049\n",
      "Batch: 622 , Combined Loss: tensor(0.7769, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7721034288406372\n",
      "Batch: 623 , Combined Loss: tensor(0.5829, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9909231662750244\n",
      "Batch: 624 , Combined Loss: tensor(0.5679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41776561737060547\n",
      "Batch: 625 , Combined Loss: tensor(0.6230, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3187088966369629\n",
      "Batch: 626 , Combined Loss: tensor(0.6790, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15903592109680176\n",
      "Batch: 627 , Combined Loss: tensor(0.8177, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2781033515930176\n",
      "Batch: 628 , Combined Loss: tensor(0.7711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9729775190353394\n",
      "----------Epoch 20, Loss: 0.6867086008451702, Accuracy: 0.9706507563022437, Dice Coef: [0.9870119670995279, 0.5793358311802101, 0.6287446939007939, 0.7099919576251242], Dice Coef Necrotic: 1.0187681315947463, Dice Coef Edema: 1.0246662061033736, Dice Coef Enhancing: 1.0251304128789454, Sensitivity: [0.9765961836366093, 0.7545147394438109, 0.8547016754509534, 0.8641619699132083], Specificity: [0.9620957795311423, 0.9972562493315182, 0.9792271193904604, 0.9956217832709344], Precision: [0.9977556837571634, 0.5459633006619188, 0.5321673386361158, 0.6473417995339896]\n",
      "-----------Validation Epoch 20, Loss: 0.6938743881129343, Accuracy: 0.9652063649728757, Dice Coef: [0.9854075870382677, 0.5127842754330216, 0.5925386827182743, 0.6593526467142137], Dice Coef Necrotic: 0.16731724783623317, Dice Coef Edema: 0.1705772028720198, Dice Coef Enhancing: 0.17145142654785137, Sensitivity: [0.9757023557610468, 0.7546605349202221, 0.7151845941029558, 0.7297383842460059], Specificity: [0.9067863450479616, 0.9947643307370877, 0.9787200071396084, 0.9948610980576331], Precision: [0.995695734789612, 0.45592194929285884, 0.5532280644145581, 0.7066997070924952]\n",
      "Batch: 0 , Combined Loss: tensor(0.7181, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2907273769378662\n",
      "Batch: 1 , Combined Loss: tensor(0.5701, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7359949350357056\n",
      "Batch: 2 , Combined Loss: tensor(0.6840, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.231691598892212\n",
      "Batch: 3 , Combined Loss: tensor(0.6070, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6351790428161621\n",
      "Batch: 4 , Combined Loss: tensor(0.6378, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.602674126625061\n",
      "Batch: 5 , Combined Loss: tensor(0.7973, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5977745056152344\n",
      "Batch: 6 , Combined Loss: tensor(0.6145, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6530566215515137\n",
      "Batch: 7 , Combined Loss: tensor(0.6894, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6657884120941162\n",
      "Batch: 8 , Combined Loss: tensor(0.6673, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.014892339706421\n",
      "Batch: 9 , Combined Loss: tensor(0.6261, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9144978523254395\n",
      "Batch: 10 , Combined Loss: tensor(0.6981, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7047765254974365\n",
      "Batch: 11 , Combined Loss: tensor(0.7218, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0928577184677124\n",
      "Batch: 12 , Combined Loss: tensor(0.6931, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8930621147155762\n",
      "Batch: 13 , Combined Loss: tensor(0.6178, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.953794002532959\n",
      "Batch: 14 , Combined Loss: tensor(0.7261, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8850759267807007\n",
      "Batch: 15 , Combined Loss: tensor(0.6262, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9844642877578735\n",
      "Batch: 16 , Combined Loss: tensor(0.6311, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9871319532394409\n",
      "Batch: 17 , Combined Loss: tensor(0.5947, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0553908348083496\n",
      "Batch: 18 , Combined Loss: tensor(0.6559, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7663465738296509\n",
      "Batch: 19 , Combined Loss: tensor(0.7200, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2878454923629761\n",
      "Batch: 20 , Combined Loss: tensor(0.7395, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9784513711929321\n",
      "Batch: 21 , Combined Loss: tensor(0.6618, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.760261058807373\n",
      "Batch: 22 , Combined Loss: tensor(0.5619, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6289321184158325\n",
      "Batch: 23 , Combined Loss: tensor(0.6720, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1461622714996338\n",
      "Batch: 24 , Combined Loss: tensor(0.7790, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6808137893676758\n",
      "Batch: 25 , Combined Loss: tensor(0.7288, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.74639892578125\n",
      "Batch: 26 , Combined Loss: tensor(0.7413, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0566067695617676\n",
      "Batch: 27 , Combined Loss: tensor(0.5802, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9181149005889893\n",
      "Batch: 28 , Combined Loss: tensor(0.6547, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7678968906402588\n",
      "Batch: 29 , Combined Loss: tensor(0.6538, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3600383996963501\n",
      "Batch: 30 , Combined Loss: tensor(0.7196, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1114535331726074\n",
      "Batch: 31 , Combined Loss: tensor(0.6488, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9854811429977417\n",
      "Batch: 32 , Combined Loss: tensor(0.5968, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.862136960029602\n",
      "Batch: 33 , Combined Loss: tensor(0.6327, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45539844036102295\n",
      "Batch: 34 , Combined Loss: tensor(0.6155, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5539275407791138\n",
      "Batch: 35 , Combined Loss: tensor(0.8150, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10020256042480469\n",
      "Batch: 36 , Combined Loss: tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0084378719329834\n",
      "Batch: 37 , Combined Loss: tensor(0.6468, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9774291515350342\n",
      "Batch: 38 , Combined Loss: tensor(0.6624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6529066562652588\n",
      "Batch: 39 , Combined Loss: tensor(0.6788, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7844406366348267\n",
      "Batch: 40 , Combined Loss: tensor(0.8030, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8083292245864868\n",
      "Batch: 41 , Combined Loss: tensor(0.6764, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0394599437713623\n",
      "Batch: 42 , Combined Loss: tensor(0.7734, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2003002166748047\n",
      "Batch: 43 , Combined Loss: tensor(0.6246, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8134467601776123\n",
      "Batch: 44 , Combined Loss: tensor(0.7650, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8428797721862793\n",
      "Batch: 45 , Combined Loss: tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.743611216545105\n",
      "Batch: 46 , Combined Loss: tensor(0.7257, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7944926023483276\n",
      "Batch: 47 , Combined Loss: tensor(0.7221, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8873260021209717\n",
      "Batch: 48 , Combined Loss: tensor(0.5399, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5022971630096436\n",
      "Batch: 49 , Combined Loss: tensor(0.8825, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8083372116088867\n",
      "Batch: 50 , Combined Loss: tensor(0.6346, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9215283393859863\n",
      "Batch: 51 , Combined Loss: tensor(0.6521, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9789886474609375\n",
      "Batch: 52 , Combined Loss: tensor(0.7038, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6220777034759521\n",
      "Batch: 53 , Combined Loss: tensor(0.6656, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0847489833831787\n",
      "Batch: 54 , Combined Loss: tensor(0.5980, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8785070180892944\n",
      "Batch: 55 , Combined Loss: tensor(0.5624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.788942813873291\n",
      "Batch: 56 , Combined Loss: tensor(0.8164, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5066447257995605\n",
      "Batch: 57 , Combined Loss: tensor(0.7431, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9132543802261353\n",
      "Batch: 58 , Combined Loss: tensor(0.6402, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7543213367462158\n",
      "Batch: 59 , Combined Loss: tensor(0.8976, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8603146076202393\n",
      "Batch: 60 , Combined Loss: tensor(0.6863, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0220510959625244\n",
      "Batch: 61 , Combined Loss: tensor(0.6774, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1049892902374268\n",
      "Batch: 62 , Combined Loss: tensor(0.7547, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0874111652374268\n",
      "Batch: 63 , Combined Loss: tensor(0.6094, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7765295505523682\n",
      "Batch: 64 , Combined Loss: tensor(0.6094, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8648737668991089\n",
      "Batch: 65 , Combined Loss: tensor(0.6094, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.993625283241272\n",
      "Batch: 66 , Combined Loss: tensor(0.6012, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8471643924713135\n",
      "Batch: 67 , Combined Loss: tensor(0.6349, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.892970085144043\n",
      "Batch: 68 , Combined Loss: tensor(0.6564, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1970844268798828\n",
      "Batch: 69 , Combined Loss: tensor(0.6660, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3924264907836914\n",
      "Batch: 70 , Combined Loss: tensor(0.6196, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5497453212738037\n",
      "Batch: 71 , Combined Loss: tensor(0.7084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44267499446868896\n",
      "Batch: 72 , Combined Loss: tensor(0.6891, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3782612085342407\n",
      "Batch: 73 , Combined Loss: tensor(0.6528, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7728646993637085\n",
      "Batch: 74 , Combined Loss: tensor(0.6892, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6598011255264282\n",
      "Batch: 75 , Combined Loss: tensor(0.5915, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7537364959716797\n",
      "Batch: 76 , Combined Loss: tensor(0.5596, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8968460559844971\n",
      "Batch: 77 , Combined Loss: tensor(0.7493, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9355628490447998\n",
      "Batch: 78 , Combined Loss: tensor(0.6938, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8477137088775635\n",
      "Batch: 79 , Combined Loss: tensor(0.7101, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9442734718322754\n",
      "Batch: 80 , Combined Loss: tensor(0.7555, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5029746294021606\n",
      "Batch: 81 , Combined Loss: tensor(0.7461, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35880017280578613\n",
      "Batch: 82 , Combined Loss: tensor(0.5667, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8169138431549072\n",
      "Batch: 83 , Combined Loss: tensor(0.5704, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9142472743988037\n",
      "Batch: 84 , Combined Loss: tensor(0.5537, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8930177688598633\n",
      "Batch: 85 , Combined Loss: tensor(0.8171, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8774785995483398\n",
      "Batch: 86 , Combined Loss: tensor(0.6663, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9036691188812256\n",
      "Batch: 87 , Combined Loss: tensor(0.6357, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.16640985012054443\n",
      "Batch: 88 , Combined Loss: tensor(0.6257, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4620105028152466\n",
      "Batch: 89 , Combined Loss: tensor(0.5847, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9754428863525391\n",
      "Batch: 90 , Combined Loss: tensor(0.6470, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6789059638977051\n",
      "Batch: 91 , Combined Loss: tensor(1.1601, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6313374042510986\n",
      "Batch: 92 , Combined Loss: tensor(0.6360, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9391077756881714\n",
      "Batch: 93 , Combined Loss: tensor(0.6240, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9428761005401611\n",
      "Batch: 94 , Combined Loss: tensor(0.6012, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1425118446350098\n",
      "Batch: 95 , Combined Loss: tensor(0.6920, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7702231407165527\n",
      "Batch: 96 , Combined Loss: tensor(0.5158, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.811010479927063\n",
      "Batch: 97 , Combined Loss: tensor(0.6448, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8060866594314575\n",
      "Batch: 98 , Combined Loss: tensor(0.5747, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.023238182067871\n",
      "Batch: 99 , Combined Loss: tensor(0.6002, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.041212558746338\n",
      "Batch: 100 , Combined Loss: tensor(0.6897, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8402242660522461\n",
      "Batch: 101 , Combined Loss: tensor(0.8011, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.040341854095459\n",
      "Batch: 102 , Combined Loss: tensor(0.6702, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6023998260498047\n",
      "Batch: 103 , Combined Loss: tensor(0.6735, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07541656494140625\n",
      "Batch: 104 , Combined Loss: tensor(0.7043, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0458917617797852\n",
      "Batch: 105 , Combined Loss: tensor(0.7378, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.591364860534668\n",
      "Batch: 106 , Combined Loss: tensor(0.6466, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8288701772689819\n",
      "Batch: 107 , Combined Loss: tensor(0.6671, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.031562089920044\n",
      "Batch: 108 , Combined Loss: tensor(0.9460, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.441705584526062\n",
      "Batch: 109 , Combined Loss: tensor(0.6148, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8482537269592285\n",
      "Batch: 110 , Combined Loss: tensor(1.0148, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8632959127426147\n",
      "Batch: 111 , Combined Loss: tensor(0.6182, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0942542552947998\n",
      "Batch: 112 , Combined Loss: tensor(0.7814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1525464057922363\n",
      "Batch: 113 , Combined Loss: tensor(0.6334, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9394464492797852\n",
      "Batch: 114 , Combined Loss: tensor(0.5347, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9368467330932617\n",
      "Batch: 115 , Combined Loss: tensor(0.6605, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0677204132080078\n",
      "Batch: 116 , Combined Loss: tensor(0.5747, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2021028995513916\n",
      "Batch: 117 , Combined Loss: tensor(0.6424, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1191532611846924\n",
      "Batch: 118 , Combined Loss: tensor(0.6101, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.023038625717163\n",
      "Batch: 119 , Combined Loss: tensor(0.9890, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0102107524871826\n",
      "Batch: 120 , Combined Loss: tensor(0.8416, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6173392534255981\n",
      "Batch: 121 , Combined Loss: tensor(0.5960, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1180922985076904\n",
      "Batch: 122 , Combined Loss: tensor(0.5579, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9550250768661499\n",
      "Batch: 123 , Combined Loss: tensor(0.6917, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9746816158294678\n",
      "Batch: 124 , Combined Loss: tensor(0.6531, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8378310203552246\n",
      "Batch: 125 , Combined Loss: tensor(0.6059, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0869290828704834\n",
      "Batch: 126 , Combined Loss: tensor(0.8743, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14315974712371826\n",
      "Batch: 127 , Combined Loss: tensor(0.6024, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.01804828643798828\n",
      "Batch: 128 , Combined Loss: tensor(0.5983, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0052759647369385\n",
      "Batch: 129 , Combined Loss: tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9522123336791992\n",
      "Batch: 130 , Combined Loss: tensor(0.5860, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7183942794799805\n",
      "Batch: 131 , Combined Loss: tensor(0.5925, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5266761779785156\n",
      "Batch: 132 , Combined Loss: tensor(0.6375, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7572041749954224\n",
      "Batch: 133 , Combined Loss: tensor(0.5612, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9740684032440186\n",
      "Batch: 134 , Combined Loss: tensor(0.8088, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6386624574661255\n",
      "Batch: 135 , Combined Loss: tensor(0.7098, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0613470077514648\n",
      "Batch: 136 , Combined Loss: tensor(0.5989, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8751578330993652\n",
      "Batch: 137 , Combined Loss: tensor(0.7971, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7259719371795654\n",
      "Batch: 138 , Combined Loss: tensor(0.5817, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0002615451812744\n",
      "Batch: 139 , Combined Loss: tensor(0.7382, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6256364583969116\n",
      "Batch: 140 , Combined Loss: tensor(0.6856, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8481540679931641\n",
      "Batch: 141 , Combined Loss: tensor(0.5944, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9796404838562012\n",
      "Batch: 142 , Combined Loss: tensor(0.7844, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9785850048065186\n",
      "Batch: 143 , Combined Loss: tensor(0.8026, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5840940475463867\n",
      "Batch: 144 , Combined Loss: tensor(0.6613, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5729662179946899\n",
      "Batch: 145 , Combined Loss: tensor(0.5553, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8386780023574829\n",
      "Batch: 146 , Combined Loss: tensor(0.5601, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6318671703338623\n",
      "Batch: 147 , Combined Loss: tensor(0.7627, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9778234958648682\n",
      "Batch: 148 , Combined Loss: tensor(0.6542, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2684328556060791\n",
      "Batch: 149 , Combined Loss: tensor(0.6562, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7611240148544312\n",
      "Batch: 150 , Combined Loss: tensor(0.7026, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8145432472229004\n",
      "Batch: 151 , Combined Loss: tensor(0.6053, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6999619007110596\n",
      "Batch: 152 , Combined Loss: tensor(0.6274, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9526644945144653\n",
      "Batch: 153 , Combined Loss: tensor(0.6563, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9151413440704346\n",
      "Batch: 154 , Combined Loss: tensor(0.6661, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8550170660018921\n",
      "Batch: 155 , Combined Loss: tensor(0.7419, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3336644172668457\n",
      "Batch: 156 , Combined Loss: tensor(0.6145, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.587511420249939\n",
      "Batch: 157 , Combined Loss: tensor(0.6313, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5420998334884644\n",
      "Batch: 158 , Combined Loss: tensor(0.6421, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06363838911056519\n",
      "Batch: 159 , Combined Loss: tensor(0.5930, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8074355125427246\n",
      "Batch: 160 , Combined Loss: tensor(0.6689, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.038356065750122\n",
      "Batch: 161 , Combined Loss: tensor(0.6289, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0286915302276611\n",
      "Batch: 162 , Combined Loss: tensor(0.5480, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13022327423095703\n",
      "Batch: 163 , Combined Loss: tensor(0.7242, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9064072370529175\n",
      "Batch: 164 , Combined Loss: tensor(0.6565, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8981038331985474\n",
      "Batch: 165 , Combined Loss: tensor(0.6711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.60219407081604\n",
      "Batch: 166 , Combined Loss: tensor(0.7655, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5873656272888184\n",
      "Batch: 167 , Combined Loss: tensor(0.7608, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.651846170425415\n",
      "Batch: 168 , Combined Loss: tensor(0.6239, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.26278167963027954\n",
      "Batch: 169 , Combined Loss: tensor(1.0151, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16397106647491455\n",
      "Batch: 170 , Combined Loss: tensor(0.6602, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9934524297714233\n",
      "Batch: 171 , Combined Loss: tensor(0.7551, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7526601552963257\n",
      "Batch: 172 , Combined Loss: tensor(0.6531, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20251715183258057\n",
      "Batch: 173 , Combined Loss: tensor(0.6013, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18896687030792236\n",
      "Batch: 174 , Combined Loss: tensor(0.6137, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.924197793006897\n",
      "Batch: 175 , Combined Loss: tensor(0.7037, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12636888027191162\n",
      "Batch: 176 , Combined Loss: tensor(0.7308, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3611499071121216\n",
      "Batch: 177 , Combined Loss: tensor(0.5973, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8252279758453369\n",
      "Batch: 178 , Combined Loss: tensor(0.6574, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7927210330963135\n",
      "Batch: 179 , Combined Loss: tensor(0.6837, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7706171274185181\n",
      "Batch: 180 , Combined Loss: tensor(0.7385, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5105499029159546\n",
      "Batch: 181 , Combined Loss: tensor(0.6899, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9485436677932739\n",
      "Batch: 182 , Combined Loss: tensor(0.7286, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5989392995834351\n",
      "Batch: 183 , Combined Loss: tensor(0.8712, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9739103317260742\n",
      "Batch: 184 , Combined Loss: tensor(0.7382, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24616765975952148\n",
      "Batch: 185 , Combined Loss: tensor(0.5618, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5824872255325317\n",
      "Batch: 186 , Combined Loss: tensor(0.9738, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4032391309738159\n",
      "Batch: 187 , Combined Loss: tensor(0.7343, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23197269439697266\n",
      "Batch: 188 , Combined Loss: tensor(0.6086, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0331623554229736\n",
      "Batch: 189 , Combined Loss: tensor(0.6839, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05164027214050293\n",
      "Batch: 190 , Combined Loss: tensor(0.8048, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5719293355941772\n",
      "Batch: 191 , Combined Loss: tensor(0.5721, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7418423891067505\n",
      "Batch: 192 , Combined Loss: tensor(0.7223, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26626718044281006\n",
      "Batch: 193 , Combined Loss: tensor(0.7495, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30245018005371094\n",
      "Batch: 194 , Combined Loss: tensor(0.6746, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2878246307373047\n",
      "Batch: 195 , Combined Loss: tensor(0.7260, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8995795249938965\n",
      "Batch: 196 , Combined Loss: tensor(0.7508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2245333194732666\n",
      "Batch: 197 , Combined Loss: tensor(0.6010, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5431076288223267\n",
      "Batch: 198 , Combined Loss: tensor(0.7514, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44735193252563477\n",
      "Batch: 199 , Combined Loss: tensor(0.6522, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.622424840927124\n",
      "Batch: 200 , Combined Loss: tensor(0.7984, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0184192657470703\n",
      "Batch: 201 , Combined Loss: tensor(0.6276, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9998335838317871\n",
      "Batch: 202 , Combined Loss: tensor(0.6420, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41840624809265137\n",
      "Batch: 203 , Combined Loss: tensor(0.6572, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8223131895065308\n",
      "Batch: 204 , Combined Loss: tensor(0.6838, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9852938652038574\n",
      "Batch: 205 , Combined Loss: tensor(0.9681, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.049957990646362305\n",
      "Batch: 206 , Combined Loss: tensor(0.6188, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7416616678237915\n",
      "Batch: 207 , Combined Loss: tensor(0.6295, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9495836496353149\n",
      "Batch: 208 , Combined Loss: tensor(0.8209, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0523476600646973\n",
      "Batch: 209 , Combined Loss: tensor(0.6895, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2785235643386841\n",
      "Batch: 210 , Combined Loss: tensor(0.6442, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8292617797851562\n",
      "Batch: 211 , Combined Loss: tensor(0.7691, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10754978656768799\n",
      "Batch: 212 , Combined Loss: tensor(0.6672, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.733772873878479\n",
      "Batch: 213 , Combined Loss: tensor(0.6305, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06018662452697754\n",
      "Batch: 214 , Combined Loss: tensor(0.6455, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32465696334838867\n",
      "Batch: 215 , Combined Loss: tensor(0.7764, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22734194993972778\n",
      "Batch: 216 , Combined Loss: tensor(0.5967, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2716646194458008\n",
      "Batch: 217 , Combined Loss: tensor(0.6570, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6506295204162598\n",
      "Batch: 218 , Combined Loss: tensor(0.6849, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9926656484603882\n",
      "Batch: 219 , Combined Loss: tensor(0.8423, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7455916404724121\n",
      "Batch: 220 , Combined Loss: tensor(0.7020, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8602043390274048\n",
      "Batch: 221 , Combined Loss: tensor(0.6430, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.13598424196243286\n",
      "Batch: 222 , Combined Loss: tensor(0.5700, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0142889022827148\n",
      "Batch: 223 , Combined Loss: tensor(0.7993, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22512710094451904\n",
      "Batch: 224 , Combined Loss: tensor(0.9700, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6752786636352539\n",
      "Batch: 225 , Combined Loss: tensor(0.7101, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.045737266540527344\n",
      "Batch: 226 , Combined Loss: tensor(0.6093, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9833327531814575\n",
      "Batch: 227 , Combined Loss: tensor(0.6929, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1298408508300781\n",
      "Batch: 228 , Combined Loss: tensor(0.6107, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1181423664093018\n",
      "Batch: 229 , Combined Loss: tensor(0.7035, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23966717720031738\n",
      "Batch: 230 , Combined Loss: tensor(0.6998, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7781710624694824\n",
      "Batch: 231 , Combined Loss: tensor(0.6195, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9226813316345215\n",
      "Batch: 232 , Combined Loss: tensor(0.6576, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9361813068389893\n",
      "Batch: 233 , Combined Loss: tensor(0.5742, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9563122987747192\n",
      "Batch: 234 , Combined Loss: tensor(0.5891, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.160782814025879\n",
      "Batch: 235 , Combined Loss: tensor(0.7289, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9736604690551758\n",
      "Batch: 236 , Combined Loss: tensor(0.8116, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7386636734008789\n",
      "Batch: 237 , Combined Loss: tensor(0.6065, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16871428489685059\n",
      "Batch: 238 , Combined Loss: tensor(0.5942, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8213179111480713\n",
      "Batch: 239 , Combined Loss: tensor(0.6513, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7473114728927612\n",
      "Batch: 240 , Combined Loss: tensor(0.6089, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.486275315284729\n",
      "Batch: 241 , Combined Loss: tensor(0.5552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9413998126983643\n",
      "Batch: 242 , Combined Loss: tensor(0.6553, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9263315200805664\n",
      "Batch: 243 , Combined Loss: tensor(0.5472, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8292415142059326\n",
      "Batch: 244 , Combined Loss: tensor(0.7400, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3284362554550171\n",
      "Batch: 245 , Combined Loss: tensor(0.6825, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19620680809020996\n",
      "Batch: 246 , Combined Loss: tensor(0.6776, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23249447345733643\n",
      "Batch: 247 , Combined Loss: tensor(0.6590, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9622480869293213\n",
      "Batch: 248 , Combined Loss: tensor(0.8376, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8117344379425049\n",
      "Batch: 249 , Combined Loss: tensor(0.8074, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5669684410095215\n",
      "Batch: 250 , Combined Loss: tensor(0.7811, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4853239059448242\n",
      "Batch: 251 , Combined Loss: tensor(0.6487, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7192039489746094\n",
      "Batch: 252 , Combined Loss: tensor(0.7021, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8356690406799316\n",
      "Batch: 253 , Combined Loss: tensor(0.6456, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.761043906211853\n",
      "Batch: 254 , Combined Loss: tensor(0.5405, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3519498109817505\n",
      "Batch: 255 , Combined Loss: tensor(0.8629, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7147132158279419\n",
      "Batch: 256 , Combined Loss: tensor(0.6804, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.856623649597168\n",
      "Batch: 257 , Combined Loss: tensor(0.6514, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9577889442443848\n",
      "Batch: 258 , Combined Loss: tensor(0.7944, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.42852336168289185\n",
      "Batch: 259 , Combined Loss: tensor(0.6272, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.782717227935791\n",
      "Batch: 260 , Combined Loss: tensor(0.8468, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21594566106796265\n",
      "Batch: 261 , Combined Loss: tensor(0.6071, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7272583246231079\n",
      "Batch: 262 , Combined Loss: tensor(0.5922, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1657339334487915\n",
      "Batch: 263 , Combined Loss: tensor(0.7402, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7302138805389404\n",
      "Batch: 264 , Combined Loss: tensor(0.5863, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4821138381958008\n",
      "Batch: 265 , Combined Loss: tensor(0.6572, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33745598793029785\n",
      "Batch: 266 , Combined Loss: tensor(0.7052, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14786499738693237\n",
      "Batch: 267 , Combined Loss: tensor(0.6738, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9532133340835571\n",
      "Batch: 268 , Combined Loss: tensor(0.7045, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6840088367462158\n",
      "Batch: 269 , Combined Loss: tensor(0.7379, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1705694198608398\n",
      "Batch: 270 , Combined Loss: tensor(0.7253, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9873749017715454\n",
      "Batch: 271 , Combined Loss: tensor(0.5594, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0926952362060547\n",
      "Batch: 272 , Combined Loss: tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5130536556243896\n",
      "Batch: 273 , Combined Loss: tensor(0.7312, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9757494926452637\n",
      "Batch: 274 , Combined Loss: tensor(0.7828, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9446488618850708\n",
      "Batch: 275 , Combined Loss: tensor(0.6812, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1640052795410156\n",
      "Batch: 276 , Combined Loss: tensor(0.6513, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7019370794296265\n",
      "Batch: 277 , Combined Loss: tensor(0.6516, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9723984003067017\n",
      "Batch: 278 , Combined Loss: tensor(0.5962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.468738317489624\n",
      "Batch: 279 , Combined Loss: tensor(0.8499, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24982142448425293\n",
      "Batch: 280 , Combined Loss: tensor(0.6326, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8679876327514648\n",
      "Batch: 281 , Combined Loss: tensor(0.6208, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0722424983978271\n",
      "Batch: 282 , Combined Loss: tensor(0.6362, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6194180250167847\n",
      "Batch: 283 , Combined Loss: tensor(0.8539, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8062883615493774\n",
      "Batch: 284 , Combined Loss: tensor(0.7497, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9280085563659668\n",
      "Batch: 285 , Combined Loss: tensor(0.6591, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.008652567863464355\n",
      "Batch: 286 , Combined Loss: tensor(0.7900, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7277884483337402\n",
      "Batch: 287 , Combined Loss: tensor(0.5765, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8253970146179199\n",
      "Batch: 288 , Combined Loss: tensor(0.6549, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8895634412765503\n",
      "Batch: 289 , Combined Loss: tensor(0.5770, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8826305866241455\n",
      "Batch: 290 , Combined Loss: tensor(0.6053, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6797789335250854\n",
      "Batch: 291 , Combined Loss: tensor(0.7275, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2187591791152954\n",
      "Batch: 292 , Combined Loss: tensor(1.3999, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4882427453994751\n",
      "Batch: 293 , Combined Loss: tensor(0.6788, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.938522458076477\n",
      "Batch: 294 , Combined Loss: tensor(0.6289, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8720781803131104\n",
      "Batch: 295 , Combined Loss: tensor(0.8506, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17806792259216309\n",
      "Batch: 296 , Combined Loss: tensor(0.5659, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.907792329788208\n",
      "Batch: 297 , Combined Loss: tensor(0.6218, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4435298442840576\n",
      "Batch: 298 , Combined Loss: tensor(0.6376, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9932527542114258\n",
      "Batch: 299 , Combined Loss: tensor(0.8126, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4484255313873291\n",
      "Batch: 300 , Combined Loss: tensor(0.5858, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7614611387252808\n",
      "Batch: 301 , Combined Loss: tensor(0.7587, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44344472885131836\n",
      "Batch: 302 , Combined Loss: tensor(0.6596, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9362773895263672\n",
      "Batch: 303 , Combined Loss: tensor(0.5936, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8441370725631714\n",
      "Batch: 304 , Combined Loss: tensor(0.6265, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9493509531021118\n",
      "Batch: 305 , Combined Loss: tensor(0.7566, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8041249513626099\n",
      "Batch: 306 , Combined Loss: tensor(0.6921, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8733642101287842\n",
      "Batch: 307 , Combined Loss: tensor(0.5943, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8676043748855591\n",
      "Batch: 308 , Combined Loss: tensor(0.5757, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7148714065551758\n",
      "Batch: 309 , Combined Loss: tensor(0.6108, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5765568017959595\n",
      "Batch: 310 , Combined Loss: tensor(0.8623, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6509959697723389\n",
      "Batch: 311 , Combined Loss: tensor(0.8184, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24198061227798462\n",
      "Batch: 312 , Combined Loss: tensor(0.5792, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6084662675857544\n",
      "Batch: 313 , Combined Loss: tensor(0.5866, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0312495231628418\n",
      "Batch: 314 , Combined Loss: tensor(0.5477, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8162379264831543\n",
      "Batch: 315 , Combined Loss: tensor(0.6999, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07924038171768188\n",
      "Batch: 316 , Combined Loss: tensor(0.7520, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8613805770874023\n",
      "Batch: 317 , Combined Loss: tensor(0.6528, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0819246768951416\n",
      "Batch: 318 , Combined Loss: tensor(0.6374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1017825603485107\n",
      "Batch: 319 , Combined Loss: tensor(0.6023, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0225303173065186\n",
      "Batch: 320 , Combined Loss: tensor(1.0389, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6076416969299316\n",
      "Batch: 321 , Combined Loss: tensor(0.6923, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8428747653961182\n",
      "Batch: 322 , Combined Loss: tensor(0.6389, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9726264476776123\n",
      "Batch: 323 , Combined Loss: tensor(0.5998, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4480612277984619\n",
      "Batch: 324 , Combined Loss: tensor(0.5982, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9216407537460327\n",
      "Batch: 325 , Combined Loss: tensor(0.5613, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7891054153442383\n",
      "Batch: 326 , Combined Loss: tensor(0.7633, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23971402645111084\n",
      "Batch: 327 , Combined Loss: tensor(0.6059, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7857522964477539\n",
      "Batch: 328 , Combined Loss: tensor(0.7358, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8589129447937012\n",
      "Batch: 329 , Combined Loss: tensor(0.8033, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7528367042541504\n",
      "Batch: 330 , Combined Loss: tensor(0.6796, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41851818561553955\n",
      "Batch: 331 , Combined Loss: tensor(0.6437, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.977739691734314\n",
      "Batch: 332 , Combined Loss: tensor(0.5584, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5156196355819702\n",
      "Batch: 333 , Combined Loss: tensor(0.6184, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7002663612365723\n",
      "Batch: 334 , Combined Loss: tensor(0.6202, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46840131282806396\n",
      "Batch: 335 , Combined Loss: tensor(0.6551, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7563599348068237\n",
      "Batch: 336 , Combined Loss: tensor(0.7985, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9481042623519897\n",
      "Batch: 337 , Combined Loss: tensor(0.6207, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6075172424316406\n",
      "Batch: 338 , Combined Loss: tensor(0.5869, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9143329858779907\n",
      "Batch: 339 , Combined Loss: tensor(0.6459, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5561954975128174\n",
      "Batch: 340 , Combined Loss: tensor(0.7246, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.989897608757019\n",
      "Batch: 341 , Combined Loss: tensor(0.6877, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47434771060943604\n",
      "Batch: 342 , Combined Loss: tensor(0.6680, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1475299596786499\n",
      "Batch: 343 , Combined Loss: tensor(0.7618, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9661399126052856\n",
      "Batch: 344 , Combined Loss: tensor(0.7694, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.690049409866333\n",
      "Batch: 345 , Combined Loss: tensor(0.7354, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.796159029006958\n",
      "Batch: 346 , Combined Loss: tensor(0.6739, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0878503322601318\n",
      "Batch: 347 , Combined Loss: tensor(0.7239, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5286940336227417\n",
      "Batch: 348 , Combined Loss: tensor(0.6029, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25463342666625977\n",
      "Batch: 349 , Combined Loss: tensor(0.7354, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8229622840881348\n",
      "Batch: 350 , Combined Loss: tensor(0.6328, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9694894552230835\n",
      "Batch: 351 , Combined Loss: tensor(0.6633, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0417578220367432\n",
      "Batch: 352 , Combined Loss: tensor(0.7901, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4824904203414917\n",
      "Batch: 353 , Combined Loss: tensor(0.6733, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7343093156814575\n",
      "Batch: 354 , Combined Loss: tensor(0.6551, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7493079900741577\n",
      "Batch: 355 , Combined Loss: tensor(0.7030, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5113755464553833\n",
      "Batch: 356 , Combined Loss: tensor(0.8228, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6415992975234985\n",
      "Batch: 357 , Combined Loss: tensor(0.8374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8712966442108154\n",
      "Batch: 358 , Combined Loss: tensor(0.6077, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9637761116027832\n",
      "Batch: 359 , Combined Loss: tensor(0.7081, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0686259269714355\n",
      "Batch: 360 , Combined Loss: tensor(0.7336, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8861892223358154\n",
      "Batch: 361 , Combined Loss: tensor(0.8105, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18888092041015625\n",
      "Batch: 362 , Combined Loss: tensor(0.6946, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9678459167480469\n",
      "Batch: 363 , Combined Loss: tensor(0.6376, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3568599224090576\n",
      "Batch: 364 , Combined Loss: tensor(0.5882, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9644167423248291\n",
      "Batch: 365 , Combined Loss: tensor(0.6683, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0629849433898926\n",
      "Batch: 366 , Combined Loss: tensor(0.7183, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6251398324966431\n",
      "Batch: 367 , Combined Loss: tensor(0.7343, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5630066394805908\n",
      "Batch: 368 , Combined Loss: tensor(0.7621, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.870663046836853\n",
      "Batch: 369 , Combined Loss: tensor(0.6339, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0978634357452393\n",
      "Batch: 370 , Combined Loss: tensor(0.6308, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30320143699645996\n",
      "Batch: 371 , Combined Loss: tensor(0.7464, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9878451824188232\n",
      "Batch: 372 , Combined Loss: tensor(0.6110, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8433997631072998\n",
      "Batch: 373 , Combined Loss: tensor(0.7657, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.022710442543029785\n",
      "Batch: 374 , Combined Loss: tensor(0.6360, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.819168210029602\n",
      "Batch: 375 , Combined Loss: tensor(0.7063, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.999019980430603\n",
      "Batch: 376 , Combined Loss: tensor(0.8255, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.894160270690918\n",
      "Batch: 377 , Combined Loss: tensor(0.8029, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.030545055866241455\n",
      "Batch: 378 , Combined Loss: tensor(0.6382, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.223625898361206\n",
      "Batch: 379 , Combined Loss: tensor(0.5860, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6510319709777832\n",
      "Batch: 380 , Combined Loss: tensor(0.6716, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8682757616043091\n",
      "Batch: 381 , Combined Loss: tensor(0.6216, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4928184747695923\n",
      "Batch: 382 , Combined Loss: tensor(0.7202, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8821448087692261\n",
      "Batch: 383 , Combined Loss: tensor(0.6510, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7710859775543213\n",
      "Batch: 384 , Combined Loss: tensor(0.6376, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.085197925567627\n",
      "Batch: 385 , Combined Loss: tensor(0.6615, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.02301943302154541\n",
      "Batch: 386 , Combined Loss: tensor(0.6409, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1776623725891113\n",
      "Batch: 387 , Combined Loss: tensor(0.6979, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.012519121170044\n",
      "Batch: 388 , Combined Loss: tensor(0.5847, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.585201621055603\n",
      "Batch: 389 , Combined Loss: tensor(0.5635, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8633202314376831\n",
      "Batch: 390 , Combined Loss: tensor(0.6814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06238037347793579\n",
      "Batch: 391 , Combined Loss: tensor(0.6032, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9807556867599487\n",
      "Batch: 392 , Combined Loss: tensor(0.5752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8763129711151123\n",
      "Batch: 393 , Combined Loss: tensor(0.5872, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9777927398681641\n",
      "Batch: 394 , Combined Loss: tensor(0.8264, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9771935939788818\n",
      "Batch: 395 , Combined Loss: tensor(0.7237, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8693943023681641\n",
      "Batch: 396 , Combined Loss: tensor(0.6711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9535244703292847\n",
      "Batch: 397 , Combined Loss: tensor(0.6045, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9284007549285889\n",
      "Batch: 398 , Combined Loss: tensor(0.7392, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9358223676681519\n",
      "Batch: 399 , Combined Loss: tensor(0.7655, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8804268836975098\n",
      "Batch: 400 , Combined Loss: tensor(0.6701, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9967942237854004\n",
      "Batch: 401 , Combined Loss: tensor(0.6917, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9290868043899536\n",
      "Batch: 402 , Combined Loss: tensor(1.0254, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0148117542266846\n",
      "Batch: 403 , Combined Loss: tensor(0.5973, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1359832286834717\n",
      "Batch: 404 , Combined Loss: tensor(0.5863, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.007953405380249023\n",
      "Batch: 405 , Combined Loss: tensor(0.6255, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9037522077560425\n",
      "Batch: 406 , Combined Loss: tensor(0.7990, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.809074878692627\n",
      "Batch: 407 , Combined Loss: tensor(0.6056, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9330296516418457\n",
      "Batch: 408 , Combined Loss: tensor(0.5511, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6995409727096558\n",
      "Batch: 409 , Combined Loss: tensor(0.5951, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.888588547706604\n",
      "Batch: 410 , Combined Loss: tensor(0.7200, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1126549243927002\n",
      "Batch: 411 , Combined Loss: tensor(1.4207, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8370800018310547\n",
      "Batch: 412 , Combined Loss: tensor(0.7417, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14009177684783936\n",
      "Batch: 413 , Combined Loss: tensor(1.0155, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7799127101898193\n",
      "Batch: 414 , Combined Loss: tensor(0.5669, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0908410549163818\n",
      "Batch: 415 , Combined Loss: tensor(0.8404, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8749841451644897\n",
      "Batch: 416 , Combined Loss: tensor(0.7436, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0453627109527588\n",
      "Batch: 417 , Combined Loss: tensor(0.7669, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9478698968887329\n",
      "Batch: 418 , Combined Loss: tensor(0.6540, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9488414525985718\n",
      "Batch: 419 , Combined Loss: tensor(0.7797, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41924798488616943\n",
      "Batch: 420 , Combined Loss: tensor(0.5946, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4160844087600708\n",
      "Batch: 421 , Combined Loss: tensor(1.0751, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39407455921173096\n",
      "Batch: 422 , Combined Loss: tensor(0.6916, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1085548400878906\n",
      "Batch: 423 , Combined Loss: tensor(0.9366, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2766590118408203\n",
      "Batch: 424 , Combined Loss: tensor(0.7880, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9455372095108032\n",
      "Batch: 425 , Combined Loss: tensor(0.7847, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0078027248382568\n",
      "Batch: 426 , Combined Loss: tensor(0.5555, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6986005306243896\n",
      "Batch: 427 , Combined Loss: tensor(0.6087, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7113965749740601\n",
      "Batch: 428 , Combined Loss: tensor(0.6407, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.006584882736206\n",
      "Batch: 429 , Combined Loss: tensor(0.7660, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6705617904663086\n",
      "Batch: 430 , Combined Loss: tensor(0.7451, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1007554531097412\n",
      "Batch: 431 , Combined Loss: tensor(0.8251, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36052966117858887\n",
      "Batch: 432 , Combined Loss: tensor(0.5843, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0856668949127197\n",
      "Batch: 433 , Combined Loss: tensor(0.5739, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7745959758758545\n",
      "Batch: 434 , Combined Loss: tensor(0.6883, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9298627376556396\n",
      "Batch: 435 , Combined Loss: tensor(0.6089, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.084965467453003\n",
      "Batch: 436 , Combined Loss: tensor(0.6216, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0052082538604736\n",
      "Batch: 437 , Combined Loss: tensor(0.7084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9453961849212646\n",
      "Batch: 438 , Combined Loss: tensor(0.6144, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35171401500701904\n",
      "Batch: 439 , Combined Loss: tensor(0.5576, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8999195098876953\n",
      "Batch: 440 , Combined Loss: tensor(0.6550, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1478567123413086\n",
      "Batch: 441 , Combined Loss: tensor(0.7471, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.925098180770874\n",
      "Batch: 442 , Combined Loss: tensor(0.5712, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9348336458206177\n",
      "Batch: 443 , Combined Loss: tensor(0.7259, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08078718185424805\n",
      "Batch: 444 , Combined Loss: tensor(0.6688, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8500005006790161\n",
      "Batch: 445 , Combined Loss: tensor(0.5803, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0843181610107422\n",
      "Batch: 446 , Combined Loss: tensor(0.6702, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9597256183624268\n",
      "Batch: 447 , Combined Loss: tensor(0.6274, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.530381441116333\n",
      "Batch: 448 , Combined Loss: tensor(0.7072, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7671643495559692\n",
      "Batch: 449 , Combined Loss: tensor(0.7181, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.251878023147583\n",
      "Batch: 450 , Combined Loss: tensor(0.5831, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40903782844543457\n",
      "Batch: 451 , Combined Loss: tensor(0.6901, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9370894432067871\n",
      "Batch: 452 , Combined Loss: tensor(0.6718, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9158122539520264\n",
      "Batch: 453 , Combined Loss: tensor(0.5598, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6482547521591187\n",
      "Batch: 454 , Combined Loss: tensor(0.5445, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8712495565414429\n",
      "Batch: 455 , Combined Loss: tensor(0.5816, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0915539264678955\n",
      "Batch: 456 , Combined Loss: tensor(0.7563, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6938356161117554\n",
      "Batch: 457 , Combined Loss: tensor(0.5843, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2021613121032715\n",
      "Batch: 458 , Combined Loss: tensor(0.7338, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22617053985595703\n",
      "Batch: 459 , Combined Loss: tensor(0.7725, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.848797082901001\n",
      "Batch: 460 , Combined Loss: tensor(0.7815, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9225836992263794\n",
      "Batch: 461 , Combined Loss: tensor(0.6664, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5377641916275024\n",
      "Batch: 462 , Combined Loss: tensor(0.5644, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4313870668411255\n",
      "Batch: 463 , Combined Loss: tensor(0.6903, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09356224536895752\n",
      "Batch: 464 , Combined Loss: tensor(0.5510, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.049475908279419\n",
      "Batch: 465 , Combined Loss: tensor(0.6269, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9029769897460938\n",
      "Batch: 466 , Combined Loss: tensor(0.7501, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8030177354812622\n",
      "Batch: 467 , Combined Loss: tensor(0.5944, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4121239185333252\n",
      "Batch: 468 , Combined Loss: tensor(0.5924, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8373135328292847\n",
      "Batch: 469 , Combined Loss: tensor(0.6273, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9436534643173218\n",
      "Batch: 470 , Combined Loss: tensor(0.6250, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7467831373214722\n",
      "Batch: 471 , Combined Loss: tensor(0.6645, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9173048734664917\n",
      "Batch: 472 , Combined Loss: tensor(0.7771, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8697105646133423\n",
      "Batch: 473 , Combined Loss: tensor(0.7124, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5059788227081299\n",
      "Batch: 474 , Combined Loss: tensor(0.5914, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.232778787612915\n",
      "Batch: 475 , Combined Loss: tensor(0.6330, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7444413900375366\n",
      "Batch: 476 , Combined Loss: tensor(0.6256, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9490269422531128\n",
      "Batch: 477 , Combined Loss: tensor(0.5687, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2644777297973633\n",
      "Batch: 478 , Combined Loss: tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1021416187286377\n",
      "Batch: 479 , Combined Loss: tensor(0.7217, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43075549602508545\n",
      "Batch: 480 , Combined Loss: tensor(0.5501, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.043794870376587\n",
      "Batch: 481 , Combined Loss: tensor(0.5631, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1697680950164795\n",
      "Batch: 482 , Combined Loss: tensor(0.7850, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33593177795410156\n",
      "Batch: 483 , Combined Loss: tensor(0.6170, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7587859630584717\n",
      "Batch: 484 , Combined Loss: tensor(0.6065, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0271594524383545\n",
      "Batch: 485 , Combined Loss: tensor(0.6268, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7821505069732666\n",
      "Batch: 486 , Combined Loss: tensor(0.5839, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.024601221084594727\n",
      "Batch: 487 , Combined Loss: tensor(0.5973, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12040174007415771\n",
      "Batch: 488 , Combined Loss: tensor(0.6808, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6563905477523804\n",
      "Batch: 489 , Combined Loss: tensor(0.6333, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9121507406234741\n",
      "Batch: 490 , Combined Loss: tensor(0.6013, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9115438461303711\n",
      "Batch: 491 , Combined Loss: tensor(0.6216, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18854427337646484\n",
      "Batch: 492 , Combined Loss: tensor(0.6624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45669877529144287\n",
      "Batch: 493 , Combined Loss: tensor(0.6436, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1750037670135498\n",
      "Batch: 494 , Combined Loss: tensor(0.6342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9514375925064087\n",
      "Batch: 495 , Combined Loss: tensor(0.6140, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38097620010375977\n",
      "Batch: 496 , Combined Loss: tensor(0.6178, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7739347219467163\n",
      "Batch: 497 , Combined Loss: tensor(0.7959, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9742026329040527\n",
      "Batch: 498 , Combined Loss: tensor(0.6446, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5498884916305542\n",
      "Batch: 499 , Combined Loss: tensor(0.6956, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.515267014503479\n",
      "Batch: 500 , Combined Loss: tensor(0.5688, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8754585981369019\n",
      "Batch: 501 , Combined Loss: tensor(0.6300, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.177823781967163\n",
      "Batch: 502 , Combined Loss: tensor(0.6119, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.06292724609375\n",
      "Batch: 503 , Combined Loss: tensor(0.6337, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17418932914733887\n",
      "Batch: 504 , Combined Loss: tensor(0.5733, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37802958488464355\n",
      "Batch: 505 , Combined Loss: tensor(0.7614, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19334328174591064\n",
      "Batch: 506 , Combined Loss: tensor(0.7263, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40710651874542236\n",
      "Batch: 507 , Combined Loss: tensor(0.6032, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47978663444519043\n",
      "Batch: 508 , Combined Loss: tensor(0.5755, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9681732654571533\n",
      "Batch: 509 , Combined Loss: tensor(0.6369, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3210848569869995\n",
      "Batch: 510 , Combined Loss: tensor(0.6491, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0014100074768066\n",
      "Batch: 511 , Combined Loss: tensor(0.7061, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7007919549942017\n",
      "Batch: 512 , Combined Loss: tensor(0.7929, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7484985589981079\n",
      "Batch: 513 , Combined Loss: tensor(0.6413, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3929988145828247\n",
      "Batch: 514 , Combined Loss: tensor(0.5657, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0982611179351807\n",
      "Batch: 515 , Combined Loss: tensor(0.7767, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5259122848510742\n",
      "Batch: 516 , Combined Loss: tensor(0.5536, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9148530960083008\n",
      "Batch: 517 , Combined Loss: tensor(0.6141, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4624108076095581\n",
      "Batch: 518 , Combined Loss: tensor(0.7009, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41105103492736816\n",
      "Batch: 519 , Combined Loss: tensor(0.6127, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03354442119598389\n",
      "Batch: 520 , Combined Loss: tensor(0.5278, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.009871006011963\n",
      "Batch: 521 , Combined Loss: tensor(0.6804, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0309853553771973\n",
      "Batch: 522 , Combined Loss: tensor(0.6008, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7686655521392822\n",
      "Batch: 523 , Combined Loss: tensor(0.6486, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0393872261047363\n",
      "Batch: 524 , Combined Loss: tensor(0.6890, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0806849002838135\n",
      "Batch: 525 , Combined Loss: tensor(0.6409, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2947230339050293\n",
      "Batch: 526 , Combined Loss: tensor(0.5991, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7612547874450684\n",
      "Batch: 527 , Combined Loss: tensor(0.5963, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.022564172744751\n",
      "Batch: 528 , Combined Loss: tensor(0.5693, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8220990896224976\n",
      "Batch: 529 , Combined Loss: tensor(0.5889, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.443234920501709\n",
      "Batch: 530 , Combined Loss: tensor(0.8340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08832013607025146\n",
      "Batch: 531 , Combined Loss: tensor(0.7051, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6100466251373291\n",
      "Batch: 532 , Combined Loss: tensor(0.5630, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1912150382995605\n",
      "Batch: 533 , Combined Loss: tensor(0.8711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3180384635925293\n",
      "Batch: 534 , Combined Loss: tensor(0.6260, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1032195091247559\n",
      "Batch: 535 , Combined Loss: tensor(0.7699, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2466433048248291\n",
      "Batch: 536 , Combined Loss: tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7334465980529785\n",
      "Batch: 537 , Combined Loss: tensor(0.5384, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8338420391082764\n",
      "Batch: 538 , Combined Loss: tensor(0.7415, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1278972625732422\n",
      "Batch: 539 , Combined Loss: tensor(0.7014, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.056901454925537\n",
      "Batch: 540 , Combined Loss: tensor(0.6557, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.851677656173706\n",
      "Batch: 541 , Combined Loss: tensor(0.6801, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7097325325012207\n",
      "Batch: 542 , Combined Loss: tensor(0.7505, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6901168823242188\n",
      "Batch: 543 , Combined Loss: tensor(0.6214, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8824917078018188\n",
      "Batch: 544 , Combined Loss: tensor(0.6753, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8416630029678345\n",
      "Batch: 545 , Combined Loss: tensor(0.6891, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8652241230010986\n",
      "Batch: 546 , Combined Loss: tensor(0.7428, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0018410682678223\n",
      "Batch: 547 , Combined Loss: tensor(0.6305, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7243517637252808\n",
      "Batch: 548 , Combined Loss: tensor(0.6358, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9448118209838867\n",
      "Batch: 549 , Combined Loss: tensor(0.6617, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0231835842132568\n",
      "Batch: 550 , Combined Loss: tensor(0.8154, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0238778591156006\n",
      "Batch: 551 , Combined Loss: tensor(0.8518, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9997413158416748\n",
      "Batch: 552 , Combined Loss: tensor(0.6741, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3305938243865967\n",
      "Batch: 553 , Combined Loss: tensor(0.7331, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0798289775848389\n",
      "Batch: 554 , Combined Loss: tensor(1.0718, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.44506943225860596\n",
      "Batch: 555 , Combined Loss: tensor(0.8289, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5600630044937134\n",
      "Batch: 556 , Combined Loss: tensor(0.5435, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8774465322494507\n",
      "Batch: 557 , Combined Loss: tensor(0.7738, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3215980529785156\n",
      "Batch: 558 , Combined Loss: tensor(0.6905, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7996954917907715\n",
      "Batch: 559 , Combined Loss: tensor(0.6729, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8987812995910645\n",
      "Batch: 560 , Combined Loss: tensor(1.0753, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4251490831375122\n",
      "Batch: 561 , Combined Loss: tensor(0.7119, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5704164505004883\n",
      "Batch: 562 , Combined Loss: tensor(0.6834, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23750078678131104\n",
      "Batch: 563 , Combined Loss: tensor(0.6247, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8022192716598511\n",
      "Batch: 564 , Combined Loss: tensor(0.5875, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.055004358291626\n",
      "Batch: 565 , Combined Loss: tensor(0.6472, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7481513023376465\n",
      "Batch: 566 , Combined Loss: tensor(0.5552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.33231693506240845\n",
      "Batch: 567 , Combined Loss: tensor(0.6409, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1272597312927246\n",
      "Batch: 568 , Combined Loss: tensor(0.6164, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5934538841247559\n",
      "Batch: 569 , Combined Loss: tensor(0.6151, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1390419006347656\n",
      "Batch: 570 , Combined Loss: tensor(0.6373, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35396528244018555\n",
      "Batch: 571 , Combined Loss: tensor(0.6678, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15109527111053467\n",
      "Batch: 572 , Combined Loss: tensor(0.6438, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8934189081192017\n",
      "Batch: 573 , Combined Loss: tensor(0.6166, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9525105953216553\n",
      "Batch: 574 , Combined Loss: tensor(0.6340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.281451940536499\n",
      "Batch: 575 , Combined Loss: tensor(0.5822, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14235341548919678\n",
      "Batch: 576 , Combined Loss: tensor(0.6164, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9522788524627686\n",
      "Batch: 577 , Combined Loss: tensor(0.6487, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5901708602905273\n",
      "Batch: 578 , Combined Loss: tensor(0.6923, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5264003276824951\n",
      "Batch: 579 , Combined Loss: tensor(0.6560, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4129149317741394\n",
      "Batch: 580 , Combined Loss: tensor(0.7396, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9037202596664429\n",
      "Batch: 581 , Combined Loss: tensor(0.6875, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.981410026550293\n",
      "Batch: 582 , Combined Loss: tensor(0.6394, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17593294382095337\n",
      "Batch: 583 , Combined Loss: tensor(0.4899, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21067333221435547\n",
      "Batch: 584 , Combined Loss: tensor(0.5579, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7569237947463989\n",
      "Batch: 585 , Combined Loss: tensor(0.5786, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6128538846969604\n",
      "Batch: 586 , Combined Loss: tensor(0.6443, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7877169847488403\n",
      "Batch: 587 , Combined Loss: tensor(0.5947, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07492029666900635\n",
      "Batch: 588 , Combined Loss: tensor(0.7308, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.755873441696167\n",
      "Batch: 589 , Combined Loss: tensor(0.6041, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0116896629333496\n",
      "Batch: 590 , Combined Loss: tensor(0.6882, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7936667203903198\n",
      "Batch: 591 , Combined Loss: tensor(0.5777, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4457230567932129\n",
      "Batch: 592 , Combined Loss: tensor(0.7102, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7909579277038574\n",
      "Batch: 593 , Combined Loss: tensor(0.6730, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.882427453994751\n",
      "Batch: 594 , Combined Loss: tensor(0.7181, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9550573825836182\n",
      "Batch: 595 , Combined Loss: tensor(0.6225, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9656842947006226\n",
      "Batch: 596 , Combined Loss: tensor(0.5780, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.813602089881897\n",
      "Batch: 597 , Combined Loss: tensor(0.5526, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08925974369049072\n",
      "Batch: 598 , Combined Loss: tensor(0.7342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9176579713821411\n",
      "Batch: 599 , Combined Loss: tensor(0.6046, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0318336486816406\n",
      "Batch: 600 , Combined Loss: tensor(0.6847, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7733951807022095\n",
      "Batch: 601 , Combined Loss: tensor(0.7229, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8790013790130615\n",
      "Batch: 602 , Combined Loss: tensor(0.5432, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8793237209320068\n",
      "Batch: 603 , Combined Loss: tensor(0.6941, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7105695009231567\n",
      "Batch: 604 , Combined Loss: tensor(0.7773, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17501068115234375\n",
      "Batch: 605 , Combined Loss: tensor(0.6876, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.056233108043670654\n",
      "Batch: 606 , Combined Loss: tensor(0.5959, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6129846572875977\n",
      "Batch: 607 , Combined Loss: tensor(0.6318, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.053367555141448975\n",
      "Batch: 608 , Combined Loss: tensor(0.6577, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6643469333648682\n",
      "Batch: 609 , Combined Loss: tensor(0.6524, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6604059934616089\n",
      "Batch: 610 , Combined Loss: tensor(0.9261, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.36084842681884766\n",
      "Batch: 611 , Combined Loss: tensor(0.6839, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5971517562866211\n",
      "Batch: 612 , Combined Loss: tensor(0.7215, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4056280851364136\n",
      "Batch: 613 , Combined Loss: tensor(0.7746, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8654977083206177\n",
      "Batch: 614 , Combined Loss: tensor(0.6222, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.081290602684021\n",
      "Batch: 615 , Combined Loss: tensor(0.6233, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0873610973358154\n",
      "Batch: 616 , Combined Loss: tensor(0.9721, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5051875114440918\n",
      "Batch: 617 , Combined Loss: tensor(0.5999, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5140931606292725\n",
      "Batch: 618 , Combined Loss: tensor(0.8158, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6170793771743774\n",
      "Batch: 619 , Combined Loss: tensor(0.6668, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7548950910568237\n",
      "Batch: 620 , Combined Loss: tensor(0.6451, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4002094268798828\n",
      "Batch: 621 , Combined Loss: tensor(0.8221, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6561321020126343\n",
      "Batch: 622 , Combined Loss: tensor(0.6490, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9617502689361572\n",
      "Batch: 623 , Combined Loss: tensor(0.6181, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34949660301208496\n",
      "Batch: 624 , Combined Loss: tensor(0.6388, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0635509490966797\n",
      "Batch: 625 , Combined Loss: tensor(0.5905, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5953810214996338\n",
      "Batch: 626 , Combined Loss: tensor(1.0057, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5218315124511719\n",
      "Batch: 627 , Combined Loss: tensor(0.7415, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7172749042510986\n",
      "Batch: 628 , Combined Loss: tensor(0.7454, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.544084906578064\n",
      "----------Epoch 21, Loss: 0.6810823862806602, Accuracy: 0.9712410450739777, Dice Coef: [0.9873243720997688, 0.5952939797332795, 0.6324675790630331, 0.7228158759068103], Dice Coef Necrotic: 1.0337920320268876, Dice Coef Edema: 1.0420039173108182, Dice Coef Enhancing: 1.0385972749580399, Sensitivity: [0.9771693778151738, 0.7505220985254761, 0.8610457264609481, 0.86472541754784], Specificity: [0.9638769489214037, 0.9976295734058314, 0.9788831298036681, 0.9961391048704308], Precision: [0.9977963889914969, 0.5704371016796121, 0.5340982295293935, 0.6700202686518182]\n",
      "Saving without nn.DataParallel\n",
      "Batch: 0 , Combined Loss: tensor(0.5903, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8921830654144287\n",
      "Batch: 1 , Combined Loss: tensor(0.5915, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5102992057800293\n",
      "Batch: 2 , Combined Loss: tensor(0.6609, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.002154231071472168\n",
      "Batch: 3 , Combined Loss: tensor(1.0473, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5788891315460205\n",
      "Batch: 4 , Combined Loss: tensor(0.5407, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7527060508728027\n",
      "Batch: 5 , Combined Loss: tensor(0.6166, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9842694997787476\n",
      "Batch: 6 , Combined Loss: tensor(0.6797, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0861968994140625\n",
      "Batch: 7 , Combined Loss: tensor(1.0091, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5296143293380737\n",
      "Batch: 8 , Combined Loss: tensor(0.9376, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08488136529922485\n",
      "Batch: 9 , Combined Loss: tensor(0.6996, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2615303993225098\n",
      "Batch: 10 , Combined Loss: tensor(0.6471, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9616320133209229\n",
      "Batch: 11 , Combined Loss: tensor(0.7061, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05424225330352783\n",
      "Batch: 12 , Combined Loss: tensor(0.6633, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18426907062530518\n",
      "Batch: 13 , Combined Loss: tensor(0.6953, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5998401641845703\n",
      "Batch: 14 , Combined Loss: tensor(0.6305, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0399346351623535\n",
      "Batch: 15 , Combined Loss: tensor(0.5995, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8862593173980713\n",
      "Batch: 16 , Combined Loss: tensor(0.5818, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.38817042112350464\n",
      "Batch: 17 , Combined Loss: tensor(0.7340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6976181268692017\n",
      "Batch: 18 , Combined Loss: tensor(0.6655, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8138954639434814\n",
      "Batch: 19 , Combined Loss: tensor(0.6427, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5101943016052246\n",
      "Batch: 20 , Combined Loss: tensor(0.7411, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4267537593841553\n",
      "Batch: 21 , Combined Loss: tensor(0.7299, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8451395034790039\n",
      "Batch: 22 , Combined Loss: tensor(0.7778, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4895981550216675\n",
      "Batch: 23 , Combined Loss: tensor(0.5843, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8945736885070801\n",
      "Batch: 24 , Combined Loss: tensor(0.6222, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9280886650085449\n",
      "Batch: 25 , Combined Loss: tensor(0.6314, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9003593921661377\n",
      "Batch: 26 , Combined Loss: tensor(0.5979, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9391833543777466\n",
      "Batch: 27 , Combined Loss: tensor(0.6173, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4797276258468628\n",
      "Batch: 28 , Combined Loss: tensor(0.8402, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46269428730010986\n",
      "Batch: 29 , Combined Loss: tensor(0.6502, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9989126920700073\n",
      "Batch: 30 , Combined Loss: tensor(0.6585, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0419960021972656\n",
      "Batch: 31 , Combined Loss: tensor(0.8316, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26475298404693604\n",
      "Batch: 32 , Combined Loss: tensor(0.6467, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7464615106582642\n",
      "Batch: 33 , Combined Loss: tensor(0.6087, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07925999164581299\n",
      "Batch: 34 , Combined Loss: tensor(0.5810, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7276051044464111\n",
      "Batch: 35 , Combined Loss: tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30364203453063965\n",
      "Batch: 36 , Combined Loss: tensor(0.6293, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.020352840423584\n",
      "Batch: 37 , Combined Loss: tensor(0.5928, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.762138843536377\n",
      "Batch: 38 , Combined Loss: tensor(0.6379, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0504846572875977\n",
      "Batch: 39 , Combined Loss: tensor(0.8530, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20610326528549194\n",
      "Batch: 40 , Combined Loss: tensor(0.7756, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9832093715667725\n",
      "Batch: 41 , Combined Loss: tensor(0.5993, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19379019737243652\n",
      "Batch: 42 , Combined Loss: tensor(0.6408, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7282149791717529\n",
      "Batch: 43 , Combined Loss: tensor(0.6905, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.818631649017334\n",
      "Batch: 44 , Combined Loss: tensor(0.6315, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9528566598892212\n",
      "Batch: 45 , Combined Loss: tensor(0.5517, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7837750911712646\n",
      "Batch: 46 , Combined Loss: tensor(0.8308, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9148198366165161\n",
      "Batch: 47 , Combined Loss: tensor(0.6258, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0656356811523438\n",
      "Batch: 48 , Combined Loss: tensor(0.6057, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.019397258758545\n",
      "Batch: 49 , Combined Loss: tensor(0.5828, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.275010108947754\n",
      "Batch: 50 , Combined Loss: tensor(0.7099, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0557172298431396\n",
      "Batch: 51 , Combined Loss: tensor(0.9367, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5999385118484497\n",
      "Batch: 52 , Combined Loss: tensor(0.6623, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7726074457168579\n",
      "Batch: 53 , Combined Loss: tensor(0.6932, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1035678386688232\n",
      "Batch: 54 , Combined Loss: tensor(0.7508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6921348571777344\n",
      "Batch: 55 , Combined Loss: tensor(0.6522, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0903193950653076\n",
      "Batch: 56 , Combined Loss: tensor(0.6146, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.822509765625\n",
      "Batch: 57 , Combined Loss: tensor(0.6508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0832502841949463\n",
      "Batch: 58 , Combined Loss: tensor(0.6326, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0845253467559814\n",
      "Batch: 59 , Combined Loss: tensor(0.7275, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07203483581542969\n",
      "Batch: 60 , Combined Loss: tensor(0.5624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1349191665649414\n",
      "Batch: 61 , Combined Loss: tensor(0.5988, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5454816818237305\n",
      "Batch: 62 , Combined Loss: tensor(0.5946, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.006166934967041\n",
      "Batch: 63 , Combined Loss: tensor(0.6095, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2753875255584717\n",
      "Batch: 64 , Combined Loss: tensor(0.6534, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7425682544708252\n",
      "Batch: 65 , Combined Loss: tensor(0.5963, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0512785911560059\n",
      "Batch: 66 , Combined Loss: tensor(0.6410, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2393467426300049\n",
      "Batch: 67 , Combined Loss: tensor(0.6717, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3890281915664673\n",
      "Batch: 68 , Combined Loss: tensor(0.8052, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9969742298126221\n",
      "Batch: 69 , Combined Loss: tensor(0.5959, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.042954921722412\n",
      "Batch: 70 , Combined Loss: tensor(0.6017, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7437386512756348\n",
      "Batch: 71 , Combined Loss: tensor(0.6654, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7665965557098389\n",
      "Batch: 72 , Combined Loss: tensor(0.6774, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.016106367111206\n",
      "Batch: 73 , Combined Loss: tensor(0.5679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1759138107299805\n",
      "Batch: 74 , Combined Loss: tensor(0.7817, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8428659439086914\n",
      "Batch: 75 , Combined Loss: tensor(0.6779, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.013088822364807129\n",
      "Batch: 76 , Combined Loss: tensor(0.6789, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0693988800048828\n",
      "Batch: 77 , Combined Loss: tensor(0.8503, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7323274612426758\n",
      "Batch: 78 , Combined Loss: tensor(0.5805, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0332615375518799\n",
      "Batch: 79 , Combined Loss: tensor(0.7097, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3972572088241577\n",
      "Batch: 80 , Combined Loss: tensor(0.5633, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8901468515396118\n",
      "Batch: 81 , Combined Loss: tensor(0.7296, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0366952419281006\n",
      "Batch: 82 , Combined Loss: tensor(0.6157, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0915675163269043\n",
      "Batch: 83 , Combined Loss: tensor(0.8166, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.820487380027771\n",
      "Batch: 84 , Combined Loss: tensor(0.6602, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03608417510986328\n",
      "Batch: 85 , Combined Loss: tensor(0.5670, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.090602159500122\n",
      "Batch: 86 , Combined Loss: tensor(0.6614, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8363598585128784\n",
      "Batch: 87 , Combined Loss: tensor(0.6897, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1461398601531982\n",
      "Batch: 88 , Combined Loss: tensor(0.6127, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8038458824157715\n",
      "Batch: 89 , Combined Loss: tensor(0.8561, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6016881465911865\n",
      "Batch: 90 , Combined Loss: tensor(0.5417, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7953356504440308\n",
      "Batch: 91 , Combined Loss: tensor(0.5692, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.914122462272644\n",
      "Batch: 92 , Combined Loss: tensor(0.6794, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19930756092071533\n",
      "Batch: 93 , Combined Loss: tensor(0.7505, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2750582695007324\n",
      "Batch: 94 , Combined Loss: tensor(0.7045, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37183678150177\n",
      "Batch: 95 , Combined Loss: tensor(0.6361, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3953198194503784\n",
      "Batch: 96 , Combined Loss: tensor(0.6564, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9148557186126709\n",
      "Batch: 97 , Combined Loss: tensor(0.6039, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8632524013519287\n",
      "Batch: 98 , Combined Loss: tensor(0.5607, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0603923797607422\n",
      "Batch: 99 , Combined Loss: tensor(0.7103, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6664001941680908\n",
      "Batch: 100 , Combined Loss: tensor(0.5500, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8940132856369019\n",
      "Batch: 101 , Combined Loss: tensor(0.7475, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8180806636810303\n",
      "Batch: 102 , Combined Loss: tensor(0.6554, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9878714084625244\n",
      "Batch: 103 , Combined Loss: tensor(0.6752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9211256504058838\n",
      "Batch: 104 , Combined Loss: tensor(0.6533, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0312983989715576\n",
      "Batch: 105 , Combined Loss: tensor(0.7350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9899123907089233\n",
      "Batch: 106 , Combined Loss: tensor(0.6975, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0243606567382812\n",
      "Batch: 107 , Combined Loss: tensor(0.6106, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.098367691040039\n",
      "Batch: 108 , Combined Loss: tensor(0.6216, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8617657423019409\n",
      "Batch: 109 , Combined Loss: tensor(0.8474, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2741943597793579\n",
      "Batch: 110 , Combined Loss: tensor(0.6239, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.009647488594055176\n",
      "Batch: 111 , Combined Loss: tensor(0.5982, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0982427597045898\n",
      "Batch: 112 , Combined Loss: tensor(0.7730, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8653796911239624\n",
      "Batch: 113 , Combined Loss: tensor(0.7739, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7089492082595825\n",
      "Batch: 114 , Combined Loss: tensor(0.6225, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1588153839111328\n",
      "Batch: 115 , Combined Loss: tensor(0.6757, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4922257661819458\n",
      "Batch: 116 , Combined Loss: tensor(0.6616, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8697336912155151\n",
      "Batch: 117 , Combined Loss: tensor(0.6297, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16186535358428955\n",
      "Batch: 118 , Combined Loss: tensor(0.7702, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2406005859375\n",
      "Batch: 119 , Combined Loss: tensor(0.6540, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8570122718811035\n",
      "Batch: 120 , Combined Loss: tensor(0.5918, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0080604553222656\n",
      "Batch: 121 , Combined Loss: tensor(0.7377, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4769200086593628\n",
      "Batch: 122 , Combined Loss: tensor(0.6672, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.37254101037979126\n",
      "Batch: 123 , Combined Loss: tensor(0.6161, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7718948125839233\n",
      "Batch: 124 , Combined Loss: tensor(0.5489, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2981414794921875\n",
      "Batch: 125 , Combined Loss: tensor(0.6530, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45039987564086914\n",
      "Batch: 126 , Combined Loss: tensor(0.6162, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4646313190460205\n",
      "Batch: 127 , Combined Loss: tensor(0.6071, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8247635364532471\n",
      "Batch: 128 , Combined Loss: tensor(0.6653, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.545770525932312\n",
      "Batch: 129 , Combined Loss: tensor(0.6424, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4026010036468506\n",
      "Batch: 130 , Combined Loss: tensor(0.6190, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04916501045227051\n",
      "Batch: 131 , Combined Loss: tensor(0.8796, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04277712106704712\n",
      "Batch: 132 , Combined Loss: tensor(0.6620, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.40056687593460083\n",
      "Batch: 133 , Combined Loss: tensor(0.6835, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11372852325439453\n",
      "Batch: 134 , Combined Loss: tensor(0.6008, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4504122734069824\n",
      "Batch: 135 , Combined Loss: tensor(0.6881, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22209882736206055\n",
      "Batch: 136 , Combined Loss: tensor(0.9831, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.021143436431884766\n",
      "Batch: 137 , Combined Loss: tensor(0.6075, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0060465335845947\n",
      "Batch: 138 , Combined Loss: tensor(0.6780, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47313809394836426\n",
      "Batch: 139 , Combined Loss: tensor(0.9226, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5113295316696167\n",
      "Batch: 140 , Combined Loss: tensor(0.5687, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12529075145721436\n",
      "Batch: 141 , Combined Loss: tensor(0.8277, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12507784366607666\n",
      "Batch: 142 , Combined Loss: tensor(0.6393, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3889986276626587\n",
      "Batch: 143 , Combined Loss: tensor(0.6117, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23282384872436523\n",
      "Batch: 144 , Combined Loss: tensor(0.7647, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5147505402565002\n",
      "Batch: 145 , Combined Loss: tensor(0.6704, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5678976774215698\n",
      "Batch: 146 , Combined Loss: tensor(0.7679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8666038513183594\n",
      "Batch: 147 , Combined Loss: tensor(0.7467, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1745457649230957\n",
      "Batch: 148 , Combined Loss: tensor(0.6502, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07073807716369629\n",
      "Batch: 149 , Combined Loss: tensor(0.6911, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49115705490112305\n",
      "Batch: 150 , Combined Loss: tensor(0.6015, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.910460352897644\n",
      "Batch: 151 , Combined Loss: tensor(0.7962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9467984437942505\n",
      "Batch: 152 , Combined Loss: tensor(0.5987, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37085485458374023\n",
      "Batch: 153 , Combined Loss: tensor(0.6700, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8720357418060303\n",
      "Batch: 154 , Combined Loss: tensor(0.6383, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16555309295654297\n",
      "Batch: 155 , Combined Loss: tensor(0.7875, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6237630844116211\n",
      "Batch: 156 , Combined Loss: tensor(0.6101, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6266956329345703\n",
      "Batch: 157 , Combined Loss: tensor(0.6230, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3448352813720703\n",
      "Batch: 158 , Combined Loss: tensor(0.6888, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1403483748435974\n",
      "Batch: 159 , Combined Loss: tensor(0.6283, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3335202932357788\n",
      "Batch: 160 , Combined Loss: tensor(0.7554, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7287393808364868\n",
      "Batch: 161 , Combined Loss: tensor(0.5943, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9178115129470825\n",
      "Batch: 162 , Combined Loss: tensor(0.7739, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6402041912078857\n",
      "Batch: 163 , Combined Loss: tensor(0.6154, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8916798830032349\n",
      "Batch: 164 , Combined Loss: tensor(0.6536, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.35337287187576294\n",
      "Batch: 165 , Combined Loss: tensor(0.7936, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7693594694137573\n",
      "Batch: 166 , Combined Loss: tensor(0.8609, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6365717649459839\n",
      "Batch: 167 , Combined Loss: tensor(0.7236, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18323147296905518\n",
      "Batch: 168 , Combined Loss: tensor(0.6369, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.743455171585083\n",
      "Batch: 169 , Combined Loss: tensor(0.6649, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8190065622329712\n",
      "Batch: 170 , Combined Loss: tensor(0.8156, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7357325553894043\n",
      "Batch: 171 , Combined Loss: tensor(0.6543, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.34262675046920776\n",
      "Batch: 172 , Combined Loss: tensor(0.7304, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5631978511810303\n",
      "Batch: 173 , Combined Loss: tensor(0.5516, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49543631076812744\n",
      "Batch: 174 , Combined Loss: tensor(0.6841, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5357410907745361\n",
      "Batch: 175 , Combined Loss: tensor(0.6282, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.24804019927978516\n",
      "Batch: 176 , Combined Loss: tensor(0.6634, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8408366441726685\n",
      "Batch: 177 , Combined Loss: tensor(0.7185, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8135024309158325\n",
      "Batch: 178 , Combined Loss: tensor(0.6799, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7986048460006714\n",
      "Batch: 179 , Combined Loss: tensor(0.7680, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5211963653564453\n",
      "Batch: 180 , Combined Loss: tensor(0.5758, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6160091161727905\n",
      "Batch: 181 , Combined Loss: tensor(0.5664, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7029856443405151\n",
      "Batch: 182 , Combined Loss: tensor(0.6539, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09813684225082397\n",
      "Batch: 183 , Combined Loss: tensor(0.6947, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6549192667007446\n",
      "Batch: 184 , Combined Loss: tensor(0.6032, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8265447616577148\n",
      "Batch: 185 , Combined Loss: tensor(0.6407, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5718264579772949\n",
      "Batch: 186 , Combined Loss: tensor(0.6186, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9232131242752075\n",
      "Batch: 187 , Combined Loss: tensor(0.7583, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20703446865081787\n",
      "Batch: 188 , Combined Loss: tensor(0.7248, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.80650794506073\n",
      "Batch: 189 , Combined Loss: tensor(0.7770, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5701159238815308\n",
      "Batch: 190 , Combined Loss: tensor(0.6015, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0576589107513428\n",
      "Batch: 191 , Combined Loss: tensor(0.6319, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33820605278015137\n",
      "Batch: 192 , Combined Loss: tensor(0.5607, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08274447917938232\n",
      "Batch: 193 , Combined Loss: tensor(0.5637, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3016228675842285\n",
      "Batch: 194 , Combined Loss: tensor(0.6311, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6803171634674072\n",
      "Batch: 195 , Combined Loss: tensor(0.6919, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9399380683898926\n",
      "Batch: 196 , Combined Loss: tensor(0.4925, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3400533199310303\n",
      "Batch: 197 , Combined Loss: tensor(0.7298, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7588114738464355\n",
      "Batch: 198 , Combined Loss: tensor(0.6019, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6909860372543335\n",
      "Batch: 199 , Combined Loss: tensor(0.6462, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43704235553741455\n",
      "Batch: 200 , Combined Loss: tensor(0.5606, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5046249628067017\n",
      "Batch: 201 , Combined Loss: tensor(0.5739, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0502631664276123\n",
      "Batch: 202 , Combined Loss: tensor(0.7374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5541001558303833\n",
      "Batch: 203 , Combined Loss: tensor(0.7029, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07521963119506836\n",
      "Batch: 204 , Combined Loss: tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9383797645568848\n",
      "Batch: 205 , Combined Loss: tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.514805793762207\n",
      "Batch: 206 , Combined Loss: tensor(0.7704, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.42927342653274536\n",
      "Batch: 207 , Combined Loss: tensor(0.6999, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7755457162857056\n",
      "Batch: 208 , Combined Loss: tensor(0.6097, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0483205318450928\n",
      "Batch: 209 , Combined Loss: tensor(0.6874, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33138060569763184\n",
      "Batch: 210 , Combined Loss: tensor(0.7430, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3709205389022827\n",
      "Batch: 211 , Combined Loss: tensor(0.7457, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6950116157531738\n",
      "Batch: 212 , Combined Loss: tensor(0.6318, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5010358095169067\n",
      "Batch: 213 , Combined Loss: tensor(0.7359, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16880857944488525\n",
      "Batch: 214 , Combined Loss: tensor(0.6114, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.785849928855896\n",
      "Batch: 215 , Combined Loss: tensor(0.7108, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7195217609405518\n",
      "Batch: 216 , Combined Loss: tensor(0.5730, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24326026439666748\n",
      "Batch: 217 , Combined Loss: tensor(0.8886, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6254358291625977\n",
      "Batch: 218 , Combined Loss: tensor(0.8642, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7323002815246582\n",
      "Batch: 219 , Combined Loss: tensor(0.6797, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8856137990951538\n",
      "Batch: 220 , Combined Loss: tensor(0.5868, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7634716033935547\n",
      "Batch: 221 , Combined Loss: tensor(0.6011, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9867719411849976\n",
      "Batch: 222 , Combined Loss: tensor(0.6060, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5048428773880005\n",
      "Batch: 223 , Combined Loss: tensor(0.6161, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8229806423187256\n",
      "Batch: 224 , Combined Loss: tensor(0.6151, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1400831937789917\n",
      "Batch: 225 , Combined Loss: tensor(0.6999, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5296003818511963\n",
      "Batch: 226 , Combined Loss: tensor(0.7767, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.044645071029663\n",
      "Batch: 227 , Combined Loss: tensor(0.6571, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9752308130264282\n",
      "Batch: 228 , Combined Loss: tensor(0.6185, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9989346265792847\n",
      "Batch: 229 , Combined Loss: tensor(0.6096, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8980405330657959\n",
      "Batch: 230 , Combined Loss: tensor(0.5850, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0379674434661865\n",
      "Batch: 231 , Combined Loss: tensor(0.6656, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8346134424209595\n",
      "Batch: 232 , Combined Loss: tensor(0.6242, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.052159070968628\n",
      "Batch: 233 , Combined Loss: tensor(0.6909, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.580060601234436\n",
      "Batch: 234 , Combined Loss: tensor(0.6656, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.052828073501587\n",
      "Batch: 235 , Combined Loss: tensor(0.8012, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4516034722328186\n",
      "Batch: 236 , Combined Loss: tensor(0.9113, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0221984386444092\n",
      "Batch: 237 , Combined Loss: tensor(0.5828, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.056300401687622\n",
      "Batch: 238 , Combined Loss: tensor(0.6584, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7276084423065186\n",
      "Batch: 239 , Combined Loss: tensor(0.6453, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.42257845401763916\n",
      "Batch: 240 , Combined Loss: tensor(0.5911, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2829697132110596\n",
      "Batch: 241 , Combined Loss: tensor(0.8977, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3204852342605591\n",
      "Batch: 242 , Combined Loss: tensor(0.8187, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9412423372268677\n",
      "Batch: 243 , Combined Loss: tensor(0.7475, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9704957008361816\n",
      "Batch: 244 , Combined Loss: tensor(0.7465, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9205565452575684\n",
      "Batch: 245 , Combined Loss: tensor(0.6673, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1411082744598389\n",
      "Batch: 246 , Combined Loss: tensor(0.7342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9799703359603882\n",
      "Batch: 247 , Combined Loss: tensor(0.6115, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7656998634338379\n",
      "Batch: 248 , Combined Loss: tensor(0.9957, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.585248589515686\n",
      "Batch: 249 , Combined Loss: tensor(0.6996, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7587798833847046\n",
      "Batch: 250 , Combined Loss: tensor(0.6819, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6333494186401367\n",
      "Batch: 251 , Combined Loss: tensor(0.8967, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8948684930801392\n",
      "Batch: 252 , Combined Loss: tensor(0.6114, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6663569211959839\n",
      "Batch: 253 , Combined Loss: tensor(0.6163, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0427308082580566\n",
      "Batch: 254 , Combined Loss: tensor(0.6396, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.916780948638916\n",
      "Batch: 255 , Combined Loss: tensor(0.6689, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.026444673538208\n",
      "Batch: 256 , Combined Loss: tensor(0.6796, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6790759563446045\n",
      "Batch: 257 , Combined Loss: tensor(0.5670, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5608285665512085\n",
      "Batch: 258 , Combined Loss: tensor(0.5968, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0909650325775146\n",
      "Batch: 259 , Combined Loss: tensor(0.6535, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38619518280029297\n",
      "Batch: 260 , Combined Loss: tensor(0.7071, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2143557071685791\n",
      "Batch: 261 , Combined Loss: tensor(0.5633, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0043385028839111\n",
      "Batch: 262 , Combined Loss: tensor(0.5809, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1443560123443604\n",
      "Batch: 263 , Combined Loss: tensor(0.5943, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.923194408416748\n",
      "Batch: 264 , Combined Loss: tensor(0.6707, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9597700834274292\n",
      "Batch: 265 , Combined Loss: tensor(0.6485, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0727629661560059\n",
      "Batch: 266 , Combined Loss: tensor(0.5966, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8841469287872314\n",
      "Batch: 267 , Combined Loss: tensor(0.6167, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28493309020996094\n",
      "Batch: 268 , Combined Loss: tensor(0.7329, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6352386474609375\n",
      "Batch: 269 , Combined Loss: tensor(0.5900, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.728351354598999\n",
      "Batch: 270 , Combined Loss: tensor(0.7730, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38895392417907715\n",
      "Batch: 271 , Combined Loss: tensor(1.1526, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4403390884399414\n",
      "Batch: 272 , Combined Loss: tensor(0.5907, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0076797008514404\n",
      "Batch: 273 , Combined Loss: tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.715394139289856\n",
      "Batch: 274 , Combined Loss: tensor(0.6274, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8867830038070679\n",
      "Batch: 275 , Combined Loss: tensor(0.6062, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9278172254562378\n",
      "Batch: 276 , Combined Loss: tensor(0.7812, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0338385105133057\n",
      "Batch: 277 , Combined Loss: tensor(0.7972, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5659337043762207\n",
      "Batch: 278 , Combined Loss: tensor(0.6247, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8450095653533936\n",
      "Batch: 279 , Combined Loss: tensor(0.6450, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0077173709869385\n",
      "Batch: 280 , Combined Loss: tensor(0.7317, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8304867744445801\n",
      "Batch: 281 , Combined Loss: tensor(0.5930, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3785970211029053\n",
      "Batch: 282 , Combined Loss: tensor(0.6229, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9533791542053223\n",
      "Batch: 283 , Combined Loss: tensor(0.6144, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.269999623298645\n",
      "Batch: 284 , Combined Loss: tensor(0.6679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4042367935180664\n",
      "Batch: 285 , Combined Loss: tensor(0.9922, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2889896631240845\n",
      "Batch: 286 , Combined Loss: tensor(0.7769, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1195411682128906\n",
      "Batch: 287 , Combined Loss: tensor(0.7286, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6998867988586426\n",
      "Batch: 288 , Combined Loss: tensor(0.6757, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.899626612663269\n",
      "Batch: 289 , Combined Loss: tensor(0.5831, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0410172939300537\n",
      "Batch: 290 , Combined Loss: tensor(0.5628, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9591737985610962\n",
      "Batch: 291 , Combined Loss: tensor(0.6441, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7614196538925171\n",
      "Batch: 292 , Combined Loss: tensor(0.9125, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2800519466400146\n",
      "Batch: 293 , Combined Loss: tensor(0.6669, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1300435066223145\n",
      "Batch: 294 , Combined Loss: tensor(0.6280, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.711835503578186\n",
      "Batch: 295 , Combined Loss: tensor(0.6671, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7360644340515137\n",
      "Batch: 296 , Combined Loss: tensor(0.5436, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9864121675491333\n",
      "Batch: 297 , Combined Loss: tensor(0.6737, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8794374465942383\n",
      "Batch: 298 , Combined Loss: tensor(0.5647, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7677745819091797\n",
      "Batch: 299 , Combined Loss: tensor(0.9380, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15873301029205322\n",
      "Batch: 300 , Combined Loss: tensor(0.6615, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.979934573173523\n",
      "Batch: 301 , Combined Loss: tensor(0.7656, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7153476476669312\n",
      "Batch: 302 , Combined Loss: tensor(0.6852, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9419728517532349\n",
      "Batch: 303 , Combined Loss: tensor(0.7309, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9569029808044434\n",
      "Batch: 304 , Combined Loss: tensor(0.7686, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.13422536849975586\n",
      "Batch: 305 , Combined Loss: tensor(0.5630, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1486597061157227\n",
      "Batch: 306 , Combined Loss: tensor(0.7218, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3799186944961548\n",
      "Batch: 307 , Combined Loss: tensor(0.7510, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8762484788894653\n",
      "Batch: 308 , Combined Loss: tensor(0.6066, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.051133632659912\n",
      "Batch: 309 , Combined Loss: tensor(0.5976, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7819304466247559\n",
      "Batch: 310 , Combined Loss: tensor(0.6505, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7684488296508789\n",
      "Batch: 311 , Combined Loss: tensor(0.6410, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42925870418548584\n",
      "Batch: 312 , Combined Loss: tensor(0.6392, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1227340698242188\n",
      "Batch: 313 , Combined Loss: tensor(0.6938, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2391992211341858\n",
      "Batch: 314 , Combined Loss: tensor(0.5784, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8144159317016602\n",
      "Batch: 315 , Combined Loss: tensor(0.5833, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8040382862091064\n",
      "Batch: 316 , Combined Loss: tensor(0.6846, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8268263339996338\n",
      "Batch: 317 , Combined Loss: tensor(0.6208, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1772916316986084\n",
      "Batch: 318 , Combined Loss: tensor(0.5684, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1744036674499512\n",
      "Batch: 319 , Combined Loss: tensor(0.6465, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8938133716583252\n",
      "Batch: 320 , Combined Loss: tensor(0.5689, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9012556076049805\n",
      "Batch: 321 , Combined Loss: tensor(0.6005, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5291086435317993\n",
      "Batch: 322 , Combined Loss: tensor(0.6125, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8028320074081421\n",
      "Batch: 323 , Combined Loss: tensor(0.9298, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30201148986816406\n",
      "Batch: 324 , Combined Loss: tensor(0.6949, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7110713720321655\n",
      "Batch: 325 , Combined Loss: tensor(0.6698, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15790235996246338\n",
      "Batch: 326 , Combined Loss: tensor(0.6706, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6582882404327393\n",
      "Batch: 327 , Combined Loss: tensor(0.7226, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8286657333374023\n",
      "Batch: 328 , Combined Loss: tensor(0.8985, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31851625442504883\n",
      "Batch: 329 , Combined Loss: tensor(1.1491, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6854664087295532\n",
      "Batch: 330 , Combined Loss: tensor(0.8283, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6534004211425781\n",
      "Batch: 331 , Combined Loss: tensor(0.5965, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48380792140960693\n",
      "Batch: 332 , Combined Loss: tensor(0.6308, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8287980556488037\n",
      "Batch: 333 , Combined Loss: tensor(0.6632, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9625459909439087\n",
      "Batch: 334 , Combined Loss: tensor(0.6299, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4537562131881714\n",
      "Batch: 335 , Combined Loss: tensor(0.6972, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6613506078720093\n",
      "Batch: 336 , Combined Loss: tensor(0.7035, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6156049966812134\n",
      "Batch: 337 , Combined Loss: tensor(0.7147, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7614520788192749\n",
      "Batch: 338 , Combined Loss: tensor(0.6153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.760671854019165\n",
      "Batch: 339 , Combined Loss: tensor(0.8676, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4295983910560608\n",
      "Batch: 340 , Combined Loss: tensor(0.7115, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06335961818695068\n",
      "Batch: 341 , Combined Loss: tensor(0.7277, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5254209041595459\n",
      "Batch: 342 , Combined Loss: tensor(0.7162, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5070936679840088\n",
      "Batch: 343 , Combined Loss: tensor(0.6173, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1304094791412354\n",
      "Batch: 344 , Combined Loss: tensor(1.0231, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.030336976051330566\n",
      "Batch: 345 , Combined Loss: tensor(0.6638, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0825090408325195\n",
      "Batch: 346 , Combined Loss: tensor(0.6867, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1873917579650879\n",
      "Batch: 347 , Combined Loss: tensor(0.7410, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8687591552734375\n",
      "Batch: 348 , Combined Loss: tensor(0.6975, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17881667613983154\n",
      "Batch: 349 , Combined Loss: tensor(0.6110, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2894703149795532\n",
      "Batch: 350 , Combined Loss: tensor(0.7097, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6452919244766235\n",
      "Batch: 351 , Combined Loss: tensor(0.6576, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14180946350097656\n",
      "Batch: 352 , Combined Loss: tensor(0.7354, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8028441667556763\n",
      "Batch: 353 , Combined Loss: tensor(0.6662, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6412183046340942\n",
      "Batch: 354 , Combined Loss: tensor(0.6962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8625668287277222\n",
      "Batch: 355 , Combined Loss: tensor(0.6740, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4005241394042969\n",
      "Batch: 356 , Combined Loss: tensor(0.7457, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1786577701568604\n",
      "Batch: 357 , Combined Loss: tensor(0.7107, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7583603858947754\n",
      "Batch: 358 , Combined Loss: tensor(0.6824, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.27545422315597534\n",
      "Batch: 359 , Combined Loss: tensor(0.7216, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3853278160095215\n",
      "Batch: 360 , Combined Loss: tensor(0.6949, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.415407657623291\n",
      "Batch: 361 , Combined Loss: tensor(0.7941, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03138852119445801\n",
      "Batch: 362 , Combined Loss: tensor(0.5911, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9008289575576782\n",
      "Batch: 363 , Combined Loss: tensor(0.6600, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.651598334312439\n",
      "Batch: 364 , Combined Loss: tensor(0.6502, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5916564464569092\n",
      "Batch: 365 , Combined Loss: tensor(0.6873, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0382695198059082\n",
      "Batch: 366 , Combined Loss: tensor(0.6665, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8510340452194214\n",
      "Batch: 367 , Combined Loss: tensor(0.7753, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8492138385772705\n",
      "Batch: 368 , Combined Loss: tensor(0.6084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9656885862350464\n",
      "Batch: 369 , Combined Loss: tensor(0.7564, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.004485189914703369\n",
      "Batch: 370 , Combined Loss: tensor(0.7245, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2517237663269043\n",
      "Batch: 371 , Combined Loss: tensor(0.6734, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0700368881225586\n",
      "Batch: 372 , Combined Loss: tensor(0.6064, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8431762456893921\n",
      "Batch: 373 , Combined Loss: tensor(0.6869, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.01586747169494629\n",
      "Batch: 374 , Combined Loss: tensor(0.5991, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08265447616577148\n",
      "Batch: 375 , Combined Loss: tensor(0.7453, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2132401466369629\n",
      "Batch: 376 , Combined Loss: tensor(0.8458, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8993008136749268\n",
      "Batch: 377 , Combined Loss: tensor(0.5503, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6130136251449585\n",
      "Batch: 378 , Combined Loss: tensor(0.7829, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.527294397354126\n",
      "Batch: 379 , Combined Loss: tensor(0.6274, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6869591474533081\n",
      "Batch: 380 , Combined Loss: tensor(0.7541, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15254902839660645\n",
      "Batch: 381 , Combined Loss: tensor(0.6496, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0113189220428467\n",
      "Batch: 382 , Combined Loss: tensor(0.7695, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4134313464164734\n",
      "Batch: 383 , Combined Loss: tensor(0.7280, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9234389066696167\n",
      "Batch: 384 , Combined Loss: tensor(0.6407, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.663743257522583\n",
      "Batch: 385 , Combined Loss: tensor(0.7119, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6648901700973511\n",
      "Batch: 386 , Combined Loss: tensor(0.6432, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8516066074371338\n",
      "Batch: 387 , Combined Loss: tensor(0.6376, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6585432291030884\n",
      "Batch: 388 , Combined Loss: tensor(0.6961, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.749260425567627\n",
      "Batch: 389 , Combined Loss: tensor(0.7511, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.057544231414795\n",
      "Batch: 390 , Combined Loss: tensor(0.6538, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3240205645561218\n",
      "Batch: 391 , Combined Loss: tensor(0.6607, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6468499898910522\n",
      "Batch: 392 , Combined Loss: tensor(0.7009, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22487932443618774\n",
      "Batch: 393 , Combined Loss: tensor(0.9787, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1745443344116211\n",
      "Batch: 394 , Combined Loss: tensor(0.6827, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7452092170715332\n",
      "Batch: 395 , Combined Loss: tensor(0.6737, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.869915246963501\n",
      "Batch: 396 , Combined Loss: tensor(0.6924, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6269303560256958\n",
      "Batch: 397 , Combined Loss: tensor(0.6615, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0645122528076172\n",
      "Batch: 398 , Combined Loss: tensor(0.6118, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6411162614822388\n",
      "Batch: 399 , Combined Loss: tensor(0.5748, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5836795568466187\n",
      "Batch: 400 , Combined Loss: tensor(0.6189, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.806907057762146\n",
      "Batch: 401 , Combined Loss: tensor(0.6593, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44780099391937256\n",
      "Batch: 402 , Combined Loss: tensor(0.7798, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8550447225570679\n",
      "Batch: 403 , Combined Loss: tensor(0.6635, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9167760610580444\n",
      "Batch: 404 , Combined Loss: tensor(0.6697, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9644967317581177\n",
      "Batch: 405 , Combined Loss: tensor(0.6194, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9687063694000244\n",
      "Batch: 406 , Combined Loss: tensor(0.6376, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7300236225128174\n",
      "Batch: 407 , Combined Loss: tensor(0.5984, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11799871921539307\n",
      "Batch: 408 , Combined Loss: tensor(0.6544, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9200718402862549\n",
      "Batch: 409 , Combined Loss: tensor(0.6523, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08826971054077148\n",
      "Batch: 410 , Combined Loss: tensor(0.7088, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7547396421432495\n",
      "Batch: 411 , Combined Loss: tensor(0.5872, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9321054220199585\n",
      "Batch: 412 , Combined Loss: tensor(0.6197, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4095419645309448\n",
      "Batch: 413 , Combined Loss: tensor(0.7750, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2707252502441406\n",
      "Batch: 414 , Combined Loss: tensor(0.7251, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7822389602661133\n",
      "Batch: 415 , Combined Loss: tensor(0.6083, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6608281135559082\n",
      "Batch: 416 , Combined Loss: tensor(0.5830, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8148771524429321\n",
      "Batch: 417 , Combined Loss: tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8530765771865845\n",
      "Batch: 418 , Combined Loss: tensor(0.7112, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7456448078155518\n",
      "Batch: 419 , Combined Loss: tensor(0.6798, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5311003923416138\n",
      "Batch: 420 , Combined Loss: tensor(0.6490, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06181800365447998\n",
      "Batch: 421 , Combined Loss: tensor(0.6328, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8960031270980835\n",
      "Batch: 422 , Combined Loss: tensor(0.6580, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9591138362884521\n",
      "Batch: 423 , Combined Loss: tensor(0.8497, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6914610862731934\n",
      "Batch: 424 , Combined Loss: tensor(0.6129, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7439979314804077\n",
      "Batch: 425 , Combined Loss: tensor(0.6392, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.690893292427063\n",
      "Batch: 426 , Combined Loss: tensor(0.6346, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.020658910274505615\n",
      "Batch: 427 , Combined Loss: tensor(0.7220, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.35531723499298096\n",
      "Batch: 428 , Combined Loss: tensor(0.5733, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6849541664123535\n",
      "Batch: 429 , Combined Loss: tensor(0.5448, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.810029149055481\n",
      "Batch: 430 , Combined Loss: tensor(0.5844, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.059934377670288\n",
      "Batch: 431 , Combined Loss: tensor(0.9134, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8287314176559448\n",
      "Batch: 432 , Combined Loss: tensor(0.7883, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.02170264720916748\n",
      "Batch: 433 , Combined Loss: tensor(0.6006, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9005393981933594\n",
      "Batch: 434 , Combined Loss: tensor(0.7261, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7791805267333984\n",
      "Batch: 435 , Combined Loss: tensor(0.6149, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.980383038520813\n",
      "Batch: 436 , Combined Loss: tensor(0.6521, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9080220460891724\n",
      "Batch: 437 , Combined Loss: tensor(0.7891, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9933515787124634\n",
      "Batch: 438 , Combined Loss: tensor(0.9027, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6939873695373535\n",
      "Batch: 439 , Combined Loss: tensor(0.5532, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0094897747039795\n",
      "Batch: 440 , Combined Loss: tensor(0.5888, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7215816974639893\n",
      "Batch: 441 , Combined Loss: tensor(0.6478, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5988762378692627\n",
      "Batch: 442 , Combined Loss: tensor(0.6066, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4786224365234375\n",
      "Batch: 443 , Combined Loss: tensor(0.7866, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7566877603530884\n",
      "Batch: 444 , Combined Loss: tensor(0.6143, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.149603009223938\n",
      "Batch: 445 , Combined Loss: tensor(0.6239, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6466671228408813\n",
      "Batch: 446 , Combined Loss: tensor(0.6416, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1351146697998047\n",
      "Batch: 447 , Combined Loss: tensor(0.5957, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8755278587341309\n",
      "Batch: 448 , Combined Loss: tensor(0.6458, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9933323860168457\n",
      "Batch: 449 , Combined Loss: tensor(0.6436, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6537832021713257\n",
      "Batch: 450 , Combined Loss: tensor(0.7259, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8414654731750488\n",
      "Batch: 451 , Combined Loss: tensor(0.6681, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.941815972328186\n",
      "Batch: 452 , Combined Loss: tensor(0.6835, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0200614929199219\n",
      "Batch: 453 , Combined Loss: tensor(0.5948, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2794315814971924\n",
      "Batch: 454 , Combined Loss: tensor(0.9272, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7734215259552002\n",
      "Batch: 455 , Combined Loss: tensor(0.5267, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7114843130111694\n",
      "Batch: 456 , Combined Loss: tensor(0.6412, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8461297750473022\n",
      "Batch: 457 , Combined Loss: tensor(0.5132, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42744457721710205\n",
      "Batch: 458 , Combined Loss: tensor(0.7997, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7021278142929077\n",
      "Batch: 459 , Combined Loss: tensor(0.9886, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6568939685821533\n",
      "Batch: 460 , Combined Loss: tensor(0.7031, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.010990619659423828\n",
      "Batch: 461 , Combined Loss: tensor(0.6227, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0181632041931152\n",
      "Batch: 462 , Combined Loss: tensor(0.5667, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.126821517944336\n",
      "Batch: 463 , Combined Loss: tensor(0.6255, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9582535028457642\n",
      "Batch: 464 , Combined Loss: tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7907510995864868\n",
      "Batch: 465 , Combined Loss: tensor(0.5662, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.045621633529663\n",
      "Batch: 466 , Combined Loss: tensor(0.7324, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45013856887817383\n",
      "Batch: 467 , Combined Loss: tensor(0.7441, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.030335664749145508\n",
      "Batch: 468 , Combined Loss: tensor(0.6454, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6203994750976562\n",
      "Batch: 469 , Combined Loss: tensor(0.6138, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2477877140045166\n",
      "Batch: 470 , Combined Loss: tensor(0.7830, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44964277744293213\n",
      "Batch: 471 , Combined Loss: tensor(0.6375, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.17598557472229\n",
      "Batch: 472 , Combined Loss: tensor(0.6831, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32111990451812744\n",
      "Batch: 473 , Combined Loss: tensor(0.8338, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6527674198150635\n",
      "Batch: 474 , Combined Loss: tensor(0.5508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9536973237991333\n",
      "Batch: 475 , Combined Loss: tensor(0.7182, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6139719486236572\n",
      "Batch: 476 , Combined Loss: tensor(0.7481, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.068932056427002\n",
      "Batch: 477 , Combined Loss: tensor(0.9029, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9567306041717529\n",
      "Batch: 478 , Combined Loss: tensor(0.5683, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.767432689666748\n",
      "Batch: 479 , Combined Loss: tensor(0.5780, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7750791311264038\n",
      "Batch: 480 , Combined Loss: tensor(0.6118, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7647303342819214\n",
      "Batch: 481 , Combined Loss: tensor(0.6033, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9203803539276123\n",
      "Batch: 482 , Combined Loss: tensor(0.7283, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.26022017002105713\n",
      "Batch: 483 , Combined Loss: tensor(1.0560, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2721666097640991\n",
      "Batch: 484 , Combined Loss: tensor(0.6207, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8857837915420532\n",
      "Batch: 485 , Combined Loss: tensor(0.7495, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8118232488632202\n",
      "Batch: 486 , Combined Loss: tensor(0.6367, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8040461540222168\n",
      "Batch: 487 , Combined Loss: tensor(0.5765, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6298966407775879\n",
      "Batch: 488 , Combined Loss: tensor(0.6175, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.33181822299957275\n",
      "Batch: 489 , Combined Loss: tensor(0.7624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9011131525039673\n",
      "Batch: 490 , Combined Loss: tensor(0.5112, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8246113061904907\n",
      "Batch: 491 , Combined Loss: tensor(0.7070, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3413790464401245\n",
      "Batch: 492 , Combined Loss: tensor(0.8018, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1821979284286499\n",
      "Batch: 493 , Combined Loss: tensor(0.7198, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8974671363830566\n",
      "Batch: 494 , Combined Loss: tensor(0.6429, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9057776927947998\n",
      "Batch: 495 , Combined Loss: tensor(0.6294, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7641230821609497\n",
      "Batch: 496 , Combined Loss: tensor(0.6189, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7787584066390991\n",
      "Batch: 497 , Combined Loss: tensor(0.7337, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.158768892288208\n",
      "Batch: 498 , Combined Loss: tensor(0.6875, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0969796180725098\n",
      "Batch: 499 , Combined Loss: tensor(0.6253, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0566949844360352\n",
      "Batch: 500 , Combined Loss: tensor(0.8055, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4754979610443115\n",
      "Batch: 501 , Combined Loss: tensor(0.6027, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07170313596725464\n",
      "Batch: 502 , Combined Loss: tensor(0.6571, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42637085914611816\n",
      "Batch: 503 , Combined Loss: tensor(0.7258, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0540480613708496\n",
      "Batch: 504 , Combined Loss: tensor(0.8397, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3285045623779297\n",
      "Batch: 505 , Combined Loss: tensor(0.7353, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5274917483329773\n",
      "Batch: 506 , Combined Loss: tensor(0.7250, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9094774723052979\n",
      "Batch: 507 , Combined Loss: tensor(0.6369, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39942729473114014\n",
      "Batch: 508 , Combined Loss: tensor(0.6439, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.013385534286499\n",
      "Batch: 509 , Combined Loss: tensor(0.5787, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5736391544342041\n",
      "Batch: 510 , Combined Loss: tensor(0.7143, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5540876388549805\n",
      "Batch: 511 , Combined Loss: tensor(0.6221, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6595878601074219\n",
      "Batch: 512 , Combined Loss: tensor(0.5823, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25529634952545166\n",
      "Batch: 513 , Combined Loss: tensor(0.6728, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40194380283355713\n",
      "Batch: 514 , Combined Loss: tensor(0.6110, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8148727416992188\n",
      "Batch: 515 , Combined Loss: tensor(0.8117, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7029298543930054\n",
      "Batch: 516 , Combined Loss: tensor(0.6025, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0268490314483643\n",
      "Batch: 517 , Combined Loss: tensor(0.6647, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9922984838485718\n",
      "Batch: 518 , Combined Loss: tensor(0.5375, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8468033075332642\n",
      "Batch: 519 , Combined Loss: tensor(0.6077, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48136866092681885\n",
      "Batch: 520 , Combined Loss: tensor(0.8896, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7314070463180542\n",
      "Batch: 521 , Combined Loss: tensor(0.5886, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7628233432769775\n",
      "Batch: 522 , Combined Loss: tensor(0.6635, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8857326507568359\n",
      "Batch: 523 , Combined Loss: tensor(0.7919, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.606345534324646\n",
      "Batch: 524 , Combined Loss: tensor(0.6547, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12273168563842773\n",
      "Batch: 525 , Combined Loss: tensor(0.6242, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.031815767288208\n",
      "Batch: 526 , Combined Loss: tensor(0.7081, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31440556049346924\n",
      "Batch: 527 , Combined Loss: tensor(0.6732, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7120810747146606\n",
      "Batch: 528 , Combined Loss: tensor(0.7202, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04183638095855713\n",
      "Batch: 529 , Combined Loss: tensor(0.6542, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.024230718612671\n",
      "Batch: 530 , Combined Loss: tensor(0.5944, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.080296277999878\n",
      "Batch: 531 , Combined Loss: tensor(0.6971, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18817579746246338\n",
      "Batch: 532 , Combined Loss: tensor(0.6205, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3367394208908081\n",
      "Batch: 533 , Combined Loss: tensor(0.5752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8313251733779907\n",
      "Batch: 534 , Combined Loss: tensor(0.6659, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8744866847991943\n",
      "Batch: 535 , Combined Loss: tensor(0.6155, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9460220336914062\n",
      "Batch: 536 , Combined Loss: tensor(0.6490, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5779547691345215\n",
      "Batch: 537 , Combined Loss: tensor(0.5949, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0176427364349365\n",
      "Batch: 538 , Combined Loss: tensor(0.6727, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7674275636672974\n",
      "Batch: 539 , Combined Loss: tensor(0.6432, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9646391868591309\n",
      "Batch: 540 , Combined Loss: tensor(0.5506, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7166591882705688\n",
      "Batch: 541 , Combined Loss: tensor(0.6231, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.793109655380249\n",
      "Batch: 542 , Combined Loss: tensor(0.5503, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.379085898399353\n",
      "Batch: 543 , Combined Loss: tensor(0.5325, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6897870302200317\n",
      "Batch: 544 , Combined Loss: tensor(0.6213, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7702597379684448\n",
      "Batch: 545 , Combined Loss: tensor(0.6294, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1155800819396973\n",
      "Batch: 546 , Combined Loss: tensor(1.1369, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8131459951400757\n",
      "Batch: 547 , Combined Loss: tensor(0.7551, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9519480466842651\n",
      "Batch: 548 , Combined Loss: tensor(0.6246, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1604266166687012\n",
      "Batch: 549 , Combined Loss: tensor(0.6024, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3191640377044678\n",
      "Batch: 550 , Combined Loss: tensor(0.8577, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0196325778961182\n",
      "Batch: 551 , Combined Loss: tensor(0.6917, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7646089792251587\n",
      "Batch: 552 , Combined Loss: tensor(0.8224, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.926821231842041\n",
      "Batch: 553 , Combined Loss: tensor(0.7586, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0747854709625244\n",
      "Batch: 554 , Combined Loss: tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9782201051712036\n",
      "Batch: 555 , Combined Loss: tensor(0.5891, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.138650894165039\n",
      "Batch: 556 , Combined Loss: tensor(0.9803, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1738262176513672\n",
      "Batch: 557 , Combined Loss: tensor(0.6165, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9108283519744873\n",
      "Batch: 558 , Combined Loss: tensor(0.6280, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1883587837219238\n",
      "Batch: 559 , Combined Loss: tensor(0.6908, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04329681396484375\n",
      "Batch: 560 , Combined Loss: tensor(0.6071, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7700299024581909\n",
      "Batch: 561 , Combined Loss: tensor(0.7043, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.137190341949463\n",
      "Batch: 562 , Combined Loss: tensor(0.6766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.108628749847412\n",
      "Batch: 563 , Combined Loss: tensor(0.5417, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7593914270401001\n",
      "Batch: 564 , Combined Loss: tensor(0.6210, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.94891357421875\n",
      "Batch: 565 , Combined Loss: tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4404255151748657\n",
      "Batch: 566 , Combined Loss: tensor(0.7356, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8887296915054321\n",
      "Batch: 567 , Combined Loss: tensor(0.7924, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.028435230255127\n",
      "Batch: 568 , Combined Loss: tensor(0.6339, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5898023843765259\n",
      "Batch: 569 , Combined Loss: tensor(0.8671, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7162958383560181\n",
      "Batch: 570 , Combined Loss: tensor(0.5394, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8705955743789673\n",
      "Batch: 571 , Combined Loss: tensor(0.5800, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1688746213912964\n",
      "Batch: 572 , Combined Loss: tensor(0.6547, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7975784540176392\n",
      "Batch: 573 , Combined Loss: tensor(0.6347, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7208037376403809\n",
      "Batch: 574 , Combined Loss: tensor(0.5619, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0307543277740479\n",
      "Batch: 575 , Combined Loss: tensor(0.5937, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9281604290008545\n",
      "Batch: 576 , Combined Loss: tensor(0.6757, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3128732442855835\n",
      "Batch: 577 , Combined Loss: tensor(0.5705, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5420534610748291\n",
      "Batch: 578 , Combined Loss: tensor(0.7379, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3269848823547363\n",
      "Batch: 579 , Combined Loss: tensor(0.6272, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0107898712158203\n",
      "Batch: 580 , Combined Loss: tensor(0.7235, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9378938674926758\n",
      "Batch: 581 , Combined Loss: tensor(0.6668, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6861140727996826\n",
      "Batch: 582 , Combined Loss: tensor(0.9328, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33237314224243164\n",
      "Batch: 583 , Combined Loss: tensor(0.9049, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9198007583618164\n",
      "Batch: 584 , Combined Loss: tensor(1.0570, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6976959705352783\n",
      "Batch: 585 , Combined Loss: tensor(0.6306, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9902669191360474\n",
      "Batch: 586 , Combined Loss: tensor(0.5780, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6594171524047852\n",
      "Batch: 587 , Combined Loss: tensor(0.6872, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3613126277923584\n",
      "Batch: 588 , Combined Loss: tensor(0.7550, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8996789455413818\n",
      "Batch: 589 , Combined Loss: tensor(0.6429, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0764448642730713\n",
      "Batch: 590 , Combined Loss: tensor(0.5653, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3138371706008911\n",
      "Batch: 591 , Combined Loss: tensor(0.6561, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9014768600463867\n",
      "Batch: 592 , Combined Loss: tensor(0.5800, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8392813205718994\n",
      "Batch: 593 , Combined Loss: tensor(0.5579, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8525755405426025\n",
      "Batch: 594 , Combined Loss: tensor(0.7602, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9315303564071655\n",
      "Batch: 595 , Combined Loss: tensor(0.7207, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.833208441734314\n",
      "Batch: 596 , Combined Loss: tensor(0.8380, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0750499963760376\n",
      "Batch: 597 , Combined Loss: tensor(0.5833, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.157226800918579\n",
      "Batch: 598 , Combined Loss: tensor(0.5904, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5634737014770508\n",
      "Batch: 599 , Combined Loss: tensor(0.5532, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9507732391357422\n",
      "Batch: 600 , Combined Loss: tensor(0.5970, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2822701930999756\n",
      "Batch: 601 , Combined Loss: tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.069319725036621\n",
      "Batch: 602 , Combined Loss: tensor(0.5793, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7374104261398315\n",
      "Batch: 603 , Combined Loss: tensor(0.5918, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9959533214569092\n",
      "Batch: 604 , Combined Loss: tensor(0.6380, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0663762092590332\n",
      "Batch: 605 , Combined Loss: tensor(0.6851, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0980565547943115\n",
      "Batch: 606 , Combined Loss: tensor(0.5741, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8045722246170044\n",
      "Batch: 607 , Combined Loss: tensor(0.6075, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0094692707061768\n",
      "Batch: 608 , Combined Loss: tensor(0.8929, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25215983390808105\n",
      "Batch: 609 , Combined Loss: tensor(0.7624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12425243854522705\n",
      "Batch: 610 , Combined Loss: tensor(0.6381, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4728083610534668\n",
      "Batch: 611 , Combined Loss: tensor(0.6322, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7868947982788086\n",
      "Batch: 612 , Combined Loss: tensor(0.6801, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9724959135055542\n",
      "Batch: 613 , Combined Loss: tensor(0.5696, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8106566667556763\n",
      "Batch: 614 , Combined Loss: tensor(0.7185, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1782057285308838\n",
      "Batch: 615 , Combined Loss: tensor(0.7455, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7356127500534058\n",
      "Batch: 616 , Combined Loss: tensor(0.6153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6710801124572754\n",
      "Batch: 617 , Combined Loss: tensor(0.5644, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2796971797943115\n",
      "Batch: 618 , Combined Loss: tensor(0.6165, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41443538665771484\n",
      "Batch: 619 , Combined Loss: tensor(0.8249, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7553619146347046\n",
      "Batch: 620 , Combined Loss: tensor(0.6542, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3291318416595459\n",
      "Batch: 621 , Combined Loss: tensor(0.6529, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19506573677062988\n",
      "Batch: 622 , Combined Loss: tensor(0.5659, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4666759967803955\n",
      "Batch: 623 , Combined Loss: tensor(0.7090, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9300535917282104\n",
      "Batch: 624 , Combined Loss: tensor(0.5778, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7622671127319336\n",
      "Batch: 625 , Combined Loss: tensor(0.6284, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6869739294052124\n",
      "Batch: 626 , Combined Loss: tensor(0.6705, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0955801010131836\n",
      "Batch: 627 , Combined Loss: tensor(0.6724, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8949844837188721\n",
      "Batch: 628 , Combined Loss: tensor(0.6815, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0508782863616943\n",
      "----------Epoch 22, Loss: 0.6793659342207098, Accuracy: 0.9680079951384867, Dice Coef: [0.9853552678431161, 0.6017640655202363, 0.6188540045627365, 0.7166258221949771], Dice Coef Necrotic: 0.9866084158038279, Dice Coef Edema: 0.9936521873952504, Dice Coef Enhancing: 0.9851244659149393, Sensitivity: [0.9732414604370468, 0.7573990202545883, 0.8718898378916689, 0.8694931039370489], Specificity: [0.9667821609917051, 0.9976428305591043, 0.9758883200123882, 0.9956856174764648], Precision: [0.9979355759764703, 0.57238498142754, 0.5164214859216462, 0.6610170765557817]\n",
      "Saving without nn.DataParallel\n",
      "Batch: 0 , Combined Loss: tensor(0.6683, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.749751091003418\n",
      "Batch: 1 , Combined Loss: tensor(0.6399, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8764276504516602\n",
      "Batch: 2 , Combined Loss: tensor(0.8292, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1007812023162842\n",
      "Batch: 3 , Combined Loss: tensor(0.6987, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3428128957748413\n",
      "Batch: 4 , Combined Loss: tensor(0.6998, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8410604000091553\n",
      "Batch: 5 , Combined Loss: tensor(0.5782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6510331630706787\n",
      "Batch: 6 , Combined Loss: tensor(0.5934, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9713027477264404\n",
      "Batch: 7 , Combined Loss: tensor(0.6546, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0797087550163269\n",
      "Batch: 8 , Combined Loss: tensor(0.8653, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.721623420715332\n",
      "Batch: 9 , Combined Loss: tensor(0.6128, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6085734367370605\n",
      "Batch: 10 , Combined Loss: tensor(0.6058, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5758976936340332\n",
      "Batch: 11 , Combined Loss: tensor(0.5708, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43460917472839355\n",
      "Batch: 12 , Combined Loss: tensor(0.6266, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31194937229156494\n",
      "Batch: 13 , Combined Loss: tensor(0.6420, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06012904644012451\n",
      "Batch: 14 , Combined Loss: tensor(0.6291, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0068464279174805\n",
      "Batch: 15 , Combined Loss: tensor(0.6228, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.940569281578064\n",
      "Batch: 16 , Combined Loss: tensor(0.5573, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0246162414550781\n",
      "Batch: 17 , Combined Loss: tensor(0.8236, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7624130249023438\n",
      "Batch: 18 , Combined Loss: tensor(0.8153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6081100702285767\n",
      "Batch: 19 , Combined Loss: tensor(0.6316, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.699687123298645\n",
      "Batch: 20 , Combined Loss: tensor(0.8527, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8748205900192261\n",
      "Batch: 21 , Combined Loss: tensor(0.7842, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03463459014892578\n",
      "Batch: 22 , Combined Loss: tensor(0.6514, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07151961326599121\n",
      "Batch: 23 , Combined Loss: tensor(0.6017, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14307141304016113\n",
      "Batch: 24 , Combined Loss: tensor(0.5502, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9082953929901123\n",
      "Batch: 25 , Combined Loss: tensor(0.7807, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9904791116714478\n",
      "Batch: 26 , Combined Loss: tensor(0.6899, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4670487642288208\n",
      "Batch: 27 , Combined Loss: tensor(0.7447, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8123557567596436\n",
      "Batch: 28 , Combined Loss: tensor(0.5246, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8657845258712769\n",
      "Batch: 29 , Combined Loss: tensor(0.7232, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09099435806274414\n",
      "Batch: 30 , Combined Loss: tensor(0.7412, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.987769365310669\n",
      "Batch: 31 , Combined Loss: tensor(0.7573, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7304219007492065\n",
      "Batch: 32 , Combined Loss: tensor(0.6411, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9271736145019531\n",
      "Batch: 33 , Combined Loss: tensor(0.7627, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5485278367996216\n",
      "Batch: 34 , Combined Loss: tensor(0.7567, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9800565242767334\n",
      "Batch: 35 , Combined Loss: tensor(0.6235, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8763307332992554\n",
      "Batch: 36 , Combined Loss: tensor(0.6193, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0804142951965332\n",
      "Batch: 37 , Combined Loss: tensor(0.5700, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9882551431655884\n",
      "Batch: 38 , Combined Loss: tensor(0.6793, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7991399765014648\n",
      "Batch: 39 , Combined Loss: tensor(0.7127, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7062250375747681\n",
      "Batch: 40 , Combined Loss: tensor(0.6593, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.057650089263916\n",
      "Batch: 41 , Combined Loss: tensor(0.8627, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6037451028823853\n",
      "Batch: 42 , Combined Loss: tensor(0.7210, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8129265308380127\n",
      "Batch: 43 , Combined Loss: tensor(0.6269, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1225118637084961\n",
      "Batch: 44 , Combined Loss: tensor(0.6551, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9943623542785645\n",
      "Batch: 45 , Combined Loss: tensor(0.8829, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2572638988494873\n",
      "Batch: 46 , Combined Loss: tensor(0.6398, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9307152032852173\n",
      "Batch: 47 , Combined Loss: tensor(0.6176, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.116471767425537\n",
      "Batch: 48 , Combined Loss: tensor(0.5788, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6927626132965088\n",
      "Batch: 49 , Combined Loss: tensor(0.6588, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39586591720581055\n",
      "Batch: 50 , Combined Loss: tensor(0.6187, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8415042161941528\n",
      "Batch: 51 , Combined Loss: tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8343745470046997\n",
      "Batch: 52 , Combined Loss: tensor(0.6699, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1214830875396729\n",
      "Batch: 53 , Combined Loss: tensor(0.5598, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.753449559211731\n",
      "Batch: 54 , Combined Loss: tensor(0.6254, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36449694633483887\n",
      "Batch: 55 , Combined Loss: tensor(0.7018, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38022053241729736\n",
      "Batch: 56 , Combined Loss: tensor(0.6533, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5903921127319336\n",
      "Batch: 57 , Combined Loss: tensor(0.6567, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5878632068634033\n",
      "Batch: 58 , Combined Loss: tensor(0.6868, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04163551330566406\n",
      "Batch: 59 , Combined Loss: tensor(0.7511, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0413572788238525\n",
      "Batch: 60 , Combined Loss: tensor(0.5878, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38044261932373047\n",
      "Batch: 61 , Combined Loss: tensor(0.7270, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3882080316543579\n",
      "Batch: 62 , Combined Loss: tensor(0.5877, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6608421802520752\n",
      "Batch: 63 , Combined Loss: tensor(0.5881, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9157567024230957\n",
      "Batch: 64 , Combined Loss: tensor(0.9766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5364042520523071\n",
      "Batch: 65 , Combined Loss: tensor(0.5928, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8292924165725708\n",
      "Batch: 66 , Combined Loss: tensor(0.6295, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9797265529632568\n",
      "Batch: 67 , Combined Loss: tensor(0.6227, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34996676445007324\n",
      "Batch: 68 , Combined Loss: tensor(0.5724, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38414549827575684\n",
      "Batch: 69 , Combined Loss: tensor(0.5932, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.836567759513855\n",
      "Batch: 70 , Combined Loss: tensor(0.5598, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5573480129241943\n",
      "Batch: 71 , Combined Loss: tensor(0.6851, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6028649806976318\n",
      "Batch: 72 , Combined Loss: tensor(0.6002, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26466262340545654\n",
      "Batch: 73 , Combined Loss: tensor(1.0225, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7485923767089844\n",
      "Batch: 74 , Combined Loss: tensor(0.5638, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7557135820388794\n",
      "Batch: 75 , Combined Loss: tensor(0.6276, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43974924087524414\n",
      "Batch: 76 , Combined Loss: tensor(0.7826, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.632961630821228\n",
      "Batch: 77 , Combined Loss: tensor(0.6788, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6855443716049194\n",
      "Batch: 78 , Combined Loss: tensor(0.7410, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.943665623664856\n",
      "Batch: 79 , Combined Loss: tensor(0.9528, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5602428913116455\n",
      "Batch: 80 , Combined Loss: tensor(0.6570, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7744016647338867\n",
      "Batch: 81 , Combined Loss: tensor(0.6212, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8670295476913452\n",
      "Batch: 82 , Combined Loss: tensor(0.6441, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5520321130752563\n",
      "Batch: 83 , Combined Loss: tensor(0.6033, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1078848838806152\n",
      "Batch: 84 , Combined Loss: tensor(0.6465, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4366265535354614\n",
      "Batch: 85 , Combined Loss: tensor(0.6626, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9487080574035645\n",
      "Batch: 86 , Combined Loss: tensor(0.6740, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7809543609619141\n",
      "Batch: 87 , Combined Loss: tensor(0.6160, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8781909942626953\n",
      "Batch: 88 , Combined Loss: tensor(0.8298, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0262930393218994\n",
      "Batch: 89 , Combined Loss: tensor(0.6452, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.010825872421264648\n",
      "Batch: 90 , Combined Loss: tensor(0.7827, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9505816698074341\n",
      "Batch: 91 , Combined Loss: tensor(0.9015, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03089761734008789\n",
      "Batch: 92 , Combined Loss: tensor(0.6828, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3887665271759033\n",
      "Batch: 93 , Combined Loss: tensor(0.6320, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8406690359115601\n",
      "Batch: 94 , Combined Loss: tensor(0.6086, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7696845531463623\n",
      "Batch: 95 , Combined Loss: tensor(0.5949, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9859682321548462\n",
      "Batch: 96 , Combined Loss: tensor(0.6065, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7076632976531982\n",
      "Batch: 97 , Combined Loss: tensor(0.7156, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3300689458847046\n",
      "Batch: 98 , Combined Loss: tensor(0.6086, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9625743627548218\n",
      "Batch: 99 , Combined Loss: tensor(0.5939, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0674042701721191\n",
      "Batch: 100 , Combined Loss: tensor(0.6460, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.838353157043457\n",
      "Batch: 101 , Combined Loss: tensor(0.7953, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5049103498458862\n",
      "Batch: 102 , Combined Loss: tensor(0.7035, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8215329647064209\n",
      "Batch: 103 , Combined Loss: tensor(0.6216, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.157651662826538\n",
      "Batch: 104 , Combined Loss: tensor(0.6585, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0650780200958252\n",
      "Batch: 105 , Combined Loss: tensor(0.7389, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5298168659210205\n",
      "Batch: 106 , Combined Loss: tensor(0.7409, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47538959980010986\n",
      "Batch: 107 , Combined Loss: tensor(0.5626, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9784075021743774\n",
      "Batch: 108 , Combined Loss: tensor(0.7460, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8008642196655273\n",
      "Batch: 109 , Combined Loss: tensor(0.6652, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1748431921005249\n",
      "Batch: 110 , Combined Loss: tensor(0.6520, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5440225601196289\n",
      "Batch: 111 , Combined Loss: tensor(0.8123, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11361551284790039\n",
      "Batch: 112 , Combined Loss: tensor(0.7031, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9642312526702881\n",
      "Batch: 113 , Combined Loss: tensor(0.6619, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0644214153289795\n",
      "Batch: 114 , Combined Loss: tensor(0.7552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0402014255523682\n",
      "Batch: 115 , Combined Loss: tensor(0.5748, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6976851224899292\n",
      "Batch: 116 , Combined Loss: tensor(0.7628, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6218959093093872\n",
      "Batch: 117 , Combined Loss: tensor(0.8416, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9814181327819824\n",
      "Batch: 118 , Combined Loss: tensor(0.7094, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8152822256088257\n",
      "Batch: 119 , Combined Loss: tensor(1.0247, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5161378383636475\n",
      "Batch: 120 , Combined Loss: tensor(0.9693, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3076874017715454\n",
      "Batch: 121 , Combined Loss: tensor(0.6500, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0933201313018799\n",
      "Batch: 122 , Combined Loss: tensor(0.6044, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0143852233886719\n",
      "Batch: 123 , Combined Loss: tensor(0.6339, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9936937093734741\n",
      "Batch: 124 , Combined Loss: tensor(0.7370, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0940074920654297\n",
      "Batch: 125 , Combined Loss: tensor(0.6641, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.160616397857666\n",
      "Batch: 126 , Combined Loss: tensor(0.6400, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6113064289093018\n",
      "Batch: 127 , Combined Loss: tensor(0.6476, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.688475489616394\n",
      "Batch: 128 , Combined Loss: tensor(0.6407, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.022242426872253418\n",
      "Batch: 129 , Combined Loss: tensor(0.5661, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.705262303352356\n",
      "Batch: 130 , Combined Loss: tensor(0.5657, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8539576530456543\n",
      "Batch: 131 , Combined Loss: tensor(0.5912, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5993926525115967\n",
      "Batch: 132 , Combined Loss: tensor(0.6854, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6362489461898804\n",
      "Batch: 133 , Combined Loss: tensor(0.7702, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5923837423324585\n",
      "Batch: 134 , Combined Loss: tensor(0.6801, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0888724327087402\n",
      "Batch: 135 , Combined Loss: tensor(0.6080, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1240448951721191\n",
      "Batch: 136 , Combined Loss: tensor(0.6013, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9670156240463257\n",
      "Batch: 137 , Combined Loss: tensor(0.5970, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8717590570449829\n",
      "Batch: 138 , Combined Loss: tensor(0.6385, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5449073314666748\n",
      "Batch: 139 , Combined Loss: tensor(0.6016, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3193295001983643\n",
      "Batch: 140 , Combined Loss: tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9927603006362915\n",
      "Batch: 141 , Combined Loss: tensor(0.7290, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0436651706695557\n",
      "Batch: 142 , Combined Loss: tensor(0.5972, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9474136829376221\n",
      "Batch: 143 , Combined Loss: tensor(0.7041, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.994351863861084\n",
      "Batch: 144 , Combined Loss: tensor(0.7358, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7197439670562744\n",
      "Batch: 145 , Combined Loss: tensor(0.5942, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4977877140045166\n",
      "Batch: 146 , Combined Loss: tensor(0.8718, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7115606069564819\n",
      "Batch: 147 , Combined Loss: tensor(0.5639, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9188019037246704\n",
      "Batch: 148 , Combined Loss: tensor(0.7034, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6257411241531372\n",
      "Batch: 149 , Combined Loss: tensor(0.6156, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8765480518341064\n",
      "Batch: 150 , Combined Loss: tensor(0.6120, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2390832901000977\n",
      "Batch: 151 , Combined Loss: tensor(0.6966, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.038773775100708\n",
      "Batch: 152 , Combined Loss: tensor(0.6430, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8714460134506226\n",
      "Batch: 153 , Combined Loss: tensor(0.7714, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1216692924499512\n",
      "Batch: 154 , Combined Loss: tensor(0.5969, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9486325979232788\n",
      "Batch: 155 , Combined Loss: tensor(0.6520, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9863511323928833\n",
      "Batch: 156 , Combined Loss: tensor(0.5683, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1756882667541504\n",
      "Batch: 157 , Combined Loss: tensor(0.6042, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1411867141723633\n",
      "Batch: 158 , Combined Loss: tensor(0.6149, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9982787370681763\n",
      "Batch: 159 , Combined Loss: tensor(0.5558, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8559621572494507\n",
      "Batch: 160 , Combined Loss: tensor(0.5582, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0880062580108643\n",
      "Batch: 161 , Combined Loss: tensor(0.5950, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1272187232971191\n",
      "Batch: 162 , Combined Loss: tensor(0.7510, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7406774759292603\n",
      "Batch: 163 , Combined Loss: tensor(0.6510, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0741333961486816\n",
      "Batch: 164 , Combined Loss: tensor(0.6337, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0624639987945557\n",
      "Batch: 165 , Combined Loss: tensor(0.6088, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9158965349197388\n",
      "Batch: 166 , Combined Loss: tensor(0.8016, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9472830295562744\n",
      "Batch: 167 , Combined Loss: tensor(0.5630, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9434183835983276\n",
      "Batch: 168 , Combined Loss: tensor(0.6346, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0713865756988525\n",
      "Batch: 169 , Combined Loss: tensor(0.6777, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9515454769134521\n",
      "Batch: 170 , Combined Loss: tensor(0.6984, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7708121538162231\n",
      "Batch: 171 , Combined Loss: tensor(0.6282, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.063039779663086\n",
      "Batch: 172 , Combined Loss: tensor(0.6062, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8721529245376587\n",
      "Batch: 173 , Combined Loss: tensor(0.5330, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5860888957977295\n",
      "Batch: 174 , Combined Loss: tensor(0.6857, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9277949333190918\n",
      "Batch: 175 , Combined Loss: tensor(0.7020, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0954887866973877\n",
      "Batch: 176 , Combined Loss: tensor(0.6151, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9048360586166382\n",
      "Batch: 177 , Combined Loss: tensor(0.7795, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0447049140930176\n",
      "Batch: 178 , Combined Loss: tensor(0.6926, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7889440059661865\n",
      "Batch: 179 , Combined Loss: tensor(0.6618, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1173088550567627\n",
      "Batch: 180 , Combined Loss: tensor(0.6176, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4300187826156616\n",
      "Batch: 181 , Combined Loss: tensor(0.8826, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.024791479110717773\n",
      "Batch: 182 , Combined Loss: tensor(0.7609, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5284734964370728\n",
      "Batch: 183 , Combined Loss: tensor(0.5789, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7457194328308105\n",
      "Batch: 184 , Combined Loss: tensor(0.6390, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8743577003479004\n",
      "Batch: 185 , Combined Loss: tensor(0.5887, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6883056163787842\n",
      "Batch: 186 , Combined Loss: tensor(0.9539, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08842706680297852\n",
      "Batch: 187 , Combined Loss: tensor(0.5558, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8752679824829102\n",
      "Batch: 188 , Combined Loss: tensor(0.5669, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8830302953720093\n",
      "Batch: 189 , Combined Loss: tensor(0.5646, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4551277160644531\n",
      "Batch: 190 , Combined Loss: tensor(0.5958, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7395765781402588\n",
      "Batch: 191 , Combined Loss: tensor(0.6603, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9930113554000854\n",
      "Batch: 192 , Combined Loss: tensor(0.5971, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7500150203704834\n",
      "Batch: 193 , Combined Loss: tensor(0.6715, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5990737676620483\n",
      "Batch: 194 , Combined Loss: tensor(0.7408, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0410101413726807\n",
      "Batch: 195 , Combined Loss: tensor(0.8145, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9844590425491333\n",
      "Batch: 196 , Combined Loss: tensor(0.6515, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.062324047088623\n",
      "Batch: 197 , Combined Loss: tensor(0.5777, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7880216836929321\n",
      "Batch: 198 , Combined Loss: tensor(0.6752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9467540979385376\n",
      "Batch: 199 , Combined Loss: tensor(0.6031, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8930881023406982\n",
      "Batch: 200 , Combined Loss: tensor(0.6296, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0265250205993652\n",
      "Batch: 201 , Combined Loss: tensor(0.6874, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9226092100143433\n",
      "Batch: 202 , Combined Loss: tensor(0.7089, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6997662782669067\n",
      "Batch: 203 , Combined Loss: tensor(0.5610, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6854315996170044\n",
      "Batch: 204 , Combined Loss: tensor(0.5934, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.540753960609436\n",
      "Batch: 205 , Combined Loss: tensor(0.7602, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0301427841186523\n",
      "Batch: 206 , Combined Loss: tensor(0.6814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8640226125717163\n",
      "Batch: 207 , Combined Loss: tensor(0.6936, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7030936479568481\n",
      "Batch: 208 , Combined Loss: tensor(0.6567, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.785515546798706\n",
      "Batch: 209 , Combined Loss: tensor(0.6559, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9949760437011719\n",
      "Batch: 210 , Combined Loss: tensor(0.5620, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0019853115081787\n",
      "Batch: 211 , Combined Loss: tensor(0.6020, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5515995025634766\n",
      "Batch: 212 , Combined Loss: tensor(0.6431, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8847659826278687\n",
      "Batch: 213 , Combined Loss: tensor(0.5764, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.30576753616333\n",
      "Batch: 214 , Combined Loss: tensor(0.6329, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0084969997406006\n",
      "Batch: 215 , Combined Loss: tensor(0.5981, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.161853551864624\n",
      "Batch: 216 , Combined Loss: tensor(0.5752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0740203857421875\n",
      "Batch: 217 , Combined Loss: tensor(0.6807, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8312922716140747\n",
      "Batch: 218 , Combined Loss: tensor(0.6460, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9018086194992065\n",
      "Batch: 219 , Combined Loss: tensor(0.7301, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8732026815414429\n",
      "Batch: 220 , Combined Loss: tensor(0.6575, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.058733582496643066\n",
      "Batch: 221 , Combined Loss: tensor(0.5546, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9567223787307739\n",
      "Batch: 222 , Combined Loss: tensor(0.5851, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0401296615600586\n",
      "Batch: 223 , Combined Loss: tensor(1.1469, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8951760530471802\n",
      "Batch: 224 , Combined Loss: tensor(0.8404, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1119263172149658\n",
      "Batch: 225 , Combined Loss: tensor(0.7808, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8040696382522583\n",
      "Batch: 226 , Combined Loss: tensor(0.8970, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0025458335876465\n",
      "Batch: 227 , Combined Loss: tensor(0.5998, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03616929054260254\n",
      "Batch: 228 , Combined Loss: tensor(0.5967, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7823125123977661\n",
      "Batch: 229 , Combined Loss: tensor(0.5700, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8617767095565796\n",
      "Batch: 230 , Combined Loss: tensor(0.5855, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3737267255783081\n",
      "Batch: 231 , Combined Loss: tensor(0.7985, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9682106971740723\n",
      "Batch: 232 , Combined Loss: tensor(0.5817, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3548370599746704\n",
      "Batch: 233 , Combined Loss: tensor(0.6416, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22395503520965576\n",
      "Batch: 234 , Combined Loss: tensor(0.5960, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9300955533981323\n",
      "Batch: 235 , Combined Loss: tensor(1.1033, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29787588119506836\n",
      "Batch: 236 , Combined Loss: tensor(0.5523, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.88511061668396\n",
      "Batch: 237 , Combined Loss: tensor(0.6864, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8012501001358032\n",
      "Batch: 238 , Combined Loss: tensor(0.6738, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2538747787475586\n",
      "Batch: 239 , Combined Loss: tensor(0.6902, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8627275228500366\n",
      "Batch: 240 , Combined Loss: tensor(0.5880, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0380537509918213\n",
      "Batch: 241 , Combined Loss: tensor(0.5571, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3912161588668823\n",
      "Batch: 242 , Combined Loss: tensor(0.6202, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0441725254058838\n",
      "Batch: 243 , Combined Loss: tensor(0.5407, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9572358131408691\n",
      "Batch: 244 , Combined Loss: tensor(0.6157, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.200791597366333\n",
      "Batch: 245 , Combined Loss: tensor(0.6831, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9465439319610596\n",
      "Batch: 246 , Combined Loss: tensor(0.6966, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9983211755752563\n",
      "Batch: 247 , Combined Loss: tensor(0.5686, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0978631973266602\n",
      "Batch: 248 , Combined Loss: tensor(0.6392, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8272126913070679\n",
      "Batch: 249 , Combined Loss: tensor(0.5880, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9969096183776855\n",
      "Batch: 250 , Combined Loss: tensor(0.5968, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6300094127655029\n",
      "Batch: 251 , Combined Loss: tensor(0.6543, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08302658796310425\n",
      "Batch: 252 , Combined Loss: tensor(0.9087, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4838341474533081\n",
      "Batch: 253 , Combined Loss: tensor(0.5894, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.078486442565918\n",
      "Batch: 254 , Combined Loss: tensor(0.7242, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7500437498092651\n",
      "Batch: 255 , Combined Loss: tensor(0.6327, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7095756530761719\n",
      "Batch: 256 , Combined Loss: tensor(0.6351, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9790676832199097\n",
      "Batch: 257 , Combined Loss: tensor(0.6497, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1039187908172607\n",
      "Batch: 258 , Combined Loss: tensor(0.6321, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.206885576248169\n",
      "Batch: 259 , Combined Loss: tensor(0.5739, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6755311489105225\n",
      "Batch: 260 , Combined Loss: tensor(0.6305, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8096383810043335\n",
      "Batch: 261 , Combined Loss: tensor(0.5830, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.015021800994873\n",
      "Batch: 262 , Combined Loss: tensor(0.6956, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.017150640487671\n",
      "Batch: 263 , Combined Loss: tensor(0.7466, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.105254888534546\n",
      "Batch: 264 , Combined Loss: tensor(0.5399, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.010038137435913\n",
      "Batch: 265 , Combined Loss: tensor(0.5720, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8369622230529785\n",
      "Batch: 266 , Combined Loss: tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9758665561676025\n",
      "Batch: 267 , Combined Loss: tensor(0.5926, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17931723594665527\n",
      "Batch: 268 , Combined Loss: tensor(0.6393, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1430399417877197\n",
      "Batch: 269 , Combined Loss: tensor(0.6796, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1235332489013672\n",
      "Batch: 270 , Combined Loss: tensor(0.7343, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38460731506347656\n",
      "Batch: 271 , Combined Loss: tensor(0.7488, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6620128154754639\n",
      "Batch: 272 , Combined Loss: tensor(0.6304, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7665433883666992\n",
      "Batch: 273 , Combined Loss: tensor(0.7190, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5513473749160767\n",
      "Batch: 274 , Combined Loss: tensor(0.7725, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.014474749565124512\n",
      "Batch: 275 , Combined Loss: tensor(0.5960, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8958708047866821\n",
      "Batch: 276 , Combined Loss: tensor(0.7108, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5985695123672485\n",
      "Batch: 277 , Combined Loss: tensor(0.8389, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7564483880996704\n",
      "Batch: 278 , Combined Loss: tensor(0.5680, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9771993160247803\n",
      "Batch: 279 , Combined Loss: tensor(0.6031, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3634169101715088\n",
      "Batch: 280 , Combined Loss: tensor(0.5910, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8241564035415649\n",
      "Batch: 281 , Combined Loss: tensor(0.6529, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1770949363708496\n",
      "Batch: 282 , Combined Loss: tensor(0.7752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26063501834869385\n",
      "Batch: 283 , Combined Loss: tensor(0.5472, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0710225105285645\n",
      "Batch: 284 , Combined Loss: tensor(0.6282, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4547063112258911\n",
      "Batch: 285 , Combined Loss: tensor(0.5998, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.016678810119628906\n",
      "Batch: 286 , Combined Loss: tensor(0.6973, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.101762056350708\n",
      "Batch: 287 , Combined Loss: tensor(0.8240, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.072066307067871\n",
      "Batch: 288 , Combined Loss: tensor(0.6549, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.100083351135254\n",
      "Batch: 289 , Combined Loss: tensor(0.6459, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7916951179504395\n",
      "Batch: 290 , Combined Loss: tensor(0.6858, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8462663888931274\n",
      "Batch: 291 , Combined Loss: tensor(0.6099, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.067136287689209\n",
      "Batch: 292 , Combined Loss: tensor(0.6509, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.128110408782959\n",
      "Batch: 293 , Combined Loss: tensor(0.5987, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9541510343551636\n",
      "Batch: 294 , Combined Loss: tensor(0.6336, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8347474336624146\n",
      "Batch: 295 , Combined Loss: tensor(0.5842, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.135047435760498\n",
      "Batch: 296 , Combined Loss: tensor(0.6693, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8975460529327393\n",
      "Batch: 297 , Combined Loss: tensor(0.6353, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6788870096206665\n",
      "Batch: 298 , Combined Loss: tensor(0.5512, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4205700159072876\n",
      "Batch: 299 , Combined Loss: tensor(0.6552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.132718563079834\n",
      "Batch: 300 , Combined Loss: tensor(0.7372, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9585882425308228\n",
      "Batch: 301 , Combined Loss: tensor(0.7182, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1857709884643555\n",
      "Batch: 302 , Combined Loss: tensor(0.6026, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.693798303604126\n",
      "Batch: 303 , Combined Loss: tensor(0.7342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9481477737426758\n",
      "Batch: 304 , Combined Loss: tensor(0.6981, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9726721048355103\n",
      "Batch: 305 , Combined Loss: tensor(0.6881, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9763302803039551\n",
      "Batch: 306 , Combined Loss: tensor(0.7250, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0133881568908691\n",
      "Batch: 307 , Combined Loss: tensor(0.6202, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48748505115509033\n",
      "Batch: 308 , Combined Loss: tensor(0.7465, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7106444835662842\n",
      "Batch: 309 , Combined Loss: tensor(0.6605, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.541303277015686\n",
      "Batch: 310 , Combined Loss: tensor(0.6361, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0392825603485107\n",
      "Batch: 311 , Combined Loss: tensor(0.6839, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0740478038787842\n",
      "Batch: 312 , Combined Loss: tensor(0.6492, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0179390907287598\n",
      "Batch: 313 , Combined Loss: tensor(0.7056, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5767768621444702\n",
      "Batch: 314 , Combined Loss: tensor(0.5934, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9811681509017944\n",
      "Batch: 315 , Combined Loss: tensor(0.5856, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0234122276306152\n",
      "Batch: 316 , Combined Loss: tensor(0.5976, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7895622253417969\n",
      "Batch: 317 , Combined Loss: tensor(0.5557, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2634820938110352\n",
      "Batch: 318 , Combined Loss: tensor(0.8425, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8184711933135986\n",
      "Batch: 319 , Combined Loss: tensor(0.6371, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0898232460021973\n",
      "Batch: 320 , Combined Loss: tensor(0.5950, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0716784000396729\n",
      "Batch: 321 , Combined Loss: tensor(0.6778, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1888580322265625\n",
      "Batch: 322 , Combined Loss: tensor(0.7008, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3806072473526001\n",
      "Batch: 323 , Combined Loss: tensor(0.8217, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6603310108184814\n",
      "Batch: 324 , Combined Loss: tensor(0.5894, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9725008010864258\n",
      "Batch: 325 , Combined Loss: tensor(0.7200, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4287654161453247\n",
      "Batch: 326 , Combined Loss: tensor(0.5381, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9069193601608276\n",
      "Batch: 327 , Combined Loss: tensor(0.7250, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1130943298339844\n",
      "Batch: 328 , Combined Loss: tensor(0.5775, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3794776201248169\n",
      "Batch: 329 , Combined Loss: tensor(0.6189, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8696421384811401\n",
      "Batch: 330 , Combined Loss: tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9527814388275146\n",
      "Batch: 331 , Combined Loss: tensor(0.8032, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8814096450805664\n",
      "Batch: 332 , Combined Loss: tensor(0.5455, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28954458236694336\n",
      "Batch: 333 , Combined Loss: tensor(0.6967, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.947517991065979\n",
      "Batch: 334 , Combined Loss: tensor(0.6432, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1195728778839111\n",
      "Batch: 335 , Combined Loss: tensor(0.8359, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5800884962081909\n",
      "Batch: 336 , Combined Loss: tensor(0.6913, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8673921823501587\n",
      "Batch: 337 , Combined Loss: tensor(0.6272, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9692189693450928\n",
      "Batch: 338 , Combined Loss: tensor(0.8096, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9953984022140503\n",
      "Batch: 339 , Combined Loss: tensor(0.5553, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1032195091247559\n",
      "Batch: 340 , Combined Loss: tensor(0.7191, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5152684450149536\n",
      "Batch: 341 , Combined Loss: tensor(0.6508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9060395956039429\n",
      "Batch: 342 , Combined Loss: tensor(0.7358, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.080444574356079\n",
      "Batch: 343 , Combined Loss: tensor(0.7020, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06215792894363403\n",
      "Batch: 344 , Combined Loss: tensor(0.6535, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.144437551498413\n",
      "Batch: 345 , Combined Loss: tensor(0.5903, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0381431579589844\n",
      "Batch: 346 , Combined Loss: tensor(0.5986, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0078661441802979\n",
      "Batch: 347 , Combined Loss: tensor(0.5439, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.748083233833313\n",
      "Batch: 348 , Combined Loss: tensor(0.7521, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4514493942260742\n",
      "Batch: 349 , Combined Loss: tensor(0.6100, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.029315710067749\n",
      "Batch: 350 , Combined Loss: tensor(0.7701, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.057680606842041\n",
      "Batch: 351 , Combined Loss: tensor(0.7311, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5988502502441406\n",
      "Batch: 352 , Combined Loss: tensor(0.7635, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6741307973861694\n",
      "Batch: 353 , Combined Loss: tensor(0.6536, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5674020051956177\n",
      "Batch: 354 , Combined Loss: tensor(0.5619, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8734322786331177\n",
      "Batch: 355 , Combined Loss: tensor(0.7559, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9437892436981201\n",
      "Batch: 356 , Combined Loss: tensor(0.6018, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1593518257141113\n",
      "Batch: 357 , Combined Loss: tensor(0.5724, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14556372165679932\n",
      "Batch: 358 , Combined Loss: tensor(0.6733, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25364184379577637\n",
      "Batch: 359 , Combined Loss: tensor(0.5442, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0239357948303223\n",
      "Batch: 360 , Combined Loss: tensor(0.5897, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.866928219795227\n",
      "Batch: 361 , Combined Loss: tensor(0.6741, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19920992851257324\n",
      "Batch: 362 , Combined Loss: tensor(0.6110, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8329139947891235\n",
      "Batch: 363 , Combined Loss: tensor(0.7784, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0510082244873047\n",
      "Batch: 364 , Combined Loss: tensor(0.5952, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8893028497695923\n",
      "Batch: 365 , Combined Loss: tensor(0.8013, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.116025686264038\n",
      "Batch: 366 , Combined Loss: tensor(0.8119, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0195930004119873\n",
      "Batch: 367 , Combined Loss: tensor(0.6143, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5774909257888794\n",
      "Batch: 368 , Combined Loss: tensor(0.6352, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7559933662414551\n",
      "Batch: 369 , Combined Loss: tensor(0.5951, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0011229515075684\n",
      "Batch: 370 , Combined Loss: tensor(0.6387, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8899049758911133\n",
      "Batch: 371 , Combined Loss: tensor(0.5623, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6280015707015991\n",
      "Batch: 372 , Combined Loss: tensor(0.5983, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0491979122161865\n",
      "Batch: 373 , Combined Loss: tensor(1.1193, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5304298400878906\n",
      "Batch: 374 , Combined Loss: tensor(0.5983, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7727007865905762\n",
      "Batch: 375 , Combined Loss: tensor(0.5968, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8232005834579468\n",
      "Batch: 376 , Combined Loss: tensor(0.5034, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7217822074890137\n",
      "Batch: 377 , Combined Loss: tensor(0.8613, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5432145595550537\n",
      "Batch: 378 , Combined Loss: tensor(0.6816, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7505736351013184\n",
      "Batch: 379 , Combined Loss: tensor(0.7512, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9692943096160889\n",
      "Batch: 380 , Combined Loss: tensor(0.5559, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6183426380157471\n",
      "Batch: 381 , Combined Loss: tensor(0.7181, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7141265869140625\n",
      "Batch: 382 , Combined Loss: tensor(0.7002, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15079116821289062\n",
      "Batch: 383 , Combined Loss: tensor(0.7389, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8770143985748291\n",
      "Batch: 384 , Combined Loss: tensor(0.6170, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4748009443283081\n",
      "Batch: 385 , Combined Loss: tensor(0.6905, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9288229942321777\n",
      "Batch: 386 , Combined Loss: tensor(0.6191, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9315851926803589\n",
      "Batch: 387 , Combined Loss: tensor(0.6077, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6726639270782471\n",
      "Batch: 388 , Combined Loss: tensor(0.8068, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29542624950408936\n",
      "Batch: 389 , Combined Loss: tensor(0.6502, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1568843126296997\n",
      "Batch: 390 , Combined Loss: tensor(0.6147, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0048136711120605\n",
      "Batch: 391 , Combined Loss: tensor(0.6346, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06259047985076904\n",
      "Batch: 392 , Combined Loss: tensor(0.5816, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.610593318939209\n",
      "Batch: 393 , Combined Loss: tensor(0.7876, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5283722877502441\n",
      "Batch: 394 , Combined Loss: tensor(0.6440, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5125374794006348\n",
      "Batch: 395 , Combined Loss: tensor(0.5975, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1496860980987549\n",
      "Batch: 396 , Combined Loss: tensor(0.7334, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7039828300476074\n",
      "Batch: 397 , Combined Loss: tensor(0.6942, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7194932699203491\n",
      "Batch: 398 , Combined Loss: tensor(0.9547, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5704562664031982\n",
      "Batch: 399 , Combined Loss: tensor(0.7217, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8807753324508667\n",
      "Batch: 400 , Combined Loss: tensor(0.6239, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27588725090026855\n",
      "Batch: 401 , Combined Loss: tensor(0.6836, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.006122767925262451\n",
      "Batch: 402 , Combined Loss: tensor(0.6595, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6354132890701294\n",
      "Batch: 403 , Combined Loss: tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0090816020965576\n",
      "Batch: 404 , Combined Loss: tensor(0.6459, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0714170932769775\n",
      "Batch: 405 , Combined Loss: tensor(0.5881, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9741394519805908\n",
      "Batch: 406 , Combined Loss: tensor(0.7001, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1073265075683594\n",
      "Batch: 407 , Combined Loss: tensor(0.5623, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.236029863357544\n",
      "Batch: 408 , Combined Loss: tensor(0.7984, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5730949640274048\n",
      "Batch: 409 , Combined Loss: tensor(0.6418, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0332188606262207\n",
      "Batch: 410 , Combined Loss: tensor(0.6319, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3823251724243164\n",
      "Batch: 411 , Combined Loss: tensor(0.5834, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7167870998382568\n",
      "Batch: 412 , Combined Loss: tensor(0.6174, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.731839656829834\n",
      "Batch: 413 , Combined Loss: tensor(0.5763, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9953029155731201\n",
      "Batch: 414 , Combined Loss: tensor(0.6854, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09048503637313843\n",
      "Batch: 415 , Combined Loss: tensor(0.5852, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9625504016876221\n",
      "Batch: 416 , Combined Loss: tensor(0.7768, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5465198755264282\n",
      "Batch: 417 , Combined Loss: tensor(0.5283, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0790441036224365\n",
      "Batch: 418 , Combined Loss: tensor(0.5958, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7615674734115601\n",
      "Batch: 419 , Combined Loss: tensor(0.7011, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4622443914413452\n",
      "Batch: 420 , Combined Loss: tensor(0.6233, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6400474309921265\n",
      "Batch: 421 , Combined Loss: tensor(0.5855, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6596511602401733\n",
      "Batch: 422 , Combined Loss: tensor(0.6489, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8185387849807739\n",
      "Batch: 423 , Combined Loss: tensor(0.6228, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2677662372589111\n",
      "Batch: 424 , Combined Loss: tensor(0.6492, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.10225248336792\n",
      "Batch: 425 , Combined Loss: tensor(0.5691, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3001762628555298\n",
      "Batch: 426 , Combined Loss: tensor(0.6803, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.024648427963256836\n",
      "Batch: 427 , Combined Loss: tensor(0.6130, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1277356147766113\n",
      "Batch: 428 , Combined Loss: tensor(0.6139, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9011645317077637\n",
      "Batch: 429 , Combined Loss: tensor(0.5347, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.710962176322937\n",
      "Batch: 430 , Combined Loss: tensor(0.7279, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9822133779525757\n",
      "Batch: 431 , Combined Loss: tensor(0.5888, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1692371368408203\n",
      "Batch: 432 , Combined Loss: tensor(0.7519, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1409292221069336\n",
      "Batch: 433 , Combined Loss: tensor(0.6501, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0208673477172852\n",
      "Batch: 434 , Combined Loss: tensor(0.6830, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7053965330123901\n",
      "Batch: 435 , Combined Loss: tensor(0.6235, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.985549807548523\n",
      "Batch: 436 , Combined Loss: tensor(0.6337, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9774472713470459\n",
      "Batch: 437 , Combined Loss: tensor(0.6180, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9624524116516113\n",
      "Batch: 438 , Combined Loss: tensor(0.6752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9912536144256592\n",
      "Batch: 439 , Combined Loss: tensor(0.6384, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7260135412216187\n",
      "Batch: 440 , Combined Loss: tensor(0.6244, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.010291337966919\n",
      "Batch: 441 , Combined Loss: tensor(0.7584, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.705376386642456\n",
      "Batch: 442 , Combined Loss: tensor(0.9467, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7696402072906494\n",
      "Batch: 443 , Combined Loss: tensor(0.6516, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9310319423675537\n",
      "Batch: 444 , Combined Loss: tensor(0.9162, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27311599254608154\n",
      "Batch: 445 , Combined Loss: tensor(0.6277, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7884407043457031\n",
      "Batch: 446 , Combined Loss: tensor(0.6615, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35064828395843506\n",
      "Batch: 447 , Combined Loss: tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5645051002502441\n",
      "Batch: 448 , Combined Loss: tensor(0.6616, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6749682426452637\n",
      "Batch: 449 , Combined Loss: tensor(0.8652, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.812934398651123\n",
      "Batch: 450 , Combined Loss: tensor(0.9070, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8996016979217529\n",
      "Batch: 451 , Combined Loss: tensor(0.6374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9071319103240967\n",
      "Batch: 452 , Combined Loss: tensor(0.5938, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1531918048858643\n",
      "Batch: 453 , Combined Loss: tensor(0.6327, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6853666305541992\n",
      "Batch: 454 , Combined Loss: tensor(0.6336, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7732024192810059\n",
      "Batch: 455 , Combined Loss: tensor(0.7015, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5384365320205688\n",
      "Batch: 456 , Combined Loss: tensor(0.4835, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5204169750213623\n",
      "Batch: 457 , Combined Loss: tensor(0.6299, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8097119331359863\n",
      "Batch: 458 , Combined Loss: tensor(0.8916, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.232824444770813\n",
      "Batch: 459 , Combined Loss: tensor(0.7176, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11211848258972168\n",
      "Batch: 460 , Combined Loss: tensor(0.6315, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0973174571990967\n",
      "Batch: 461 , Combined Loss: tensor(0.6176, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9226316213607788\n",
      "Batch: 462 , Combined Loss: tensor(0.5932, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2326596975326538\n",
      "Batch: 463 , Combined Loss: tensor(0.6303, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17278027534484863\n",
      "Batch: 464 , Combined Loss: tensor(0.7036, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11109709739685059\n",
      "Batch: 465 , Combined Loss: tensor(0.6088, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8602275848388672\n",
      "Batch: 466 , Combined Loss: tensor(0.8489, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7363307476043701\n",
      "Batch: 467 , Combined Loss: tensor(0.8109, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.911424994468689\n",
      "Batch: 468 , Combined Loss: tensor(0.7102, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8723101615905762\n",
      "Batch: 469 , Combined Loss: tensor(0.6168, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07274842262268066\n",
      "Batch: 470 , Combined Loss: tensor(0.7765, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3530372381210327\n",
      "Batch: 471 , Combined Loss: tensor(0.6313, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1831412315368652\n",
      "Batch: 472 , Combined Loss: tensor(0.5334, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8346763849258423\n",
      "Batch: 473 , Combined Loss: tensor(0.5956, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6394628286361694\n",
      "Batch: 474 , Combined Loss: tensor(0.6805, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6871500015258789\n",
      "Batch: 475 , Combined Loss: tensor(0.8603, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.679167628288269\n",
      "Batch: 476 , Combined Loss: tensor(0.6853, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3249170780181885\n",
      "Batch: 477 , Combined Loss: tensor(0.7320, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8478994369506836\n",
      "Batch: 478 , Combined Loss: tensor(0.6709, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44875621795654297\n",
      "Batch: 479 , Combined Loss: tensor(0.7534, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9974441528320312\n",
      "Batch: 480 , Combined Loss: tensor(0.6454, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8903535604476929\n",
      "Batch: 481 , Combined Loss: tensor(0.6674, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0885555744171143\n",
      "Batch: 482 , Combined Loss: tensor(0.6538, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24811172485351562\n",
      "Batch: 483 , Combined Loss: tensor(0.7484, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5303624868392944\n",
      "Batch: 484 , Combined Loss: tensor(0.6155, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.062084674835205\n",
      "Batch: 485 , Combined Loss: tensor(0.6804, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0165021419525146\n",
      "Batch: 486 , Combined Loss: tensor(0.6909, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0100188255310059\n",
      "Batch: 487 , Combined Loss: tensor(0.6065, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2645156383514404\n",
      "Batch: 488 , Combined Loss: tensor(0.8026, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6385780572891235\n",
      "Batch: 489 , Combined Loss: tensor(0.6618, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1399104595184326\n",
      "Batch: 490 , Combined Loss: tensor(0.6562, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9144679307937622\n",
      "Batch: 491 , Combined Loss: tensor(0.6711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41883790493011475\n",
      "Batch: 492 , Combined Loss: tensor(0.5805, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8308740854263306\n",
      "Batch: 493 , Combined Loss: tensor(0.6635, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4912087917327881\n",
      "Batch: 494 , Combined Loss: tensor(0.5559, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8615190982818604\n",
      "Batch: 495 , Combined Loss: tensor(0.6863, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0545737743377686\n",
      "Batch: 496 , Combined Loss: tensor(0.5415, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7579587697982788\n",
      "Batch: 497 , Combined Loss: tensor(0.5990, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9184569120407104\n",
      "Batch: 498 , Combined Loss: tensor(0.8589, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5282212495803833\n",
      "Batch: 499 , Combined Loss: tensor(0.8507, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45994997024536133\n",
      "Batch: 500 , Combined Loss: tensor(0.5085, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.898759126663208\n",
      "Batch: 501 , Combined Loss: tensor(0.6832, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9846929311752319\n",
      "Batch: 502 , Combined Loss: tensor(0.6031, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9020541906356812\n",
      "Batch: 503 , Combined Loss: tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2791109085083008\n",
      "Batch: 504 , Combined Loss: tensor(0.6100, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31333887577056885\n",
      "Batch: 505 , Combined Loss: tensor(0.7992, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6232215166091919\n",
      "Batch: 506 , Combined Loss: tensor(0.7394, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9472739696502686\n",
      "Batch: 507 , Combined Loss: tensor(0.7472, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.233870506286621\n",
      "Batch: 508 , Combined Loss: tensor(0.8076, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5479844808578491\n",
      "Batch: 509 , Combined Loss: tensor(0.6826, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5762187242507935\n",
      "Batch: 510 , Combined Loss: tensor(0.7066, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7402671575546265\n",
      "Batch: 511 , Combined Loss: tensor(0.5770, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0341541767120361\n",
      "Batch: 512 , Combined Loss: tensor(0.6844, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.006150484085083\n",
      "Batch: 513 , Combined Loss: tensor(0.6960, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9665250778198242\n",
      "Batch: 514 , Combined Loss: tensor(0.9811, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.661426305770874\n",
      "Batch: 515 , Combined Loss: tensor(0.6185, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9109117984771729\n",
      "Batch: 516 , Combined Loss: tensor(0.6382, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6628912687301636\n",
      "Batch: 517 , Combined Loss: tensor(0.6607, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7808226346969604\n",
      "Batch: 518 , Combined Loss: tensor(0.7102, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9169771671295166\n",
      "Batch: 519 , Combined Loss: tensor(0.7800, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8862048387527466\n",
      "Batch: 520 , Combined Loss: tensor(0.6337, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0420112609863281\n",
      "Batch: 521 , Combined Loss: tensor(0.7912, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7112377882003784\n",
      "Batch: 522 , Combined Loss: tensor(0.6757, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1539759635925293\n",
      "Batch: 523 , Combined Loss: tensor(0.7009, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.790162205696106\n",
      "Batch: 524 , Combined Loss: tensor(0.6992, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15690350532531738\n",
      "Batch: 525 , Combined Loss: tensor(0.6430, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28794968128204346\n",
      "Batch: 526 , Combined Loss: tensor(0.7097, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37933599948883057\n",
      "Batch: 527 , Combined Loss: tensor(0.7019, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8294656276702881\n",
      "Batch: 528 , Combined Loss: tensor(0.7492, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8329246044158936\n",
      "Batch: 529 , Combined Loss: tensor(0.6854, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8751108646392822\n",
      "Batch: 530 , Combined Loss: tensor(0.8405, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7996402978897095\n",
      "Batch: 531 , Combined Loss: tensor(0.6946, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9632492065429688\n",
      "Batch: 532 , Combined Loss: tensor(0.7092, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7438939809799194\n",
      "Batch: 533 , Combined Loss: tensor(0.7134, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6954578161239624\n",
      "Batch: 534 , Combined Loss: tensor(0.7772, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9475822448730469\n",
      "Batch: 535 , Combined Loss: tensor(0.5960, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1509053707122803\n",
      "Batch: 536 , Combined Loss: tensor(0.6644, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9236329793930054\n",
      "Batch: 537 , Combined Loss: tensor(0.6451, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8874562978744507\n",
      "Batch: 538 , Combined Loss: tensor(0.6562, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1868386268615723\n",
      "Batch: 539 , Combined Loss: tensor(0.7329, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20153045654296875\n",
      "Batch: 540 , Combined Loss: tensor(0.6009, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9255428314208984\n",
      "Batch: 541 , Combined Loss: tensor(0.6384, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6923465728759766\n",
      "Batch: 542 , Combined Loss: tensor(0.7988, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3236745595932007\n",
      "Batch: 543 , Combined Loss: tensor(0.6047, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21832895278930664\n",
      "Batch: 544 , Combined Loss: tensor(0.6081, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0573952198028564\n",
      "Batch: 545 , Combined Loss: tensor(0.6493, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0137767791748047\n",
      "Batch: 546 , Combined Loss: tensor(0.5597, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.110762357711792\n",
      "Batch: 547 , Combined Loss: tensor(0.6483, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0644116401672363\n",
      "Batch: 548 , Combined Loss: tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8598843812942505\n",
      "Batch: 549 , Combined Loss: tensor(0.6628, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0761356353759766\n",
      "Batch: 550 , Combined Loss: tensor(0.7491, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3621666431427002\n",
      "Batch: 551 , Combined Loss: tensor(0.5630, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07498610019683838\n",
      "Batch: 552 , Combined Loss: tensor(0.6250, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.913741946220398\n",
      "Batch: 553 , Combined Loss: tensor(0.6126, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7581139802932739\n",
      "Batch: 554 , Combined Loss: tensor(0.5994, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0101993083953857\n",
      "Batch: 555 , Combined Loss: tensor(0.6720, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9293153285980225\n",
      "Batch: 556 , Combined Loss: tensor(0.6187, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33374786376953125\n",
      "Batch: 557 , Combined Loss: tensor(0.6103, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3166388273239136\n",
      "Batch: 558 , Combined Loss: tensor(0.7380, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9417614936828613\n",
      "Batch: 559 , Combined Loss: tensor(0.6769, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6171154975891113\n",
      "Batch: 560 , Combined Loss: tensor(0.5975, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.116163730621338\n",
      "Batch: 561 , Combined Loss: tensor(0.9459, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3943215608596802\n",
      "Batch: 562 , Combined Loss: tensor(0.6436, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3633146286010742\n",
      "Batch: 563 , Combined Loss: tensor(0.7868, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6372126340866089\n",
      "Batch: 564 , Combined Loss: tensor(0.6826, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1104485988616943\n",
      "Batch: 565 , Combined Loss: tensor(0.7135, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8913431167602539\n",
      "Batch: 566 , Combined Loss: tensor(0.6337, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9441236257553101\n",
      "Batch: 567 , Combined Loss: tensor(0.5978, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9163448810577393\n",
      "Batch: 568 , Combined Loss: tensor(0.7333, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.083517074584961\n",
      "Batch: 569 , Combined Loss: tensor(0.6123, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8038811683654785\n",
      "Batch: 570 , Combined Loss: tensor(0.7551, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7367939949035645\n",
      "Batch: 571 , Combined Loss: tensor(0.6311, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9590777158737183\n",
      "Batch: 572 , Combined Loss: tensor(0.6883, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8981033563613892\n",
      "Batch: 573 , Combined Loss: tensor(0.6343, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47452759742736816\n",
      "Batch: 574 , Combined Loss: tensor(0.6077, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6814724206924438\n",
      "Batch: 575 , Combined Loss: tensor(0.6029, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.850732684135437\n",
      "Batch: 576 , Combined Loss: tensor(0.6118, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9583345651626587\n",
      "Batch: 577 , Combined Loss: tensor(0.6452, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9035531282424927\n",
      "Batch: 578 , Combined Loss: tensor(0.5427, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5060967206954956\n",
      "Batch: 579 , Combined Loss: tensor(0.5962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5629199743270874\n",
      "Batch: 580 , Combined Loss: tensor(0.6006, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8297669887542725\n",
      "Batch: 581 , Combined Loss: tensor(0.5566, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7047497034072876\n",
      "Batch: 582 , Combined Loss: tensor(0.6509, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7305684089660645\n",
      "Batch: 583 , Combined Loss: tensor(0.6361, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0224957466125488\n",
      "Batch: 584 , Combined Loss: tensor(0.6359, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.836764931678772\n",
      "Batch: 585 , Combined Loss: tensor(0.6783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49512314796447754\n",
      "Batch: 586 , Combined Loss: tensor(0.6568, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8723256587982178\n",
      "Batch: 587 , Combined Loss: tensor(0.7413, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2911231517791748\n",
      "Batch: 588 , Combined Loss: tensor(0.6745, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4491758346557617\n",
      "Batch: 589 , Combined Loss: tensor(0.6089, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7835544347763062\n",
      "Batch: 590 , Combined Loss: tensor(0.6654, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0863862037658691\n",
      "Batch: 591 , Combined Loss: tensor(0.6587, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9968656301498413\n",
      "Batch: 592 , Combined Loss: tensor(0.6642, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.079735517501831\n",
      "Batch: 593 , Combined Loss: tensor(0.7297, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.060784101486206\n",
      "Batch: 594 , Combined Loss: tensor(0.6599, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.69781494140625\n",
      "Batch: 595 , Combined Loss: tensor(0.6293, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.532440185546875\n",
      "Batch: 596 , Combined Loss: tensor(0.5663, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9208395481109619\n",
      "Batch: 597 , Combined Loss: tensor(0.6467, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29773175716400146\n",
      "Batch: 598 , Combined Loss: tensor(0.5622, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2053735256195068\n",
      "Batch: 599 , Combined Loss: tensor(0.5967, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1315655708312988\n",
      "Batch: 600 , Combined Loss: tensor(0.6338, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6825075149536133\n",
      "Batch: 601 , Combined Loss: tensor(0.6083, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0341660976409912\n",
      "Batch: 602 , Combined Loss: tensor(0.5362, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7638590335845947\n",
      "Batch: 603 , Combined Loss: tensor(0.6029, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7881884574890137\n",
      "Batch: 604 , Combined Loss: tensor(0.5963, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.108203411102295\n",
      "Batch: 605 , Combined Loss: tensor(0.6679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1139352321624756\n",
      "Batch: 606 , Combined Loss: tensor(0.6663, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9004573822021484\n",
      "Batch: 607 , Combined Loss: tensor(0.6244, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6167911291122437\n",
      "Batch: 608 , Combined Loss: tensor(0.6334, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9238309860229492\n",
      "Batch: 609 , Combined Loss: tensor(0.6271, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0049316883087158\n",
      "Batch: 610 , Combined Loss: tensor(0.6200, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7018336057662964\n",
      "Batch: 611 , Combined Loss: tensor(0.9537, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2194931507110596\n",
      "Batch: 612 , Combined Loss: tensor(0.5899, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9507911205291748\n",
      "Batch: 613 , Combined Loss: tensor(0.6646, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.839539647102356\n",
      "Batch: 614 , Combined Loss: tensor(0.6129, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0176029205322266\n",
      "Batch: 615 , Combined Loss: tensor(0.6813, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8091703653335571\n",
      "Batch: 616 , Combined Loss: tensor(0.5939, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1460106372833252\n",
      "Batch: 617 , Combined Loss: tensor(0.5626, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0217595100402832\n",
      "Batch: 618 , Combined Loss: tensor(0.5960, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5476353168487549\n",
      "Batch: 619 , Combined Loss: tensor(0.6152, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9993970394134521\n",
      "Batch: 620 , Combined Loss: tensor(0.8228, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5465148687362671\n",
      "Batch: 621 , Combined Loss: tensor(0.7263, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8874483108520508\n",
      "Batch: 622 , Combined Loss: tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1542332172393799\n",
      "Batch: 623 , Combined Loss: tensor(0.7193, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.320478916168213\n",
      "Batch: 624 , Combined Loss: tensor(0.5786, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8706238269805908\n",
      "Batch: 625 , Combined Loss: tensor(0.6129, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9694255590438843\n",
      "Batch: 626 , Combined Loss: tensor(0.6734, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8667713403701782\n",
      "Batch: 627 , Combined Loss: tensor(0.7526, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0131433010101318\n",
      "Batch: 628 , Combined Loss: tensor(0.6450, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1036608219146729\n",
      "----------Epoch 23, Loss: 0.6691881365635816, Accuracy: 0.9753216643401663, Dice Coef: [0.9892265975759594, 0.6151180122477288, 0.6650872736722667, 0.7389719304980398], Dice Coef Necrotic: 1.0387701213160543, Dice Coef Edema: 1.0510999844160493, Dice Coef Enhancing: 1.0539307737371144, Sensitivity: [0.9807470714723742, 0.741006009820051, 0.8709839421823408, 0.893703492497507], Specificity: [0.9648611846902602, 0.9979525181940136, 0.982636388894674, 0.996129985833585], Precision: [0.9979166868949733, 0.6032434036525944, 0.5687768894134534, 0.6712476306752967]\n",
      "Saving without nn.DataParallel\n",
      "Batch: 0 , Combined Loss: tensor(0.6924, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0456795692443848\n",
      "Batch: 1 , Combined Loss: tensor(0.6723, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5261482000350952\n",
      "Batch: 2 , Combined Loss: tensor(0.6389, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.026479959487915\n",
      "Batch: 3 , Combined Loss: tensor(0.6647, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.777030348777771\n",
      "Batch: 4 , Combined Loss: tensor(0.6034, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7617473602294922\n",
      "Batch: 5 , Combined Loss: tensor(0.6007, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0636625289916992\n",
      "Batch: 6 , Combined Loss: tensor(0.6332, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1629118919372559\n",
      "Batch: 7 , Combined Loss: tensor(0.6538, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0964288711547852\n",
      "Batch: 8 , Combined Loss: tensor(0.7085, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8496583700180054\n",
      "Batch: 9 , Combined Loss: tensor(0.6277, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8476393222808838\n",
      "Batch: 10 , Combined Loss: tensor(0.7041, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0109052658081055\n",
      "Batch: 11 , Combined Loss: tensor(0.7508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9249967336654663\n",
      "Batch: 12 , Combined Loss: tensor(0.6653, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8923125267028809\n",
      "Batch: 13 , Combined Loss: tensor(0.9558, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28401315212249756\n",
      "Batch: 14 , Combined Loss: tensor(0.6784, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2482566833496094\n",
      "Batch: 15 , Combined Loss: tensor(0.6117, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1909756660461426\n",
      "Batch: 16 , Combined Loss: tensor(0.8396, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8300542831420898\n",
      "Batch: 17 , Combined Loss: tensor(0.8743, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19888651371002197\n",
      "Batch: 18 , Combined Loss: tensor(0.5355, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0522031784057617\n",
      "Batch: 19 , Combined Loss: tensor(0.7062, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2527103424072266\n",
      "Batch: 20 , Combined Loss: tensor(0.6411, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9921371936798096\n",
      "Batch: 21 , Combined Loss: tensor(0.6372, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9469150304794312\n",
      "Batch: 22 , Combined Loss: tensor(0.5524, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9854514598846436\n",
      "Batch: 23 , Combined Loss: tensor(0.5367, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9695694446563721\n",
      "Batch: 24 , Combined Loss: tensor(0.6924, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8600736856460571\n",
      "Batch: 25 , Combined Loss: tensor(0.5452, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1673076152801514\n",
      "Batch: 26 , Combined Loss: tensor(0.6983, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9619613885879517\n",
      "Batch: 27 , Combined Loss: tensor(0.6920, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9064176082611084\n",
      "Batch: 28 , Combined Loss: tensor(0.6663, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7590062618255615\n",
      "Batch: 29 , Combined Loss: tensor(0.6828, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4324451684951782\n",
      "Batch: 30 , Combined Loss: tensor(0.6037, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2239630222320557\n",
      "Batch: 31 , Combined Loss: tensor(0.5999, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.157426118850708\n",
      "Batch: 32 , Combined Loss: tensor(0.6702, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9480736255645752\n",
      "Batch: 33 , Combined Loss: tensor(1.0708, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5320099592208862\n",
      "Batch: 34 , Combined Loss: tensor(0.5747, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8664509057998657\n",
      "Batch: 35 , Combined Loss: tensor(0.6656, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9822081327438354\n",
      "Batch: 36 , Combined Loss: tensor(0.6300, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.568423867225647\n",
      "Batch: 37 , Combined Loss: tensor(0.7802, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6047449111938477\n",
      "Batch: 38 , Combined Loss: tensor(0.5709, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.072901725769043\n",
      "Batch: 39 , Combined Loss: tensor(0.6435, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1012654304504395\n",
      "Batch: 40 , Combined Loss: tensor(0.7471, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8029509782791138\n",
      "Batch: 41 , Combined Loss: tensor(0.6112, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9616140127182007\n",
      "Batch: 42 , Combined Loss: tensor(0.7215, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33686256408691406\n",
      "Batch: 43 , Combined Loss: tensor(0.7033, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5165704488754272\n",
      "Batch: 44 , Combined Loss: tensor(0.5224, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.925544261932373\n",
      "Batch: 45 , Combined Loss: tensor(0.6921, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05074179172515869\n",
      "Batch: 46 , Combined Loss: tensor(0.6143, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2003793716430664\n",
      "Batch: 47 , Combined Loss: tensor(0.6110, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0242421627044678\n",
      "Batch: 48 , Combined Loss: tensor(0.5763, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1341214179992676\n",
      "Batch: 49 , Combined Loss: tensor(0.5330, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35748815536499023\n",
      "Batch: 50 , Combined Loss: tensor(0.5972, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0855660438537598\n",
      "Batch: 51 , Combined Loss: tensor(0.7064, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1004338264465332\n",
      "Batch: 52 , Combined Loss: tensor(0.6831, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.048478603363037\n",
      "Batch: 53 , Combined Loss: tensor(0.5768, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6616904735565186\n",
      "Batch: 54 , Combined Loss: tensor(0.6188, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8154302835464478\n",
      "Batch: 55 , Combined Loss: tensor(0.5677, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5605263710021973\n",
      "Batch: 56 , Combined Loss: tensor(0.6414, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31258201599121094\n",
      "Batch: 57 , Combined Loss: tensor(0.6648, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40291404724121094\n",
      "Batch: 58 , Combined Loss: tensor(0.8270, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7532768249511719\n",
      "Batch: 59 , Combined Loss: tensor(0.8822, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8929141759872437\n",
      "Batch: 60 , Combined Loss: tensor(0.5788, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3682898283004761\n",
      "Batch: 61 , Combined Loss: tensor(0.6196, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1757018566131592\n",
      "Batch: 62 , Combined Loss: tensor(0.6295, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22366511821746826\n",
      "Batch: 63 , Combined Loss: tensor(0.6399, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.133457899093628\n",
      "Batch: 64 , Combined Loss: tensor(0.6229, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2135331630706787\n",
      "Batch: 65 , Combined Loss: tensor(0.5562, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8553164005279541\n",
      "Batch: 66 , Combined Loss: tensor(0.6779, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7886617183685303\n",
      "Batch: 67 , Combined Loss: tensor(0.6271, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9384535551071167\n",
      "Batch: 68 , Combined Loss: tensor(0.5922, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4492417573928833\n",
      "Batch: 69 , Combined Loss: tensor(0.6876, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1354670524597168\n",
      "Batch: 70 , Combined Loss: tensor(0.6879, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7487610578536987\n",
      "Batch: 71 , Combined Loss: tensor(0.6194, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9788006544113159\n",
      "Batch: 72 , Combined Loss: tensor(0.6030, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.878455638885498\n",
      "Batch: 73 , Combined Loss: tensor(0.6620, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10621094703674316\n",
      "Batch: 74 , Combined Loss: tensor(0.7514, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8037149906158447\n",
      "Batch: 75 , Combined Loss: tensor(0.6152, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4387054443359375\n",
      "Batch: 76 , Combined Loss: tensor(0.6687, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5311557054519653\n",
      "Batch: 77 , Combined Loss: tensor(0.5885, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6536988019943237\n",
      "Batch: 78 , Combined Loss: tensor(0.7135, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0813987255096436\n",
      "Batch: 79 , Combined Loss: tensor(0.5609, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7685128450393677\n",
      "Batch: 80 , Combined Loss: tensor(0.5522, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.944233775138855\n",
      "Batch: 81 , Combined Loss: tensor(0.7317, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6589837074279785\n",
      "Batch: 82 , Combined Loss: tensor(0.7338, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4703458547592163\n",
      "Batch: 83 , Combined Loss: tensor(0.6264, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7452845573425293\n",
      "Batch: 84 , Combined Loss: tensor(0.7232, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31147122383117676\n",
      "Batch: 85 , Combined Loss: tensor(0.6219, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9376872777938843\n",
      "Batch: 86 , Combined Loss: tensor(0.6602, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7623614072799683\n",
      "Batch: 87 , Combined Loss: tensor(0.6480, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41100335121154785\n",
      "Batch: 88 , Combined Loss: tensor(0.6287, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8753920793533325\n",
      "Batch: 89 , Combined Loss: tensor(0.5895, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.031380534172058105\n",
      "Batch: 90 , Combined Loss: tensor(0.5975, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05891275405883789\n",
      "Batch: 91 , Combined Loss: tensor(0.5901, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6546643972396851\n",
      "Batch: 92 , Combined Loss: tensor(0.7774, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16410589218139648\n",
      "Batch: 93 , Combined Loss: tensor(0.6748, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9976885318756104\n",
      "Batch: 94 , Combined Loss: tensor(0.6041, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8506900072097778\n",
      "Batch: 95 , Combined Loss: tensor(0.8583, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9321321249008179\n",
      "Batch: 96 , Combined Loss: tensor(0.6787, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8537019491195679\n",
      "Batch: 97 , Combined Loss: tensor(0.7438, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7032148838043213\n",
      "Batch: 98 , Combined Loss: tensor(0.5962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7896021604537964\n",
      "Batch: 99 , Combined Loss: tensor(0.7403, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9225254058837891\n",
      "Batch: 100 , Combined Loss: tensor(0.7504, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7953046560287476\n",
      "Batch: 101 , Combined Loss: tensor(0.6395, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7952089309692383\n",
      "Batch: 102 , Combined Loss: tensor(0.6141, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9281421899795532\n",
      "Batch: 103 , Combined Loss: tensor(0.6415, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.076596736907959\n",
      "Batch: 104 , Combined Loss: tensor(0.6606, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8300567865371704\n",
      "Batch: 105 , Combined Loss: tensor(0.6703, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0385050773620605\n",
      "Batch: 106 , Combined Loss: tensor(0.7078, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34081077575683594\n",
      "Batch: 107 , Combined Loss: tensor(0.7098, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8515549898147583\n",
      "Batch: 108 , Combined Loss: tensor(0.6031, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9075042009353638\n",
      "Batch: 109 , Combined Loss: tensor(0.6671, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6170177459716797\n",
      "Batch: 110 , Combined Loss: tensor(0.6240, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8524006605148315\n",
      "Batch: 111 , Combined Loss: tensor(0.6044, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12367188930511475\n",
      "Batch: 112 , Combined Loss: tensor(0.7891, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6190078258514404\n",
      "Batch: 113 , Combined Loss: tensor(0.6212, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6995561122894287\n",
      "Batch: 114 , Combined Loss: tensor(0.6092, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8259049654006958\n",
      "Batch: 115 , Combined Loss: tensor(0.6291, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1773736476898193\n",
      "Batch: 116 , Combined Loss: tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6487681865692139\n",
      "Batch: 117 , Combined Loss: tensor(0.6007, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8450272083282471\n",
      "Batch: 118 , Combined Loss: tensor(0.5296, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7948781251907349\n",
      "Batch: 119 , Combined Loss: tensor(0.6359, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8893375396728516\n",
      "Batch: 120 , Combined Loss: tensor(0.5809, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35584723949432373\n",
      "Batch: 121 , Combined Loss: tensor(0.5738, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5106110572814941\n",
      "Batch: 122 , Combined Loss: tensor(0.5641, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7870303392410278\n",
      "Batch: 123 , Combined Loss: tensor(0.6685, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7952696084976196\n",
      "Batch: 124 , Combined Loss: tensor(0.7576, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30810678005218506\n",
      "Batch: 125 , Combined Loss: tensor(0.7862, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13121116161346436\n",
      "Batch: 126 , Combined Loss: tensor(0.5893, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31601715087890625\n",
      "Batch: 127 , Combined Loss: tensor(0.6040, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1145226955413818\n",
      "Batch: 128 , Combined Loss: tensor(0.6458, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7913786172866821\n",
      "Batch: 129 , Combined Loss: tensor(0.5838, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6564217805862427\n",
      "Batch: 130 , Combined Loss: tensor(0.7999, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6465458869934082\n",
      "Batch: 131 , Combined Loss: tensor(0.6370, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8929122686386108\n",
      "Batch: 132 , Combined Loss: tensor(0.6414, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7868667840957642\n",
      "Batch: 133 , Combined Loss: tensor(0.6619, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3300442695617676\n",
      "Batch: 134 , Combined Loss: tensor(0.6338, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9542959928512573\n",
      "Batch: 135 , Combined Loss: tensor(0.6169, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9825437068939209\n",
      "Batch: 136 , Combined Loss: tensor(0.6362, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29378461837768555\n",
      "Batch: 137 , Combined Loss: tensor(0.6296, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9452505111694336\n",
      "Batch: 138 , Combined Loss: tensor(0.6800, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8323774337768555\n",
      "Batch: 139 , Combined Loss: tensor(0.9292, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6630127429962158\n",
      "Batch: 140 , Combined Loss: tensor(0.5834, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45090651512145996\n",
      "Batch: 141 , Combined Loss: tensor(0.5597, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5549544095993042\n",
      "Batch: 142 , Combined Loss: tensor(0.5893, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6949182748794556\n",
      "Batch: 143 , Combined Loss: tensor(0.6393, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8702393770217896\n",
      "Batch: 144 , Combined Loss: tensor(0.8662, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12987375259399414\n",
      "Batch: 145 , Combined Loss: tensor(0.6678, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5153037309646606\n",
      "Batch: 146 , Combined Loss: tensor(0.6674, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25277626514434814\n",
      "Batch: 147 , Combined Loss: tensor(0.7455, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2345792055130005\n",
      "Batch: 148 , Combined Loss: tensor(0.5978, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9019722938537598\n",
      "Batch: 149 , Combined Loss: tensor(0.8262, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9052073955535889\n",
      "Batch: 150 , Combined Loss: tensor(0.6859, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6853681802749634\n",
      "Batch: 151 , Combined Loss: tensor(0.6571, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8668084144592285\n",
      "Batch: 152 , Combined Loss: tensor(0.5975, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9592316150665283\n",
      "Batch: 153 , Combined Loss: tensor(0.6843, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7966142892837524\n",
      "Batch: 154 , Combined Loss: tensor(0.6620, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0109269618988037\n",
      "Batch: 155 , Combined Loss: tensor(0.6592, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5169639587402344\n",
      "Batch: 156 , Combined Loss: tensor(0.6806, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0996274948120117\n",
      "Batch: 157 , Combined Loss: tensor(0.7596, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3315460681915283\n",
      "Batch: 158 , Combined Loss: tensor(0.6207, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6871143579483032\n",
      "Batch: 159 , Combined Loss: tensor(0.6662, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6915322542190552\n",
      "Batch: 160 , Combined Loss: tensor(0.6488, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4981733560562134\n",
      "Batch: 161 , Combined Loss: tensor(0.7067, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7916998863220215\n",
      "Batch: 162 , Combined Loss: tensor(0.6666, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11733090877532959\n",
      "Batch: 163 , Combined Loss: tensor(0.7907, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44176244735717773\n",
      "Batch: 164 , Combined Loss: tensor(0.8597, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0316205024719238\n",
      "Batch: 165 , Combined Loss: tensor(0.7239, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0452229976654053\n",
      "Batch: 166 , Combined Loss: tensor(0.6183, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7302299737930298\n",
      "Batch: 167 , Combined Loss: tensor(0.7198, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7747037410736084\n",
      "Batch: 168 , Combined Loss: tensor(0.7315, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9181104898452759\n",
      "Batch: 169 , Combined Loss: tensor(0.6324, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.079822063446045\n",
      "Batch: 170 , Combined Loss: tensor(0.6241, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8223493099212646\n",
      "Batch: 171 , Combined Loss: tensor(0.9360, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5173462629318237\n",
      "Batch: 172 , Combined Loss: tensor(0.6218, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22144567966461182\n",
      "Batch: 173 , Combined Loss: tensor(0.7024, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3073580265045166\n",
      "Batch: 174 , Combined Loss: tensor(0.6301, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1082167625427246\n",
      "Batch: 175 , Combined Loss: tensor(0.6392, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0784558653831482\n",
      "Batch: 176 , Combined Loss: tensor(0.6461, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7179087400436401\n",
      "Batch: 177 , Combined Loss: tensor(0.6572, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8352975845336914\n",
      "Batch: 178 , Combined Loss: tensor(0.7069, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5432993173599243\n",
      "Batch: 179 , Combined Loss: tensor(0.7292, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5646878480911255\n",
      "Batch: 180 , Combined Loss: tensor(0.6942, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.851150393486023\n",
      "Batch: 181 , Combined Loss: tensor(0.6368, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8913166522979736\n",
      "Batch: 182 , Combined Loss: tensor(0.5992, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0269224643707275\n",
      "Batch: 183 , Combined Loss: tensor(0.5664, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6280311346054077\n",
      "Batch: 184 , Combined Loss: tensor(0.7360, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8514928817749023\n",
      "Batch: 185 , Combined Loss: tensor(0.8833, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8110274076461792\n",
      "Batch: 186 , Combined Loss: tensor(0.6941, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15321820974349976\n",
      "Batch: 187 , Combined Loss: tensor(0.6282, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.387262225151062\n",
      "Batch: 188 , Combined Loss: tensor(0.6607, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6616952419281006\n",
      "Batch: 189 , Combined Loss: tensor(0.6419, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5538716316223145\n",
      "Batch: 190 , Combined Loss: tensor(0.6435, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4573601484298706\n",
      "Batch: 191 , Combined Loss: tensor(0.6479, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6799724102020264\n",
      "Batch: 192 , Combined Loss: tensor(0.6540, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6628156900405884\n",
      "Batch: 193 , Combined Loss: tensor(0.6143, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2528679370880127\n",
      "Batch: 194 , Combined Loss: tensor(0.6959, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6169129610061646\n",
      "Batch: 195 , Combined Loss: tensor(0.6015, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8152811527252197\n",
      "Batch: 196 , Combined Loss: tensor(0.6176, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9305545091629028\n",
      "Batch: 197 , Combined Loss: tensor(0.6790, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8837742805480957\n",
      "Batch: 198 , Combined Loss: tensor(0.6317, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8692283630371094\n",
      "Batch: 199 , Combined Loss: tensor(0.6178, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5512157678604126\n",
      "Batch: 200 , Combined Loss: tensor(0.7736, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03209763765335083\n",
      "Batch: 201 , Combined Loss: tensor(0.6352, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9476194381713867\n",
      "Batch: 202 , Combined Loss: tensor(0.6928, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17683935165405273\n",
      "Batch: 203 , Combined Loss: tensor(0.6875, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0937135219573975\n",
      "Batch: 204 , Combined Loss: tensor(0.6426, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8833796977996826\n",
      "Batch: 205 , Combined Loss: tensor(0.5508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9762942790985107\n",
      "Batch: 206 , Combined Loss: tensor(0.6398, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0177929401397705\n",
      "Batch: 207 , Combined Loss: tensor(0.8248, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.601104736328125\n",
      "Batch: 208 , Combined Loss: tensor(0.6339, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7087247371673584\n",
      "Batch: 209 , Combined Loss: tensor(0.9283, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8848270177841187\n",
      "Batch: 210 , Combined Loss: tensor(0.6991, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2683500051498413\n",
      "Batch: 211 , Combined Loss: tensor(0.6416, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7589845657348633\n",
      "Batch: 212 , Combined Loss: tensor(0.6650, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3909972906112671\n",
      "Batch: 213 , Combined Loss: tensor(0.7010, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9068186283111572\n",
      "Batch: 214 , Combined Loss: tensor(0.8680, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6332391500473022\n",
      "Batch: 215 , Combined Loss: tensor(0.5756, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8097361326217651\n",
      "Batch: 216 , Combined Loss: tensor(0.5390, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5083352327346802\n",
      "Batch: 217 , Combined Loss: tensor(0.6531, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.917100191116333\n",
      "Batch: 218 , Combined Loss: tensor(0.6468, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7896292209625244\n",
      "Batch: 219 , Combined Loss: tensor(0.8735, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3740807771682739\n",
      "Batch: 220 , Combined Loss: tensor(0.6253, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8755043745040894\n",
      "Batch: 221 , Combined Loss: tensor(0.5538, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6733349561691284\n",
      "Batch: 222 , Combined Loss: tensor(0.6335, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6819256544113159\n",
      "Batch: 223 , Combined Loss: tensor(0.6628, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8666908740997314\n",
      "Batch: 224 , Combined Loss: tensor(0.5310, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4400712251663208\n",
      "Batch: 225 , Combined Loss: tensor(0.7957, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0012881755828857\n",
      "Batch: 226 , Combined Loss: tensor(0.7158, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7234736680984497\n",
      "Batch: 227 , Combined Loss: tensor(0.6807, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9895524978637695\n",
      "Batch: 228 , Combined Loss: tensor(0.6369, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0784516334533691\n",
      "Batch: 229 , Combined Loss: tensor(0.5715, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8117538690567017\n",
      "Batch: 230 , Combined Loss: tensor(0.5958, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6771678924560547\n",
      "Batch: 231 , Combined Loss: tensor(0.6392, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0739586353302002\n",
      "Batch: 232 , Combined Loss: tensor(0.5137, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4853708744049072\n",
      "Batch: 233 , Combined Loss: tensor(0.5626, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8575286865234375\n",
      "Batch: 234 , Combined Loss: tensor(0.6157, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19872748851776123\n",
      "Batch: 235 , Combined Loss: tensor(0.7214, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8346569538116455\n",
      "Batch: 236 , Combined Loss: tensor(0.7188, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8748410940170288\n",
      "Batch: 237 , Combined Loss: tensor(0.7260, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.711552619934082\n",
      "Batch: 238 , Combined Loss: tensor(0.6323, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.548072099685669\n",
      "Batch: 239 , Combined Loss: tensor(0.6486, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4681488275527954\n",
      "Batch: 240 , Combined Loss: tensor(0.6047, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8961489200592041\n",
      "Batch: 241 , Combined Loss: tensor(0.8187, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.701324462890625\n",
      "Batch: 242 , Combined Loss: tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9340000152587891\n",
      "Batch: 243 , Combined Loss: tensor(0.7568, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6786712408065796\n",
      "Batch: 244 , Combined Loss: tensor(0.6184, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0226447582244873\n",
      "Batch: 245 , Combined Loss: tensor(0.6782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21806395053863525\n",
      "Batch: 246 , Combined Loss: tensor(0.6980, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.894212007522583\n",
      "Batch: 247 , Combined Loss: tensor(0.7024, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9162857532501221\n",
      "Batch: 248 , Combined Loss: tensor(0.6523, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3582197427749634\n",
      "Batch: 249 , Combined Loss: tensor(1.0641, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8044978380203247\n",
      "Batch: 250 , Combined Loss: tensor(0.6827, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9824416637420654\n",
      "Batch: 251 , Combined Loss: tensor(0.6382, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5109483003616333\n",
      "Batch: 252 , Combined Loss: tensor(0.6580, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5942896604537964\n",
      "Batch: 253 , Combined Loss: tensor(0.5742, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0966711044311523\n",
      "Batch: 254 , Combined Loss: tensor(0.6181, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9572016000747681\n",
      "Batch: 255 , Combined Loss: tensor(0.5464, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6281694173812866\n",
      "Batch: 256 , Combined Loss: tensor(0.6617, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.642831563949585\n",
      "Batch: 257 , Combined Loss: tensor(1.0908, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20302033424377441\n",
      "Batch: 258 , Combined Loss: tensor(0.5825, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8820627927780151\n",
      "Batch: 259 , Combined Loss: tensor(0.6350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.038517951965332\n",
      "Batch: 260 , Combined Loss: tensor(0.6826, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.66196608543396\n",
      "Batch: 261 , Combined Loss: tensor(0.7336, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07118427753448486\n",
      "Batch: 262 , Combined Loss: tensor(0.7523, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.715712308883667\n",
      "Batch: 263 , Combined Loss: tensor(0.6110, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.685128927230835\n",
      "Batch: 264 , Combined Loss: tensor(1.0483, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4562143087387085\n",
      "Batch: 265 , Combined Loss: tensor(0.6238, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7060049772262573\n",
      "Batch: 266 , Combined Loss: tensor(0.7088, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6226723194122314\n",
      "Batch: 267 , Combined Loss: tensor(0.6996, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0037651062011719\n",
      "Batch: 268 , Combined Loss: tensor(0.6131, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8360010385513306\n",
      "Batch: 269 , Combined Loss: tensor(0.5991, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.826072096824646\n",
      "Batch: 270 , Combined Loss: tensor(0.6735, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2888094186782837\n",
      "Batch: 271 , Combined Loss: tensor(0.6097, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8371492624282837\n",
      "Batch: 272 , Combined Loss: tensor(0.6669, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.725645899772644\n",
      "Batch: 273 , Combined Loss: tensor(0.6965, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9682122468948364\n",
      "Batch: 274 , Combined Loss: tensor(0.6105, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49772608280181885\n",
      "Batch: 275 , Combined Loss: tensor(0.6522, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3635784387588501\n",
      "Batch: 276 , Combined Loss: tensor(0.7708, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5097733736038208\n",
      "Batch: 277 , Combined Loss: tensor(0.6323, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21519255638122559\n",
      "Batch: 278 , Combined Loss: tensor(0.7577, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5766235589981079\n",
      "Batch: 279 , Combined Loss: tensor(0.7014, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3782397508621216\n",
      "Batch: 280 , Combined Loss: tensor(0.7008, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8856090307235718\n",
      "Batch: 281 , Combined Loss: tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10418999195098877\n",
      "Batch: 282 , Combined Loss: tensor(0.9126, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.052416205406188965\n",
      "Batch: 283 , Combined Loss: tensor(0.6558, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5918885469436646\n",
      "Batch: 284 , Combined Loss: tensor(0.6515, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12205135822296143\n",
      "Batch: 285 , Combined Loss: tensor(0.8075, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5271774530410767\n",
      "Batch: 286 , Combined Loss: tensor(0.7444, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6094498634338379\n",
      "Batch: 287 , Combined Loss: tensor(0.7226, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.012396693229675293\n",
      "Batch: 288 , Combined Loss: tensor(0.6927, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.587725043296814\n",
      "Batch: 289 , Combined Loss: tensor(0.7089, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5440654754638672\n",
      "Batch: 290 , Combined Loss: tensor(0.5946, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5736043453216553\n",
      "Batch: 291 , Combined Loss: tensor(0.8596, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.830877423286438\n",
      "Batch: 292 , Combined Loss: tensor(0.7314, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3977426290512085\n",
      "Batch: 293 , Combined Loss: tensor(0.8128, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37753915786743164\n",
      "Batch: 294 , Combined Loss: tensor(0.8378, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7848756313323975\n",
      "Batch: 295 , Combined Loss: tensor(0.6764, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8219118118286133\n",
      "Batch: 296 , Combined Loss: tensor(0.6581, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2714357376098633\n",
      "Batch: 297 , Combined Loss: tensor(0.5789, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9403438568115234\n",
      "Batch: 298 , Combined Loss: tensor(0.5918, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3277881145477295\n",
      "Batch: 299 , Combined Loss: tensor(0.7997, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5028517246246338\n",
      "Batch: 300 , Combined Loss: tensor(0.6903, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0501675605773926\n",
      "Batch: 301 , Combined Loss: tensor(0.6416, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24138426780700684\n",
      "Batch: 302 , Combined Loss: tensor(0.5820, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6454662084579468\n",
      "Batch: 303 , Combined Loss: tensor(0.6972, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8877180814743042\n",
      "Batch: 304 , Combined Loss: tensor(0.8851, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9448295831680298\n",
      "Batch: 305 , Combined Loss: tensor(0.6504, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7985091209411621\n",
      "Batch: 306 , Combined Loss: tensor(0.5510, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7991361618041992\n",
      "Batch: 307 , Combined Loss: tensor(0.6028, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8386244773864746\n",
      "Batch: 308 , Combined Loss: tensor(0.8396, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7031557559967041\n",
      "Batch: 309 , Combined Loss: tensor(0.9156, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.003363192081451416\n",
      "Batch: 310 , Combined Loss: tensor(0.6536, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0453624725341797\n",
      "Batch: 311 , Combined Loss: tensor(0.6604, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6198959350585938\n",
      "Batch: 312 , Combined Loss: tensor(0.6210, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0507445335388184\n",
      "Batch: 313 , Combined Loss: tensor(0.7496, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6692622900009155\n",
      "Batch: 314 , Combined Loss: tensor(0.9204, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38343560695648193\n",
      "Batch: 315 , Combined Loss: tensor(0.6880, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1065342426300049\n",
      "Batch: 316 , Combined Loss: tensor(0.6315, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.051781415939331\n",
      "Batch: 317 , Combined Loss: tensor(0.6811, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8213794231414795\n",
      "Batch: 318 , Combined Loss: tensor(0.6050, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03766167163848877\n",
      "Batch: 319 , Combined Loss: tensor(0.5792, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1254976987838745\n",
      "Batch: 320 , Combined Loss: tensor(0.6461, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9606655836105347\n",
      "Batch: 321 , Combined Loss: tensor(0.6982, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9224791526794434\n",
      "Batch: 322 , Combined Loss: tensor(0.5960, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8796013593673706\n",
      "Batch: 323 , Combined Loss: tensor(0.6417, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9048453569412231\n",
      "Batch: 324 , Combined Loss: tensor(0.7206, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.823468804359436\n",
      "Batch: 325 , Combined Loss: tensor(0.6790, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1657843589782715\n",
      "Batch: 326 , Combined Loss: tensor(0.6699, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0210683345794678\n",
      "Batch: 327 , Combined Loss: tensor(0.7771, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7546899318695068\n",
      "Batch: 328 , Combined Loss: tensor(0.8278, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9952768087387085\n",
      "Batch: 329 , Combined Loss: tensor(0.8720, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6523996591567993\n",
      "Batch: 330 , Combined Loss: tensor(0.9176, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0677649974822998\n",
      "Batch: 331 , Combined Loss: tensor(0.6522, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29061031341552734\n",
      "Batch: 332 , Combined Loss: tensor(0.6524, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5535048246383667\n",
      "Batch: 333 , Combined Loss: tensor(0.5778, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8418203592300415\n",
      "Batch: 334 , Combined Loss: tensor(0.9623, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44757747650146484\n",
      "Batch: 335 , Combined Loss: tensor(0.6947, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2042646408081055\n",
      "Batch: 336 , Combined Loss: tensor(0.6690, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6887909173965454\n",
      "Batch: 337 , Combined Loss: tensor(0.7433, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0367207527160645\n",
      "Batch: 338 , Combined Loss: tensor(0.6881, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0250582695007324\n",
      "Batch: 339 , Combined Loss: tensor(0.6144, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7557191848754883\n",
      "Batch: 340 , Combined Loss: tensor(0.6473, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1231768131256104\n",
      "Batch: 341 , Combined Loss: tensor(1.0621, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7426080703735352\n",
      "Batch: 342 , Combined Loss: tensor(0.4819, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4961336851119995\n",
      "Batch: 343 , Combined Loss: tensor(0.6823, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0303914546966553\n",
      "Batch: 344 , Combined Loss: tensor(0.7105, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0667178630828857\n",
      "Batch: 345 , Combined Loss: tensor(0.5793, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8122212886810303\n",
      "Batch: 346 , Combined Loss: tensor(0.6045, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9624319076538086\n",
      "Batch: 347 , Combined Loss: tensor(0.6661, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0683698654174805\n",
      "Batch: 348 , Combined Loss: tensor(0.7242, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0311980247497559\n",
      "Batch: 349 , Combined Loss: tensor(0.7305, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8951578140258789\n",
      "Batch: 350 , Combined Loss: tensor(0.6874, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9981143474578857\n",
      "Batch: 351 , Combined Loss: tensor(0.6451, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6122035980224609\n",
      "Batch: 352 , Combined Loss: tensor(0.7469, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5165486335754395\n",
      "Batch: 353 , Combined Loss: tensor(0.7301, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37238144874572754\n",
      "Batch: 354 , Combined Loss: tensor(0.7303, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1241865158081055\n",
      "Batch: 355 , Combined Loss: tensor(0.6424, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04963397979736328\n",
      "Batch: 356 , Combined Loss: tensor(0.6649, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5284935235977173\n",
      "Batch: 357 , Combined Loss: tensor(0.6834, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.880691409111023\n",
      "Batch: 358 , Combined Loss: tensor(1.0423, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8433820009231567\n",
      "Batch: 359 , Combined Loss: tensor(0.6862, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1156673431396484\n",
      "Batch: 360 , Combined Loss: tensor(0.8648, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0659008026123047\n",
      "Batch: 361 , Combined Loss: tensor(0.8705, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1248745918273926\n",
      "Batch: 362 , Combined Loss: tensor(0.5965, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9835927486419678\n",
      "Batch: 363 , Combined Loss: tensor(0.7822, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5781030654907227\n",
      "Batch: 364 , Combined Loss: tensor(0.5474, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9406065940856934\n",
      "Batch: 365 , Combined Loss: tensor(0.6438, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2518073320388794\n",
      "Batch: 366 , Combined Loss: tensor(0.6831, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9239641427993774\n",
      "Batch: 367 , Combined Loss: tensor(0.7462, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8646306991577148\n",
      "Batch: 368 , Combined Loss: tensor(0.6475, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2586556673049927\n",
      "Batch: 369 , Combined Loss: tensor(0.9445, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6680923700332642\n",
      "Batch: 370 , Combined Loss: tensor(0.7307, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9647140502929688\n",
      "Batch: 371 , Combined Loss: tensor(0.6811, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6832005977630615\n",
      "Batch: 372 , Combined Loss: tensor(0.6680, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5804624557495117\n",
      "Batch: 373 , Combined Loss: tensor(0.8374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.166301965713501\n",
      "Batch: 374 , Combined Loss: tensor(0.5572, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12350451946258545\n",
      "Batch: 375 , Combined Loss: tensor(0.6348, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2734777927398682\n",
      "Batch: 376 , Combined Loss: tensor(0.9354, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8320139646530151\n",
      "Batch: 377 , Combined Loss: tensor(0.6874, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1747043132781982\n",
      "Batch: 378 , Combined Loss: tensor(0.7528, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43608033657073975\n",
      "Batch: 379 , Combined Loss: tensor(0.8290, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9784048795700073\n",
      "Batch: 380 , Combined Loss: tensor(0.6302, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7099753618240356\n",
      "Batch: 381 , Combined Loss: tensor(0.7391, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9298967123031616\n",
      "Batch: 382 , Combined Loss: tensor(0.6587, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.757169246673584\n",
      "Batch: 383 , Combined Loss: tensor(0.6402, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9286147356033325\n",
      "Batch: 384 , Combined Loss: tensor(0.6168, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0402565002441406\n",
      "Batch: 385 , Combined Loss: tensor(0.5618, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6558995246887207\n",
      "Batch: 386 , Combined Loss: tensor(0.6408, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9994914531707764\n",
      "Batch: 387 , Combined Loss: tensor(0.5992, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35586750507354736\n",
      "Batch: 388 , Combined Loss: tensor(0.5892, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7718547582626343\n",
      "Batch: 389 , Combined Loss: tensor(0.6621, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7784570455551147\n",
      "Batch: 390 , Combined Loss: tensor(0.6812, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6736397743225098\n",
      "Batch: 391 , Combined Loss: tensor(0.6043, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9164808988571167\n",
      "Batch: 392 , Combined Loss: tensor(0.6556, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7918624877929688\n",
      "Batch: 393 , Combined Loss: tensor(0.7542, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8645356893539429\n",
      "Batch: 394 , Combined Loss: tensor(0.7608, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5468242168426514\n",
      "Batch: 395 , Combined Loss: tensor(0.7314, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7153518199920654\n",
      "Batch: 396 , Combined Loss: tensor(0.7640, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7688126564025879\n",
      "Batch: 397 , Combined Loss: tensor(0.7110, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8976098299026489\n",
      "Batch: 398 , Combined Loss: tensor(0.6959, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29288947582244873\n",
      "Batch: 399 , Combined Loss: tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1931650638580322\n",
      "Batch: 400 , Combined Loss: tensor(0.6260, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8298485279083252\n",
      "Batch: 401 , Combined Loss: tensor(0.7857, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7356859445571899\n",
      "Batch: 402 , Combined Loss: tensor(0.6616, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8088464736938477\n",
      "Batch: 403 , Combined Loss: tensor(0.6587, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9930204153060913\n",
      "Batch: 404 , Combined Loss: tensor(0.8168, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9535447359085083\n",
      "Batch: 405 , Combined Loss: tensor(0.6265, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9709233045578003\n",
      "Batch: 406 , Combined Loss: tensor(0.6666, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1117863655090332\n",
      "Batch: 407 , Combined Loss: tensor(0.7387, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10217738151550293\n",
      "Batch: 408 , Combined Loss: tensor(0.6455, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32791340351104736\n",
      "Batch: 409 , Combined Loss: tensor(0.7470, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.572567343711853\n",
      "Batch: 410 , Combined Loss: tensor(0.5713, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7415465116500854\n",
      "Batch: 411 , Combined Loss: tensor(0.9615, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.597602128982544\n",
      "Batch: 412 , Combined Loss: tensor(0.6431, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1473450660705566\n",
      "Batch: 413 , Combined Loss: tensor(0.8284, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5617733001708984\n",
      "Batch: 414 , Combined Loss: tensor(0.6498, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0128810405731201\n",
      "Batch: 415 , Combined Loss: tensor(0.6918, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7209751605987549\n",
      "Batch: 416 , Combined Loss: tensor(0.7309, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8906925916671753\n",
      "Batch: 417 , Combined Loss: tensor(0.7145, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7885662317276001\n",
      "Batch: 418 , Combined Loss: tensor(0.7178, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8414263725280762\n",
      "Batch: 419 , Combined Loss: tensor(0.7677, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26243388652801514\n",
      "Batch: 420 , Combined Loss: tensor(0.6663, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9700506925582886\n",
      "Batch: 421 , Combined Loss: tensor(0.6979, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5582605600357056\n",
      "Batch: 422 , Combined Loss: tensor(0.5711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.096038579940796\n",
      "Batch: 423 , Combined Loss: tensor(0.7715, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3215597867965698\n",
      "Batch: 424 , Combined Loss: tensor(0.7444, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8967359066009521\n",
      "Batch: 425 , Combined Loss: tensor(0.6475, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1525874137878418\n",
      "Batch: 426 , Combined Loss: tensor(0.5788, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6446874141693115\n",
      "Batch: 427 , Combined Loss: tensor(0.7367, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8839226961135864\n",
      "Batch: 428 , Combined Loss: tensor(0.6728, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8549830913543701\n",
      "Batch: 429 , Combined Loss: tensor(0.6611, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9403567314147949\n",
      "Batch: 430 , Combined Loss: tensor(0.7357, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9252411127090454\n",
      "Batch: 431 , Combined Loss: tensor(0.7674, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09913182258605957\n",
      "Batch: 432 , Combined Loss: tensor(0.7602, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3983684778213501\n",
      "Batch: 433 , Combined Loss: tensor(0.6886, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14247214794158936\n",
      "Batch: 434 , Combined Loss: tensor(0.8062, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8066860437393188\n",
      "Batch: 435 , Combined Loss: tensor(0.7111, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08726644515991211\n",
      "Batch: 436 , Combined Loss: tensor(0.6229, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06411075592041016\n",
      "Batch: 437 , Combined Loss: tensor(0.9663, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3917447328567505\n",
      "Batch: 438 , Combined Loss: tensor(0.6477, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7920329570770264\n",
      "Batch: 439 , Combined Loss: tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8048379421234131\n",
      "Batch: 440 , Combined Loss: tensor(0.6192, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8168010711669922\n",
      "Batch: 441 , Combined Loss: tensor(0.6319, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7388641834259033\n",
      "Batch: 442 , Combined Loss: tensor(0.7272, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9761244058609009\n",
      "Batch: 443 , Combined Loss: tensor(0.6222, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0935702323913574\n",
      "Batch: 444 , Combined Loss: tensor(0.6924, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3600274324417114\n",
      "Batch: 445 , Combined Loss: tensor(0.7360, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0089378356933594\n",
      "Batch: 446 , Combined Loss: tensor(1.0352, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4412611722946167\n",
      "Batch: 447 , Combined Loss: tensor(0.6124, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4235008955001831\n",
      "Batch: 448 , Combined Loss: tensor(0.6539, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5043810606002808\n",
      "Batch: 449 , Combined Loss: tensor(0.6631, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5657802820205688\n",
      "Batch: 450 , Combined Loss: tensor(0.7770, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38877737522125244\n",
      "Batch: 451 , Combined Loss: tensor(0.7997, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24209892749786377\n",
      "Batch: 452 , Combined Loss: tensor(0.6299, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.703454852104187\n",
      "Batch: 453 , Combined Loss: tensor(0.5932, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1043295860290527\n",
      "Batch: 454 , Combined Loss: tensor(0.6118, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.13967597484588623\n",
      "Batch: 455 , Combined Loss: tensor(0.6396, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8046754598617554\n",
      "Batch: 456 , Combined Loss: tensor(0.6651, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9597283601760864\n",
      "Batch: 457 , Combined Loss: tensor(0.7401, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9184166193008423\n",
      "Batch: 458 , Combined Loss: tensor(0.6331, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8977922201156616\n",
      "Batch: 459 , Combined Loss: tensor(0.6545, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7903332710266113\n",
      "Batch: 460 , Combined Loss: tensor(0.6544, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8423570394515991\n",
      "Batch: 461 , Combined Loss: tensor(0.7403, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5570602416992188\n",
      "Batch: 462 , Combined Loss: tensor(0.6406, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1184799671173096\n",
      "Batch: 463 , Combined Loss: tensor(0.6355, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9041712284088135\n",
      "Batch: 464 , Combined Loss: tensor(0.6677, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11627054214477539\n",
      "Batch: 465 , Combined Loss: tensor(0.6975, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1016674041748047\n",
      "Batch: 466 , Combined Loss: tensor(0.6322, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7627406120300293\n",
      "Batch: 467 , Combined Loss: tensor(0.6027, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4552955627441406\n",
      "Batch: 468 , Combined Loss: tensor(0.6724, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.038187026977539\n",
      "Batch: 469 , Combined Loss: tensor(0.5630, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8192312717437744\n",
      "Batch: 470 , Combined Loss: tensor(0.6378, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5683807134628296\n",
      "Batch: 471 , Combined Loss: tensor(0.6722, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7299991846084595\n",
      "Batch: 472 , Combined Loss: tensor(0.7832, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9819933176040649\n",
      "Batch: 473 , Combined Loss: tensor(0.7936, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7269102334976196\n",
      "Batch: 474 , Combined Loss: tensor(0.5818, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0309984683990479\n",
      "Batch: 475 , Combined Loss: tensor(0.5892, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9327318668365479\n",
      "Batch: 476 , Combined Loss: tensor(0.5813, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9522233009338379\n",
      "Batch: 477 , Combined Loss: tensor(0.8687, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3900265693664551\n",
      "Batch: 478 , Combined Loss: tensor(0.6333, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14789366722106934\n",
      "Batch: 479 , Combined Loss: tensor(0.7955, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9628942012786865\n",
      "Batch: 480 , Combined Loss: tensor(0.7270, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.760671854019165\n",
      "Batch: 481 , Combined Loss: tensor(0.6731, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5854576826095581\n",
      "Batch: 482 , Combined Loss: tensor(0.5715, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.95225989818573\n",
      "Batch: 483 , Combined Loss: tensor(0.8009, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0037269592285156\n",
      "Batch: 484 , Combined Loss: tensor(0.6690, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.050550937652588\n",
      "Batch: 485 , Combined Loss: tensor(0.7072, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8815469741821289\n",
      "Batch: 486 , Combined Loss: tensor(0.6492, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5985909700393677\n",
      "Batch: 487 , Combined Loss: tensor(0.6192, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8135138750076294\n",
      "Batch: 488 , Combined Loss: tensor(0.7574, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0682666301727295\n",
      "Batch: 489 , Combined Loss: tensor(0.6191, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0452125072479248\n",
      "Batch: 490 , Combined Loss: tensor(0.5420, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0235657691955566\n",
      "Batch: 491 , Combined Loss: tensor(0.6487, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8923529386520386\n",
      "Batch: 492 , Combined Loss: tensor(0.5626, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.995585560798645\n",
      "Batch: 493 , Combined Loss: tensor(0.6580, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9748213291168213\n",
      "Batch: 494 , Combined Loss: tensor(0.7945, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6884163618087769\n",
      "Batch: 495 , Combined Loss: tensor(0.5499, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.086897611618042\n",
      "Batch: 496 , Combined Loss: tensor(0.8055, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9153369665145874\n",
      "Batch: 497 , Combined Loss: tensor(0.6554, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.064852237701416\n",
      "Batch: 498 , Combined Loss: tensor(0.8250, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6589950323104858\n",
      "Batch: 499 , Combined Loss: tensor(0.7497, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4840015172958374\n",
      "Batch: 500 , Combined Loss: tensor(0.6099, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0445191860198975\n",
      "Batch: 501 , Combined Loss: tensor(0.6667, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8755910396575928\n",
      "Batch: 502 , Combined Loss: tensor(0.6401, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.12532639503479\n",
      "Batch: 503 , Combined Loss: tensor(0.6493, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1686708927154541\n",
      "Batch: 504 , Combined Loss: tensor(0.6230, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9419962167739868\n",
      "Batch: 505 , Combined Loss: tensor(0.6618, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9185068607330322\n",
      "Batch: 506 , Combined Loss: tensor(0.6667, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9716154336929321\n",
      "Batch: 507 , Combined Loss: tensor(0.8229, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19893109798431396\n",
      "Batch: 508 , Combined Loss: tensor(0.7698, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9924720525741577\n",
      "Batch: 509 , Combined Loss: tensor(0.6641, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12827420234680176\n",
      "Batch: 510 , Combined Loss: tensor(0.6962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6141132116317749\n",
      "Batch: 511 , Combined Loss: tensor(0.6496, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7527502775192261\n",
      "Batch: 512 , Combined Loss: tensor(0.7175, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0243759155273438\n",
      "Batch: 513 , Combined Loss: tensor(0.5958, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1881320476531982\n",
      "Batch: 514 , Combined Loss: tensor(0.6084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9683680534362793\n",
      "Batch: 515 , Combined Loss: tensor(0.9251, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.214311122894287\n",
      "Batch: 516 , Combined Loss: tensor(0.6725, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0069365501403809\n",
      "Batch: 517 , Combined Loss: tensor(0.8885, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2789539098739624\n",
      "Batch: 518 , Combined Loss: tensor(0.6396, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3336455821990967\n",
      "Batch: 519 , Combined Loss: tensor(0.5485, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8448812961578369\n",
      "Batch: 520 , Combined Loss: tensor(0.8608, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7537003755569458\n",
      "Batch: 521 , Combined Loss: tensor(0.5182, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5904943943023682\n",
      "Batch: 522 , Combined Loss: tensor(0.5684, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1293206214904785\n",
      "Batch: 523 , Combined Loss: tensor(0.5979, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9536768198013306\n",
      "Batch: 524 , Combined Loss: tensor(0.5913, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0338881015777588\n",
      "Batch: 525 , Combined Loss: tensor(0.6836, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7186770439147949\n",
      "Batch: 526 , Combined Loss: tensor(0.5799, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1354188919067383\n",
      "Batch: 527 , Combined Loss: tensor(0.6167, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8921011686325073\n",
      "Batch: 528 , Combined Loss: tensor(0.7217, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6894227266311646\n",
      "Batch: 529 , Combined Loss: tensor(0.6575, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8353954553604126\n",
      "Batch: 530 , Combined Loss: tensor(0.8159, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.28989046812057495\n",
      "Batch: 531 , Combined Loss: tensor(0.6825, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05860698223114014\n",
      "Batch: 532 , Combined Loss: tensor(0.6140, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9938468933105469\n",
      "Batch: 533 , Combined Loss: tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9537526369094849\n",
      "Batch: 534 , Combined Loss: tensor(0.5931, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.877393364906311\n",
      "Batch: 535 , Combined Loss: tensor(1.1695, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7816030979156494\n",
      "Batch: 536 , Combined Loss: tensor(0.7876, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8882670402526855\n",
      "Batch: 537 , Combined Loss: tensor(0.5341, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8193780183792114\n",
      "Batch: 538 , Combined Loss: tensor(0.7839, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9587934017181396\n",
      "Batch: 539 , Combined Loss: tensor(0.6181, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8573870658874512\n",
      "Batch: 540 , Combined Loss: tensor(0.7285, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.321366310119629\n",
      "Batch: 541 , Combined Loss: tensor(0.5765, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.247779130935669\n",
      "Batch: 542 , Combined Loss: tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9680721759796143\n",
      "Batch: 543 , Combined Loss: tensor(0.6862, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8549679517745972\n",
      "Batch: 544 , Combined Loss: tensor(0.7906, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5820859670639038\n",
      "Batch: 545 , Combined Loss: tensor(0.5499, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8625475168228149\n",
      "Batch: 546 , Combined Loss: tensor(0.7735, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7428770065307617\n",
      "Batch: 547 , Combined Loss: tensor(0.5684, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0731241703033447\n",
      "Batch: 548 , Combined Loss: tensor(0.5982, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9187006950378418\n",
      "Batch: 549 , Combined Loss: tensor(0.6685, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5308635234832764\n",
      "Batch: 550 , Combined Loss: tensor(0.6045, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8101145029067993\n",
      "Batch: 551 , Combined Loss: tensor(0.7870, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0327377319335938\n",
      "Batch: 552 , Combined Loss: tensor(0.5459, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0054140090942383\n",
      "Batch: 553 , Combined Loss: tensor(0.8587, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8438010215759277\n",
      "Batch: 554 , Combined Loss: tensor(0.7069, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2620501518249512\n",
      "Batch: 555 , Combined Loss: tensor(0.6908, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20932471752166748\n",
      "Batch: 556 , Combined Loss: tensor(0.6390, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5262331962585449\n",
      "Batch: 557 , Combined Loss: tensor(0.6112, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.041785478591919\n",
      "Batch: 558 , Combined Loss: tensor(0.6926, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2869560718536377\n",
      "Batch: 559 , Combined Loss: tensor(0.6205, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.03826904296875\n",
      "Batch: 560 , Combined Loss: tensor(0.7029, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6254997253417969\n",
      "Batch: 561 , Combined Loss: tensor(0.7805, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9820472002029419\n",
      "Batch: 562 , Combined Loss: tensor(0.5846, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8479421138763428\n",
      "Batch: 563 , Combined Loss: tensor(0.5986, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8107637166976929\n",
      "Batch: 564 , Combined Loss: tensor(0.5793, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4220937490463257\n",
      "Batch: 565 , Combined Loss: tensor(0.5801, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5396431684494019\n",
      "Batch: 566 , Combined Loss: tensor(0.8042, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6240146160125732\n",
      "Batch: 567 , Combined Loss: tensor(0.5991, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5639489889144897\n",
      "Batch: 568 , Combined Loss: tensor(0.7866, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10069131851196289\n",
      "Batch: 569 , Combined Loss: tensor(0.6838, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9811513423919678\n",
      "Batch: 570 , Combined Loss: tensor(0.5696, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.691115140914917\n",
      "Batch: 571 , Combined Loss: tensor(0.7470, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7889407873153687\n",
      "Batch: 572 , Combined Loss: tensor(0.6748, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5952852964401245\n",
      "Batch: 573 , Combined Loss: tensor(0.6273, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25579822063446045\n",
      "Batch: 574 , Combined Loss: tensor(0.5815, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8367325067520142\n",
      "Batch: 575 , Combined Loss: tensor(0.5558, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5283010005950928\n",
      "Batch: 576 , Combined Loss: tensor(0.6275, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.660580039024353\n",
      "Batch: 577 , Combined Loss: tensor(0.6325, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12943828105926514\n",
      "Batch: 578 , Combined Loss: tensor(0.5805, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5056513547897339\n",
      "Batch: 579 , Combined Loss: tensor(0.7922, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9836896657943726\n",
      "Batch: 580 , Combined Loss: tensor(0.8052, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9151127338409424\n",
      "Batch: 581 , Combined Loss: tensor(0.7078, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04459977149963379\n",
      "Batch: 582 , Combined Loss: tensor(0.6521, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.038686990737915\n",
      "Batch: 583 , Combined Loss: tensor(0.5814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6419045925140381\n",
      "Batch: 584 , Combined Loss: tensor(0.6042, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7579443454742432\n",
      "Batch: 585 , Combined Loss: tensor(0.6649, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2731703519821167\n",
      "Batch: 586 , Combined Loss: tensor(0.6395, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.506684422492981\n",
      "Batch: 587 , Combined Loss: tensor(0.5863, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0913026332855225\n",
      "Batch: 588 , Combined Loss: tensor(0.5722, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06787252426147461\n",
      "Batch: 589 , Combined Loss: tensor(0.9181, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7412654161453247\n",
      "Batch: 590 , Combined Loss: tensor(0.5878, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.747073769569397\n",
      "Batch: 591 , Combined Loss: tensor(0.6441, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15846192836761475\n",
      "Batch: 592 , Combined Loss: tensor(0.5977, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6186473369598389\n",
      "Batch: 593 , Combined Loss: tensor(0.6614, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3521904945373535\n",
      "Batch: 594 , Combined Loss: tensor(0.6609, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9548397064208984\n",
      "Batch: 595 , Combined Loss: tensor(0.6453, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.906514048576355\n",
      "Batch: 596 , Combined Loss: tensor(0.6289, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.573328971862793\n",
      "Batch: 597 , Combined Loss: tensor(0.6567, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5126732587814331\n",
      "Batch: 598 , Combined Loss: tensor(0.7001, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.846826434135437\n",
      "Batch: 599 , Combined Loss: tensor(0.6338, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8835793733596802\n",
      "Batch: 600 , Combined Loss: tensor(0.6187, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8364351987838745\n",
      "Batch: 601 , Combined Loss: tensor(0.6078, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0362281799316406\n",
      "Batch: 602 , Combined Loss: tensor(0.7604, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.862612247467041\n",
      "Batch: 603 , Combined Loss: tensor(0.6038, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5677953958511353\n",
      "Batch: 604 , Combined Loss: tensor(0.5626, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0846564769744873\n",
      "Batch: 605 , Combined Loss: tensor(0.6921, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8487585783004761\n",
      "Batch: 606 , Combined Loss: tensor(0.6342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24546873569488525\n",
      "Batch: 607 , Combined Loss: tensor(0.6682, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0011756420135498\n",
      "Batch: 608 , Combined Loss: tensor(0.6046, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7202255725860596\n",
      "Batch: 609 , Combined Loss: tensor(0.6009, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8560510873794556\n",
      "Batch: 610 , Combined Loss: tensor(0.5463, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4819597005844116\n",
      "Batch: 611 , Combined Loss: tensor(0.5784, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2383732795715332\n",
      "Batch: 612 , Combined Loss: tensor(0.6685, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3445167541503906\n",
      "Batch: 613 , Combined Loss: tensor(0.6082, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7226330041885376\n",
      "Batch: 614 , Combined Loss: tensor(0.5548, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7113949060440063\n",
      "Batch: 615 , Combined Loss: tensor(0.5768, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9522538185119629\n",
      "Batch: 616 , Combined Loss: tensor(0.6918, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7912392616271973\n",
      "Batch: 617 , Combined Loss: tensor(0.6096, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5670114755630493\n",
      "Batch: 618 , Combined Loss: tensor(0.6077, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5197134017944336\n",
      "Batch: 619 , Combined Loss: tensor(0.6053, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7535793781280518\n",
      "Batch: 620 , Combined Loss: tensor(0.8120, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4164541959762573\n",
      "Batch: 621 , Combined Loss: tensor(0.5535, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33480286598205566\n",
      "Batch: 622 , Combined Loss: tensor(0.6303, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9635748863220215\n",
      "Batch: 623 , Combined Loss: tensor(0.5949, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3197985887527466\n",
      "Batch: 624 , Combined Loss: tensor(0.6435, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9037281274795532\n",
      "Batch: 625 , Combined Loss: tensor(0.5724, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7175577878952026\n",
      "Batch: 626 , Combined Loss: tensor(1.0513, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5447529554367065\n",
      "Batch: 627 , Combined Loss: tensor(0.6363, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7425806522369385\n",
      "Batch: 628 , Combined Loss: tensor(0.6699, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9897021055221558\n",
      "----------Epoch 24, Loss: 0.678945853808726, Accuracy: 0.9712880328652969, Dice Coef: [0.9878639450891977, 0.5377831554346195, 0.6235398521974634, 0.7243009089135869], Dice Coef Necrotic: 1.0281396797202353, Dice Coef Edema: 1.0472321749588893, Dice Coef Enhancing: 1.0452128658449062, Sensitivity: [0.9778035814697678, 0.6791928838499373, 0.8511565282395989, 0.8572951597065349], Specificity: [0.9706322678700918, 0.9973209223610797, 0.9787465444808924, 0.9962281213276716], Precision: [0.9982070557074251, 0.5392714334390495, 0.5221294738825734, 0.6719202460849396]\n",
      "Batch: 0 , Combined Loss: tensor(0.8065, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7713925838470459\n",
      "Batch: 1 , Combined Loss: tensor(0.6064, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7844551801681519\n",
      "Batch: 2 , Combined Loss: tensor(0.6584, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4020421504974365\n",
      "Batch: 3 , Combined Loss: tensor(0.5533, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1260027885437012\n",
      "Batch: 4 , Combined Loss: tensor(0.8135, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46337974071502686\n",
      "Batch: 5 , Combined Loss: tensor(0.5897, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6520529985427856\n",
      "Batch: 6 , Combined Loss: tensor(0.6240, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9160159826278687\n",
      "Batch: 7 , Combined Loss: tensor(0.7782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7248444557189941\n",
      "Batch: 8 , Combined Loss: tensor(0.5991, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3167778253555298\n",
      "Batch: 9 , Combined Loss: tensor(0.6109, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6082476377487183\n",
      "Batch: 10 , Combined Loss: tensor(0.6131, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.116011381149292\n",
      "Batch: 11 , Combined Loss: tensor(0.6066, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8949424028396606\n",
      "Batch: 12 , Combined Loss: tensor(0.6100, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7714786529541016\n",
      "Batch: 13 , Combined Loss: tensor(0.5907, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49992573261260986\n",
      "Batch: 14 , Combined Loss: tensor(0.6049, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0390353202819824\n",
      "Batch: 15 , Combined Loss: tensor(0.6208, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1128857135772705\n",
      "Batch: 16 , Combined Loss: tensor(0.5786, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3433581590652466\n",
      "Batch: 17 , Combined Loss: tensor(0.6741, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.540238618850708\n",
      "Batch: 18 , Combined Loss: tensor(0.5619, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9890594482421875\n",
      "Batch: 19 , Combined Loss: tensor(0.8057, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0290071964263916\n",
      "Batch: 20 , Combined Loss: tensor(0.5871, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8550682067871094\n",
      "Batch: 21 , Combined Loss: tensor(0.6313, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9769703149795532\n",
      "Batch: 22 , Combined Loss: tensor(0.7382, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0764775276184082\n",
      "Batch: 23 , Combined Loss: tensor(0.6187, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8518918752670288\n",
      "Batch: 24 , Combined Loss: tensor(0.6421, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.593663215637207\n",
      "Batch: 25 , Combined Loss: tensor(0.5668, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9843817949295044\n",
      "Batch: 26 , Combined Loss: tensor(0.9502, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7793993949890137\n",
      "Batch: 27 , Combined Loss: tensor(0.5676, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0804057121276855\n",
      "Batch: 28 , Combined Loss: tensor(0.7230, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0756354331970215\n",
      "Batch: 29 , Combined Loss: tensor(0.5570, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6992100477218628\n",
      "Batch: 30 , Combined Loss: tensor(0.5909, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9507153034210205\n",
      "Batch: 31 , Combined Loss: tensor(0.6243, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9986350536346436\n",
      "Batch: 32 , Combined Loss: tensor(0.7421, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7623478174209595\n",
      "Batch: 33 , Combined Loss: tensor(0.5883, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42884016036987305\n",
      "Batch: 34 , Combined Loss: tensor(0.8028, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6116137504577637\n",
      "Batch: 35 , Combined Loss: tensor(0.6926, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0315396785736084\n",
      "Batch: 36 , Combined Loss: tensor(0.6926, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.094815969467163\n",
      "Batch: 37 , Combined Loss: tensor(0.6707, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0430493354797363\n",
      "Batch: 38 , Combined Loss: tensor(0.7086, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3393540382385254\n",
      "Batch: 39 , Combined Loss: tensor(0.9029, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.44132065773010254\n",
      "Batch: 40 , Combined Loss: tensor(0.5449, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7812625169754028\n",
      "Batch: 41 , Combined Loss: tensor(0.6039, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8444472551345825\n",
      "Batch: 42 , Combined Loss: tensor(0.8578, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1158158779144287\n",
      "Batch: 43 , Combined Loss: tensor(0.5867, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22625303268432617\n",
      "Batch: 44 , Combined Loss: tensor(0.6805, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1187684535980225\n",
      "Batch: 45 , Combined Loss: tensor(0.6169, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.025179147720337\n",
      "Batch: 46 , Combined Loss: tensor(0.6191, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9143897294998169\n",
      "Batch: 47 , Combined Loss: tensor(0.5881, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37699317932128906\n",
      "Batch: 48 , Combined Loss: tensor(0.6042, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0910818576812744\n",
      "Batch: 49 , Combined Loss: tensor(0.5919, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.636212944984436\n",
      "Batch: 50 , Combined Loss: tensor(0.6950, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0703771114349365\n",
      "Batch: 51 , Combined Loss: tensor(0.6651, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.886948823928833\n",
      "Batch: 52 , Combined Loss: tensor(0.5447, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0263690948486328\n",
      "Batch: 53 , Combined Loss: tensor(0.6384, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.198322057723999\n",
      "Batch: 54 , Combined Loss: tensor(0.5526, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0932128429412842\n",
      "Batch: 55 , Combined Loss: tensor(0.9887, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3488900661468506\n",
      "Batch: 56 , Combined Loss: tensor(0.7275, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9341741800308228\n",
      "Batch: 57 , Combined Loss: tensor(0.7674, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39081358909606934\n",
      "Batch: 58 , Combined Loss: tensor(0.6153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09244608879089355\n",
      "Batch: 59 , Combined Loss: tensor(0.6110, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.717988133430481\n",
      "Batch: 60 , Combined Loss: tensor(0.7679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5256156921386719\n",
      "Batch: 61 , Combined Loss: tensor(0.6218, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7716377973556519\n",
      "Batch: 62 , Combined Loss: tensor(0.5934, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7353249788284302\n",
      "Batch: 63 , Combined Loss: tensor(0.5565, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7846237421035767\n",
      "Batch: 64 , Combined Loss: tensor(0.8309, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7692341804504395\n",
      "Batch: 65 , Combined Loss: tensor(0.6499, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8098268508911133\n",
      "Batch: 66 , Combined Loss: tensor(0.5969, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0168216228485107\n",
      "Batch: 67 , Combined Loss: tensor(0.5846, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1717803478240967\n",
      "Batch: 68 , Combined Loss: tensor(0.6525, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.119642972946167\n",
      "Batch: 69 , Combined Loss: tensor(0.7000, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8747040033340454\n",
      "Batch: 70 , Combined Loss: tensor(0.6443, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.086561679840088\n",
      "Batch: 71 , Combined Loss: tensor(0.5996, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19415664672851562\n",
      "Batch: 72 , Combined Loss: tensor(0.5994, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1049680709838867\n",
      "Batch: 73 , Combined Loss: tensor(0.5678, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6988314390182495\n",
      "Batch: 74 , Combined Loss: tensor(0.5473, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0054125785827637\n",
      "Batch: 75 , Combined Loss: tensor(0.6734, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.012253522872924805\n",
      "Batch: 76 , Combined Loss: tensor(0.7019, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6695367097854614\n",
      "Batch: 77 , Combined Loss: tensor(0.6131, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9411908388137817\n",
      "Batch: 78 , Combined Loss: tensor(0.6668, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08314621448516846\n",
      "Batch: 79 , Combined Loss: tensor(0.5613, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8715543746948242\n",
      "Batch: 80 , Combined Loss: tensor(0.5128, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4569514989852905\n",
      "Batch: 81 , Combined Loss: tensor(0.5840, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9395304918289185\n",
      "Batch: 82 , Combined Loss: tensor(0.5569, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7907373905181885\n",
      "Batch: 83 , Combined Loss: tensor(0.8173, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8117622137069702\n",
      "Batch: 84 , Combined Loss: tensor(0.6077, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.051177978515625\n",
      "Batch: 85 , Combined Loss: tensor(0.6255, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2736910581588745\n",
      "Batch: 86 , Combined Loss: tensor(0.7439, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.01549673080444336\n",
      "Batch: 87 , Combined Loss: tensor(0.7636, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0244784355163574\n",
      "Batch: 88 , Combined Loss: tensor(0.6950, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8501133918762207\n",
      "Batch: 89 , Combined Loss: tensor(0.6394, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9687716960906982\n",
      "Batch: 90 , Combined Loss: tensor(0.6518, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43118321895599365\n",
      "Batch: 91 , Combined Loss: tensor(0.6962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8836483955383301\n",
      "Batch: 92 , Combined Loss: tensor(0.6487, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1182494163513184\n",
      "Batch: 93 , Combined Loss: tensor(0.6938, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8724011182785034\n",
      "Batch: 94 , Combined Loss: tensor(0.6118, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8319888114929199\n",
      "Batch: 95 , Combined Loss: tensor(0.6508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.822664737701416\n",
      "Batch: 96 , Combined Loss: tensor(0.5752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.693831205368042\n",
      "Batch: 97 , Combined Loss: tensor(0.6294, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9212027788162231\n",
      "Batch: 98 , Combined Loss: tensor(0.5511, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7991828918457031\n",
      "Batch: 99 , Combined Loss: tensor(0.6772, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5974893569946289\n",
      "Batch: 100 , Combined Loss: tensor(0.6330, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.018693447113037\n",
      "Batch: 101 , Combined Loss: tensor(0.7786, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.417077898979187\n",
      "Batch: 102 , Combined Loss: tensor(0.7396, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0151398181915283\n",
      "Batch: 103 , Combined Loss: tensor(0.6458, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7138516902923584\n",
      "Batch: 104 , Combined Loss: tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3508784770965576\n",
      "Batch: 105 , Combined Loss: tensor(0.6677, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6603516340255737\n",
      "Batch: 106 , Combined Loss: tensor(0.5489, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8772112131118774\n",
      "Batch: 107 , Combined Loss: tensor(0.5728, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6735951900482178\n",
      "Batch: 108 , Combined Loss: tensor(0.5391, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8631995916366577\n",
      "Batch: 109 , Combined Loss: tensor(0.6274, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9675537347793579\n",
      "Batch: 110 , Combined Loss: tensor(0.5490, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.187981367111206\n",
      "Batch: 111 , Combined Loss: tensor(0.5823, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5111221075057983\n",
      "Batch: 112 , Combined Loss: tensor(0.5605, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0597350597381592\n",
      "Batch: 113 , Combined Loss: tensor(0.5699, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9970052242279053\n",
      "Batch: 114 , Combined Loss: tensor(0.6470, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0766291618347168\n",
      "Batch: 115 , Combined Loss: tensor(0.6379, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6780908107757568\n",
      "Batch: 116 , Combined Loss: tensor(0.5844, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1155316829681396\n",
      "Batch: 117 , Combined Loss: tensor(0.7226, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18410563468933105\n",
      "Batch: 118 , Combined Loss: tensor(0.6821, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0797557830810547\n",
      "Batch: 119 , Combined Loss: tensor(0.6877, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3254258632659912\n",
      "Batch: 120 , Combined Loss: tensor(0.6653, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.961669921875\n",
      "Batch: 121 , Combined Loss: tensor(0.9105, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6728280782699585\n",
      "Batch: 122 , Combined Loss: tensor(0.6474, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.01330101490020752\n",
      "Batch: 123 , Combined Loss: tensor(0.5790, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8346954584121704\n",
      "Batch: 124 , Combined Loss: tensor(0.6418, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9908549785614014\n",
      "Batch: 125 , Combined Loss: tensor(0.8391, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.729701042175293\n",
      "Batch: 126 , Combined Loss: tensor(0.6778, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7215850353240967\n",
      "Batch: 127 , Combined Loss: tensor(0.5603, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9527243375778198\n",
      "Batch: 128 , Combined Loss: tensor(0.6481, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0127134323120117\n",
      "Batch: 129 , Combined Loss: tensor(0.5831, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9322223663330078\n",
      "Batch: 130 , Combined Loss: tensor(0.5778, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0824079513549805\n",
      "Batch: 131 , Combined Loss: tensor(0.6074, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8823344707489014\n",
      "Batch: 132 , Combined Loss: tensor(0.6031, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8093100786209106\n",
      "Batch: 133 , Combined Loss: tensor(0.8007, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0130763053894043\n",
      "Batch: 134 , Combined Loss: tensor(0.6340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15591681003570557\n",
      "Batch: 135 , Combined Loss: tensor(0.6849, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09122538566589355\n",
      "Batch: 136 , Combined Loss: tensor(0.5434, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9852571487426758\n",
      "Batch: 137 , Combined Loss: tensor(0.5851, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8908958435058594\n",
      "Batch: 138 , Combined Loss: tensor(0.5598, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.848628044128418\n",
      "Batch: 139 , Combined Loss: tensor(0.6521, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.037002503871917725\n",
      "Batch: 140 , Combined Loss: tensor(0.7270, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.99027419090271\n",
      "Batch: 141 , Combined Loss: tensor(0.6674, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7999269962310791\n",
      "Batch: 142 , Combined Loss: tensor(0.7510, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7843097448348999\n",
      "Batch: 143 , Combined Loss: tensor(0.6029, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.984929084777832\n",
      "Batch: 144 , Combined Loss: tensor(0.7936, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0145186185836792\n",
      "Batch: 145 , Combined Loss: tensor(0.6505, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8891031742095947\n",
      "Batch: 146 , Combined Loss: tensor(0.6030, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7547708749771118\n",
      "Batch: 147 , Combined Loss: tensor(0.7097, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4215719699859619\n",
      "Batch: 148 , Combined Loss: tensor(0.9007, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7709507942199707\n",
      "Batch: 149 , Combined Loss: tensor(0.6967, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35442888736724854\n",
      "Batch: 150 , Combined Loss: tensor(0.5724, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0592153072357178\n",
      "Batch: 151 , Combined Loss: tensor(0.6274, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9839262962341309\n",
      "Batch: 152 , Combined Loss: tensor(0.8290, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8886677026748657\n",
      "Batch: 153 , Combined Loss: tensor(0.6784, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7384474277496338\n",
      "Batch: 154 , Combined Loss: tensor(0.5713, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8465954065322876\n",
      "Batch: 155 , Combined Loss: tensor(0.7455, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7924344539642334\n",
      "Batch: 156 , Combined Loss: tensor(0.5373, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9985238313674927\n",
      "Batch: 157 , Combined Loss: tensor(0.5637, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7127188444137573\n",
      "Batch: 158 , Combined Loss: tensor(0.5567, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8034065961837769\n",
      "Batch: 159 , Combined Loss: tensor(0.6517, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7936801910400391\n",
      "Batch: 160 , Combined Loss: tensor(0.6070, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5858362913131714\n",
      "Batch: 161 , Combined Loss: tensor(0.6853, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3643091917037964\n",
      "Batch: 162 , Combined Loss: tensor(1.2047, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7527260780334473\n",
      "Batch: 163 , Combined Loss: tensor(0.6086, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7689536809921265\n",
      "Batch: 164 , Combined Loss: tensor(0.6582, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7907567024230957\n",
      "Batch: 165 , Combined Loss: tensor(0.5832, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.944717526435852\n",
      "Batch: 166 , Combined Loss: tensor(0.7320, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.978132963180542\n",
      "Batch: 167 , Combined Loss: tensor(0.8629, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7487958669662476\n",
      "Batch: 168 , Combined Loss: tensor(0.6388, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5677269697189331\n",
      "Batch: 169 , Combined Loss: tensor(0.6406, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9890444278717041\n",
      "Batch: 170 , Combined Loss: tensor(0.6650, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0065739154815674\n",
      "Batch: 171 , Combined Loss: tensor(0.6241, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6969882249832153\n",
      "Batch: 172 , Combined Loss: tensor(0.7571, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03207039833068848\n",
      "Batch: 173 , Combined Loss: tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.973861575126648\n",
      "Batch: 174 , Combined Loss: tensor(0.5379, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6776102781295776\n",
      "Batch: 175 , Combined Loss: tensor(0.5999, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8361979722976685\n",
      "Batch: 176 , Combined Loss: tensor(0.5770, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31153953075408936\n",
      "Batch: 177 , Combined Loss: tensor(0.5390, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8873792886734009\n",
      "Batch: 178 , Combined Loss: tensor(0.6088, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9941833019256592\n",
      "Batch: 179 , Combined Loss: tensor(0.5312, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8128176927566528\n",
      "Batch: 180 , Combined Loss: tensor(0.6998, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20931005477905273\n",
      "Batch: 181 , Combined Loss: tensor(0.5913, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0692977905273438\n",
      "Batch: 182 , Combined Loss: tensor(0.7239, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15481722354888916\n",
      "Batch: 183 , Combined Loss: tensor(0.5381, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8593530654907227\n",
      "Batch: 184 , Combined Loss: tensor(0.6974, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8393460512161255\n",
      "Batch: 185 , Combined Loss: tensor(0.7202, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37116360664367676\n",
      "Batch: 186 , Combined Loss: tensor(0.7358, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9729229211807251\n",
      "Batch: 187 , Combined Loss: tensor(0.8948, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3376120328903198\n",
      "Batch: 188 , Combined Loss: tensor(0.7320, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9784733057022095\n",
      "Batch: 189 , Combined Loss: tensor(0.6990, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7233697175979614\n",
      "Batch: 190 , Combined Loss: tensor(0.5360, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.880771279335022\n",
      "Batch: 191 , Combined Loss: tensor(0.7083, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8385570049285889\n",
      "Batch: 192 , Combined Loss: tensor(0.6132, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9112691879272461\n",
      "Batch: 193 , Combined Loss: tensor(0.6330, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6679872274398804\n",
      "Batch: 194 , Combined Loss: tensor(0.6319, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2442126274108887\n",
      "Batch: 195 , Combined Loss: tensor(0.8370, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9713106155395508\n",
      "Batch: 196 , Combined Loss: tensor(0.5618, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5944457054138184\n",
      "Batch: 197 , Combined Loss: tensor(0.6229, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6767280101776123\n",
      "Batch: 198 , Combined Loss: tensor(0.5827, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3535580039024353\n",
      "Batch: 199 , Combined Loss: tensor(0.7514, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9735101461410522\n",
      "Batch: 200 , Combined Loss: tensor(1.0430, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48770594596862793\n",
      "Batch: 201 , Combined Loss: tensor(0.6390, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5437251329421997\n",
      "Batch: 202 , Combined Loss: tensor(0.6769, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15436136722564697\n",
      "Batch: 203 , Combined Loss: tensor(0.5530, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9074224233627319\n",
      "Batch: 204 , Combined Loss: tensor(0.7022, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0498294830322266\n",
      "Batch: 205 , Combined Loss: tensor(0.8209, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8902016878128052\n",
      "Batch: 206 , Combined Loss: tensor(0.6543, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21848416328430176\n",
      "Batch: 207 , Combined Loss: tensor(0.8521, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6964807510375977\n",
      "Batch: 208 , Combined Loss: tensor(0.6870, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.46201056241989136\n",
      "Batch: 209 , Combined Loss: tensor(0.6184, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8534938097000122\n",
      "Batch: 210 , Combined Loss: tensor(0.6279, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1172702312469482\n",
      "Batch: 211 , Combined Loss: tensor(0.7815, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6689612865447998\n",
      "Batch: 212 , Combined Loss: tensor(0.5940, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7509099245071411\n",
      "Batch: 213 , Combined Loss: tensor(0.6770, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6552937030792236\n",
      "Batch: 214 , Combined Loss: tensor(0.5197, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6677989959716797\n",
      "Batch: 215 , Combined Loss: tensor(0.6123, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9776715040206909\n",
      "Batch: 216 , Combined Loss: tensor(0.6260, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9876145124435425\n",
      "Batch: 217 , Combined Loss: tensor(0.7210, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.568794846534729\n",
      "Batch: 218 , Combined Loss: tensor(0.6036, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6860272884368896\n",
      "Batch: 219 , Combined Loss: tensor(0.6443, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9184731245040894\n",
      "Batch: 220 , Combined Loss: tensor(0.6796, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.060570240020752\n",
      "Batch: 221 , Combined Loss: tensor(0.6596, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9652762413024902\n",
      "Batch: 222 , Combined Loss: tensor(0.6388, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6572033166885376\n",
      "Batch: 223 , Combined Loss: tensor(0.5819, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7982442378997803\n",
      "Batch: 224 , Combined Loss: tensor(0.7916, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8095566034317017\n",
      "Batch: 225 , Combined Loss: tensor(0.6148, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7339788675308228\n",
      "Batch: 226 , Combined Loss: tensor(0.6032, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6483113765716553\n",
      "Batch: 227 , Combined Loss: tensor(0.7348, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2393193244934082\n",
      "Batch: 228 , Combined Loss: tensor(0.7118, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8644140958786011\n",
      "Batch: 229 , Combined Loss: tensor(0.6783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9888235330581665\n",
      "Batch: 230 , Combined Loss: tensor(0.6034, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22265803813934326\n",
      "Batch: 231 , Combined Loss: tensor(0.5700, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0961897373199463\n",
      "Batch: 232 , Combined Loss: tensor(0.6229, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8477327823638916\n",
      "Batch: 233 , Combined Loss: tensor(0.5320, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8500469923019409\n",
      "Batch: 234 , Combined Loss: tensor(0.7393, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.877360463142395\n",
      "Batch: 235 , Combined Loss: tensor(0.6823, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8156017065048218\n",
      "Batch: 236 , Combined Loss: tensor(0.6039, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5010521411895752\n",
      "Batch: 237 , Combined Loss: tensor(0.5584, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26726722717285156\n",
      "Batch: 238 , Combined Loss: tensor(0.6491, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.048069953918457\n",
      "Batch: 239 , Combined Loss: tensor(0.5581, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0318171977996826\n",
      "Batch: 240 , Combined Loss: tensor(0.7055, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1022968292236328\n",
      "Batch: 241 , Combined Loss: tensor(0.6160, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9085586071014404\n",
      "Batch: 242 , Combined Loss: tensor(0.5987, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.875800371170044\n",
      "Batch: 243 , Combined Loss: tensor(0.7035, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0507206916809082\n",
      "Batch: 244 , Combined Loss: tensor(0.5444, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8187150955200195\n",
      "Batch: 245 , Combined Loss: tensor(0.6503, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9167677164077759\n",
      "Batch: 246 , Combined Loss: tensor(0.5556, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9951772689819336\n",
      "Batch: 247 , Combined Loss: tensor(0.6213, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0723638534545898\n",
      "Batch: 248 , Combined Loss: tensor(0.6781, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9563348293304443\n",
      "Batch: 249 , Combined Loss: tensor(0.8005, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9038029909133911\n",
      "Batch: 250 , Combined Loss: tensor(0.5919, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.207873821258545\n",
      "Batch: 251 , Combined Loss: tensor(0.6495, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.713226318359375\n",
      "Batch: 252 , Combined Loss: tensor(0.6154, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5339667797088623\n",
      "Batch: 253 , Combined Loss: tensor(0.6912, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0146484375\n",
      "Batch: 254 , Combined Loss: tensor(0.6500, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.889270544052124\n",
      "Batch: 255 , Combined Loss: tensor(0.6114, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0661888122558594\n",
      "Batch: 256 , Combined Loss: tensor(0.9024, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9839545488357544\n",
      "Batch: 257 , Combined Loss: tensor(0.6350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7534588575363159\n",
      "Batch: 258 , Combined Loss: tensor(0.6497, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8015537261962891\n",
      "Batch: 259 , Combined Loss: tensor(0.5502, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8521738052368164\n",
      "Batch: 260 , Combined Loss: tensor(0.6411, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0373854637145996\n",
      "Batch: 261 , Combined Loss: tensor(0.6499, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8892711400985718\n",
      "Batch: 262 , Combined Loss: tensor(0.5869, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9645328521728516\n",
      "Batch: 263 , Combined Loss: tensor(0.7723, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.54433274269104\n",
      "Batch: 264 , Combined Loss: tensor(0.6184, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0689077377319336\n",
      "Batch: 265 , Combined Loss: tensor(0.6436, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9960702657699585\n",
      "Batch: 266 , Combined Loss: tensor(0.5886, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0139424800872803\n",
      "Batch: 267 , Combined Loss: tensor(0.5498, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8728827238082886\n",
      "Batch: 268 , Combined Loss: tensor(0.5934, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0365655422210693\n",
      "Batch: 269 , Combined Loss: tensor(0.6126, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8254787921905518\n",
      "Batch: 270 , Combined Loss: tensor(0.6063, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8456059694290161\n",
      "Batch: 271 , Combined Loss: tensor(0.5495, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.829403281211853\n",
      "Batch: 272 , Combined Loss: tensor(0.6729, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9325506687164307\n",
      "Batch: 273 , Combined Loss: tensor(0.5993, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.859009861946106\n",
      "Batch: 274 , Combined Loss: tensor(0.5863, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4027540683746338\n",
      "Batch: 275 , Combined Loss: tensor(0.5422, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9352911710739136\n",
      "Batch: 276 , Combined Loss: tensor(0.4950, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9149072170257568\n",
      "Batch: 277 , Combined Loss: tensor(0.5361, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0986032485961914\n",
      "Batch: 278 , Combined Loss: tensor(0.6677, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1768476963043213\n",
      "Batch: 279 , Combined Loss: tensor(0.5792, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.138129472732544\n",
      "Batch: 280 , Combined Loss: tensor(0.7262, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2117469310760498\n",
      "Batch: 281 , Combined Loss: tensor(0.6897, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.571947455406189\n",
      "Batch: 282 , Combined Loss: tensor(0.5954, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9842190742492676\n",
      "Batch: 283 , Combined Loss: tensor(0.5184, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8885174989700317\n",
      "Batch: 284 , Combined Loss: tensor(0.6644, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.788936972618103\n",
      "Batch: 285 , Combined Loss: tensor(0.7626, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0335757732391357\n",
      "Batch: 286 , Combined Loss: tensor(0.8525, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6464884281158447\n",
      "Batch: 287 , Combined Loss: tensor(0.7800, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1009242534637451\n",
      "Batch: 288 , Combined Loss: tensor(0.7220, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6380149126052856\n",
      "Batch: 289 , Combined Loss: tensor(0.8270, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0744905471801758\n",
      "Batch: 290 , Combined Loss: tensor(0.6012, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1234025955200195\n",
      "Batch: 291 , Combined Loss: tensor(0.5814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9068398475646973\n",
      "Batch: 292 , Combined Loss: tensor(0.7258, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34338057041168213\n",
      "Batch: 293 , Combined Loss: tensor(0.7267, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.369523525238037\n",
      "Batch: 294 , Combined Loss: tensor(0.6288, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.149951696395874\n",
      "Batch: 295 , Combined Loss: tensor(0.5883, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6400606632232666\n",
      "Batch: 296 , Combined Loss: tensor(0.6096, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0081329345703125\n",
      "Batch: 297 , Combined Loss: tensor(0.7444, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9432575702667236\n",
      "Batch: 298 , Combined Loss: tensor(0.7619, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8663817644119263\n",
      "Batch: 299 , Combined Loss: tensor(0.6438, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.989255428314209\n",
      "Batch: 300 , Combined Loss: tensor(0.6261, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8013818264007568\n",
      "Batch: 301 , Combined Loss: tensor(0.5890, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2166335582733154\n",
      "Batch: 302 , Combined Loss: tensor(0.8949, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6294211149215698\n",
      "Batch: 303 , Combined Loss: tensor(0.6042, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0561225414276123\n",
      "Batch: 304 , Combined Loss: tensor(0.6209, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7540249824523926\n",
      "Batch: 305 , Combined Loss: tensor(0.5871, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7407022714614868\n",
      "Batch: 306 , Combined Loss: tensor(0.5835, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8503865003585815\n",
      "Batch: 307 , Combined Loss: tensor(0.5771, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.02278459072113037\n",
      "Batch: 308 , Combined Loss: tensor(0.6912, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0481770038604736\n",
      "Batch: 309 , Combined Loss: tensor(0.5415, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2329161167144775\n",
      "Batch: 310 , Combined Loss: tensor(0.6113, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0584840774536133\n",
      "Batch: 311 , Combined Loss: tensor(0.7110, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08627474308013916\n",
      "Batch: 312 , Combined Loss: tensor(0.6906, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06973457336425781\n",
      "Batch: 313 , Combined Loss: tensor(0.6600, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08474421501159668\n",
      "Batch: 314 , Combined Loss: tensor(0.8508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3851981163024902\n",
      "Batch: 315 , Combined Loss: tensor(0.6871, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34730541706085205\n",
      "Batch: 316 , Combined Loss: tensor(0.6292, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.06141996383667\n",
      "Batch: 317 , Combined Loss: tensor(0.6306, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4178425073623657\n",
      "Batch: 318 , Combined Loss: tensor(0.6853, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6493309736251831\n",
      "Batch: 319 , Combined Loss: tensor(0.5480, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6318544149398804\n",
      "Batch: 320 , Combined Loss: tensor(0.6730, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6705702543258667\n",
      "Batch: 321 , Combined Loss: tensor(0.5571, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0348892211914062\n",
      "Batch: 322 , Combined Loss: tensor(0.7354, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9003801345825195\n",
      "Batch: 323 , Combined Loss: tensor(0.6759, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8786991834640503\n",
      "Batch: 324 , Combined Loss: tensor(0.6228, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21933281421661377\n",
      "Batch: 325 , Combined Loss: tensor(0.7743, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9762990474700928\n",
      "Batch: 326 , Combined Loss: tensor(0.5897, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4934495687484741\n",
      "Batch: 327 , Combined Loss: tensor(0.6531, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22379988431930542\n",
      "Batch: 328 , Combined Loss: tensor(0.6226, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.876672625541687\n",
      "Batch: 329 , Combined Loss: tensor(0.7306, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41518914699554443\n",
      "Batch: 330 , Combined Loss: tensor(1.4188, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4993314743041992\n",
      "Batch: 331 , Combined Loss: tensor(0.7026, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5423070192337036\n",
      "Batch: 332 , Combined Loss: tensor(0.6473, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8169233798980713\n",
      "Batch: 333 , Combined Loss: tensor(0.6187, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8343864679336548\n",
      "Batch: 334 , Combined Loss: tensor(0.6764, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0538811683654785\n",
      "Batch: 335 , Combined Loss: tensor(0.5737, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4866880178451538\n",
      "Batch: 336 , Combined Loss: tensor(0.5440, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49247288703918457\n",
      "Batch: 337 , Combined Loss: tensor(0.7664, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8369808197021484\n",
      "Batch: 338 , Combined Loss: tensor(0.5906, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0302660465240479\n",
      "Batch: 339 , Combined Loss: tensor(0.5853, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16334426403045654\n",
      "Batch: 340 , Combined Loss: tensor(0.5700, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8123691082000732\n",
      "Batch: 341 , Combined Loss: tensor(0.5476, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7880468368530273\n",
      "Batch: 342 , Combined Loss: tensor(0.6571, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9071532487869263\n",
      "Batch: 343 , Combined Loss: tensor(0.8625, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3315701484680176\n",
      "Batch: 344 , Combined Loss: tensor(0.5876, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25385892391204834\n",
      "Batch: 345 , Combined Loss: tensor(0.7043, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8015381097793579\n",
      "Batch: 346 , Combined Loss: tensor(0.5785, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5514875650405884\n",
      "Batch: 347 , Combined Loss: tensor(0.6766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04590874910354614\n",
      "Batch: 348 , Combined Loss: tensor(0.5566, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1356284618377686\n",
      "Batch: 349 , Combined Loss: tensor(0.8605, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7114524841308594\n",
      "Batch: 350 , Combined Loss: tensor(0.9678, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.017477095127105713\n",
      "Batch: 351 , Combined Loss: tensor(0.5854, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8901991844177246\n",
      "Batch: 352 , Combined Loss: tensor(0.6270, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1626009941101074\n",
      "Batch: 353 , Combined Loss: tensor(0.7879, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5027042627334595\n",
      "Batch: 354 , Combined Loss: tensor(0.5822, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8433539867401123\n",
      "Batch: 355 , Combined Loss: tensor(0.6026, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9406722784042358\n",
      "Batch: 356 , Combined Loss: tensor(0.8117, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38645315170288086\n",
      "Batch: 357 , Combined Loss: tensor(0.7217, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5042879581451416\n",
      "Batch: 358 , Combined Loss: tensor(0.5784, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8933937549591064\n",
      "Batch: 359 , Combined Loss: tensor(1.0856, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.468151330947876\n",
      "Batch: 360 , Combined Loss: tensor(0.6028, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5829596519470215\n",
      "Batch: 361 , Combined Loss: tensor(0.7655, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6756677627563477\n",
      "Batch: 362 , Combined Loss: tensor(0.6779, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36986684799194336\n",
      "Batch: 363 , Combined Loss: tensor(0.7398, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0104472637176514\n",
      "Batch: 364 , Combined Loss: tensor(0.6600, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.634014368057251\n",
      "Batch: 365 , Combined Loss: tensor(0.7573, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39806675910949707\n",
      "Batch: 366 , Combined Loss: tensor(0.8523, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28513264656066895\n",
      "Batch: 367 , Combined Loss: tensor(0.6663, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1565864086151123\n",
      "Batch: 368 , Combined Loss: tensor(1.1662, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5401111841201782\n",
      "Batch: 369 , Combined Loss: tensor(0.6865, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7844828367233276\n",
      "Batch: 370 , Combined Loss: tensor(0.6916, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6113365888595581\n",
      "Batch: 371 , Combined Loss: tensor(0.8612, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2682204246520996\n",
      "Batch: 372 , Combined Loss: tensor(0.5627, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4813295602798462\n",
      "Batch: 373 , Combined Loss: tensor(0.6863, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.676425576210022\n",
      "Batch: 374 , Combined Loss: tensor(0.6252, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9665956497192383\n",
      "Batch: 375 , Combined Loss: tensor(0.8380, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39711993932724\n",
      "Batch: 376 , Combined Loss: tensor(0.6790, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.726021409034729\n",
      "Batch: 377 , Combined Loss: tensor(0.5658, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10505545139312744\n",
      "Batch: 378 , Combined Loss: tensor(0.7105, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4753965139389038\n",
      "Batch: 379 , Combined Loss: tensor(0.7291, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15566575527191162\n",
      "Batch: 380 , Combined Loss: tensor(0.7243, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3667824864387512\n",
      "Batch: 381 , Combined Loss: tensor(0.5679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8236687183380127\n",
      "Batch: 382 , Combined Loss: tensor(0.6419, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7795779705047607\n",
      "Batch: 383 , Combined Loss: tensor(0.6223, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9564410448074341\n",
      "Batch: 384 , Combined Loss: tensor(0.6978, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8223279714584351\n",
      "Batch: 385 , Combined Loss: tensor(0.6270, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2671269178390503\n",
      "Batch: 386 , Combined Loss: tensor(0.6169, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9798097610473633\n",
      "Batch: 387 , Combined Loss: tensor(0.5947, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.350339412689209\n",
      "Batch: 388 , Combined Loss: tensor(0.6076, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0639495849609375\n",
      "Batch: 389 , Combined Loss: tensor(0.7290, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7839051485061646\n",
      "Batch: 390 , Combined Loss: tensor(0.5820, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7901082038879395\n",
      "Batch: 391 , Combined Loss: tensor(0.7093, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39368951320648193\n",
      "Batch: 392 , Combined Loss: tensor(0.7351, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9093451499938965\n",
      "Batch: 393 , Combined Loss: tensor(0.6635, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.725928783416748\n",
      "Batch: 394 , Combined Loss: tensor(0.6469, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14471125602722168\n",
      "Batch: 395 , Combined Loss: tensor(0.7556, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8217992782592773\n",
      "Batch: 396 , Combined Loss: tensor(0.5989, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6276912689208984\n",
      "Batch: 397 , Combined Loss: tensor(0.5663, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36917686462402344\n",
      "Batch: 398 , Combined Loss: tensor(0.7282, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5832946300506592\n",
      "Batch: 399 , Combined Loss: tensor(0.7597, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07349073886871338\n",
      "Batch: 400 , Combined Loss: tensor(0.5902, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19479405879974365\n",
      "Batch: 401 , Combined Loss: tensor(0.6552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31269240379333496\n",
      "Batch: 402 , Combined Loss: tensor(0.5884, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8315352201461792\n",
      "Batch: 403 , Combined Loss: tensor(0.6581, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6914641857147217\n",
      "Batch: 404 , Combined Loss: tensor(0.6050, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9310915470123291\n",
      "Batch: 405 , Combined Loss: tensor(0.6540, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5595241785049438\n",
      "Batch: 406 , Combined Loss: tensor(0.8446, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25994300842285156\n",
      "Batch: 407 , Combined Loss: tensor(0.6813, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7751998901367188\n",
      "Batch: 408 , Combined Loss: tensor(0.6862, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8278158903121948\n",
      "Batch: 409 , Combined Loss: tensor(0.7027, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6577051877975464\n",
      "Batch: 410 , Combined Loss: tensor(0.6290, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4303501844406128\n",
      "Batch: 411 , Combined Loss: tensor(0.7786, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8728708028793335\n",
      "Batch: 412 , Combined Loss: tensor(0.6131, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2739142179489136\n",
      "Batch: 413 , Combined Loss: tensor(0.6730, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15712523460388184\n",
      "Batch: 414 , Combined Loss: tensor(0.8910, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.481337308883667\n",
      "Batch: 415 , Combined Loss: tensor(0.6017, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13684725761413574\n",
      "Batch: 416 , Combined Loss: tensor(0.6760, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.972327470779419\n",
      "Batch: 417 , Combined Loss: tensor(0.5835, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.877094030380249\n",
      "Batch: 418 , Combined Loss: tensor(0.6560, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28453528881073\n",
      "Batch: 419 , Combined Loss: tensor(0.6085, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7115113735198975\n",
      "Batch: 420 , Combined Loss: tensor(0.6822, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9727978706359863\n",
      "Batch: 421 , Combined Loss: tensor(0.6132, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0292870998382568\n",
      "Batch: 422 , Combined Loss: tensor(0.6406, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6415727138519287\n",
      "Batch: 423 , Combined Loss: tensor(0.6802, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.988517165184021\n",
      "Batch: 424 , Combined Loss: tensor(0.7117, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5853780508041382\n",
      "Batch: 425 , Combined Loss: tensor(0.7116, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6085728406906128\n",
      "Batch: 426 , Combined Loss: tensor(0.7833, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39273589849472046\n",
      "Batch: 427 , Combined Loss: tensor(0.7303, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9409549236297607\n",
      "Batch: 428 , Combined Loss: tensor(0.6959, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8640719652175903\n",
      "Batch: 429 , Combined Loss: tensor(0.5559, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6187626123428345\n",
      "Batch: 430 , Combined Loss: tensor(0.6815, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0643489360809326\n",
      "Batch: 431 , Combined Loss: tensor(0.7394, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7876267433166504\n",
      "Batch: 432 , Combined Loss: tensor(0.8121, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0699303150177002\n",
      "Batch: 433 , Combined Loss: tensor(0.7326, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4546804428100586\n",
      "Batch: 434 , Combined Loss: tensor(0.7684, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8577851057052612\n",
      "Batch: 435 , Combined Loss: tensor(0.6657, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.150315523147583\n",
      "Batch: 436 , Combined Loss: tensor(0.7287, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5602039098739624\n",
      "Batch: 437 , Combined Loss: tensor(0.5739, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8012149333953857\n",
      "Batch: 438 , Combined Loss: tensor(0.6722, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10839605331420898\n",
      "Batch: 439 , Combined Loss: tensor(0.6693, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7479586601257324\n",
      "Batch: 440 , Combined Loss: tensor(0.9364, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7474485635757446\n",
      "Batch: 441 , Combined Loss: tensor(0.8303, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7427806854248047\n",
      "Batch: 442 , Combined Loss: tensor(0.7261, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7803716659545898\n",
      "Batch: 443 , Combined Loss: tensor(0.5766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3544306755065918\n",
      "Batch: 444 , Combined Loss: tensor(0.6635, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0336918830871582\n",
      "Batch: 445 , Combined Loss: tensor(0.6197, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1995640993118286\n",
      "Batch: 446 , Combined Loss: tensor(0.5551, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9846560955047607\n",
      "Batch: 447 , Combined Loss: tensor(0.7092, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8246062994003296\n",
      "Batch: 448 , Combined Loss: tensor(0.6241, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07622087001800537\n",
      "Batch: 449 , Combined Loss: tensor(0.8346, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.57647705078125\n",
      "Batch: 450 , Combined Loss: tensor(0.6022, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8398447036743164\n",
      "Batch: 451 , Combined Loss: tensor(1.0212, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3697030544281006\n",
      "Batch: 452 , Combined Loss: tensor(0.6325, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5401644706726074\n",
      "Batch: 453 , Combined Loss: tensor(0.6009, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9787137508392334\n",
      "Batch: 454 , Combined Loss: tensor(0.5710, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5329787731170654\n",
      "Batch: 455 , Combined Loss: tensor(0.6357, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4654121398925781\n",
      "Batch: 456 , Combined Loss: tensor(0.8314, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9768674373626709\n",
      "Batch: 457 , Combined Loss: tensor(0.8096, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8780322074890137\n",
      "Batch: 458 , Combined Loss: tensor(0.5631, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7946295738220215\n",
      "Batch: 459 , Combined Loss: tensor(0.6867, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9388784170150757\n",
      "Batch: 460 , Combined Loss: tensor(0.6145, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2902073860168457\n",
      "Batch: 461 , Combined Loss: tensor(0.6425, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6369009017944336\n",
      "Batch: 462 , Combined Loss: tensor(0.5878, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1672072410583496\n",
      "Batch: 463 , Combined Loss: tensor(0.6544, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9899846315383911\n",
      "Batch: 464 , Combined Loss: tensor(0.7218, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.932217001914978\n",
      "Batch: 465 , Combined Loss: tensor(0.7200, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2526721954345703\n",
      "Batch: 466 , Combined Loss: tensor(0.6352, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8533912897109985\n",
      "Batch: 467 , Combined Loss: tensor(0.6032, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.985369086265564\n",
      "Batch: 468 , Combined Loss: tensor(0.5879, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9715516567230225\n",
      "Batch: 469 , Combined Loss: tensor(0.5735, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9648624658584595\n",
      "Batch: 470 , Combined Loss: tensor(0.5889, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1365442276000977\n",
      "Batch: 471 , Combined Loss: tensor(0.9209, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09882628917694092\n",
      "Batch: 472 , Combined Loss: tensor(0.6902, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0502116680145264\n",
      "Batch: 473 , Combined Loss: tensor(0.7067, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9953948259353638\n",
      "Batch: 474 , Combined Loss: tensor(0.6016, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7502195835113525\n",
      "Batch: 475 , Combined Loss: tensor(0.6810, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9054491519927979\n",
      "Batch: 476 , Combined Loss: tensor(0.6456, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03783261775970459\n",
      "Batch: 477 , Combined Loss: tensor(0.6410, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2744503021240234\n",
      "Batch: 478 , Combined Loss: tensor(0.6488, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1927857398986816\n",
      "Batch: 479 , Combined Loss: tensor(0.6422, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1134135723114014\n",
      "Batch: 480 , Combined Loss: tensor(0.6557, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.331303596496582\n",
      "Batch: 481 , Combined Loss: tensor(0.6467, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.738530158996582\n",
      "Batch: 482 , Combined Loss: tensor(0.8318, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04010128974914551\n",
      "Batch: 483 , Combined Loss: tensor(0.6159, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0946128368377686\n",
      "Batch: 484 , Combined Loss: tensor(0.6010, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7987838983535767\n",
      "Batch: 485 , Combined Loss: tensor(0.5868, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2028106451034546\n",
      "Batch: 486 , Combined Loss: tensor(0.6423, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1440486907958984\n",
      "Batch: 487 , Combined Loss: tensor(0.7089, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0721373558044434\n",
      "Batch: 488 , Combined Loss: tensor(0.7513, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08001768589019775\n",
      "Batch: 489 , Combined Loss: tensor(0.5589, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0324993133544922\n",
      "Batch: 490 , Combined Loss: tensor(0.5712, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.166485071182251\n",
      "Batch: 491 , Combined Loss: tensor(0.6061, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0879051685333252\n",
      "Batch: 492 , Combined Loss: tensor(0.5306, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6200135946273804\n",
      "Batch: 493 , Combined Loss: tensor(0.6074, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0514178276062012\n",
      "Batch: 494 , Combined Loss: tensor(0.5387, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.060286045074463\n",
      "Batch: 495 , Combined Loss: tensor(0.7088, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9365644454956055\n",
      "Batch: 496 , Combined Loss: tensor(0.6533, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8299018144607544\n",
      "Batch: 497 , Combined Loss: tensor(0.7067, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0693800449371338\n",
      "Batch: 498 , Combined Loss: tensor(0.6300, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8578609228134155\n",
      "Batch: 499 , Combined Loss: tensor(0.6603, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7746872901916504\n",
      "Batch: 500 , Combined Loss: tensor(0.6567, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0386793613433838\n",
      "Batch: 501 , Combined Loss: tensor(0.5359, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6771317720413208\n",
      "Batch: 502 , Combined Loss: tensor(0.6293, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20692527294158936\n",
      "Batch: 503 , Combined Loss: tensor(0.5688, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8348637819290161\n",
      "Batch: 504 , Combined Loss: tensor(0.6623, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0269050598144531\n",
      "Batch: 505 , Combined Loss: tensor(0.5939, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9369544982910156\n",
      "Batch: 506 , Combined Loss: tensor(0.7258, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0343780517578125\n",
      "Batch: 507 , Combined Loss: tensor(0.6928, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8333806991577148\n",
      "Batch: 508 , Combined Loss: tensor(0.5716, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1059515476226807\n",
      "Batch: 509 , Combined Loss: tensor(0.6701, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.046131134033203125\n",
      "Batch: 510 , Combined Loss: tensor(0.5750, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0787441730499268\n",
      "Batch: 511 , Combined Loss: tensor(0.5753, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2461659908294678\n",
      "Batch: 512 , Combined Loss: tensor(0.5656, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5719797611236572\n",
      "Batch: 513 , Combined Loss: tensor(0.5644, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0506978034973145\n",
      "Batch: 514 , Combined Loss: tensor(0.7693, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8909376859664917\n",
      "Batch: 515 , Combined Loss: tensor(0.5551, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1369624137878418\n",
      "Batch: 516 , Combined Loss: tensor(0.7113, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9966385364532471\n",
      "Batch: 517 , Combined Loss: tensor(1.0373, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8133829832077026\n",
      "Batch: 518 , Combined Loss: tensor(0.8865, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5227608680725098\n",
      "Batch: 519 , Combined Loss: tensor(0.6897, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.237955093383789\n",
      "Batch: 520 , Combined Loss: tensor(0.6635, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.797860860824585\n",
      "Batch: 521 , Combined Loss: tensor(0.5896, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9220068454742432\n",
      "Batch: 522 , Combined Loss: tensor(0.6476, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3360421657562256\n",
      "Batch: 523 , Combined Loss: tensor(0.6740, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8942949771881104\n",
      "Batch: 524 , Combined Loss: tensor(0.5787, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1614940166473389\n",
      "Batch: 525 , Combined Loss: tensor(0.6451, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0479485988616943\n",
      "Batch: 526 , Combined Loss: tensor(0.6202, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.665468692779541\n",
      "Batch: 527 , Combined Loss: tensor(0.6024, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.223048210144043\n",
      "Batch: 528 , Combined Loss: tensor(0.6191, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1844584941864014\n",
      "Batch: 529 , Combined Loss: tensor(0.6909, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3297215700149536\n",
      "Batch: 530 , Combined Loss: tensor(0.8192, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0739514827728271\n",
      "Batch: 531 , Combined Loss: tensor(0.7210, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7286549806594849\n",
      "Batch: 532 , Combined Loss: tensor(0.5651, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8076155185699463\n",
      "Batch: 533 , Combined Loss: tensor(0.6350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0099592208862305\n",
      "Batch: 534 , Combined Loss: tensor(0.5055, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8294483423233032\n",
      "Batch: 535 , Combined Loss: tensor(0.7785, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0386261940002441\n",
      "Batch: 536 , Combined Loss: tensor(0.6317, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8270425796508789\n",
      "Batch: 537 , Combined Loss: tensor(0.6717, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8541293144226074\n",
      "Batch: 538 , Combined Loss: tensor(0.5330, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9386526346206665\n",
      "Batch: 539 , Combined Loss: tensor(0.5882, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40453338623046875\n",
      "Batch: 540 , Combined Loss: tensor(0.6623, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8565702438354492\n",
      "Batch: 541 , Combined Loss: tensor(0.5846, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1085176467895508\n",
      "Batch: 542 , Combined Loss: tensor(0.7047, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9689522981643677\n",
      "Batch: 543 , Combined Loss: tensor(0.6866, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9553301334381104\n",
      "Batch: 544 , Combined Loss: tensor(0.8585, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0255577564239502\n",
      "Batch: 545 , Combined Loss: tensor(0.6195, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8224815130233765\n",
      "Batch: 546 , Combined Loss: tensor(0.6580, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0749883651733398\n",
      "Batch: 547 , Combined Loss: tensor(0.6960, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2143044471740723\n",
      "Batch: 548 , Combined Loss: tensor(0.7310, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9873992204666138\n",
      "Batch: 549 , Combined Loss: tensor(0.5651, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5236235857009888\n",
      "Batch: 550 , Combined Loss: tensor(0.6461, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6068754196166992\n",
      "Batch: 551 , Combined Loss: tensor(0.6383, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8544067144393921\n",
      "Batch: 552 , Combined Loss: tensor(0.6660, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8374159336090088\n",
      "Batch: 553 , Combined Loss: tensor(0.6290, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.994389533996582\n",
      "Batch: 554 , Combined Loss: tensor(0.6232, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6106383800506592\n",
      "Batch: 555 , Combined Loss: tensor(0.7666, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9119821786880493\n",
      "Batch: 556 , Combined Loss: tensor(0.6395, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1113567352294922\n",
      "Batch: 557 , Combined Loss: tensor(0.5900, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.973490834236145\n",
      "Batch: 558 , Combined Loss: tensor(0.6162, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9742411375045776\n",
      "Batch: 559 , Combined Loss: tensor(0.5768, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.138664960861206\n",
      "Batch: 560 , Combined Loss: tensor(0.6603, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8213274478912354\n",
      "Batch: 561 , Combined Loss: tensor(0.6243, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8689746856689453\n",
      "Batch: 562 , Combined Loss: tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9360815286636353\n",
      "Batch: 563 , Combined Loss: tensor(0.7978, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7291216850280762\n",
      "Batch: 564 , Combined Loss: tensor(0.8198, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7139118909835815\n",
      "Batch: 565 , Combined Loss: tensor(0.6534, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7768038511276245\n",
      "Batch: 566 , Combined Loss: tensor(0.6040, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8171703815460205\n",
      "Batch: 567 , Combined Loss: tensor(0.6365, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8888000249862671\n",
      "Batch: 568 , Combined Loss: tensor(0.5826, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9792892932891846\n",
      "Batch: 569 , Combined Loss: tensor(0.6866, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4723857641220093\n",
      "Batch: 570 , Combined Loss: tensor(0.8540, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1918606758117676\n",
      "Batch: 571 , Combined Loss: tensor(0.6285, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9233829975128174\n",
      "Batch: 572 , Combined Loss: tensor(0.6876, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6242468357086182\n",
      "Batch: 573 , Combined Loss: tensor(0.6311, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8013901710510254\n",
      "Batch: 574 , Combined Loss: tensor(0.6768, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3310117721557617\n",
      "Batch: 575 , Combined Loss: tensor(0.8554, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48374462127685547\n",
      "Batch: 576 , Combined Loss: tensor(0.6494, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0168178081512451\n",
      "Batch: 577 , Combined Loss: tensor(0.6312, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1706843376159668\n",
      "Batch: 578 , Combined Loss: tensor(0.6766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.13522851467132568\n",
      "Batch: 579 , Combined Loss: tensor(0.6142, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0740668773651123\n",
      "Batch: 580 , Combined Loss: tensor(0.5251, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5229077339172363\n",
      "Batch: 581 , Combined Loss: tensor(0.6442, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9180916547775269\n",
      "Batch: 582 , Combined Loss: tensor(0.5913, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.00276780128479\n",
      "Batch: 583 , Combined Loss: tensor(0.4903, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.500208854675293\n",
      "Batch: 584 , Combined Loss: tensor(0.5971, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.221689224243164\n",
      "Batch: 585 , Combined Loss: tensor(0.6900, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0358128547668457\n",
      "Batch: 586 , Combined Loss: tensor(0.6692, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1480307579040527\n",
      "Batch: 587 , Combined Loss: tensor(0.6868, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8241300582885742\n",
      "Batch: 588 , Combined Loss: tensor(0.5993, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5798060894012451\n",
      "Batch: 589 , Combined Loss: tensor(0.7219, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4580206871032715\n",
      "Batch: 590 , Combined Loss: tensor(0.6294, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4477272033691406\n",
      "Batch: 591 , Combined Loss: tensor(0.6021, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1908204555511475\n",
      "Batch: 592 , Combined Loss: tensor(0.5927, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7959271669387817\n",
      "Batch: 593 , Combined Loss: tensor(0.7548, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28841888904571533\n",
      "Batch: 594 , Combined Loss: tensor(0.5970, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0008213520050048828\n",
      "Batch: 595 , Combined Loss: tensor(0.6217, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0451910495758057\n",
      "Batch: 596 , Combined Loss: tensor(0.6544, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28097057342529297\n",
      "Batch: 597 , Combined Loss: tensor(0.6276, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9682590961456299\n",
      "Batch: 598 , Combined Loss: tensor(0.6480, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0971472263336182\n",
      "Batch: 599 , Combined Loss: tensor(0.5614, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5229160785675049\n",
      "Batch: 600 , Combined Loss: tensor(0.6851, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.128739595413208\n",
      "Batch: 601 , Combined Loss: tensor(0.6358, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6395459175109863\n",
      "Batch: 602 , Combined Loss: tensor(0.6604, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8999439477920532\n",
      "Batch: 603 , Combined Loss: tensor(0.6205, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0091471672058105\n",
      "Batch: 604 , Combined Loss: tensor(0.7725, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7340402603149414\n",
      "Batch: 605 , Combined Loss: tensor(0.7384, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12636971473693848\n",
      "Batch: 606 , Combined Loss: tensor(0.5659, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1019105911254883\n",
      "Batch: 607 , Combined Loss: tensor(0.6397, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9655548334121704\n",
      "Batch: 608 , Combined Loss: tensor(0.8149, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41773056983947754\n",
      "Batch: 609 , Combined Loss: tensor(0.9853, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7420673370361328\n",
      "Batch: 610 , Combined Loss: tensor(0.7569, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9975746870040894\n",
      "Batch: 611 , Combined Loss: tensor(0.6804, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9004524946212769\n",
      "Batch: 612 , Combined Loss: tensor(0.7170, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6161373853683472\n",
      "Batch: 613 , Combined Loss: tensor(0.8107, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.503563404083252\n",
      "Batch: 614 , Combined Loss: tensor(0.6019, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9962564706802368\n",
      "Batch: 615 , Combined Loss: tensor(0.7396, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6128411293029785\n",
      "Batch: 616 , Combined Loss: tensor(0.6813, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7616829872131348\n",
      "Batch: 617 , Combined Loss: tensor(0.5937, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7894971370697021\n",
      "Batch: 618 , Combined Loss: tensor(0.6098, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5695434808731079\n",
      "Batch: 619 , Combined Loss: tensor(0.6781, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9621113538742065\n",
      "Batch: 620 , Combined Loss: tensor(0.6311, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6840935945510864\n",
      "Batch: 621 , Combined Loss: tensor(0.7650, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9919002056121826\n",
      "Batch: 622 , Combined Loss: tensor(0.5815, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.867529034614563\n",
      "Batch: 623 , Combined Loss: tensor(0.6109, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2163710594177246\n",
      "Batch: 624 , Combined Loss: tensor(0.5861, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.991155743598938\n",
      "Batch: 625 , Combined Loss: tensor(0.6701, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17098069190979004\n",
      "Batch: 626 , Combined Loss: tensor(0.6189, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1244864463806152\n",
      "Batch: 627 , Combined Loss: tensor(0.5722, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6337831020355225\n",
      "Batch: 628 , Combined Loss: tensor(0.6184, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3179851770401001\n",
      "----------Epoch 25, Loss: 0.6633031342670156, Accuracy: 0.9740025682555473, Dice Coef: [0.9886617110908884, 0.6115244737767278, 0.653109564731873, 0.729563794770276], Dice Coef Necrotic: 1.0350318077710463, Dice Coef Edema: 1.043997675755537, Dice Coef Enhancing: 1.0484091120998345, Sensitivity: [0.9796464402459574, 0.7587885323642429, 0.8610458432123752, 0.8781310918552887], Specificity: [0.9656741076129798, 0.9977421111446496, 0.9816393025918303, 0.9959909311349138], Precision: [0.9979192754801582, 0.5870014418278993, 0.5579942627474369, 0.6691104180215812]\n",
      "Saving without nn.DataParallel\n",
      "Batch: 0 , Combined Loss: tensor(0.8782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47764670848846436\n",
      "Batch: 1 , Combined Loss: tensor(0.6105, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3511488437652588\n",
      "Batch: 2 , Combined Loss: tensor(0.6070, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0619158744812012\n",
      "Batch: 3 , Combined Loss: tensor(0.5062, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3931492567062378\n",
      "Batch: 4 , Combined Loss: tensor(0.5918, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6430214643478394\n",
      "Batch: 5 , Combined Loss: tensor(0.7191, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.728290319442749\n",
      "Batch: 6 , Combined Loss: tensor(0.8139, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8165746927261353\n",
      "Batch: 7 , Combined Loss: tensor(0.6153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9493989944458008\n",
      "Batch: 8 , Combined Loss: tensor(0.6702, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6828337907791138\n",
      "Batch: 9 , Combined Loss: tensor(0.5285, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0220792293548584\n",
      "Batch: 10 , Combined Loss: tensor(0.5966, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.061330795288086\n",
      "Batch: 11 , Combined Loss: tensor(0.6071, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7218992710113525\n",
      "Batch: 12 , Combined Loss: tensor(0.5860, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0182545185089111\n",
      "Batch: 13 , Combined Loss: tensor(0.7422, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5739495754241943\n",
      "Batch: 14 , Combined Loss: tensor(0.6019, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0548224449157715\n",
      "Batch: 15 , Combined Loss: tensor(0.6735, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35361039638519287\n",
      "Batch: 16 , Combined Loss: tensor(0.5726, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7620477676391602\n",
      "Batch: 17 , Combined Loss: tensor(0.6444, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5000149011611938\n",
      "Batch: 18 , Combined Loss: tensor(0.5509, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.232720136642456\n",
      "Batch: 19 , Combined Loss: tensor(0.6990, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9087679386138916\n",
      "Batch: 20 , Combined Loss: tensor(0.7747, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7488940954208374\n",
      "Batch: 21 , Combined Loss: tensor(0.6185, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.009307861328125\n",
      "Batch: 22 , Combined Loss: tensor(0.5905, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08582818508148193\n",
      "Batch: 23 , Combined Loss: tensor(0.5724, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8836280107498169\n",
      "Batch: 24 , Combined Loss: tensor(0.7782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.019557237625122\n",
      "Batch: 25 , Combined Loss: tensor(0.5655, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8182766437530518\n",
      "Batch: 26 , Combined Loss: tensor(0.5294, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.095862627029419\n",
      "Batch: 27 , Combined Loss: tensor(0.7407, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1268904209136963\n",
      "Batch: 28 , Combined Loss: tensor(0.5445, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.089935064315796\n",
      "Batch: 29 , Combined Loss: tensor(0.6750, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1240060329437256\n",
      "Batch: 30 , Combined Loss: tensor(0.6343, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43888795375823975\n",
      "Batch: 31 , Combined Loss: tensor(0.5847, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7083823680877686\n",
      "Batch: 32 , Combined Loss: tensor(0.5922, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8440244197845459\n",
      "Batch: 33 , Combined Loss: tensor(0.6167, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0026906728744506836\n",
      "Batch: 34 , Combined Loss: tensor(0.6113, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0708668231964111\n",
      "Batch: 35 , Combined Loss: tensor(0.6700, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21469497680664062\n",
      "Batch: 36 , Combined Loss: tensor(0.7052, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.843163013458252\n",
      "Batch: 37 , Combined Loss: tensor(0.5589, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6220734119415283\n",
      "Batch: 38 , Combined Loss: tensor(0.6024, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8965622186660767\n",
      "Batch: 39 , Combined Loss: tensor(0.8417, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4808114767074585\n",
      "Batch: 40 , Combined Loss: tensor(0.7038, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0450503826141357\n",
      "Batch: 41 , Combined Loss: tensor(0.6606, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0517454147338867\n",
      "Batch: 42 , Combined Loss: tensor(0.5986, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0474202632904053\n",
      "Batch: 43 , Combined Loss: tensor(0.5112, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9795175790786743\n",
      "Batch: 44 , Combined Loss: tensor(0.7367, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5787431001663208\n",
      "Batch: 45 , Combined Loss: tensor(0.6163, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1585280895233154\n",
      "Batch: 46 , Combined Loss: tensor(0.5971, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8801474571228027\n",
      "Batch: 47 , Combined Loss: tensor(0.6182, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2213606834411621\n",
      "Batch: 48 , Combined Loss: tensor(0.8591, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.033628225326538\n",
      "Batch: 49 , Combined Loss: tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7376542091369629\n",
      "Batch: 50 , Combined Loss: tensor(0.7002, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0606284141540527\n",
      "Batch: 51 , Combined Loss: tensor(0.6217, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0168447494506836\n",
      "Batch: 52 , Combined Loss: tensor(0.6469, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03421574831008911\n",
      "Batch: 53 , Combined Loss: tensor(0.6008, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7696917057037354\n",
      "Batch: 54 , Combined Loss: tensor(0.6011, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9174834489822388\n",
      "Batch: 55 , Combined Loss: tensor(0.5545, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9370565414428711\n",
      "Batch: 56 , Combined Loss: tensor(0.7219, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7411012649536133\n",
      "Batch: 57 , Combined Loss: tensor(0.6274, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17926204204559326\n",
      "Batch: 58 , Combined Loss: tensor(0.5185, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8325462341308594\n",
      "Batch: 59 , Combined Loss: tensor(0.6599, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5508061647415161\n",
      "Batch: 60 , Combined Loss: tensor(0.5313, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2546037435531616\n",
      "Batch: 61 , Combined Loss: tensor(0.6108, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0433483123779297\n",
      "Batch: 62 , Combined Loss: tensor(0.7873, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8479923009872437\n",
      "Batch: 63 , Combined Loss: tensor(0.5829, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7050565481185913\n",
      "Batch: 64 , Combined Loss: tensor(0.5950, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0187721252441406\n",
      "Batch: 65 , Combined Loss: tensor(0.7163, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07389205694198608\n",
      "Batch: 66 , Combined Loss: tensor(0.5924, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0913915634155273\n",
      "Batch: 67 , Combined Loss: tensor(0.6361, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0660605430603027\n",
      "Batch: 68 , Combined Loss: tensor(0.7033, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07969337701797485\n",
      "Batch: 69 , Combined Loss: tensor(0.5917, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7350078821182251\n",
      "Batch: 70 , Combined Loss: tensor(0.5779, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9227524995803833\n",
      "Batch: 71 , Combined Loss: tensor(0.6365, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5515053272247314\n",
      "Batch: 72 , Combined Loss: tensor(0.7782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40684258937835693\n",
      "Batch: 73 , Combined Loss: tensor(0.5814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8546921014785767\n",
      "Batch: 74 , Combined Loss: tensor(0.8241, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19679439067840576\n",
      "Batch: 75 , Combined Loss: tensor(0.7350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7919427156448364\n",
      "Batch: 76 , Combined Loss: tensor(0.6453, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11738115549087524\n",
      "Batch: 77 , Combined Loss: tensor(0.6478, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.78375244140625\n",
      "Batch: 78 , Combined Loss: tensor(0.8104, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7167948484420776\n",
      "Batch: 79 , Combined Loss: tensor(0.6314, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8191107511520386\n",
      "Batch: 80 , Combined Loss: tensor(0.6162, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.47464990615844727\n",
      "Batch: 81 , Combined Loss: tensor(0.5962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12048089504241943\n",
      "Batch: 82 , Combined Loss: tensor(0.5586, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5723639726638794\n",
      "Batch: 83 , Combined Loss: tensor(0.7657, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8757027387619019\n",
      "Batch: 84 , Combined Loss: tensor(0.6218, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5558243989944458\n",
      "Batch: 85 , Combined Loss: tensor(0.6491, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2154552936553955\n",
      "Batch: 86 , Combined Loss: tensor(0.7435, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2948603630065918\n",
      "Batch: 87 , Combined Loss: tensor(0.5268, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8155571222305298\n",
      "Batch: 88 , Combined Loss: tensor(0.6510, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7803362607955933\n",
      "Batch: 89 , Combined Loss: tensor(0.6489, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.064068078994751\n",
      "Batch: 90 , Combined Loss: tensor(0.6505, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.051886796951294\n",
      "Batch: 91 , Combined Loss: tensor(0.5993, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5303071737289429\n",
      "Batch: 92 , Combined Loss: tensor(0.5711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8127110004425049\n",
      "Batch: 93 , Combined Loss: tensor(0.8059, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.004744410514831543\n",
      "Batch: 94 , Combined Loss: tensor(0.6273, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41973447799682617\n",
      "Batch: 95 , Combined Loss: tensor(0.6346, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.092297077178955\n",
      "Batch: 96 , Combined Loss: tensor(0.5798, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0763626098632812\n",
      "Batch: 97 , Combined Loss: tensor(0.6314, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9755353927612305\n",
      "Batch: 98 , Combined Loss: tensor(0.6577, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8047347068786621\n",
      "Batch: 99 , Combined Loss: tensor(0.6053, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0203771591186523\n",
      "Batch: 100 , Combined Loss: tensor(0.6415, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8967912197113037\n",
      "Batch: 101 , Combined Loss: tensor(0.7404, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07380306720733643\n",
      "Batch: 102 , Combined Loss: tensor(0.7312, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0283877849578857\n",
      "Batch: 103 , Combined Loss: tensor(0.5533, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.607376217842102\n",
      "Batch: 104 , Combined Loss: tensor(0.6323, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7401729822158813\n",
      "Batch: 105 , Combined Loss: tensor(0.7124, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.874524712562561\n",
      "Batch: 106 , Combined Loss: tensor(0.6912, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16633129119873047\n",
      "Batch: 107 , Combined Loss: tensor(0.7098, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6554675102233887\n",
      "Batch: 108 , Combined Loss: tensor(0.6453, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0013010501861572\n",
      "Batch: 109 , Combined Loss: tensor(0.5572, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7822729349136353\n",
      "Batch: 110 , Combined Loss: tensor(0.5774, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0107834339141846\n",
      "Batch: 111 , Combined Loss: tensor(0.5414, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.984216570854187\n",
      "Batch: 112 , Combined Loss: tensor(0.6390, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1045095920562744\n",
      "Batch: 113 , Combined Loss: tensor(0.5702, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0751979351043701\n",
      "Batch: 114 , Combined Loss: tensor(0.6447, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0844242572784424\n",
      "Batch: 115 , Combined Loss: tensor(0.6064, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0811283588409424\n",
      "Batch: 116 , Combined Loss: tensor(0.6445, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6288540363311768\n",
      "Batch: 117 , Combined Loss: tensor(0.8729, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.001509428024292\n",
      "Batch: 118 , Combined Loss: tensor(0.5914, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1204817295074463\n",
      "Batch: 119 , Combined Loss: tensor(0.5682, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2507603168487549\n",
      "Batch: 120 , Combined Loss: tensor(0.5535, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5378625392913818\n",
      "Batch: 121 , Combined Loss: tensor(0.7596, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0081419944763184\n",
      "Batch: 122 , Combined Loss: tensor(0.6732, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9338127374649048\n",
      "Batch: 123 , Combined Loss: tensor(0.6187, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6431729793548584\n",
      "Batch: 124 , Combined Loss: tensor(0.7180, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9705153703689575\n",
      "Batch: 125 , Combined Loss: tensor(0.6969, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1734797954559326\n",
      "Batch: 126 , Combined Loss: tensor(0.5687, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0062799453735352\n",
      "Batch: 127 , Combined Loss: tensor(0.5918, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2239909172058105\n",
      "Batch: 128 , Combined Loss: tensor(0.8141, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6667827367782593\n",
      "Batch: 129 , Combined Loss: tensor(0.6680, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5573656558990479\n",
      "Batch: 130 , Combined Loss: tensor(1.0333, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5184264183044434\n",
      "Batch: 131 , Combined Loss: tensor(0.6606, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6203494071960449\n",
      "Batch: 132 , Combined Loss: tensor(0.6059, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8281844854354858\n",
      "Batch: 133 , Combined Loss: tensor(0.6555, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2573099136352539\n",
      "Batch: 134 , Combined Loss: tensor(0.7212, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9458940029144287\n",
      "Batch: 135 , Combined Loss: tensor(0.6408, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9061417579650879\n",
      "Batch: 136 , Combined Loss: tensor(0.6800, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.13279986381530762\n",
      "Batch: 137 , Combined Loss: tensor(0.6153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1381940841674805\n",
      "Batch: 138 , Combined Loss: tensor(0.6072, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8766582012176514\n",
      "Batch: 139 , Combined Loss: tensor(0.6829, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10018265247344971\n",
      "Batch: 140 , Combined Loss: tensor(0.7487, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8263845443725586\n",
      "Batch: 141 , Combined Loss: tensor(0.5688, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8672292232513428\n",
      "Batch: 142 , Combined Loss: tensor(0.6969, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9969480037689209\n",
      "Batch: 143 , Combined Loss: tensor(0.5979, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9631979465484619\n",
      "Batch: 144 , Combined Loss: tensor(0.6373, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0847501754760742\n",
      "Batch: 145 , Combined Loss: tensor(0.5687, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5419923067092896\n",
      "Batch: 146 , Combined Loss: tensor(0.6567, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0701780319213867\n",
      "Batch: 147 , Combined Loss: tensor(0.6950, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0451695919036865\n",
      "Batch: 148 , Combined Loss: tensor(0.5918, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8520315885543823\n",
      "Batch: 149 , Combined Loss: tensor(0.6858, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0127582550048828\n",
      "Batch: 150 , Combined Loss: tensor(0.9039, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3566676378250122\n",
      "Batch: 151 , Combined Loss: tensor(0.7141, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37418031692504883\n",
      "Batch: 152 , Combined Loss: tensor(0.6675, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8893483877182007\n",
      "Batch: 153 , Combined Loss: tensor(0.6874, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1764022707939148\n",
      "Batch: 154 , Combined Loss: tensor(0.6493, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8331217765808105\n",
      "Batch: 155 , Combined Loss: tensor(0.6328, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2844043970108032\n",
      "Batch: 156 , Combined Loss: tensor(0.5814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6328785419464111\n",
      "Batch: 157 , Combined Loss: tensor(0.6500, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8842755556106567\n",
      "Batch: 158 , Combined Loss: tensor(0.5773, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7595701217651367\n",
      "Batch: 159 , Combined Loss: tensor(0.5680, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9713646173477173\n",
      "Batch: 160 , Combined Loss: tensor(0.6588, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2196104526519775\n",
      "Batch: 161 , Combined Loss: tensor(0.5795, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9539555311203003\n",
      "Batch: 162 , Combined Loss: tensor(0.5799, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9676209688186646\n",
      "Batch: 163 , Combined Loss: tensor(0.7006, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47614598274230957\n",
      "Batch: 164 , Combined Loss: tensor(0.6387, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7032545804977417\n",
      "Batch: 165 , Combined Loss: tensor(0.7333, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9522895812988281\n",
      "Batch: 166 , Combined Loss: tensor(0.5996, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9194163084030151\n",
      "Batch: 167 , Combined Loss: tensor(0.6979, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8370105028152466\n",
      "Batch: 168 , Combined Loss: tensor(0.6027, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9849684238433838\n",
      "Batch: 169 , Combined Loss: tensor(0.6427, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6433184146881104\n",
      "Batch: 170 , Combined Loss: tensor(0.5767, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9431463479995728\n",
      "Batch: 171 , Combined Loss: tensor(0.6036, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1846444606781006\n",
      "Batch: 172 , Combined Loss: tensor(0.7757, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36200833320617676\n",
      "Batch: 173 , Combined Loss: tensor(0.6206, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.058126211166381836\n",
      "Batch: 174 , Combined Loss: tensor(0.6492, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9196289777755737\n",
      "Batch: 175 , Combined Loss: tensor(0.5435, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7467364072799683\n",
      "Batch: 176 , Combined Loss: tensor(0.7547, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1496220827102661\n",
      "Batch: 177 , Combined Loss: tensor(0.6326, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3016674518585205\n",
      "Batch: 178 , Combined Loss: tensor(0.6178, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0420176982879639\n",
      "Batch: 179 , Combined Loss: tensor(0.5986, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.254732608795166\n",
      "Batch: 180 , Combined Loss: tensor(0.5586, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0882718563079834\n",
      "Batch: 181 , Combined Loss: tensor(0.8674, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.517094612121582\n",
      "Batch: 182 , Combined Loss: tensor(0.6704, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9051711559295654\n",
      "Batch: 183 , Combined Loss: tensor(0.6211, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7454278469085693\n",
      "Batch: 184 , Combined Loss: tensor(0.6791, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5734012126922607\n",
      "Batch: 185 , Combined Loss: tensor(0.6480, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9118859767913818\n",
      "Batch: 186 , Combined Loss: tensor(0.6048, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9810938835144043\n",
      "Batch: 187 , Combined Loss: tensor(0.5448, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1947343349456787\n",
      "Batch: 188 , Combined Loss: tensor(0.6994, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07371115684509277\n",
      "Batch: 189 , Combined Loss: tensor(0.7188, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0621020793914795\n",
      "Batch: 190 , Combined Loss: tensor(0.7190, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7587016820907593\n",
      "Batch: 191 , Combined Loss: tensor(0.6811, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9058979749679565\n",
      "Batch: 192 , Combined Loss: tensor(0.5989, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06650644540786743\n",
      "Batch: 193 , Combined Loss: tensor(1.0581, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20222783088684082\n",
      "Batch: 194 , Combined Loss: tensor(0.6377, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9038636684417725\n",
      "Batch: 195 , Combined Loss: tensor(0.5774, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.166710615158081\n",
      "Batch: 196 , Combined Loss: tensor(0.6144, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13765180110931396\n",
      "Batch: 197 , Combined Loss: tensor(0.5356, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8231546878814697\n",
      "Batch: 198 , Combined Loss: tensor(0.5876, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.984535813331604\n",
      "Batch: 199 , Combined Loss: tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6900945901870728\n",
      "Batch: 200 , Combined Loss: tensor(0.6245, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5357644557952881\n",
      "Batch: 201 , Combined Loss: tensor(0.6078, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.871994137763977\n",
      "Batch: 202 , Combined Loss: tensor(0.6005, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.733228325843811\n",
      "Batch: 203 , Combined Loss: tensor(0.5665, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6486870050430298\n",
      "Batch: 204 , Combined Loss: tensor(0.5851, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9405028820037842\n",
      "Batch: 205 , Combined Loss: tensor(0.5630, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6780095100402832\n",
      "Batch: 206 , Combined Loss: tensor(0.6009, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8172608613967896\n",
      "Batch: 207 , Combined Loss: tensor(0.7230, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9600187540054321\n",
      "Batch: 208 , Combined Loss: tensor(0.7578, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.02829742431640625\n",
      "Batch: 209 , Combined Loss: tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0191054344177246\n",
      "Batch: 210 , Combined Loss: tensor(0.5689, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.43995916843414307\n",
      "Batch: 211 , Combined Loss: tensor(0.6582, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7537475824356079\n",
      "Batch: 212 , Combined Loss: tensor(0.6563, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9555224180221558\n",
      "Batch: 213 , Combined Loss: tensor(0.9272, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12137603759765625\n",
      "Batch: 214 , Combined Loss: tensor(0.6933, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.838749885559082\n",
      "Batch: 215 , Combined Loss: tensor(0.6570, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9562200307846069\n",
      "Batch: 216 , Combined Loss: tensor(0.6516, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7802296876907349\n",
      "Batch: 217 , Combined Loss: tensor(0.5317, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9783555269241333\n",
      "Batch: 218 , Combined Loss: tensor(0.6197, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4705986976623535\n",
      "Batch: 219 , Combined Loss: tensor(0.7699, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9382556676864624\n",
      "Batch: 220 , Combined Loss: tensor(0.6692, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8886511325836182\n",
      "Batch: 221 , Combined Loss: tensor(0.6915, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7857083082199097\n",
      "Batch: 222 , Combined Loss: tensor(0.6728, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33714544773101807\n",
      "Batch: 223 , Combined Loss: tensor(0.6037, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9180183410644531\n",
      "Batch: 224 , Combined Loss: tensor(0.8864, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6383047103881836\n",
      "Batch: 225 , Combined Loss: tensor(0.5849, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9422460794448853\n",
      "Batch: 226 , Combined Loss: tensor(0.6062, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0174641609191895\n",
      "Batch: 227 , Combined Loss: tensor(0.5902, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1012763977050781\n",
      "Batch: 228 , Combined Loss: tensor(0.6336, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5589227676391602\n",
      "Batch: 229 , Combined Loss: tensor(0.6487, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5927414894104004\n",
      "Batch: 230 , Combined Loss: tensor(0.6578, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5413342714309692\n",
      "Batch: 231 , Combined Loss: tensor(1.0269, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8304921388626099\n",
      "Batch: 232 , Combined Loss: tensor(0.6299, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36588871479034424\n",
      "Batch: 233 , Combined Loss: tensor(0.7035, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08154135942459106\n",
      "Batch: 234 , Combined Loss: tensor(0.7387, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8898462057113647\n",
      "Batch: 235 , Combined Loss: tensor(0.5975, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6823732852935791\n",
      "Batch: 236 , Combined Loss: tensor(0.6585, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7041283845901489\n",
      "Batch: 237 , Combined Loss: tensor(0.6720, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.026713132858276367\n",
      "Batch: 238 , Combined Loss: tensor(0.6697, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19166386127471924\n",
      "Batch: 239 , Combined Loss: tensor(0.7460, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.349603533744812\n",
      "Batch: 240 , Combined Loss: tensor(0.6915, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7851840257644653\n",
      "Batch: 241 , Combined Loss: tensor(0.5795, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8062349557876587\n",
      "Batch: 242 , Combined Loss: tensor(0.5834, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.067798376083374\n",
      "Batch: 243 , Combined Loss: tensor(0.7093, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.002985954284668\n",
      "Batch: 244 , Combined Loss: tensor(0.6761, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8340746164321899\n",
      "Batch: 245 , Combined Loss: tensor(0.7086, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9595719575881958\n",
      "Batch: 246 , Combined Loss: tensor(0.6165, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5350614786148071\n",
      "Batch: 247 , Combined Loss: tensor(0.6488, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9671947956085205\n",
      "Batch: 248 , Combined Loss: tensor(0.6263, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.968065619468689\n",
      "Batch: 249 , Combined Loss: tensor(0.6418, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.725428581237793\n",
      "Batch: 250 , Combined Loss: tensor(0.6166, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49932706356048584\n",
      "Batch: 251 , Combined Loss: tensor(0.6220, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17613518238067627\n",
      "Batch: 252 , Combined Loss: tensor(0.6307, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5905346870422363\n",
      "Batch: 253 , Combined Loss: tensor(0.7035, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9122366905212402\n",
      "Batch: 254 , Combined Loss: tensor(0.6382, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9001895189285278\n",
      "Batch: 255 , Combined Loss: tensor(0.6045, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5738778114318848\n",
      "Batch: 256 , Combined Loss: tensor(0.6476, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8079754114151001\n",
      "Batch: 257 , Combined Loss: tensor(0.7281, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14782392978668213\n",
      "Batch: 258 , Combined Loss: tensor(0.6446, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0246119499206543\n",
      "Batch: 259 , Combined Loss: tensor(0.7877, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49214744567871094\n",
      "Batch: 260 , Combined Loss: tensor(0.5952, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7723329067230225\n",
      "Batch: 261 , Combined Loss: tensor(0.6771, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8004001379013062\n",
      "Batch: 262 , Combined Loss: tensor(0.7042, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8048062324523926\n",
      "Batch: 263 , Combined Loss: tensor(0.6891, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7729440927505493\n",
      "Batch: 264 , Combined Loss: tensor(0.6139, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7084330320358276\n",
      "Batch: 265 , Combined Loss: tensor(0.9401, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4265308380126953\n",
      "Batch: 266 , Combined Loss: tensor(0.6293, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.84563148021698\n",
      "Batch: 267 , Combined Loss: tensor(0.7651, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10629415512084961\n",
      "Batch: 268 , Combined Loss: tensor(0.5934, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8084486722946167\n",
      "Batch: 269 , Combined Loss: tensor(0.6382, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.561279296875\n",
      "Batch: 270 , Combined Loss: tensor(0.5857, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2106117606163025\n",
      "Batch: 271 , Combined Loss: tensor(0.5759, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9182080030441284\n",
      "Batch: 272 , Combined Loss: tensor(0.7176, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5321798324584961\n",
      "Batch: 273 , Combined Loss: tensor(0.7301, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9222289323806763\n",
      "Batch: 274 , Combined Loss: tensor(0.6095, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.899410605430603\n",
      "Batch: 275 , Combined Loss: tensor(0.6128, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8983794450759888\n",
      "Batch: 276 , Combined Loss: tensor(0.6546, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7282366752624512\n",
      "Batch: 277 , Combined Loss: tensor(0.6685, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.20863401889801025\n",
      "Batch: 278 , Combined Loss: tensor(0.6699, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.822733998298645\n",
      "Batch: 279 , Combined Loss: tensor(0.6221, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7688101530075073\n",
      "Batch: 280 , Combined Loss: tensor(0.7051, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6166462898254395\n",
      "Batch: 281 , Combined Loss: tensor(0.7986, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5215717554092407\n",
      "Batch: 282 , Combined Loss: tensor(0.7041, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9743386507034302\n",
      "Batch: 283 , Combined Loss: tensor(0.6890, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6306784152984619\n",
      "Batch: 284 , Combined Loss: tensor(0.6175, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6714125871658325\n",
      "Batch: 285 , Combined Loss: tensor(0.6452, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1242750883102417\n",
      "Batch: 286 , Combined Loss: tensor(0.6820, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7685589790344238\n",
      "Batch: 287 , Combined Loss: tensor(0.5839, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1798555850982666\n",
      "Batch: 288 , Combined Loss: tensor(0.6701, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.040043830871582\n",
      "Batch: 289 , Combined Loss: tensor(0.6922, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0416555404663086\n",
      "Batch: 290 , Combined Loss: tensor(0.6269, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6223915815353394\n",
      "Batch: 291 , Combined Loss: tensor(0.5598, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37183189392089844\n",
      "Batch: 292 , Combined Loss: tensor(0.6319, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8124433755874634\n",
      "Batch: 293 , Combined Loss: tensor(0.5757, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05424070358276367\n",
      "Batch: 294 , Combined Loss: tensor(0.5911, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8649181127548218\n",
      "Batch: 295 , Combined Loss: tensor(0.6408, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7664765119552612\n",
      "Batch: 296 , Combined Loss: tensor(0.6583, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8844506740570068\n",
      "Batch: 297 , Combined Loss: tensor(0.7177, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5568357706069946\n",
      "Batch: 298 , Combined Loss: tensor(0.5675, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.943792462348938\n",
      "Batch: 299 , Combined Loss: tensor(0.6227, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4884546995162964\n",
      "Batch: 300 , Combined Loss: tensor(0.5924, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6575977802276611\n",
      "Batch: 301 , Combined Loss: tensor(0.6160, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2864128351211548\n",
      "Batch: 302 , Combined Loss: tensor(0.7593, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.18059253692626953\n",
      "Batch: 303 , Combined Loss: tensor(0.5627, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0025467872619628906\n",
      "Batch: 304 , Combined Loss: tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6445624828338623\n",
      "Batch: 305 , Combined Loss: tensor(0.5427, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7610688209533691\n",
      "Batch: 306 , Combined Loss: tensor(0.6775, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7774782180786133\n",
      "Batch: 307 , Combined Loss: tensor(0.5305, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8760172128677368\n",
      "Batch: 308 , Combined Loss: tensor(0.5587, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8642853498458862\n",
      "Batch: 309 , Combined Loss: tensor(0.7624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10033082962036133\n",
      "Batch: 310 , Combined Loss: tensor(0.6148, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9814833402633667\n",
      "Batch: 311 , Combined Loss: tensor(0.6077, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7844231128692627\n",
      "Batch: 312 , Combined Loss: tensor(0.6291, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5805562734603882\n",
      "Batch: 313 , Combined Loss: tensor(0.6805, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3192613124847412\n",
      "Batch: 314 , Combined Loss: tensor(0.5956, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.168900728225708\n",
      "Batch: 315 , Combined Loss: tensor(0.5809, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5253055095672607\n",
      "Batch: 316 , Combined Loss: tensor(0.7314, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9024755954742432\n",
      "Batch: 317 , Combined Loss: tensor(0.7189, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6694315671920776\n",
      "Batch: 318 , Combined Loss: tensor(0.5928, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9978135824203491\n",
      "Batch: 319 , Combined Loss: tensor(0.7070, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1384096145629883\n",
      "Batch: 320 , Combined Loss: tensor(0.7707, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1786575317382812\n",
      "Batch: 321 , Combined Loss: tensor(0.5804, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8763747215270996\n",
      "Batch: 322 , Combined Loss: tensor(0.6551, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.966838002204895\n",
      "Batch: 323 , Combined Loss: tensor(0.6255, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9774807691574097\n",
      "Batch: 324 , Combined Loss: tensor(0.5863, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3407251834869385\n",
      "Batch: 325 , Combined Loss: tensor(0.6785, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1991629600524902\n",
      "Batch: 326 , Combined Loss: tensor(0.6160, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.10866379737854\n",
      "Batch: 327 , Combined Loss: tensor(0.6946, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9549188613891602\n",
      "Batch: 328 , Combined Loss: tensor(0.5909, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18412292003631592\n",
      "Batch: 329 , Combined Loss: tensor(0.8953, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9043408632278442\n",
      "Batch: 330 , Combined Loss: tensor(0.6584, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.909454345703125\n",
      "Batch: 331 , Combined Loss: tensor(0.5752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1676950454711914\n",
      "Batch: 332 , Combined Loss: tensor(0.7227, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8573175668716431\n",
      "Batch: 333 , Combined Loss: tensor(0.5756, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9995619058609009\n",
      "Batch: 334 , Combined Loss: tensor(0.5721, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9260902404785156\n",
      "Batch: 335 , Combined Loss: tensor(0.7901, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6603360176086426\n",
      "Batch: 336 , Combined Loss: tensor(0.6820, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9134825468063354\n",
      "Batch: 337 , Combined Loss: tensor(0.6960, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7705605030059814\n",
      "Batch: 338 , Combined Loss: tensor(0.9219, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8779981136322021\n",
      "Batch: 339 , Combined Loss: tensor(0.5860, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8980367183685303\n",
      "Batch: 340 , Combined Loss: tensor(0.6152, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0677669048309326\n",
      "Batch: 341 , Combined Loss: tensor(0.5836, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5625336170196533\n",
      "Batch: 342 , Combined Loss: tensor(0.6891, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1205229759216309\n",
      "Batch: 343 , Combined Loss: tensor(0.9039, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7477424144744873\n",
      "Batch: 344 , Combined Loss: tensor(0.6714, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0440568923950195\n",
      "Batch: 345 , Combined Loss: tensor(0.7664, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1284496784210205\n",
      "Batch: 346 , Combined Loss: tensor(0.6319, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2194175720214844\n",
      "Batch: 347 , Combined Loss: tensor(0.8621, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9868148565292358\n",
      "Batch: 348 , Combined Loss: tensor(0.6493, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2770755290985107\n",
      "Batch: 349 , Combined Loss: tensor(0.7836, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0823829174041748\n",
      "Batch: 350 , Combined Loss: tensor(0.7568, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7660394906997681\n",
      "Batch: 351 , Combined Loss: tensor(0.6420, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7184025049209595\n",
      "Batch: 352 , Combined Loss: tensor(0.5876, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0017268657684326\n",
      "Batch: 353 , Combined Loss: tensor(0.6031, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9112588167190552\n",
      "Batch: 354 , Combined Loss: tensor(0.6702, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9118149280548096\n",
      "Batch: 355 , Combined Loss: tensor(0.6139, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3629721403121948\n",
      "Batch: 356 , Combined Loss: tensor(0.6942, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0552246570587158\n",
      "Batch: 357 , Combined Loss: tensor(0.7772, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9426385164260864\n",
      "Batch: 358 , Combined Loss: tensor(0.7057, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6219577789306641\n",
      "Batch: 359 , Combined Loss: tensor(0.5942, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9566426277160645\n",
      "Batch: 360 , Combined Loss: tensor(0.6137, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8771625757217407\n",
      "Batch: 361 , Combined Loss: tensor(0.5997, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9418210983276367\n",
      "Batch: 362 , Combined Loss: tensor(0.7027, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9812649488449097\n",
      "Batch: 363 , Combined Loss: tensor(0.5381, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9887409210205078\n",
      "Batch: 364 , Combined Loss: tensor(0.6989, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8111854791641235\n",
      "Batch: 365 , Combined Loss: tensor(0.6520, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9237402677536011\n",
      "Batch: 366 , Combined Loss: tensor(0.7739, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9980043172836304\n",
      "Batch: 367 , Combined Loss: tensor(0.6505, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.057591438293457\n",
      "Batch: 368 , Combined Loss: tensor(0.5839, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9820220470428467\n",
      "Batch: 369 , Combined Loss: tensor(0.6187, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33437812328338623\n",
      "Batch: 370 , Combined Loss: tensor(0.5605, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0342183113098145\n",
      "Batch: 371 , Combined Loss: tensor(0.6544, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1294505596160889\n",
      "Batch: 372 , Combined Loss: tensor(0.6250, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8894146680831909\n",
      "Batch: 373 , Combined Loss: tensor(0.6517, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0832514762878418\n",
      "Batch: 374 , Combined Loss: tensor(0.6281, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1312077045440674\n",
      "Batch: 375 , Combined Loss: tensor(0.6850, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0816593170166016\n",
      "Batch: 376 , Combined Loss: tensor(0.5933, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9735556840896606\n",
      "Batch: 377 , Combined Loss: tensor(0.5756, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4653891324996948\n",
      "Batch: 378 , Combined Loss: tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0764422416687012\n",
      "Batch: 379 , Combined Loss: tensor(0.5784, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1625816822052002\n",
      "Batch: 380 , Combined Loss: tensor(0.7917, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0211012363433838\n",
      "Batch: 381 , Combined Loss: tensor(0.6093, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7003421783447266\n",
      "Batch: 382 , Combined Loss: tensor(0.5785, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6103391647338867\n",
      "Batch: 383 , Combined Loss: tensor(0.6623, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8203239440917969\n",
      "Batch: 384 , Combined Loss: tensor(0.8419, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05152672529220581\n",
      "Batch: 385 , Combined Loss: tensor(0.6488, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6989696025848389\n",
      "Batch: 386 , Combined Loss: tensor(0.6273, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0157616138458252\n",
      "Batch: 387 , Combined Loss: tensor(0.6808, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1494746208190918\n",
      "Batch: 388 , Combined Loss: tensor(0.7657, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2280738353729248\n",
      "Batch: 389 , Combined Loss: tensor(0.6862, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34214508533477783\n",
      "Batch: 390 , Combined Loss: tensor(0.6339, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4559367895126343\n",
      "Batch: 391 , Combined Loss: tensor(0.5365, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.259965419769287\n",
      "Batch: 392 , Combined Loss: tensor(0.6277, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.059920310974121\n",
      "Batch: 393 , Combined Loss: tensor(0.5416, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9359703063964844\n",
      "Batch: 394 , Combined Loss: tensor(0.6251, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0915353298187256\n",
      "Batch: 395 , Combined Loss: tensor(0.5695, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9914586544036865\n",
      "Batch: 396 , Combined Loss: tensor(0.7298, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9593023061752319\n",
      "Batch: 397 , Combined Loss: tensor(0.7757, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.572772741317749\n",
      "Batch: 398 , Combined Loss: tensor(0.5580, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8643697500228882\n",
      "Batch: 399 , Combined Loss: tensor(0.6200, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.188504934310913\n",
      "Batch: 400 , Combined Loss: tensor(0.7205, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1833724975585938\n",
      "Batch: 401 , Combined Loss: tensor(0.5624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49079060554504395\n",
      "Batch: 402 , Combined Loss: tensor(0.8708, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.602314829826355\n",
      "Batch: 403 , Combined Loss: tensor(0.5335, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5366578102111816\n",
      "Batch: 404 , Combined Loss: tensor(0.6783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8519171476364136\n",
      "Batch: 405 , Combined Loss: tensor(0.6926, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9170418977737427\n",
      "Batch: 406 , Combined Loss: tensor(0.5972, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8786064386367798\n",
      "Batch: 407 , Combined Loss: tensor(0.6611, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0723340511322021\n",
      "Batch: 408 , Combined Loss: tensor(0.6532, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0408344268798828\n",
      "Batch: 409 , Combined Loss: tensor(0.5763, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9863845109939575\n",
      "Batch: 410 , Combined Loss: tensor(0.6968, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8291499614715576\n",
      "Batch: 411 , Combined Loss: tensor(0.5193, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9090412855148315\n",
      "Batch: 412 , Combined Loss: tensor(0.6180, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.053236484527588\n",
      "Batch: 413 , Combined Loss: tensor(0.5901, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1046299934387207\n",
      "Batch: 414 , Combined Loss: tensor(0.7479, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8050041198730469\n",
      "Batch: 415 , Combined Loss: tensor(0.8123, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7827723026275635\n",
      "Batch: 416 , Combined Loss: tensor(0.7195, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6195695400238037\n",
      "Batch: 417 , Combined Loss: tensor(0.7278, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0790650844573975\n",
      "Batch: 418 , Combined Loss: tensor(0.5537, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1156246662139893\n",
      "Batch: 419 , Combined Loss: tensor(0.6210, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8805582523345947\n",
      "Batch: 420 , Combined Loss: tensor(0.7197, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.098945140838623\n",
      "Batch: 421 , Combined Loss: tensor(0.5523, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1785807609558105\n",
      "Batch: 422 , Combined Loss: tensor(0.6643, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4658886194229126\n",
      "Batch: 423 , Combined Loss: tensor(0.5705, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7774516344070435\n",
      "Batch: 424 , Combined Loss: tensor(0.5732, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9241710901260376\n",
      "Batch: 425 , Combined Loss: tensor(0.5395, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0618572235107422\n",
      "Batch: 426 , Combined Loss: tensor(0.5998, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7369776964187622\n",
      "Batch: 427 , Combined Loss: tensor(0.5350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.92401123046875\n",
      "Batch: 428 , Combined Loss: tensor(0.7188, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2709903717041016\n",
      "Batch: 429 , Combined Loss: tensor(0.5788, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2056031227111816\n",
      "Batch: 430 , Combined Loss: tensor(0.7281, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5359846353530884\n",
      "Batch: 431 , Combined Loss: tensor(0.5743, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.153369665145874\n",
      "Batch: 432 , Combined Loss: tensor(0.6190, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1450018882751465\n",
      "Batch: 433 , Combined Loss: tensor(0.7227, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0818233489990234\n",
      "Batch: 434 , Combined Loss: tensor(0.5447, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9010891914367676\n",
      "Batch: 435 , Combined Loss: tensor(0.5214, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7899620532989502\n",
      "Batch: 436 , Combined Loss: tensor(0.6640, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2169146537780762\n",
      "Batch: 437 , Combined Loss: tensor(0.8603, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9713585376739502\n",
      "Batch: 438 , Combined Loss: tensor(0.5529, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9043066501617432\n",
      "Batch: 439 , Combined Loss: tensor(0.6449, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20127952098846436\n",
      "Batch: 440 , Combined Loss: tensor(0.6003, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1150307655334473\n",
      "Batch: 441 , Combined Loss: tensor(0.6521, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3968024253845215\n",
      "Batch: 442 , Combined Loss: tensor(0.5385, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2356374263763428\n",
      "Batch: 443 , Combined Loss: tensor(0.6224, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9998681545257568\n",
      "Batch: 444 , Combined Loss: tensor(0.7375, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.585422158241272\n",
      "Batch: 445 , Combined Loss: tensor(0.5609, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.049971580505371\n",
      "Batch: 446 , Combined Loss: tensor(0.5930, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2941269874572754\n",
      "Batch: 447 , Combined Loss: tensor(0.5932, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6240376234054565\n",
      "Batch: 448 , Combined Loss: tensor(0.6736, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0604503154754639\n",
      "Batch: 449 , Combined Loss: tensor(0.7300, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7907172441482544\n",
      "Batch: 450 , Combined Loss: tensor(0.6492, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7639729976654053\n",
      "Batch: 451 , Combined Loss: tensor(0.5579, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0161147117614746\n",
      "Batch: 452 , Combined Loss: tensor(0.6692, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0791382789611816\n",
      "Batch: 453 , Combined Loss: tensor(0.5888, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0267045497894287\n",
      "Batch: 454 , Combined Loss: tensor(0.6205, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5642138719558716\n",
      "Batch: 455 , Combined Loss: tensor(0.6485, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0772192478179932\n",
      "Batch: 456 , Combined Loss: tensor(0.7562, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7908836603164673\n",
      "Batch: 457 , Combined Loss: tensor(1.0445, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8139406442642212\n",
      "Batch: 458 , Combined Loss: tensor(0.8088, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4118497371673584\n",
      "Batch: 459 , Combined Loss: tensor(0.5912, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8372002840042114\n",
      "Batch: 460 , Combined Loss: tensor(0.5871, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9763661623001099\n",
      "Batch: 461 , Combined Loss: tensor(0.6245, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6569801568984985\n",
      "Batch: 462 , Combined Loss: tensor(0.6408, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7584989070892334\n",
      "Batch: 463 , Combined Loss: tensor(0.5714, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.590421199798584\n",
      "Batch: 464 , Combined Loss: tensor(0.6231, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2162985801696777\n",
      "Batch: 465 , Combined Loss: tensor(0.7239, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5797518491744995\n",
      "Batch: 466 , Combined Loss: tensor(0.6785, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6544760465621948\n",
      "Batch: 467 , Combined Loss: tensor(0.6356, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9152864217758179\n",
      "Batch: 468 , Combined Loss: tensor(0.6063, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8323696851730347\n",
      "Batch: 469 , Combined Loss: tensor(0.7311, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7561542987823486\n",
      "Batch: 470 , Combined Loss: tensor(0.6354, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9390735626220703\n",
      "Batch: 471 , Combined Loss: tensor(0.7077, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6393417119979858\n",
      "Batch: 472 , Combined Loss: tensor(0.7319, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8473668098449707\n",
      "Batch: 473 , Combined Loss: tensor(0.6470, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8429696559906006\n",
      "Batch: 474 , Combined Loss: tensor(0.6997, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6447352170944214\n",
      "Batch: 475 , Combined Loss: tensor(0.8317, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5093034505844116\n",
      "Batch: 476 , Combined Loss: tensor(0.6522, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4877054691314697\n",
      "Batch: 477 , Combined Loss: tensor(1.0296, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33067166805267334\n",
      "Batch: 478 , Combined Loss: tensor(0.5898, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9727996587753296\n",
      "Batch: 479 , Combined Loss: tensor(0.5823, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6240997314453125\n",
      "Batch: 480 , Combined Loss: tensor(0.6080, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2539174556732178\n",
      "Batch: 481 , Combined Loss: tensor(0.5846, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.638964056968689\n",
      "Batch: 482 , Combined Loss: tensor(0.6962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7830867767333984\n",
      "Batch: 483 , Combined Loss: tensor(0.7588, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5892856121063232\n",
      "Batch: 484 , Combined Loss: tensor(0.6037, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4611548185348511\n",
      "Batch: 485 , Combined Loss: tensor(0.6383, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4213531017303467\n",
      "Batch: 486 , Combined Loss: tensor(0.6166, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0060515403747559\n",
      "Batch: 487 , Combined Loss: tensor(0.5695, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7118884325027466\n",
      "Batch: 488 , Combined Loss: tensor(0.5638, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9405006170272827\n",
      "Batch: 489 , Combined Loss: tensor(0.8056, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6804543733596802\n",
      "Batch: 490 , Combined Loss: tensor(0.6876, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.992099404335022\n",
      "Batch: 491 , Combined Loss: tensor(0.6055, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9295681715011597\n",
      "Batch: 492 , Combined Loss: tensor(0.7021, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49326372146606445\n",
      "Batch: 493 , Combined Loss: tensor(0.6258, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9500941038131714\n",
      "Batch: 494 , Combined Loss: tensor(0.5943, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0312860012054443\n",
      "Batch: 495 , Combined Loss: tensor(0.5413, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0419509410858154\n",
      "Batch: 496 , Combined Loss: tensor(0.5097, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7229679822921753\n",
      "Batch: 497 , Combined Loss: tensor(0.5606, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9604319334030151\n",
      "Batch: 498 , Combined Loss: tensor(0.6941, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6068395376205444\n",
      "Batch: 499 , Combined Loss: tensor(0.5573, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6660394668579102\n",
      "Batch: 500 , Combined Loss: tensor(0.7940, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2608088254928589\n",
      "Batch: 501 , Combined Loss: tensor(0.9017, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07129687070846558\n",
      "Batch: 502 , Combined Loss: tensor(0.7769, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37723827362060547\n",
      "Batch: 503 , Combined Loss: tensor(0.6155, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0016393661499023\n",
      "Batch: 504 , Combined Loss: tensor(0.8591, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4050289988517761\n",
      "Batch: 505 , Combined Loss: tensor(0.6403, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.18012017011642456\n",
      "Batch: 506 , Combined Loss: tensor(0.5673, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1289403438568115\n",
      "Batch: 507 , Combined Loss: tensor(0.5546, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0547361373901367\n",
      "Batch: 508 , Combined Loss: tensor(0.6198, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7072347402572632\n",
      "Batch: 509 , Combined Loss: tensor(0.6559, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5840998888015747\n",
      "Batch: 510 , Combined Loss: tensor(0.5629, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3186769485473633\n",
      "Batch: 511 , Combined Loss: tensor(0.6717, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7257347106933594\n",
      "Batch: 512 , Combined Loss: tensor(0.6402, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4372001886367798\n",
      "Batch: 513 , Combined Loss: tensor(0.5775, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.123056411743164\n",
      "Batch: 514 , Combined Loss: tensor(0.5787, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8712282180786133\n",
      "Batch: 515 , Combined Loss: tensor(0.6925, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43519914150238037\n",
      "Batch: 516 , Combined Loss: tensor(0.5300, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8787940740585327\n",
      "Batch: 517 , Combined Loss: tensor(0.6331, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3296915292739868\n",
      "Batch: 518 , Combined Loss: tensor(0.5841, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7746175527572632\n",
      "Batch: 519 , Combined Loss: tensor(0.6619, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1348574161529541\n",
      "Batch: 520 , Combined Loss: tensor(0.8925, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.705535888671875\n",
      "Batch: 521 , Combined Loss: tensor(0.7609, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.120983362197876\n",
      "Batch: 522 , Combined Loss: tensor(0.8371, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8744194507598877\n",
      "Batch: 523 , Combined Loss: tensor(0.7106, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9042572975158691\n",
      "Batch: 524 , Combined Loss: tensor(0.9606, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.075927495956421\n",
      "Batch: 525 , Combined Loss: tensor(0.5846, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9155205488204956\n",
      "Batch: 526 , Combined Loss: tensor(0.8109, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9045417308807373\n",
      "Batch: 527 , Combined Loss: tensor(0.6985, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9694494009017944\n",
      "Batch: 528 , Combined Loss: tensor(0.6985, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21760618686676025\n",
      "Batch: 529 , Combined Loss: tensor(0.5601, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9004300832748413\n",
      "Batch: 530 , Combined Loss: tensor(0.5805, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0176982879638672\n",
      "Batch: 531 , Combined Loss: tensor(0.6167, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9188253879547119\n",
      "Batch: 532 , Combined Loss: tensor(0.6546, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9001132249832153\n",
      "Batch: 533 , Combined Loss: tensor(0.6780, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7212642431259155\n",
      "Batch: 534 , Combined Loss: tensor(0.7232, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6980413198471069\n",
      "Batch: 535 , Combined Loss: tensor(0.5821, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9258681535720825\n",
      "Batch: 536 , Combined Loss: tensor(0.5660, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9973529577255249\n",
      "Batch: 537 , Combined Loss: tensor(0.7883, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5368717908859253\n",
      "Batch: 538 , Combined Loss: tensor(0.8448, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24486708641052246\n",
      "Batch: 539 , Combined Loss: tensor(0.7809, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6136194467544556\n",
      "Batch: 540 , Combined Loss: tensor(0.6514, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7209596633911133\n",
      "Batch: 541 , Combined Loss: tensor(0.6342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4426358938217163\n",
      "Batch: 542 , Combined Loss: tensor(0.7554, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6527440547943115\n",
      "Batch: 543 , Combined Loss: tensor(0.6205, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4030953645706177\n",
      "Batch: 544 , Combined Loss: tensor(0.6181, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05280256271362305\n",
      "Batch: 545 , Combined Loss: tensor(0.5508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06027054786682129\n",
      "Batch: 546 , Combined Loss: tensor(0.6646, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6454826593399048\n",
      "Batch: 547 , Combined Loss: tensor(0.5854, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6033555269241333\n",
      "Batch: 548 , Combined Loss: tensor(0.7529, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4251375198364258\n",
      "Batch: 549 , Combined Loss: tensor(0.7311, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3724861145019531\n",
      "Batch: 550 , Combined Loss: tensor(0.5338, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7069618701934814\n",
      "Batch: 551 , Combined Loss: tensor(0.6333, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.027768969535827637\n",
      "Batch: 552 , Combined Loss: tensor(0.7354, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.887093186378479\n",
      "Batch: 553 , Combined Loss: tensor(0.6348, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9565136432647705\n",
      "Batch: 554 , Combined Loss: tensor(0.6471, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6143984794616699\n",
      "Batch: 555 , Combined Loss: tensor(0.6850, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8985968828201294\n",
      "Batch: 556 , Combined Loss: tensor(0.8422, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.941533088684082\n",
      "Batch: 557 , Combined Loss: tensor(0.4935, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4040881395339966\n",
      "Batch: 558 , Combined Loss: tensor(0.6456, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46916210651397705\n",
      "Batch: 559 , Combined Loss: tensor(0.9254, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08411437273025513\n",
      "Batch: 560 , Combined Loss: tensor(0.6310, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8880300521850586\n",
      "Batch: 561 , Combined Loss: tensor(0.6065, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5049058198928833\n",
      "Batch: 562 , Combined Loss: tensor(0.6355, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0605947971343994\n",
      "Batch: 563 , Combined Loss: tensor(0.7324, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2510298490524292\n",
      "Batch: 564 , Combined Loss: tensor(0.5738, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0909488201141357\n",
      "Batch: 565 , Combined Loss: tensor(0.7232, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21940720081329346\n",
      "Batch: 566 , Combined Loss: tensor(0.6666, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9948711395263672\n",
      "Batch: 567 , Combined Loss: tensor(0.6752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6292421817779541\n",
      "Batch: 568 , Combined Loss: tensor(0.7521, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8112386465072632\n",
      "Batch: 569 , Combined Loss: tensor(0.6315, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6112000942230225\n",
      "Batch: 570 , Combined Loss: tensor(0.5914, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9914096593856812\n",
      "Batch: 571 , Combined Loss: tensor(1.1721, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.7145512104034424\n",
      "Batch: 572 , Combined Loss: tensor(0.5543, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5707908868789673\n",
      "Batch: 573 , Combined Loss: tensor(0.5508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5745339393615723\n",
      "Batch: 574 , Combined Loss: tensor(0.5361, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6708924770355225\n",
      "Batch: 575 , Combined Loss: tensor(0.6121, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0102283954620361\n",
      "Batch: 576 , Combined Loss: tensor(0.6360, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8622949123382568\n",
      "Batch: 577 , Combined Loss: tensor(0.6582, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23611927032470703\n",
      "Batch: 578 , Combined Loss: tensor(0.6220, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0531337261199951\n",
      "Batch: 579 , Combined Loss: tensor(0.5936, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2030091285705566\n",
      "Batch: 580 , Combined Loss: tensor(0.5776, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7237290143966675\n",
      "Batch: 581 , Combined Loss: tensor(0.8029, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7045115232467651\n",
      "Batch: 582 , Combined Loss: tensor(0.6754, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7275418043136597\n",
      "Batch: 583 , Combined Loss: tensor(0.6594, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1331391334533691\n",
      "Batch: 584 , Combined Loss: tensor(0.5402, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9083794355392456\n",
      "Batch: 585 , Combined Loss: tensor(0.5968, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2565968036651611\n",
      "Batch: 586 , Combined Loss: tensor(0.5793, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.221578598022461\n",
      "Batch: 587 , Combined Loss: tensor(0.7702, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0570945739746094\n",
      "Batch: 588 , Combined Loss: tensor(0.5768, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8565889596939087\n",
      "Batch: 589 , Combined Loss: tensor(0.6962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9005169868469238\n",
      "Batch: 590 , Combined Loss: tensor(0.6262, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1251952648162842\n",
      "Batch: 591 , Combined Loss: tensor(0.6155, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7840478420257568\n",
      "Batch: 592 , Combined Loss: tensor(0.6118, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10179746150970459\n",
      "Batch: 593 , Combined Loss: tensor(0.6053, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2355091571807861\n",
      "Batch: 594 , Combined Loss: tensor(0.5592, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8763707876205444\n",
      "Batch: 595 , Combined Loss: tensor(0.5367, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5382511615753174\n",
      "Batch: 596 , Combined Loss: tensor(0.7215, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8855444192886353\n",
      "Batch: 597 , Combined Loss: tensor(0.5612, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1090435981750488\n",
      "Batch: 598 , Combined Loss: tensor(0.6772, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9110822677612305\n",
      "Batch: 599 , Combined Loss: tensor(0.6295, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0404419898986816\n",
      "Batch: 600 , Combined Loss: tensor(0.6853, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0514569282531738\n",
      "Batch: 601 , Combined Loss: tensor(0.6872, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.771965742111206\n",
      "Batch: 602 , Combined Loss: tensor(0.7989, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8485809564590454\n",
      "Batch: 603 , Combined Loss: tensor(0.6994, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9856135845184326\n",
      "Batch: 604 , Combined Loss: tensor(0.6603, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9614987373352051\n",
      "Batch: 605 , Combined Loss: tensor(0.5645, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40953266620635986\n",
      "Batch: 606 , Combined Loss: tensor(0.6439, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0070405006408691\n",
      "Batch: 607 , Combined Loss: tensor(0.4951, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8158859014511108\n",
      "Batch: 608 , Combined Loss: tensor(0.6645, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1488194465637207\n",
      "Batch: 609 , Combined Loss: tensor(0.5754, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0001559257507324\n",
      "Batch: 610 , Combined Loss: tensor(0.5509, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23181462287902832\n",
      "Batch: 611 , Combined Loss: tensor(0.8951, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9721801280975342\n",
      "Batch: 612 , Combined Loss: tensor(0.4977, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8948491811752319\n",
      "Batch: 613 , Combined Loss: tensor(0.7832, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9998148679733276\n",
      "Batch: 614 , Combined Loss: tensor(0.5574, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6781071424484253\n",
      "Batch: 615 , Combined Loss: tensor(0.8072, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9279118776321411\n",
      "Batch: 616 , Combined Loss: tensor(0.5814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8061844110488892\n",
      "Batch: 617 , Combined Loss: tensor(0.6509, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0594172477722168\n",
      "Batch: 618 , Combined Loss: tensor(0.5868, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0329656600952148\n",
      "Batch: 619 , Combined Loss: tensor(0.9394, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7890363931655884\n",
      "Batch: 620 , Combined Loss: tensor(0.7667, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8751046657562256\n",
      "Batch: 621 , Combined Loss: tensor(0.6371, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2113122940063477\n",
      "Batch: 622 , Combined Loss: tensor(0.6420, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.243863821029663\n",
      "Batch: 623 , Combined Loss: tensor(0.5406, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.198542833328247\n",
      "Batch: 624 , Combined Loss: tensor(0.5878, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1073691844940186\n",
      "Batch: 625 , Combined Loss: tensor(0.9258, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8777475357055664\n",
      "Batch: 626 , Combined Loss: tensor(0.6093, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8033879995346069\n",
      "Batch: 627 , Combined Loss: tensor(0.6088, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1489334106445312\n",
      "Batch: 628 , Combined Loss: tensor(0.8641, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09662961959838867\n",
      "----------Epoch 26, Loss: 0.6567593880222787, Accuracy: 0.9743756649035528, Dice Coef: [0.9886623495902469, 0.6182202396431042, 0.6592623352632815, 0.7461814261253032], Dice Coef Necrotic: 1.0477660020143114, Dice Coef Edema: 1.072176794543706, Dice Coef Enhancing: 1.075587413890991, Sensitivity: [0.9795316805521141, 0.7834995183207412, 0.8722756405987308, 0.8705794271052073], Specificity: [0.9672990515235876, 0.9977140697652092, 0.981350352066689, 0.996546218618869], Precision: [0.9980537036644067, 0.5807887767486916, 0.5628717211001558, 0.6927331407922387]\n",
      "Saving without nn.DataParallel\n",
      "Batch: 0 , Combined Loss: tensor(0.6712, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0516440868377686\n",
      "Batch: 1 , Combined Loss: tensor(0.5653, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6047106981277466\n",
      "Batch: 2 , Combined Loss: tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9515831470489502\n",
      "Batch: 3 , Combined Loss: tensor(0.5230, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0130691528320312\n",
      "Batch: 4 , Combined Loss: tensor(0.6402, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9493738412857056\n",
      "Batch: 5 , Combined Loss: tensor(0.5296, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9539976119995117\n",
      "Batch: 6 , Combined Loss: tensor(0.6072, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6458580493927002\n",
      "Batch: 7 , Combined Loss: tensor(0.7017, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8423036336898804\n",
      "Batch: 8 , Combined Loss: tensor(0.5589, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0550553798675537\n",
      "Batch: 9 , Combined Loss: tensor(0.5572, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7346816062927246\n",
      "Batch: 10 , Combined Loss: tensor(0.6992, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3655376434326172\n",
      "Batch: 11 , Combined Loss: tensor(0.8159, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9335095882415771\n",
      "Batch: 12 , Combined Loss: tensor(0.7172, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0215258598327637\n",
      "Batch: 13 , Combined Loss: tensor(0.5778, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38935625553131104\n",
      "Batch: 14 , Combined Loss: tensor(0.7733, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.903282880783081\n",
      "Batch: 15 , Combined Loss: tensor(0.6459, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9543691873550415\n",
      "Batch: 16 , Combined Loss: tensor(0.7822, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7008219957351685\n",
      "Batch: 17 , Combined Loss: tensor(0.6491, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.99873948097229\n",
      "Batch: 18 , Combined Loss: tensor(0.5889, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0332238674163818\n",
      "Batch: 19 , Combined Loss: tensor(0.6131, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0071499347686768\n",
      "Batch: 20 , Combined Loss: tensor(0.6212, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7713823318481445\n",
      "Batch: 21 , Combined Loss: tensor(0.5824, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7922582626342773\n",
      "Batch: 22 , Combined Loss: tensor(0.6987, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3064929246902466\n",
      "Batch: 23 , Combined Loss: tensor(0.5531, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5814297199249268\n",
      "Batch: 24 , Combined Loss: tensor(0.5897, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9970303773880005\n",
      "Batch: 25 , Combined Loss: tensor(0.5778, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1501219272613525\n",
      "Batch: 26 , Combined Loss: tensor(0.5274, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9314208030700684\n",
      "Batch: 27 , Combined Loss: tensor(0.5539, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0843849778175354\n",
      "Batch: 28 , Combined Loss: tensor(0.5694, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2064146995544434\n",
      "Batch: 29 , Combined Loss: tensor(0.5980, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1913940906524658\n",
      "Batch: 30 , Combined Loss: tensor(0.6967, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5703529119491577\n",
      "Batch: 31 , Combined Loss: tensor(0.5932, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.190140962600708\n",
      "Batch: 32 , Combined Loss: tensor(0.7076, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8895727396011353\n",
      "Batch: 33 , Combined Loss: tensor(0.5745, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7908205986022949\n",
      "Batch: 34 , Combined Loss: tensor(0.6459, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10519635677337646\n",
      "Batch: 35 , Combined Loss: tensor(0.6980, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8821746110916138\n",
      "Batch: 36 , Combined Loss: tensor(0.6158, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0384366512298584\n",
      "Batch: 37 , Combined Loss: tensor(0.6158, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8265632390975952\n",
      "Batch: 38 , Combined Loss: tensor(0.6677, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.13195276260375977\n",
      "Batch: 39 , Combined Loss: tensor(0.7297, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.057246446609497\n",
      "Batch: 40 , Combined Loss: tensor(0.7262, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0269694328308105\n",
      "Batch: 41 , Combined Loss: tensor(0.5402, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8615907430648804\n",
      "Batch: 42 , Combined Loss: tensor(0.6792, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.713047981262207\n",
      "Batch: 43 , Combined Loss: tensor(0.6154, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0955934524536133\n",
      "Batch: 44 , Combined Loss: tensor(0.7488, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.074808120727539\n",
      "Batch: 45 , Combined Loss: tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6802647113800049\n",
      "Batch: 46 , Combined Loss: tensor(0.7853, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0514068603515625\n",
      "Batch: 47 , Combined Loss: tensor(0.6549, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.840896487236023\n",
      "Batch: 48 , Combined Loss: tensor(0.6624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22590255737304688\n",
      "Batch: 49 , Combined Loss: tensor(0.6276, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7059460878372192\n",
      "Batch: 50 , Combined Loss: tensor(0.6249, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1044433116912842\n",
      "Batch: 51 , Combined Loss: tensor(0.9966, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5657545328140259\n",
      "Batch: 52 , Combined Loss: tensor(0.7224, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9268527030944824\n",
      "Batch: 53 , Combined Loss: tensor(0.6640, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1245495080947876\n",
      "Batch: 54 , Combined Loss: tensor(0.5463, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.04510080814361572\n",
      "Batch: 55 , Combined Loss: tensor(0.7027, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.900052547454834\n",
      "Batch: 56 , Combined Loss: tensor(0.6471, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1808247566223145\n",
      "Batch: 57 , Combined Loss: tensor(0.5810, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.558560848236084\n",
      "Batch: 58 , Combined Loss: tensor(0.8053, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7738080024719238\n",
      "Batch: 59 , Combined Loss: tensor(0.5285, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45537829399108887\n",
      "Batch: 60 , Combined Loss: tensor(0.6933, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8538364171981812\n",
      "Batch: 61 , Combined Loss: tensor(0.5935, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9607106447219849\n",
      "Batch: 62 , Combined Loss: tensor(1.0288, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32903194427490234\n",
      "Batch: 63 , Combined Loss: tensor(0.6075, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8722660541534424\n",
      "Batch: 64 , Combined Loss: tensor(0.5722, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8652831315994263\n",
      "Batch: 65 , Combined Loss: tensor(0.5543, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8611447811126709\n",
      "Batch: 66 , Combined Loss: tensor(0.5981, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2679729461669922\n",
      "Batch: 67 , Combined Loss: tensor(0.5905, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0297574996948242\n",
      "Batch: 68 , Combined Loss: tensor(0.7463, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0544555187225342\n",
      "Batch: 69 , Combined Loss: tensor(0.5355, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0133166313171387\n",
      "Batch: 70 , Combined Loss: tensor(0.7593, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40404772758483887\n",
      "Batch: 71 , Combined Loss: tensor(0.6766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8254148960113525\n",
      "Batch: 72 , Combined Loss: tensor(0.5852, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8891762495040894\n",
      "Batch: 73 , Combined Loss: tensor(0.6350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2834435701370239\n",
      "Batch: 74 , Combined Loss: tensor(0.5763, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7339862585067749\n",
      "Batch: 75 , Combined Loss: tensor(0.7926, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7224911451339722\n",
      "Batch: 76 , Combined Loss: tensor(0.5562, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7980736494064331\n",
      "Batch: 77 , Combined Loss: tensor(0.5582, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6751632690429688\n",
      "Batch: 78 , Combined Loss: tensor(0.5714, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42865443229675293\n",
      "Batch: 79 , Combined Loss: tensor(0.7831, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8866959810256958\n",
      "Batch: 80 , Combined Loss: tensor(0.5246, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.596532940864563\n",
      "Batch: 81 , Combined Loss: tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8754554986953735\n",
      "Batch: 82 , Combined Loss: tensor(0.9035, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2699333429336548\n",
      "Batch: 83 , Combined Loss: tensor(0.6574, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0968983173370361\n",
      "Batch: 84 , Combined Loss: tensor(0.5716, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1284286975860596\n",
      "Batch: 85 , Combined Loss: tensor(0.5188, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7610048055648804\n",
      "Batch: 86 , Combined Loss: tensor(0.5985, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7395035028457642\n",
      "Batch: 87 , Combined Loss: tensor(0.7135, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6476376056671143\n",
      "Batch: 88 , Combined Loss: tensor(0.5531, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0298011302947998\n",
      "Batch: 89 , Combined Loss: tensor(0.5885, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0173773765563965\n",
      "Batch: 90 , Combined Loss: tensor(0.5776, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8835184574127197\n",
      "Batch: 91 , Combined Loss: tensor(0.6727, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1297791004180908\n",
      "Batch: 92 , Combined Loss: tensor(0.7412, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36036157608032227\n",
      "Batch: 93 , Combined Loss: tensor(0.6336, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9414101839065552\n",
      "Batch: 94 , Combined Loss: tensor(0.6183, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0321943759918213\n",
      "Batch: 95 , Combined Loss: tensor(0.6617, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7795403003692627\n",
      "Batch: 96 , Combined Loss: tensor(0.7346, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.074488878250122\n",
      "Batch: 97 , Combined Loss: tensor(0.6750, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0541608333587646\n",
      "Batch: 98 , Combined Loss: tensor(0.5367, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7870504856109619\n",
      "Batch: 99 , Combined Loss: tensor(0.5982, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10580611228942871\n",
      "Batch: 100 , Combined Loss: tensor(0.6173, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8842636346817017\n",
      "Batch: 101 , Combined Loss: tensor(0.5942, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7992923259735107\n",
      "Batch: 102 , Combined Loss: tensor(0.5616, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2184937000274658\n",
      "Batch: 103 , Combined Loss: tensor(0.5393, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4594740867614746\n",
      "Batch: 104 , Combined Loss: tensor(0.7545, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2236542701721191\n",
      "Batch: 105 , Combined Loss: tensor(0.6084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.928597092628479\n",
      "Batch: 106 , Combined Loss: tensor(0.7910, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7615686655044556\n",
      "Batch: 107 , Combined Loss: tensor(0.6825, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0557832717895508\n",
      "Batch: 108 , Combined Loss: tensor(0.6000, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5414043664932251\n",
      "Batch: 109 , Combined Loss: tensor(0.7555, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5906620025634766\n",
      "Batch: 110 , Combined Loss: tensor(0.6162, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.870414137840271\n",
      "Batch: 111 , Combined Loss: tensor(0.6320, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8160321712493896\n",
      "Batch: 112 , Combined Loss: tensor(0.5971, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0871891975402832\n",
      "Batch: 113 , Combined Loss: tensor(0.5819, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5381070375442505\n",
      "Batch: 114 , Combined Loss: tensor(0.5412, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7877535820007324\n",
      "Batch: 115 , Combined Loss: tensor(0.5931, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0250701904296875\n",
      "Batch: 116 , Combined Loss: tensor(0.7752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0571537017822266\n",
      "Batch: 117 , Combined Loss: tensor(0.6577, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6474374532699585\n",
      "Batch: 118 , Combined Loss: tensor(0.6140, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0414392948150635\n",
      "Batch: 119 , Combined Loss: tensor(0.7941, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28381896018981934\n",
      "Batch: 120 , Combined Loss: tensor(0.5547, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1259472370147705\n",
      "Batch: 121 , Combined Loss: tensor(0.6687, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30281877517700195\n",
      "Batch: 122 , Combined Loss: tensor(0.8521, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6376607418060303\n",
      "Batch: 123 , Combined Loss: tensor(0.5942, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0202088356018066\n",
      "Batch: 124 , Combined Loss: tensor(0.7148, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.036353588104248\n",
      "Batch: 125 , Combined Loss: tensor(0.6980, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9974062442779541\n",
      "Batch: 126 , Combined Loss: tensor(0.7540, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9156389236450195\n",
      "Batch: 127 , Combined Loss: tensor(0.8045, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2554852962493896\n",
      "Batch: 128 , Combined Loss: tensor(0.7595, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7775659561157227\n",
      "Batch: 129 , Combined Loss: tensor(0.5753, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6922316551208496\n",
      "Batch: 130 , Combined Loss: tensor(0.6938, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6153147220611572\n",
      "Batch: 131 , Combined Loss: tensor(0.6536, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.203516960144043\n",
      "Batch: 132 , Combined Loss: tensor(0.8267, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0660393238067627\n",
      "Batch: 133 , Combined Loss: tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.011935412883758545\n",
      "Batch: 134 , Combined Loss: tensor(0.5733, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.179741621017456\n",
      "Batch: 135 , Combined Loss: tensor(0.6439, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.630298376083374\n",
      "Batch: 136 , Combined Loss: tensor(0.6736, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0509655475616455\n",
      "Batch: 137 , Combined Loss: tensor(0.7605, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8340353965759277\n",
      "Batch: 138 , Combined Loss: tensor(0.5998, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2542644739151001\n",
      "Batch: 139 , Combined Loss: tensor(0.7247, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5121035575866699\n",
      "Batch: 140 , Combined Loss: tensor(0.7688, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8122434616088867\n",
      "Batch: 141 , Combined Loss: tensor(0.8751, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9092594385147095\n",
      "Batch: 142 , Combined Loss: tensor(0.6577, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5295848846435547\n",
      "Batch: 143 , Combined Loss: tensor(0.5754, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0635418891906738\n",
      "Batch: 144 , Combined Loss: tensor(0.6558, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8160449266433716\n",
      "Batch: 145 , Combined Loss: tensor(0.5518, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9147881269454956\n",
      "Batch: 146 , Combined Loss: tensor(0.8750, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7156902551651001\n",
      "Batch: 147 , Combined Loss: tensor(0.5611, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.183668851852417\n",
      "Batch: 148 , Combined Loss: tensor(0.6041, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1495134830474854\n",
      "Batch: 149 , Combined Loss: tensor(0.5641, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0067250728607178\n",
      "Batch: 150 , Combined Loss: tensor(0.6702, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3157875537872314\n",
      "Batch: 151 , Combined Loss: tensor(0.5959, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5555957555770874\n",
      "Batch: 152 , Combined Loss: tensor(0.6746, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6202993392944336\n",
      "Batch: 153 , Combined Loss: tensor(0.6571, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0748157501220703\n",
      "Batch: 154 , Combined Loss: tensor(0.6026, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8959617614746094\n",
      "Batch: 155 , Combined Loss: tensor(0.5709, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9867876768112183\n",
      "Batch: 156 , Combined Loss: tensor(0.6718, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8247404098510742\n",
      "Batch: 157 , Combined Loss: tensor(0.8398, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6143534183502197\n",
      "Batch: 158 , Combined Loss: tensor(0.6129, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1204359531402588\n",
      "Batch: 159 , Combined Loss: tensor(0.5635, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.179060697555542\n",
      "Batch: 160 , Combined Loss: tensor(0.5560, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0582125186920166\n",
      "Batch: 161 , Combined Loss: tensor(0.6738, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7556679248809814\n",
      "Batch: 162 , Combined Loss: tensor(0.7008, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8692349195480347\n",
      "Batch: 163 , Combined Loss: tensor(0.5226, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8501189947128296\n",
      "Batch: 164 , Combined Loss: tensor(0.7265, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0944857597351074\n",
      "Batch: 165 , Combined Loss: tensor(0.7330, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1179897785186768\n",
      "Batch: 166 , Combined Loss: tensor(0.7652, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47910308837890625\n",
      "Batch: 167 , Combined Loss: tensor(0.5765, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9456561803817749\n",
      "Batch: 168 , Combined Loss: tensor(0.6233, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9003626108169556\n",
      "Batch: 169 , Combined Loss: tensor(0.7047, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8969476222991943\n",
      "Batch: 170 , Combined Loss: tensor(0.6900, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9249517917633057\n",
      "Batch: 171 , Combined Loss: tensor(0.6675, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7830033302307129\n",
      "Batch: 172 , Combined Loss: tensor(0.5377, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7976983785629272\n",
      "Batch: 173 , Combined Loss: tensor(0.6486, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.944108247756958\n",
      "Batch: 174 , Combined Loss: tensor(0.5574, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9603315591812134\n",
      "Batch: 175 , Combined Loss: tensor(0.6538, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.015249252319336\n",
      "Batch: 176 , Combined Loss: tensor(0.7255, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1657676696777344\n",
      "Batch: 177 , Combined Loss: tensor(0.6592, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7056884765625\n",
      "Batch: 178 , Combined Loss: tensor(0.7091, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5155361890792847\n",
      "Batch: 179 , Combined Loss: tensor(0.6297, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6700253486633301\n",
      "Batch: 180 , Combined Loss: tensor(0.6760, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0803701877593994\n",
      "Batch: 181 , Combined Loss: tensor(0.9665, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28931915760040283\n",
      "Batch: 182 , Combined Loss: tensor(0.5944, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2662484645843506\n",
      "Batch: 183 , Combined Loss: tensor(0.5818, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7104434967041016\n",
      "Batch: 184 , Combined Loss: tensor(0.6250, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3900657892227173\n",
      "Batch: 185 , Combined Loss: tensor(0.7204, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8567347526550293\n",
      "Batch: 186 , Combined Loss: tensor(0.7203, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4713728427886963\n",
      "Batch: 187 , Combined Loss: tensor(0.5605, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0590851306915283\n",
      "Batch: 188 , Combined Loss: tensor(0.6681, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8245131969451904\n",
      "Batch: 189 , Combined Loss: tensor(0.6841, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1325087547302246\n",
      "Batch: 190 , Combined Loss: tensor(0.5368, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1845018863677979\n",
      "Batch: 191 , Combined Loss: tensor(0.5668, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.021172046661377\n",
      "Batch: 192 , Combined Loss: tensor(0.5981, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0014333724975586\n",
      "Batch: 193 , Combined Loss: tensor(0.5818, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1249232292175293\n",
      "Batch: 194 , Combined Loss: tensor(0.6289, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1419708728790283\n",
      "Batch: 195 , Combined Loss: tensor(0.6432, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3017442226409912\n",
      "Batch: 196 , Combined Loss: tensor(0.6002, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9124972820281982\n",
      "Batch: 197 , Combined Loss: tensor(0.5495, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1885251998901367\n",
      "Batch: 198 , Combined Loss: tensor(0.6035, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9801700115203857\n",
      "Batch: 199 , Combined Loss: tensor(0.6450, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1433184146881104\n",
      "Batch: 200 , Combined Loss: tensor(0.5432, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6288340091705322\n",
      "Batch: 201 , Combined Loss: tensor(0.9305, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3439807891845703\n",
      "Batch: 202 , Combined Loss: tensor(0.6510, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9424687623977661\n",
      "Batch: 203 , Combined Loss: tensor(0.7886, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.141589641571045\n",
      "Batch: 204 , Combined Loss: tensor(0.5723, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1571910381317139\n",
      "Batch: 205 , Combined Loss: tensor(0.5708, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0892832279205322\n",
      "Batch: 206 , Combined Loss: tensor(0.7014, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9299975633621216\n",
      "Batch: 207 , Combined Loss: tensor(0.5987, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.503831148147583\n",
      "Batch: 208 , Combined Loss: tensor(0.5514, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0937771797180176\n",
      "Batch: 209 , Combined Loss: tensor(0.6245, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4171689748764038\n",
      "Batch: 210 , Combined Loss: tensor(0.7064, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0750045776367188\n",
      "Batch: 211 , Combined Loss: tensor(0.6446, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9070451259613037\n",
      "Batch: 212 , Combined Loss: tensor(1.0929, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5676776170730591\n",
      "Batch: 213 , Combined Loss: tensor(0.5940, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.972470760345459\n",
      "Batch: 214 , Combined Loss: tensor(0.5651, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.511887788772583\n",
      "Batch: 215 , Combined Loss: tensor(0.5426, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47609639167785645\n",
      "Batch: 216 , Combined Loss: tensor(0.6049, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.224055290222168\n",
      "Batch: 217 , Combined Loss: tensor(0.6917, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1322457790374756\n",
      "Batch: 218 , Combined Loss: tensor(0.6611, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5613130331039429\n",
      "Batch: 219 , Combined Loss: tensor(0.4719, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8504762649536133\n",
      "Batch: 220 , Combined Loss: tensor(0.5174, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.901166558265686\n",
      "Batch: 221 , Combined Loss: tensor(0.5930, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.069833755493164\n",
      "Batch: 222 , Combined Loss: tensor(0.6224, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1216769218444824\n",
      "Batch: 223 , Combined Loss: tensor(0.6949, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8688596487045288\n",
      "Batch: 224 , Combined Loss: tensor(0.5379, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9386597871780396\n",
      "Batch: 225 , Combined Loss: tensor(0.6081, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2564880847930908\n",
      "Batch: 226 , Combined Loss: tensor(0.6473, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8643079996109009\n",
      "Batch: 227 , Combined Loss: tensor(0.6349, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0096943378448486\n",
      "Batch: 228 , Combined Loss: tensor(0.8004, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0834612846374512\n",
      "Batch: 229 , Combined Loss: tensor(0.6154, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9499568939208984\n",
      "Batch: 230 , Combined Loss: tensor(0.5658, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9832197427749634\n",
      "Batch: 231 , Combined Loss: tensor(0.5705, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9701148271560669\n",
      "Batch: 232 , Combined Loss: tensor(0.6370, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3342466354370117\n",
      "Batch: 233 , Combined Loss: tensor(0.5557, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1670193672180176\n",
      "Batch: 234 , Combined Loss: tensor(0.8532, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3570067882537842\n",
      "Batch: 235 , Combined Loss: tensor(0.5424, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8311767578125\n",
      "Batch: 236 , Combined Loss: tensor(0.6483, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9535799026489258\n",
      "Batch: 237 , Combined Loss: tensor(0.7039, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0949902534484863\n",
      "Batch: 238 , Combined Loss: tensor(0.7071, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0712785720825195\n",
      "Batch: 239 , Combined Loss: tensor(0.8043, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9660848379135132\n",
      "Batch: 240 , Combined Loss: tensor(0.6794, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0043623447418213\n",
      "Batch: 241 , Combined Loss: tensor(0.5200, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.113466501235962\n",
      "Batch: 242 , Combined Loss: tensor(0.5711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0065555572509766\n",
      "Batch: 243 , Combined Loss: tensor(0.6413, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0852694511413574\n",
      "Batch: 244 , Combined Loss: tensor(0.7100, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2211827039718628\n",
      "Batch: 245 , Combined Loss: tensor(0.5786, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9269088506698608\n",
      "Batch: 246 , Combined Loss: tensor(0.7893, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0440561771392822\n",
      "Batch: 247 , Combined Loss: tensor(0.7699, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1178522109985352\n",
      "Batch: 248 , Combined Loss: tensor(0.6379, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0819329023361206\n",
      "Batch: 249 , Combined Loss: tensor(0.5528, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6218905448913574\n",
      "Batch: 250 , Combined Loss: tensor(0.6496, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2563972473144531\n",
      "Batch: 251 , Combined Loss: tensor(0.6070, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9580488204956055\n",
      "Batch: 252 , Combined Loss: tensor(0.6110, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.199486255645752\n",
      "Batch: 253 , Combined Loss: tensor(0.5685, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1452832221984863\n",
      "Batch: 254 , Combined Loss: tensor(0.4808, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6908117532730103\n",
      "Batch: 255 , Combined Loss: tensor(0.7436, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38777947425842285\n",
      "Batch: 256 , Combined Loss: tensor(0.5472, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0451326370239258\n",
      "Batch: 257 , Combined Loss: tensor(0.6224, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9888651371002197\n",
      "Batch: 258 , Combined Loss: tensor(0.6255, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1067345142364502\n",
      "Batch: 259 , Combined Loss: tensor(0.6418, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3242850303649902\n",
      "Batch: 260 , Combined Loss: tensor(0.5947, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1042437553405762\n",
      "Batch: 261 , Combined Loss: tensor(0.6496, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0916240215301514\n",
      "Batch: 262 , Combined Loss: tensor(0.6858, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8824609518051147\n",
      "Batch: 263 , Combined Loss: tensor(0.5585, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7884410619735718\n",
      "Batch: 264 , Combined Loss: tensor(0.6448, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14878475666046143\n",
      "Batch: 265 , Combined Loss: tensor(0.6221, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.905493974685669\n",
      "Batch: 266 , Combined Loss: tensor(0.6366, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0370445251464844\n",
      "Batch: 267 , Combined Loss: tensor(0.6825, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8606455326080322\n",
      "Batch: 268 , Combined Loss: tensor(0.7720, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6022928953170776\n",
      "Batch: 269 , Combined Loss: tensor(0.5573, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47368764877319336\n",
      "Batch: 270 , Combined Loss: tensor(0.5751, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1181111335754395\n",
      "Batch: 271 , Combined Loss: tensor(0.5378, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9105888605117798\n",
      "Batch: 272 , Combined Loss: tensor(0.5904, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2646219730377197\n",
      "Batch: 273 , Combined Loss: tensor(0.5902, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.144430160522461\n",
      "Batch: 274 , Combined Loss: tensor(0.5749, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0864973068237305\n",
      "Batch: 275 , Combined Loss: tensor(0.6527, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8536146879196167\n",
      "Batch: 276 , Combined Loss: tensor(0.5950, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5044282674789429\n",
      "Batch: 277 , Combined Loss: tensor(0.5624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.702856183052063\n",
      "Batch: 278 , Combined Loss: tensor(0.6314, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2365083694458008\n",
      "Batch: 279 , Combined Loss: tensor(0.5874, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8584451675415039\n",
      "Batch: 280 , Combined Loss: tensor(0.5244, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.854299783706665\n",
      "Batch: 281 , Combined Loss: tensor(0.6859, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6889630556106567\n",
      "Batch: 282 , Combined Loss: tensor(0.8183, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47121942043304443\n",
      "Batch: 283 , Combined Loss: tensor(0.6476, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.879469633102417\n",
      "Batch: 284 , Combined Loss: tensor(0.5910, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0652389526367188\n",
      "Batch: 285 , Combined Loss: tensor(0.6233, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.073408603668213\n",
      "Batch: 286 , Combined Loss: tensor(0.5736, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0906422138214111\n",
      "Batch: 287 , Combined Loss: tensor(0.5510, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0315775871276855\n",
      "Batch: 288 , Combined Loss: tensor(0.5593, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1384336948394775\n",
      "Batch: 289 , Combined Loss: tensor(0.6425, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1015007495880127\n",
      "Batch: 290 , Combined Loss: tensor(0.6241, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1525182723999023\n",
      "Batch: 291 , Combined Loss: tensor(0.7094, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.525457501411438\n",
      "Batch: 292 , Combined Loss: tensor(0.6851, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.052711009979248\n",
      "Batch: 293 , Combined Loss: tensor(0.8395, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7161325216293335\n",
      "Batch: 294 , Combined Loss: tensor(0.5450, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6524081230163574\n",
      "Batch: 295 , Combined Loss: tensor(0.6587, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8298500776290894\n",
      "Batch: 296 , Combined Loss: tensor(0.5874, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8131515979766846\n",
      "Batch: 297 , Combined Loss: tensor(0.6232, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1833374500274658\n",
      "Batch: 298 , Combined Loss: tensor(0.5333, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0264842510223389\n",
      "Batch: 299 , Combined Loss: tensor(0.7315, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3699716329574585\n",
      "Batch: 300 , Combined Loss: tensor(0.8268, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9234744310379028\n",
      "Batch: 301 , Combined Loss: tensor(0.5712, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.4448156356811523\n",
      "Batch: 302 , Combined Loss: tensor(0.5638, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9654815196990967\n",
      "Batch: 303 , Combined Loss: tensor(0.5968, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8922387361526489\n",
      "Batch: 304 , Combined Loss: tensor(0.8578, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0721986293792725\n",
      "Batch: 305 , Combined Loss: tensor(0.7493, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.771085262298584\n",
      "Batch: 306 , Combined Loss: tensor(0.6734, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.094282627105713\n",
      "Batch: 307 , Combined Loss: tensor(0.6476, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06769704818725586\n",
      "Batch: 308 , Combined Loss: tensor(0.5213, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9536798000335693\n",
      "Batch: 309 , Combined Loss: tensor(0.6552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9156515598297119\n",
      "Batch: 310 , Combined Loss: tensor(0.5623, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.712968111038208\n",
      "Batch: 311 , Combined Loss: tensor(0.9312, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8751308917999268\n",
      "Batch: 312 , Combined Loss: tensor(0.6961, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9133114814758301\n",
      "Batch: 313 , Combined Loss: tensor(0.6723, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2855027914047241\n",
      "Batch: 314 , Combined Loss: tensor(0.5887, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8929265737533569\n",
      "Batch: 315 , Combined Loss: tensor(0.7397, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9154483079910278\n",
      "Batch: 316 , Combined Loss: tensor(0.5828, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13988947868347168\n",
      "Batch: 317 , Combined Loss: tensor(0.6965, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.963600754737854\n",
      "Batch: 318 , Combined Loss: tensor(0.5830, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8219220638275146\n",
      "Batch: 319 , Combined Loss: tensor(0.5700, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0599653720855713\n",
      "Batch: 320 , Combined Loss: tensor(0.6585, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0910441875457764\n",
      "Batch: 321 , Combined Loss: tensor(0.6272, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9441475868225098\n",
      "Batch: 322 , Combined Loss: tensor(0.5883, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.048212528228759766\n",
      "Batch: 323 , Combined Loss: tensor(0.6950, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21597838401794434\n",
      "Batch: 324 , Combined Loss: tensor(0.6414, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9384793043136597\n",
      "Batch: 325 , Combined Loss: tensor(0.6745, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1365511417388916\n",
      "Batch: 326 , Combined Loss: tensor(0.7403, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7432589530944824\n",
      "Batch: 327 , Combined Loss: tensor(0.7090, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2775604724884033\n",
      "Batch: 328 , Combined Loss: tensor(0.6011, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0365912914276123\n",
      "Batch: 329 , Combined Loss: tensor(0.6735, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7885057926177979\n",
      "Batch: 330 , Combined Loss: tensor(0.5443, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6021431684494019\n",
      "Batch: 331 , Combined Loss: tensor(0.5500, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9580807685852051\n",
      "Batch: 332 , Combined Loss: tensor(0.8653, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5688924789428711\n",
      "Batch: 333 , Combined Loss: tensor(0.6245, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0480220317840576\n",
      "Batch: 334 , Combined Loss: tensor(0.5781, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9410405158996582\n",
      "Batch: 335 , Combined Loss: tensor(0.6035, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7576582431793213\n",
      "Batch: 336 , Combined Loss: tensor(0.5793, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8622423410415649\n",
      "Batch: 337 , Combined Loss: tensor(0.5427, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7692919969558716\n",
      "Batch: 338 , Combined Loss: tensor(0.5295, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7289111614227295\n",
      "Batch: 339 , Combined Loss: tensor(0.5672, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4760202169418335\n",
      "Batch: 340 , Combined Loss: tensor(0.6189, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5659836530685425\n",
      "Batch: 341 , Combined Loss: tensor(0.7106, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2915228605270386\n",
      "Batch: 342 , Combined Loss: tensor(0.6488, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6785882711410522\n",
      "Batch: 343 , Combined Loss: tensor(0.5962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26314687728881836\n",
      "Batch: 344 , Combined Loss: tensor(0.5772, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1841373443603516\n",
      "Batch: 345 , Combined Loss: tensor(0.6280, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9096745252609253\n",
      "Batch: 346 , Combined Loss: tensor(0.7544, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39588987827301025\n",
      "Batch: 347 , Combined Loss: tensor(0.5572, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4601362943649292\n",
      "Batch: 348 , Combined Loss: tensor(0.6475, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9020764827728271\n",
      "Batch: 349 , Combined Loss: tensor(0.7440, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3310776948928833\n",
      "Batch: 350 , Combined Loss: tensor(0.7371, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7933533191680908\n",
      "Batch: 351 , Combined Loss: tensor(0.8199, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7590490579605103\n",
      "Batch: 352 , Combined Loss: tensor(0.5928, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7497435808181763\n",
      "Batch: 353 , Combined Loss: tensor(0.7664, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4108092188835144\n",
      "Batch: 354 , Combined Loss: tensor(0.6814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19220340251922607\n",
      "Batch: 355 , Combined Loss: tensor(0.6391, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41586291790008545\n",
      "Batch: 356 , Combined Loss: tensor(0.5874, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7150813341140747\n",
      "Batch: 357 , Combined Loss: tensor(0.6679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8929802179336548\n",
      "Batch: 358 , Combined Loss: tensor(0.6395, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3626614809036255\n",
      "Batch: 359 , Combined Loss: tensor(0.5843, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0051014423370361\n",
      "Batch: 360 , Combined Loss: tensor(0.7243, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5516592264175415\n",
      "Batch: 361 , Combined Loss: tensor(0.7749, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9502319097518921\n",
      "Batch: 362 , Combined Loss: tensor(0.5785, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9976977109909058\n",
      "Batch: 363 , Combined Loss: tensor(0.7100, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.523193359375\n",
      "Batch: 364 , Combined Loss: tensor(0.7521, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8857696056365967\n",
      "Batch: 365 , Combined Loss: tensor(0.5740, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4915637969970703\n",
      "Batch: 366 , Combined Loss: tensor(0.6424, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9832668304443359\n",
      "Batch: 367 , Combined Loss: tensor(0.7621, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.029948949813842773\n",
      "Batch: 368 , Combined Loss: tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7679780721664429\n",
      "Batch: 369 , Combined Loss: tensor(0.6598, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8571832180023193\n",
      "Batch: 370 , Combined Loss: tensor(0.5899, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6281777620315552\n",
      "Batch: 371 , Combined Loss: tensor(0.6707, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9791426658630371\n",
      "Batch: 372 , Combined Loss: tensor(0.6113, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9174695014953613\n",
      "Batch: 373 , Combined Loss: tensor(0.7075, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5865422487258911\n",
      "Batch: 374 , Combined Loss: tensor(0.5311, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8308466672897339\n",
      "Batch: 375 , Combined Loss: tensor(0.7598, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9372360706329346\n",
      "Batch: 376 , Combined Loss: tensor(0.5936, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7431929111480713\n",
      "Batch: 377 , Combined Loss: tensor(0.5696, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.863571286201477\n",
      "Batch: 378 , Combined Loss: tensor(0.6430, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8726339340209961\n",
      "Batch: 379 , Combined Loss: tensor(0.6137, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9240463972091675\n",
      "Batch: 380 , Combined Loss: tensor(0.8299, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16204214096069336\n",
      "Batch: 381 , Combined Loss: tensor(0.6109, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.633832573890686\n",
      "Batch: 382 , Combined Loss: tensor(0.6315, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9937000274658203\n",
      "Batch: 383 , Combined Loss: tensor(0.6164, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8887226581573486\n",
      "Batch: 384 , Combined Loss: tensor(0.6527, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1538400650024414\n",
      "Batch: 385 , Combined Loss: tensor(0.6248, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0631656646728516\n",
      "Batch: 386 , Combined Loss: tensor(0.6529, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9268598556518555\n",
      "Batch: 387 , Combined Loss: tensor(0.4647, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5464906692504883\n",
      "Batch: 388 , Combined Loss: tensor(0.5994, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04995971918106079\n",
      "Batch: 389 , Combined Loss: tensor(1.0891, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.46625638008117676\n",
      "Batch: 390 , Combined Loss: tensor(0.5802, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0410919189453125\n",
      "Batch: 391 , Combined Loss: tensor(0.6526, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8659480810165405\n",
      "Batch: 392 , Combined Loss: tensor(0.6032, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7910912036895752\n",
      "Batch: 393 , Combined Loss: tensor(0.7019, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9390655755996704\n",
      "Batch: 394 , Combined Loss: tensor(0.5995, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9990389347076416\n",
      "Batch: 395 , Combined Loss: tensor(0.6185, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.109539270401001\n",
      "Batch: 396 , Combined Loss: tensor(0.5385, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9196350574493408\n",
      "Batch: 397 , Combined Loss: tensor(0.5587, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4966474771499634\n",
      "Batch: 398 , Combined Loss: tensor(0.6713, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3085300922393799\n",
      "Batch: 399 , Combined Loss: tensor(0.6898, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2529693841934204\n",
      "Batch: 400 , Combined Loss: tensor(0.8598, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1317996978759766\n",
      "Batch: 401 , Combined Loss: tensor(0.5839, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9677131175994873\n",
      "Batch: 402 , Combined Loss: tensor(0.7360, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2634353637695312\n",
      "Batch: 403 , Combined Loss: tensor(0.6184, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8049741983413696\n",
      "Batch: 404 , Combined Loss: tensor(0.5616, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9135576486587524\n",
      "Batch: 405 , Combined Loss: tensor(0.6972, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9982671737670898\n",
      "Batch: 406 , Combined Loss: tensor(0.6983, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0272738933563232\n",
      "Batch: 407 , Combined Loss: tensor(0.9095, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13815534114837646\n",
      "Batch: 408 , Combined Loss: tensor(0.7234, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7123273611068726\n",
      "Batch: 409 , Combined Loss: tensor(0.6015, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9642413854598999\n",
      "Batch: 410 , Combined Loss: tensor(0.7381, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0537750720977783\n",
      "Batch: 411 , Combined Loss: tensor(0.5853, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8853386640548706\n",
      "Batch: 412 , Combined Loss: tensor(0.5215, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.853745698928833\n",
      "Batch: 413 , Combined Loss: tensor(0.6391, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5002975463867188\n",
      "Batch: 414 , Combined Loss: tensor(0.5881, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9520198106765747\n",
      "Batch: 415 , Combined Loss: tensor(0.5716, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0697228908538818\n",
      "Batch: 416 , Combined Loss: tensor(0.6185, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8246062994003296\n",
      "Batch: 417 , Combined Loss: tensor(0.6570, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7017282247543335\n",
      "Batch: 418 , Combined Loss: tensor(0.5804, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0839691162109375\n",
      "Batch: 419 , Combined Loss: tensor(0.5357, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8856296539306641\n",
      "Batch: 420 , Combined Loss: tensor(0.6118, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0750815868377686\n",
      "Batch: 421 , Combined Loss: tensor(0.8580, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.275825023651123\n",
      "Batch: 422 , Combined Loss: tensor(0.6737, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8557312488555908\n",
      "Batch: 423 , Combined Loss: tensor(0.7739, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6199357509613037\n",
      "Batch: 424 , Combined Loss: tensor(0.5846, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7185318470001221\n",
      "Batch: 425 , Combined Loss: tensor(0.6023, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0217878818511963\n",
      "Batch: 426 , Combined Loss: tensor(0.5550, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0194430351257324\n",
      "Batch: 427 , Combined Loss: tensor(0.6150, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9897531270980835\n",
      "Batch: 428 , Combined Loss: tensor(0.6659, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43196237087249756\n",
      "Batch: 429 , Combined Loss: tensor(0.6596, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6966173648834229\n",
      "Batch: 430 , Combined Loss: tensor(0.6519, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9830060005187988\n",
      "Batch: 431 , Combined Loss: tensor(1.3776, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.495780348777771\n",
      "Batch: 432 , Combined Loss: tensor(0.6722, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6871178150177002\n",
      "Batch: 433 , Combined Loss: tensor(0.6424, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0514490604400635\n",
      "Batch: 434 , Combined Loss: tensor(0.6650, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.019763469696045\n",
      "Batch: 435 , Combined Loss: tensor(0.7206, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8858743906021118\n",
      "Batch: 436 , Combined Loss: tensor(0.6666, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9003888368606567\n",
      "Batch: 437 , Combined Loss: tensor(0.7283, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08645772933959961\n",
      "Batch: 438 , Combined Loss: tensor(0.7261, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8450497388839722\n",
      "Batch: 439 , Combined Loss: tensor(0.7665, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7653870582580566\n",
      "Batch: 440 , Combined Loss: tensor(0.6772, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6174067258834839\n",
      "Batch: 441 , Combined Loss: tensor(0.9374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9126179218292236\n",
      "Batch: 442 , Combined Loss: tensor(0.6230, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5476821660995483\n",
      "Batch: 443 , Combined Loss: tensor(0.6416, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9228228330612183\n",
      "Batch: 444 , Combined Loss: tensor(0.6377, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9949806928634644\n",
      "Batch: 445 , Combined Loss: tensor(0.5330, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2737817764282227\n",
      "Batch: 446 , Combined Loss: tensor(0.6780, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3796234130859375\n",
      "Batch: 447 , Combined Loss: tensor(0.7376, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0315818786621094\n",
      "Batch: 448 , Combined Loss: tensor(0.8015, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9597419500350952\n",
      "Batch: 449 , Combined Loss: tensor(0.5384, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1314575672149658\n",
      "Batch: 450 , Combined Loss: tensor(0.5963, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3082618713378906\n",
      "Batch: 451 , Combined Loss: tensor(0.6281, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0615108013153076\n",
      "Batch: 452 , Combined Loss: tensor(0.6508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5708963871002197\n",
      "Batch: 453 , Combined Loss: tensor(0.5980, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0178098678588867\n",
      "Batch: 454 , Combined Loss: tensor(0.6179, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2011711597442627\n",
      "Batch: 455 , Combined Loss: tensor(0.6354, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9198590517044067\n",
      "Batch: 456 , Combined Loss: tensor(0.7035, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44428324699401855\n",
      "Batch: 457 , Combined Loss: tensor(0.5896, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8541237115859985\n",
      "Batch: 458 , Combined Loss: tensor(0.5996, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0601370334625244\n",
      "Batch: 459 , Combined Loss: tensor(0.7769, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1204078197479248\n",
      "Batch: 460 , Combined Loss: tensor(0.6978, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9534680843353271\n",
      "Batch: 461 , Combined Loss: tensor(0.6514, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1284961700439453\n",
      "Batch: 462 , Combined Loss: tensor(0.5863, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0299246311187744\n",
      "Batch: 463 , Combined Loss: tensor(0.6740, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.11604905128479\n",
      "Batch: 464 , Combined Loss: tensor(0.7265, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9702656269073486\n",
      "Batch: 465 , Combined Loss: tensor(0.6018, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.03363037109375\n",
      "Batch: 466 , Combined Loss: tensor(0.8366, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.566028356552124\n",
      "Batch: 467 , Combined Loss: tensor(0.5859, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.170072078704834\n",
      "Batch: 468 , Combined Loss: tensor(0.5905, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.022214651107788\n",
      "Batch: 469 , Combined Loss: tensor(0.5732, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.032851219177246\n",
      "Batch: 470 , Combined Loss: tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8910889625549316\n",
      "Batch: 471 , Combined Loss: tensor(0.6028, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1081597805023193\n",
      "Batch: 472 , Combined Loss: tensor(0.7080, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0379550457000732\n",
      "Batch: 473 , Combined Loss: tensor(0.6100, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9210168123245239\n",
      "Batch: 474 , Combined Loss: tensor(0.5587, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9874305725097656\n",
      "Batch: 475 , Combined Loss: tensor(1.1751, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6228616237640381\n",
      "Batch: 476 , Combined Loss: tensor(0.7930, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9758403301239014\n",
      "Batch: 477 , Combined Loss: tensor(0.5265, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.201216697692871\n",
      "Batch: 478 , Combined Loss: tensor(0.6141, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5027776956558228\n",
      "Batch: 479 , Combined Loss: tensor(0.6005, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7927112579345703\n",
      "Batch: 480 , Combined Loss: tensor(0.6589, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6959552764892578\n",
      "Batch: 481 , Combined Loss: tensor(0.5815, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5348299741744995\n",
      "Batch: 482 , Combined Loss: tensor(0.5691, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5882151126861572\n",
      "Batch: 483 , Combined Loss: tensor(0.5621, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9855436086654663\n",
      "Batch: 484 , Combined Loss: tensor(0.6084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8351658582687378\n",
      "Batch: 485 , Combined Loss: tensor(0.5818, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8932956457138062\n",
      "Batch: 486 , Combined Loss: tensor(0.8278, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7721749544143677\n",
      "Batch: 487 , Combined Loss: tensor(0.5274, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8324203491210938\n",
      "Batch: 488 , Combined Loss: tensor(0.7264, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6535481214523315\n",
      "Batch: 489 , Combined Loss: tensor(0.6456, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8013514280319214\n",
      "Batch: 490 , Combined Loss: tensor(0.5425, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8959083557128906\n",
      "Batch: 491 , Combined Loss: tensor(0.6596, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8108556270599365\n",
      "Batch: 492 , Combined Loss: tensor(0.5964, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7941246032714844\n",
      "Batch: 493 , Combined Loss: tensor(0.6374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8673794269561768\n",
      "Batch: 494 , Combined Loss: tensor(0.5450, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5249807834625244\n",
      "Batch: 495 , Combined Loss: tensor(0.6155, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9977315664291382\n",
      "Batch: 496 , Combined Loss: tensor(0.5736, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9525507688522339\n",
      "Batch: 497 , Combined Loss: tensor(0.6073, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8364529609680176\n",
      "Batch: 498 , Combined Loss: tensor(0.6958, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8196989297866821\n",
      "Batch: 499 , Combined Loss: tensor(0.5146, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5913947820663452\n",
      "Batch: 500 , Combined Loss: tensor(0.5420, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8206479549407959\n",
      "Batch: 501 , Combined Loss: tensor(0.6146, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4438650608062744\n",
      "Batch: 502 , Combined Loss: tensor(0.6025, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7554874420166016\n",
      "Batch: 503 , Combined Loss: tensor(0.5310, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7957580089569092\n",
      "Batch: 504 , Combined Loss: tensor(0.6067, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6233911514282227\n",
      "Batch: 505 , Combined Loss: tensor(0.7686, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6314554214477539\n",
      "Batch: 506 , Combined Loss: tensor(0.5156, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8756645917892456\n",
      "Batch: 507 , Combined Loss: tensor(0.5833, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.008648157119751\n",
      "Batch: 508 , Combined Loss: tensor(0.6666, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8523976802825928\n",
      "Batch: 509 , Combined Loss: tensor(0.5791, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9093904495239258\n",
      "Batch: 510 , Combined Loss: tensor(0.6286, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28539299964904785\n",
      "Batch: 511 , Combined Loss: tensor(0.5562, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8448807001113892\n",
      "Batch: 512 , Combined Loss: tensor(0.5457, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0624449253082275\n",
      "Batch: 513 , Combined Loss: tensor(0.5689, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6914358139038086\n",
      "Batch: 514 , Combined Loss: tensor(0.5810, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8410664796829224\n",
      "Batch: 515 , Combined Loss: tensor(0.7550, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9640039205551147\n",
      "Batch: 516 , Combined Loss: tensor(0.5589, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0502626895904541\n",
      "Batch: 517 , Combined Loss: tensor(0.6536, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8463164567947388\n",
      "Batch: 518 , Combined Loss: tensor(0.7410, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6719156503677368\n",
      "Batch: 519 , Combined Loss: tensor(0.7897, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0492737293243408\n",
      "Batch: 520 , Combined Loss: tensor(0.6239, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47723233699798584\n",
      "Batch: 521 , Combined Loss: tensor(1.0722, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8391481637954712\n",
      "Batch: 522 , Combined Loss: tensor(0.6366, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8009228706359863\n",
      "Batch: 523 , Combined Loss: tensor(0.6422, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1360926628112793\n",
      "Batch: 524 , Combined Loss: tensor(0.7351, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1395803689956665\n",
      "Batch: 525 , Combined Loss: tensor(0.5088, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8923206329345703\n",
      "Batch: 526 , Combined Loss: tensor(0.9841, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5899364948272705\n",
      "Batch: 527 , Combined Loss: tensor(0.6852, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8932143449783325\n",
      "Batch: 528 , Combined Loss: tensor(0.6414, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9770867824554443\n",
      "Batch: 529 , Combined Loss: tensor(0.7354, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.824471116065979\n",
      "Batch: 530 , Combined Loss: tensor(0.5203, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8427256345748901\n",
      "Batch: 531 , Combined Loss: tensor(0.5607, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9421482086181641\n",
      "Batch: 532 , Combined Loss: tensor(0.6081, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.928396463394165\n",
      "Batch: 533 , Combined Loss: tensor(0.5699, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8316043615341187\n",
      "Batch: 534 , Combined Loss: tensor(0.7633, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6856516599655151\n",
      "Batch: 535 , Combined Loss: tensor(0.5365, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2650042772293091\n",
      "Batch: 536 , Combined Loss: tensor(1.3201, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8229426145553589\n",
      "Batch: 537 , Combined Loss: tensor(0.5798, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6272462606430054\n",
      "Batch: 538 , Combined Loss: tensor(0.6166, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0576047897338867\n",
      "Batch: 539 , Combined Loss: tensor(0.6351, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8250147104263306\n",
      "Batch: 540 , Combined Loss: tensor(0.6326, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7293423414230347\n",
      "Batch: 541 , Combined Loss: tensor(0.6433, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.061824917793273926\n",
      "Batch: 542 , Combined Loss: tensor(0.6675, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.012109518051147461\n",
      "Batch: 543 , Combined Loss: tensor(0.7144, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2338252067565918\n",
      "Batch: 544 , Combined Loss: tensor(0.7180, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9070457220077515\n",
      "Batch: 545 , Combined Loss: tensor(0.6219, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9153914451599121\n",
      "Batch: 546 , Combined Loss: tensor(0.7465, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3255422115325928\n",
      "Batch: 547 , Combined Loss: tensor(0.5752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8090014457702637\n",
      "Batch: 548 , Combined Loss: tensor(0.7109, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1323397159576416\n",
      "Batch: 549 , Combined Loss: tensor(0.5165, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9900736808776855\n",
      "Batch: 550 , Combined Loss: tensor(0.7862, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07558530569076538\n",
      "Batch: 551 , Combined Loss: tensor(0.6007, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8760062456130981\n",
      "Batch: 552 , Combined Loss: tensor(1.0121, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2496342658996582\n",
      "Batch: 553 , Combined Loss: tensor(0.5936, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9397433996200562\n",
      "Batch: 554 , Combined Loss: tensor(0.6603, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6195477247238159\n",
      "Batch: 555 , Combined Loss: tensor(0.6900, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9915972948074341\n",
      "Batch: 556 , Combined Loss: tensor(0.5590, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0464930534362793\n",
      "Batch: 557 , Combined Loss: tensor(0.5767, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9986672401428223\n",
      "Batch: 558 , Combined Loss: tensor(0.5915, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23487800359725952\n",
      "Batch: 559 , Combined Loss: tensor(0.5721, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9181256294250488\n",
      "Batch: 560 , Combined Loss: tensor(0.5941, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9084177017211914\n",
      "Batch: 561 , Combined Loss: tensor(0.5288, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7717411518096924\n",
      "Batch: 562 , Combined Loss: tensor(0.7833, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8124589920043945\n",
      "Batch: 563 , Combined Loss: tensor(0.6115, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8169037103652954\n",
      "Batch: 564 , Combined Loss: tensor(0.7632, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0519225597381592\n",
      "Batch: 565 , Combined Loss: tensor(0.6014, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9882019758224487\n",
      "Batch: 566 , Combined Loss: tensor(0.7237, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4934968948364258\n",
      "Batch: 567 , Combined Loss: tensor(0.6458, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38615357875823975\n",
      "Batch: 568 , Combined Loss: tensor(0.6562, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2351229190826416\n",
      "Batch: 569 , Combined Loss: tensor(0.6962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.052194356918335\n",
      "Batch: 570 , Combined Loss: tensor(0.7570, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5711503028869629\n",
      "Batch: 571 , Combined Loss: tensor(0.5568, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.610338568687439\n",
      "Batch: 572 , Combined Loss: tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22512143850326538\n",
      "Batch: 573 , Combined Loss: tensor(0.6834, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0110819339752197\n",
      "Batch: 574 , Combined Loss: tensor(0.6425, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0006651878356934\n",
      "Batch: 575 , Combined Loss: tensor(0.7243, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0219876766204834\n",
      "Batch: 576 , Combined Loss: tensor(0.8673, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10619550943374634\n",
      "Batch: 577 , Combined Loss: tensor(0.6190, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8744397163391113\n",
      "Batch: 578 , Combined Loss: tensor(0.6052, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.038320779800415\n",
      "Batch: 579 , Combined Loss: tensor(0.8641, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6929886341094971\n",
      "Batch: 580 , Combined Loss: tensor(0.7529, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1173887252807617\n",
      "Batch: 581 , Combined Loss: tensor(0.6417, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7187786102294922\n",
      "Batch: 582 , Combined Loss: tensor(0.7877, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9529879093170166\n",
      "Batch: 583 , Combined Loss: tensor(0.5896, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8048629760742188\n",
      "Batch: 584 , Combined Loss: tensor(0.5887, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8474975824356079\n",
      "Batch: 585 , Combined Loss: tensor(0.6164, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8370131254196167\n",
      "Batch: 586 , Combined Loss: tensor(0.5949, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5720864534378052\n",
      "Batch: 587 , Combined Loss: tensor(0.6598, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0136466026306152\n",
      "Batch: 588 , Combined Loss: tensor(0.8057, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.863004207611084\n",
      "Batch: 589 , Combined Loss: tensor(0.6587, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0640125274658203\n",
      "Batch: 590 , Combined Loss: tensor(0.5653, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0374364852905273\n",
      "Batch: 591 , Combined Loss: tensor(0.6105, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.13401198387146\n",
      "Batch: 592 , Combined Loss: tensor(0.5534, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7989664077758789\n",
      "Batch: 593 , Combined Loss: tensor(0.7692, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7619431018829346\n",
      "Batch: 594 , Combined Loss: tensor(0.6129, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42781949043273926\n",
      "Batch: 595 , Combined Loss: tensor(0.5938, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0710692405700684\n",
      "Batch: 596 , Combined Loss: tensor(0.5795, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.16695237159729\n",
      "Batch: 597 , Combined Loss: tensor(0.9841, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5532361268997192\n",
      "Batch: 598 , Combined Loss: tensor(0.5741, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0199997425079346\n",
      "Batch: 599 , Combined Loss: tensor(0.5344, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1864428520202637\n",
      "Batch: 600 , Combined Loss: tensor(0.5846, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0858509540557861\n",
      "Batch: 601 , Combined Loss: tensor(0.7049, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7583199739456177\n",
      "Batch: 602 , Combined Loss: tensor(0.5593, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1027143001556396\n",
      "Batch: 603 , Combined Loss: tensor(0.5299, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5397045612335205\n",
      "Batch: 604 , Combined Loss: tensor(0.5589, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8369656801223755\n",
      "Batch: 605 , Combined Loss: tensor(0.5756, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1209063529968262\n",
      "Batch: 606 , Combined Loss: tensor(0.6254, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0672435760498047\n",
      "Batch: 607 , Combined Loss: tensor(0.6784, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7723349332809448\n",
      "Batch: 608 , Combined Loss: tensor(0.6277, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8606538772583008\n",
      "Batch: 609 , Combined Loss: tensor(0.5735, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.786670446395874\n",
      "Batch: 610 , Combined Loss: tensor(0.8610, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0686728954315186\n",
      "Batch: 611 , Combined Loss: tensor(0.8059, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6655741930007935\n",
      "Batch: 612 , Combined Loss: tensor(0.5890, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6311131715774536\n",
      "Batch: 613 , Combined Loss: tensor(0.7015, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7978441715240479\n",
      "Batch: 614 , Combined Loss: tensor(0.8378, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5464457273483276\n",
      "Batch: 615 , Combined Loss: tensor(0.6554, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7145935297012329\n",
      "Batch: 616 , Combined Loss: tensor(0.5229, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0867681503295898\n",
      "Batch: 617 , Combined Loss: tensor(0.5982, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9600591659545898\n",
      "Batch: 618 , Combined Loss: tensor(0.6664, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8362425565719604\n",
      "Batch: 619 , Combined Loss: tensor(0.8315, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8866522312164307\n",
      "Batch: 620 , Combined Loss: tensor(0.5078, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0281329154968262\n",
      "Batch: 621 , Combined Loss: tensor(0.5417, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.845368504524231\n",
      "Batch: 622 , Combined Loss: tensor(0.5980, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0554018020629883\n",
      "Batch: 623 , Combined Loss: tensor(0.5552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1852340698242188\n",
      "Batch: 624 , Combined Loss: tensor(0.6072, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0741329193115234\n",
      "Batch: 625 , Combined Loss: tensor(0.5947, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0877783298492432\n",
      "Batch: 626 , Combined Loss: tensor(0.5328, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1818032264709473\n",
      "Batch: 627 , Combined Loss: tensor(0.6682, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0391771793365479\n",
      "Batch: 628 , Combined Loss: tensor(0.5305, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0557808876037598\n",
      "----------Epoch 27, Loss: 0.6516573643267439, Accuracy: 0.9780318839371868, Dice Coef: [0.9905190766331501, 0.6474449333839611, 0.6855989434014723, 0.7612063179274073], Dice Coef Necrotic: 1.0459941478241215, Dice Coef Edema: 1.068927648924873, Dice Coef Enhancing: 1.0759948558259407, Sensitivity: [0.9835455108712322, 0.7483516626873621, 0.8676140903478965, 0.8938953190426], Specificity: [0.9608264028173182, 0.9985325994097372, 0.9845382250928348, 0.9966646422452882], Precision: [0.9976471989446679, 0.6440840495781032, 0.5962194387411814, 0.6997987635454773]\n",
      "Saving without nn.DataParallel\n",
      "Batch: 0 , Combined Loss: tensor(0.6345, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37566065788269043\n",
      "Batch: 1 , Combined Loss: tensor(0.5222, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9350390434265137\n",
      "Batch: 2 , Combined Loss: tensor(0.6756, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9765037298202515\n",
      "Batch: 3 , Combined Loss: tensor(0.7799, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0230474472045898\n",
      "Batch: 4 , Combined Loss: tensor(1.0377, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5983865261077881\n",
      "Batch: 5 , Combined Loss: tensor(0.5558, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5341209173202515\n",
      "Batch: 6 , Combined Loss: tensor(0.5514, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7836041450500488\n",
      "Batch: 7 , Combined Loss: tensor(0.5943, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6298174858093262\n",
      "Batch: 8 , Combined Loss: tensor(0.7212, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8237625360488892\n",
      "Batch: 9 , Combined Loss: tensor(1.1337, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3762255907058716\n",
      "Batch: 10 , Combined Loss: tensor(0.6249, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.916502833366394\n",
      "Batch: 11 , Combined Loss: tensor(0.5932, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0600547790527344\n",
      "Batch: 12 , Combined Loss: tensor(0.6051, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5695384740829468\n",
      "Batch: 13 , Combined Loss: tensor(0.5896, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9407788515090942\n",
      "Batch: 14 , Combined Loss: tensor(0.6299, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.346269130706787\n",
      "Batch: 15 , Combined Loss: tensor(0.8231, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44609761238098145\n",
      "Batch: 16 , Combined Loss: tensor(0.6142, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7307103872299194\n",
      "Batch: 17 , Combined Loss: tensor(0.5748, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.349717378616333\n",
      "Batch: 18 , Combined Loss: tensor(0.7041, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8568308353424072\n",
      "Batch: 19 , Combined Loss: tensor(0.5434, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.00028228759765625\n",
      "Batch: 20 , Combined Loss: tensor(0.5899, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9573341608047485\n",
      "Batch: 21 , Combined Loss: tensor(0.7698, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9239096641540527\n",
      "Batch: 22 , Combined Loss: tensor(0.6217, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08786261081695557\n",
      "Batch: 23 , Combined Loss: tensor(0.6826, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7690752744674683\n",
      "Batch: 24 , Combined Loss: tensor(0.5662, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8748975992202759\n",
      "Batch: 25 , Combined Loss: tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.00172758102417\n",
      "Batch: 26 , Combined Loss: tensor(0.5766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5063872337341309\n",
      "Batch: 27 , Combined Loss: tensor(0.6563, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8371405601501465\n",
      "Batch: 28 , Combined Loss: tensor(0.7587, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13459229469299316\n",
      "Batch: 29 , Combined Loss: tensor(0.6790, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34189343452453613\n",
      "Batch: 30 , Combined Loss: tensor(0.6057, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07776713371276855\n",
      "Batch: 31 , Combined Loss: tensor(0.8826, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6285442113876343\n",
      "Batch: 32 , Combined Loss: tensor(0.6173, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6633905172348022\n",
      "Batch: 33 , Combined Loss: tensor(0.6282, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8670995235443115\n",
      "Batch: 34 , Combined Loss: tensor(0.7263, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0367659330368042\n",
      "Batch: 35 , Combined Loss: tensor(0.6522, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6837062835693359\n",
      "Batch: 36 , Combined Loss: tensor(0.6123, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23923546075820923\n",
      "Batch: 37 , Combined Loss: tensor(0.7059, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5545834302902222\n",
      "Batch: 38 , Combined Loss: tensor(0.6222, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3717317581176758\n",
      "Batch: 39 , Combined Loss: tensor(0.6040, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8099600076675415\n",
      "Batch: 40 , Combined Loss: tensor(0.7411, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.561294436454773\n",
      "Batch: 41 , Combined Loss: tensor(0.7138, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7283052206039429\n",
      "Batch: 42 , Combined Loss: tensor(0.6583, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41829609870910645\n",
      "Batch: 43 , Combined Loss: tensor(0.7239, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4544914960861206\n",
      "Batch: 44 , Combined Loss: tensor(0.6739, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.599439263343811\n",
      "Batch: 45 , Combined Loss: tensor(0.9132, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19374001026153564\n",
      "Batch: 46 , Combined Loss: tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8547302484512329\n",
      "Batch: 47 , Combined Loss: tensor(0.8459, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09049254655838013\n",
      "Batch: 48 , Combined Loss: tensor(0.6245, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6218054294586182\n",
      "Batch: 49 , Combined Loss: tensor(0.6391, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3946419954299927\n",
      "Batch: 50 , Combined Loss: tensor(0.5987, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.584030032157898\n",
      "Batch: 51 , Combined Loss: tensor(0.5886, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9651377201080322\n",
      "Batch: 52 , Combined Loss: tensor(0.6909, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3540080785751343\n",
      "Batch: 53 , Combined Loss: tensor(0.8821, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7146831750869751\n",
      "Batch: 54 , Combined Loss: tensor(0.5970, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7541797161102295\n",
      "Batch: 55 , Combined Loss: tensor(0.7554, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1729280948638916\n",
      "Batch: 56 , Combined Loss: tensor(0.7422, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5024533271789551\n",
      "Batch: 57 , Combined Loss: tensor(0.5949, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8692657947540283\n",
      "Batch: 58 , Combined Loss: tensor(0.6458, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29618239402770996\n",
      "Batch: 59 , Combined Loss: tensor(0.6174, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8323225975036621\n",
      "Batch: 60 , Combined Loss: tensor(0.5567, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42571747303009033\n",
      "Batch: 61 , Combined Loss: tensor(0.8771, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.017727792263031006\n",
      "Batch: 62 , Combined Loss: tensor(0.7896, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7350122928619385\n",
      "Batch: 63 , Combined Loss: tensor(0.5491, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6740924119949341\n",
      "Batch: 64 , Combined Loss: tensor(0.7412, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22182244062423706\n",
      "Batch: 65 , Combined Loss: tensor(0.6301, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35918498039245605\n",
      "Batch: 66 , Combined Loss: tensor(0.6709, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.08150988817214966\n",
      "Batch: 67 , Combined Loss: tensor(0.7125, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46660637855529785\n",
      "Batch: 68 , Combined Loss: tensor(0.6651, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2655620574951172\n",
      "Batch: 69 , Combined Loss: tensor(0.6134, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9138349294662476\n",
      "Batch: 70 , Combined Loss: tensor(0.6466, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6781467199325562\n",
      "Batch: 71 , Combined Loss: tensor(0.7242, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33246302604675293\n",
      "Batch: 72 , Combined Loss: tensor(0.6639, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0007177591323852539\n",
      "Batch: 73 , Combined Loss: tensor(0.6233, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8249680995941162\n",
      "Batch: 74 , Combined Loss: tensor(0.5688, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4441995620727539\n",
      "Batch: 75 , Combined Loss: tensor(0.7003, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6400518417358398\n",
      "Batch: 76 , Combined Loss: tensor(0.6838, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14737635850906372\n",
      "Batch: 77 , Combined Loss: tensor(0.5208, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7083700895309448\n",
      "Batch: 78 , Combined Loss: tensor(0.6503, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3729661703109741\n",
      "Batch: 79 , Combined Loss: tensor(0.6785, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3581465482711792\n",
      "Batch: 80 , Combined Loss: tensor(0.6323, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6315840482711792\n",
      "Batch: 81 , Combined Loss: tensor(0.5811, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8828091621398926\n",
      "Batch: 82 , Combined Loss: tensor(0.6336, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7342054843902588\n",
      "Batch: 83 , Combined Loss: tensor(0.6658, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9623533487319946\n",
      "Batch: 84 , Combined Loss: tensor(0.6869, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7126278877258301\n",
      "Batch: 85 , Combined Loss: tensor(0.6596, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6793760061264038\n",
      "Batch: 86 , Combined Loss: tensor(0.8877, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0027167797088623047\n",
      "Batch: 87 , Combined Loss: tensor(0.5288, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8134838342666626\n",
      "Batch: 88 , Combined Loss: tensor(0.6839, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2057197093963623\n",
      "Batch: 89 , Combined Loss: tensor(0.6938, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6863621473312378\n",
      "Batch: 90 , Combined Loss: tensor(0.6701, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6842347383499146\n",
      "Batch: 91 , Combined Loss: tensor(0.7042, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45682084560394287\n",
      "Batch: 92 , Combined Loss: tensor(0.6458, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.867282509803772\n",
      "Batch: 93 , Combined Loss: tensor(0.7883, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5292657613754272\n",
      "Batch: 94 , Combined Loss: tensor(0.5941, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1794404983520508\n",
      "Batch: 95 , Combined Loss: tensor(0.6193, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9103575944900513\n",
      "Batch: 96 , Combined Loss: tensor(0.5801, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5219275951385498\n",
      "Batch: 97 , Combined Loss: tensor(0.5567, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5080103874206543\n",
      "Batch: 98 , Combined Loss: tensor(0.7564, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.796754002571106\n",
      "Batch: 99 , Combined Loss: tensor(0.7030, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5261038541793823\n",
      "Batch: 100 , Combined Loss: tensor(0.6327, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.056255578994751\n",
      "Batch: 101 , Combined Loss: tensor(0.6355, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9891790151596069\n",
      "Batch: 102 , Combined Loss: tensor(0.7106, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41884779930114746\n",
      "Batch: 103 , Combined Loss: tensor(0.6765, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2411201000213623\n",
      "Batch: 104 , Combined Loss: tensor(0.5740, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0722506046295166\n",
      "Batch: 105 , Combined Loss: tensor(0.4734, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5231744050979614\n",
      "Batch: 106 , Combined Loss: tensor(0.6651, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12918561697006226\n",
      "Batch: 107 , Combined Loss: tensor(0.5988, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9152309894561768\n",
      "Batch: 108 , Combined Loss: tensor(0.7414, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8549548387527466\n",
      "Batch: 109 , Combined Loss: tensor(0.6032, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8004308938980103\n",
      "Batch: 110 , Combined Loss: tensor(0.5997, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9048486948013306\n",
      "Batch: 111 , Combined Loss: tensor(0.6613, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0087239742279053\n",
      "Batch: 112 , Combined Loss: tensor(0.6085, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23843109607696533\n",
      "Batch: 113 , Combined Loss: tensor(0.6445, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.020540475845337\n",
      "Batch: 114 , Combined Loss: tensor(0.5714, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0031192302703857\n",
      "Batch: 115 , Combined Loss: tensor(0.7664, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8410840034484863\n",
      "Batch: 116 , Combined Loss: tensor(0.5620, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.081362247467041\n",
      "Batch: 117 , Combined Loss: tensor(0.5309, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7524141073226929\n",
      "Batch: 118 , Combined Loss: tensor(0.6306, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0327105522155762\n",
      "Batch: 119 , Combined Loss: tensor(0.7462, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3966437578201294\n",
      "Batch: 120 , Combined Loss: tensor(0.7057, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8997867107391357\n",
      "Batch: 121 , Combined Loss: tensor(0.6931, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0426805019378662\n",
      "Batch: 122 , Combined Loss: tensor(0.5753, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.984722375869751\n",
      "Batch: 123 , Combined Loss: tensor(0.5662, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.503261923789978\n",
      "Batch: 124 , Combined Loss: tensor(0.5914, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7416338920593262\n",
      "Batch: 125 , Combined Loss: tensor(0.8249, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7849506139755249\n",
      "Batch: 126 , Combined Loss: tensor(0.5865, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1795413494110107\n",
      "Batch: 127 , Combined Loss: tensor(0.6171, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9126015901565552\n",
      "Batch: 128 , Combined Loss: tensor(0.6803, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9768023490905762\n",
      "Batch: 129 , Combined Loss: tensor(0.6506, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8320200443267822\n",
      "Batch: 130 , Combined Loss: tensor(0.6367, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9476292133331299\n",
      "Batch: 131 , Combined Loss: tensor(0.6393, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8908427953720093\n",
      "Batch: 132 , Combined Loss: tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0083065032958984\n",
      "Batch: 133 , Combined Loss: tensor(0.5375, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9323704242706299\n",
      "Batch: 134 , Combined Loss: tensor(0.6837, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8169088363647461\n",
      "Batch: 135 , Combined Loss: tensor(0.5606, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1514778137207031\n",
      "Batch: 136 , Combined Loss: tensor(0.6108, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8669954538345337\n",
      "Batch: 137 , Combined Loss: tensor(0.5685, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7525144815444946\n",
      "Batch: 138 , Combined Loss: tensor(0.6829, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.336078405380249\n",
      "Batch: 139 , Combined Loss: tensor(0.5842, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2507176399230957\n",
      "Batch: 140 , Combined Loss: tensor(0.6987, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8041002750396729\n",
      "Batch: 141 , Combined Loss: tensor(0.6041, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8671202659606934\n",
      "Batch: 142 , Combined Loss: tensor(0.5711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45239531993865967\n",
      "Batch: 143 , Combined Loss: tensor(0.5654, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4297459125518799\n",
      "Batch: 144 , Combined Loss: tensor(0.6082, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1965458393096924\n",
      "Batch: 145 , Combined Loss: tensor(0.8277, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07983201742172241\n",
      "Batch: 146 , Combined Loss: tensor(0.6948, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.655077338218689\n",
      "Batch: 147 , Combined Loss: tensor(0.5852, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0260701179504395\n",
      "Batch: 148 , Combined Loss: tensor(0.6691, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2998150587081909\n",
      "Batch: 149 , Combined Loss: tensor(0.6226, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6856787204742432\n",
      "Batch: 150 , Combined Loss: tensor(0.6451, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7982708215713501\n",
      "Batch: 151 , Combined Loss: tensor(0.7287, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24479305744171143\n",
      "Batch: 152 , Combined Loss: tensor(0.5207, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6154053211212158\n",
      "Batch: 153 , Combined Loss: tensor(0.7567, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6886590719223022\n",
      "Batch: 154 , Combined Loss: tensor(0.6884, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3811984062194824\n",
      "Batch: 155 , Combined Loss: tensor(0.6901, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36147236824035645\n",
      "Batch: 156 , Combined Loss: tensor(0.7040, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7811803817749023\n",
      "Batch: 157 , Combined Loss: tensor(0.6801, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11875569820404053\n",
      "Batch: 158 , Combined Loss: tensor(0.5684, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9410529136657715\n",
      "Batch: 159 , Combined Loss: tensor(0.5213, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5654737949371338\n",
      "Batch: 160 , Combined Loss: tensor(0.7886, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8580200672149658\n",
      "Batch: 161 , Combined Loss: tensor(0.6523, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9519839286804199\n",
      "Batch: 162 , Combined Loss: tensor(0.5111, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.032336950302124\n",
      "Batch: 163 , Combined Loss: tensor(0.6657, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0599439144134521\n",
      "Batch: 164 , Combined Loss: tensor(0.6550, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9076273441314697\n",
      "Batch: 165 , Combined Loss: tensor(0.5577, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.047633171081543\n",
      "Batch: 166 , Combined Loss: tensor(0.6132, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8903446197509766\n",
      "Batch: 167 , Combined Loss: tensor(0.6329, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6206415891647339\n",
      "Batch: 168 , Combined Loss: tensor(0.6034, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0345556735992432\n",
      "Batch: 169 , Combined Loss: tensor(0.6258, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8655657768249512\n",
      "Batch: 170 , Combined Loss: tensor(0.6304, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13818073272705078\n",
      "Batch: 171 , Combined Loss: tensor(0.6877, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8925126791000366\n",
      "Batch: 172 , Combined Loss: tensor(0.6648, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1998107433319092\n",
      "Batch: 173 , Combined Loss: tensor(0.7308, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.895054817199707\n",
      "Batch: 174 , Combined Loss: tensor(0.6013, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0158355236053467\n",
      "Batch: 175 , Combined Loss: tensor(0.5379, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7633541822433472\n",
      "Batch: 176 , Combined Loss: tensor(0.7521, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9565553665161133\n",
      "Batch: 177 , Combined Loss: tensor(0.6598, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28689098358154297\n",
      "Batch: 178 , Combined Loss: tensor(0.6873, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6264053583145142\n",
      "Batch: 179 , Combined Loss: tensor(0.5604, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9693471193313599\n",
      "Batch: 180 , Combined Loss: tensor(0.5620, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0844860076904297\n",
      "Batch: 181 , Combined Loss: tensor(0.6842, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27715325355529785\n",
      "Batch: 182 , Combined Loss: tensor(0.5682, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7052383422851562\n",
      "Batch: 183 , Combined Loss: tensor(0.9237, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0046005249023438\n",
      "Batch: 184 , Combined Loss: tensor(0.5153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0793747901916504\n",
      "Batch: 185 , Combined Loss: tensor(0.5822, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9705401659011841\n",
      "Batch: 186 , Combined Loss: tensor(0.5553, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1788694858551025\n",
      "Batch: 187 , Combined Loss: tensor(0.5474, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.859569787979126\n",
      "Batch: 188 , Combined Loss: tensor(0.6185, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2523462772369385\n",
      "Batch: 189 , Combined Loss: tensor(0.7012, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22329354286193848\n",
      "Batch: 190 , Combined Loss: tensor(0.5918, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2228975296020508\n",
      "Batch: 191 , Combined Loss: tensor(0.5871, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2028262615203857\n",
      "Batch: 192 , Combined Loss: tensor(0.8063, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5780116319656372\n",
      "Batch: 193 , Combined Loss: tensor(0.6174, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8342207670211792\n",
      "Batch: 194 , Combined Loss: tensor(0.5976, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48894834518432617\n",
      "Batch: 195 , Combined Loss: tensor(0.7114, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0465049743652344\n",
      "Batch: 196 , Combined Loss: tensor(0.5319, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8942320346832275\n",
      "Batch: 197 , Combined Loss: tensor(0.9059, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20543134212493896\n",
      "Batch: 198 , Combined Loss: tensor(0.7107, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1151306629180908\n",
      "Batch: 199 , Combined Loss: tensor(0.5936, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.891380786895752\n",
      "Batch: 200 , Combined Loss: tensor(0.8690, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44348692893981934\n",
      "Batch: 201 , Combined Loss: tensor(0.5403, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0961191654205322\n",
      "Batch: 202 , Combined Loss: tensor(0.6983, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8542871475219727\n",
      "Batch: 203 , Combined Loss: tensor(0.6500, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2969937324523926\n",
      "Batch: 204 , Combined Loss: tensor(0.5962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9808993339538574\n",
      "Batch: 205 , Combined Loss: tensor(0.5391, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7838568687438965\n",
      "Batch: 206 , Combined Loss: tensor(0.5878, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9368842840194702\n",
      "Batch: 207 , Combined Loss: tensor(0.5553, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.613930344581604\n",
      "Batch: 208 , Combined Loss: tensor(0.5143, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5651382207870483\n",
      "Batch: 209 , Combined Loss: tensor(0.7300, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0188062191009521\n",
      "Batch: 210 , Combined Loss: tensor(0.5193, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1643762588500977\n",
      "Batch: 211 , Combined Loss: tensor(0.6316, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5236791372299194\n",
      "Batch: 212 , Combined Loss: tensor(0.5433, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9500424861907959\n",
      "Batch: 213 , Combined Loss: tensor(0.6999, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0330440998077393\n",
      "Batch: 214 , Combined Loss: tensor(0.5083, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0276975631713867\n",
      "Batch: 215 , Combined Loss: tensor(0.7477, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0534427165985107\n",
      "Batch: 216 , Combined Loss: tensor(0.6509, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5058721303939819\n",
      "Batch: 217 , Combined Loss: tensor(0.6736, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9351828098297119\n",
      "Batch: 218 , Combined Loss: tensor(0.5945, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6741443872451782\n",
      "Batch: 219 , Combined Loss: tensor(0.9515, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8496360778808594\n",
      "Batch: 220 , Combined Loss: tensor(0.5713, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2034046649932861\n",
      "Batch: 221 , Combined Loss: tensor(0.6193, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9009766578674316\n",
      "Batch: 222 , Combined Loss: tensor(0.6535, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8804233074188232\n",
      "Batch: 223 , Combined Loss: tensor(0.6374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.02567720413208\n",
      "Batch: 224 , Combined Loss: tensor(0.5524, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7543244361877441\n",
      "Batch: 225 , Combined Loss: tensor(0.5646, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.103473424911499\n",
      "Batch: 226 , Combined Loss: tensor(0.5984, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9990233182907104\n",
      "Batch: 227 , Combined Loss: tensor(0.5406, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0452156066894531\n",
      "Batch: 228 , Combined Loss: tensor(0.7255, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8002687692642212\n",
      "Batch: 229 , Combined Loss: tensor(0.5558, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0248708724975586\n",
      "Batch: 230 , Combined Loss: tensor(0.5704, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8066858053207397\n",
      "Batch: 231 , Combined Loss: tensor(0.8786, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8403700590133667\n",
      "Batch: 232 , Combined Loss: tensor(0.9870, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7877095937728882\n",
      "Batch: 233 , Combined Loss: tensor(0.6053, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9284809827804565\n",
      "Batch: 234 , Combined Loss: tensor(0.5862, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9756631851196289\n",
      "Batch: 235 , Combined Loss: tensor(0.6058, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.185186505317688\n",
      "Batch: 236 , Combined Loss: tensor(0.6980, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0567176342010498\n",
      "Batch: 237 , Combined Loss: tensor(0.5284, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.944413423538208\n",
      "Batch: 238 , Combined Loss: tensor(0.6353, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.066422700881958\n",
      "Batch: 239 , Combined Loss: tensor(0.5938, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9725418090820312\n",
      "Batch: 240 , Combined Loss: tensor(0.6385, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9569354057312012\n",
      "Batch: 241 , Combined Loss: tensor(0.6091, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8465697765350342\n",
      "Batch: 242 , Combined Loss: tensor(0.5703, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2366013526916504\n",
      "Batch: 243 , Combined Loss: tensor(0.6524, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.997539758682251\n",
      "Batch: 244 , Combined Loss: tensor(0.5651, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43070411682128906\n",
      "Batch: 245 , Combined Loss: tensor(0.5925, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9894981384277344\n",
      "Batch: 246 , Combined Loss: tensor(0.6432, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5534989833831787\n",
      "Batch: 247 , Combined Loss: tensor(0.5592, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9386205673217773\n",
      "Batch: 248 , Combined Loss: tensor(0.5566, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.13645601272583\n",
      "Batch: 249 , Combined Loss: tensor(0.6016, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.746306300163269\n",
      "Batch: 250 , Combined Loss: tensor(0.6124, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0216658115386963\n",
      "Batch: 251 , Combined Loss: tensor(1.2676, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.458204984664917\n",
      "Batch: 252 , Combined Loss: tensor(0.6830, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4159584045410156\n",
      "Batch: 253 , Combined Loss: tensor(0.5430, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7388730049133301\n",
      "Batch: 254 , Combined Loss: tensor(0.6438, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0249278545379639\n",
      "Batch: 255 , Combined Loss: tensor(0.6045, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17282795906066895\n",
      "Batch: 256 , Combined Loss: tensor(0.7752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7571452856063843\n",
      "Batch: 257 , Combined Loss: tensor(0.6267, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0673494338989258\n",
      "Batch: 258 , Combined Loss: tensor(0.5257, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5821880102157593\n",
      "Batch: 259 , Combined Loss: tensor(0.6406, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9026780128479004\n",
      "Batch: 260 , Combined Loss: tensor(0.5126, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7180792093276978\n",
      "Batch: 261 , Combined Loss: tensor(0.6990, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23267459869384766\n",
      "Batch: 262 , Combined Loss: tensor(0.8045, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6334215402603149\n",
      "Batch: 263 , Combined Loss: tensor(0.7524, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.590787410736084\n",
      "Batch: 264 , Combined Loss: tensor(0.5665, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29033994674682617\n",
      "Batch: 265 , Combined Loss: tensor(0.5811, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9748749732971191\n",
      "Batch: 266 , Combined Loss: tensor(0.6583, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3917948007583618\n",
      "Batch: 267 , Combined Loss: tensor(0.5903, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.905319333076477\n",
      "Batch: 268 , Combined Loss: tensor(0.6912, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.600608229637146\n",
      "Batch: 269 , Combined Loss: tensor(0.5376, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7225587368011475\n",
      "Batch: 270 , Combined Loss: tensor(0.7725, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5726414918899536\n",
      "Batch: 271 , Combined Loss: tensor(0.7234, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8395830392837524\n",
      "Batch: 272 , Combined Loss: tensor(0.6376, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9303144216537476\n",
      "Batch: 273 , Combined Loss: tensor(0.7907, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5248187780380249\n",
      "Batch: 274 , Combined Loss: tensor(0.6492, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1009273529052734\n",
      "Batch: 275 , Combined Loss: tensor(0.5287, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9676386117935181\n",
      "Batch: 276 , Combined Loss: tensor(0.7217, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5853511095046997\n",
      "Batch: 277 , Combined Loss: tensor(0.5751, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9545838832855225\n",
      "Batch: 278 , Combined Loss: tensor(0.6380, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.041172981262207\n",
      "Batch: 279 , Combined Loss: tensor(0.5864, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9193105697631836\n",
      "Batch: 280 , Combined Loss: tensor(0.5950, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9925657510757446\n",
      "Batch: 281 , Combined Loss: tensor(0.5666, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0682077407836914\n",
      "Batch: 282 , Combined Loss: tensor(0.5567, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4518827199935913\n",
      "Batch: 283 , Combined Loss: tensor(0.5895, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8000437021255493\n",
      "Batch: 284 , Combined Loss: tensor(0.5502, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.286811113357544\n",
      "Batch: 285 , Combined Loss: tensor(0.6016, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1342244148254395\n",
      "Batch: 286 , Combined Loss: tensor(1.0180, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8714382648468018\n",
      "Batch: 287 , Combined Loss: tensor(0.7199, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9675155878067017\n",
      "Batch: 288 , Combined Loss: tensor(0.6622, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.033008456230163574\n",
      "Batch: 289 , Combined Loss: tensor(0.6029, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35649728775024414\n",
      "Batch: 290 , Combined Loss: tensor(0.7312, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9946839809417725\n",
      "Batch: 291 , Combined Loss: tensor(0.5300, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0817124843597412\n",
      "Batch: 292 , Combined Loss: tensor(0.4855, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7516838312149048\n",
      "Batch: 293 , Combined Loss: tensor(0.6511, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3199162483215332\n",
      "Batch: 294 , Combined Loss: tensor(0.5609, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0276329517364502\n",
      "Batch: 295 , Combined Loss: tensor(0.5816, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9057744741439819\n",
      "Batch: 296 , Combined Loss: tensor(0.7081, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8841224908828735\n",
      "Batch: 297 , Combined Loss: tensor(0.7702, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9587219953536987\n",
      "Batch: 298 , Combined Loss: tensor(0.6241, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0189435482025146\n",
      "Batch: 299 , Combined Loss: tensor(0.5556, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9970535039901733\n",
      "Batch: 300 , Combined Loss: tensor(0.6149, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8993219137191772\n",
      "Batch: 301 , Combined Loss: tensor(0.5999, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7247796058654785\n",
      "Batch: 302 , Combined Loss: tensor(0.6109, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1706337928771973\n",
      "Batch: 303 , Combined Loss: tensor(0.6082, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9731762409210205\n",
      "Batch: 304 , Combined Loss: tensor(0.7659, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0158653259277344\n",
      "Batch: 305 , Combined Loss: tensor(0.5793, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8991353511810303\n",
      "Batch: 306 , Combined Loss: tensor(0.7192, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.862501859664917\n",
      "Batch: 307 , Combined Loss: tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.591423749923706\n",
      "Batch: 308 , Combined Loss: tensor(0.6381, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8033586740493774\n",
      "Batch: 309 , Combined Loss: tensor(0.6493, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8576242923736572\n",
      "Batch: 310 , Combined Loss: tensor(0.5481, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8320151567459106\n",
      "Batch: 311 , Combined Loss: tensor(0.6284, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8126612901687622\n",
      "Batch: 312 , Combined Loss: tensor(0.5688, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9789048433303833\n",
      "Batch: 313 , Combined Loss: tensor(0.5708, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8213262557983398\n",
      "Batch: 314 , Combined Loss: tensor(0.5922, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.928101658821106\n",
      "Batch: 315 , Combined Loss: tensor(0.5917, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.855571985244751\n",
      "Batch: 316 , Combined Loss: tensor(0.6203, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8051835298538208\n",
      "Batch: 317 , Combined Loss: tensor(0.5843, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.050816297531128\n",
      "Batch: 318 , Combined Loss: tensor(0.6540, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4111166000366211\n",
      "Batch: 319 , Combined Loss: tensor(0.5382, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9957181215286255\n",
      "Batch: 320 , Combined Loss: tensor(0.6039, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.722507119178772\n",
      "Batch: 321 , Combined Loss: tensor(0.6197, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8792933225631714\n",
      "Batch: 322 , Combined Loss: tensor(0.6306, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0525355339050293\n",
      "Batch: 323 , Combined Loss: tensor(0.5866, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6821498870849609\n",
      "Batch: 324 , Combined Loss: tensor(0.6612, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0671076774597168\n",
      "Batch: 325 , Combined Loss: tensor(0.6648, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9797837734222412\n",
      "Batch: 326 , Combined Loss: tensor(0.5838, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8840512037277222\n",
      "Batch: 327 , Combined Loss: tensor(0.6940, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21599328517913818\n",
      "Batch: 328 , Combined Loss: tensor(0.5213, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6907480955123901\n",
      "Batch: 329 , Combined Loss: tensor(0.7280, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9226415157318115\n",
      "Batch: 330 , Combined Loss: tensor(0.6172, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4900400638580322\n",
      "Batch: 331 , Combined Loss: tensor(0.7859, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48449039459228516\n",
      "Batch: 332 , Combined Loss: tensor(0.5496, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9232994318008423\n",
      "Batch: 333 , Combined Loss: tensor(0.6127, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8616104125976562\n",
      "Batch: 334 , Combined Loss: tensor(0.8391, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.223197340965271\n",
      "Batch: 335 , Combined Loss: tensor(0.7854, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32975471019744873\n",
      "Batch: 336 , Combined Loss: tensor(0.5732, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0796318054199219\n",
      "Batch: 337 , Combined Loss: tensor(0.5985, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.01259315013885498\n",
      "Batch: 338 , Combined Loss: tensor(0.7729, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8994656801223755\n",
      "Batch: 339 , Combined Loss: tensor(0.5765, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3338395357131958\n",
      "Batch: 340 , Combined Loss: tensor(0.5626, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.946880578994751\n",
      "Batch: 341 , Combined Loss: tensor(0.6041, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44282984733581543\n",
      "Batch: 342 , Combined Loss: tensor(0.6700, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9888439178466797\n",
      "Batch: 343 , Combined Loss: tensor(0.6009, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7721492052078247\n",
      "Batch: 344 , Combined Loss: tensor(0.7390, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.022076845169067383\n",
      "Batch: 345 , Combined Loss: tensor(0.6840, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1544818878173828\n",
      "Batch: 346 , Combined Loss: tensor(0.7048, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5508272647857666\n",
      "Batch: 347 , Combined Loss: tensor(0.5819, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0580370426177979\n",
      "Batch: 348 , Combined Loss: tensor(0.5349, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8194370269775391\n",
      "Batch: 349 , Combined Loss: tensor(0.5960, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6510727405548096\n",
      "Batch: 350 , Combined Loss: tensor(0.9784, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5583728551864624\n",
      "Batch: 351 , Combined Loss: tensor(0.5737, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5830775499343872\n",
      "Batch: 352 , Combined Loss: tensor(0.6409, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9751619100570679\n",
      "Batch: 353 , Combined Loss: tensor(0.6419, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8873974084854126\n",
      "Batch: 354 , Combined Loss: tensor(0.5737, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.073941707611084\n",
      "Batch: 355 , Combined Loss: tensor(0.6124, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.082991361618042\n",
      "Batch: 356 , Combined Loss: tensor(0.6086, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.886441707611084\n",
      "Batch: 357 , Combined Loss: tensor(0.6420, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7484310865402222\n",
      "Batch: 358 , Combined Loss: tensor(0.5848, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5008538961410522\n",
      "Batch: 359 , Combined Loss: tensor(0.7073, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8983563184738159\n",
      "Batch: 360 , Combined Loss: tensor(0.6337, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.577569842338562\n",
      "Batch: 361 , Combined Loss: tensor(0.8389, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.884333610534668\n",
      "Batch: 362 , Combined Loss: tensor(0.6696, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0619196891784668\n",
      "Batch: 363 , Combined Loss: tensor(0.5664, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8891924619674683\n",
      "Batch: 364 , Combined Loss: tensor(0.6583, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0241832733154297\n",
      "Batch: 365 , Combined Loss: tensor(0.7708, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.77559494972229\n",
      "Batch: 366 , Combined Loss: tensor(0.5450, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3659834861755371\n",
      "Batch: 367 , Combined Loss: tensor(0.5246, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1522221565246582\n",
      "Batch: 368 , Combined Loss: tensor(0.6227, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0428011417388916\n",
      "Batch: 369 , Combined Loss: tensor(0.8608, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.931471586227417\n",
      "Batch: 370 , Combined Loss: tensor(0.5633, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8284609317779541\n",
      "Batch: 371 , Combined Loss: tensor(0.8825, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06929194927215576\n",
      "Batch: 372 , Combined Loss: tensor(0.6757, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8528392314910889\n",
      "Batch: 373 , Combined Loss: tensor(0.5559, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.833354115486145\n",
      "Batch: 374 , Combined Loss: tensor(0.5349, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.006127119064331\n",
      "Batch: 375 , Combined Loss: tensor(0.5335, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8321744203567505\n",
      "Batch: 376 , Combined Loss: tensor(0.6892, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9136377573013306\n",
      "Batch: 377 , Combined Loss: tensor(0.5671, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.024907112121582\n",
      "Batch: 378 , Combined Loss: tensor(0.7211, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.943265438079834\n",
      "Batch: 379 , Combined Loss: tensor(0.6433, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1308436393737793\n",
      "Batch: 380 , Combined Loss: tensor(0.5445, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8603798151016235\n",
      "Batch: 381 , Combined Loss: tensor(0.5537, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8680282831192017\n",
      "Batch: 382 , Combined Loss: tensor(0.6882, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6029788255691528\n",
      "Batch: 383 , Combined Loss: tensor(0.6461, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8175703287124634\n",
      "Batch: 384 , Combined Loss: tensor(0.6412, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8462295532226562\n",
      "Batch: 385 , Combined Loss: tensor(0.6508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.115786075592041\n",
      "Batch: 386 , Combined Loss: tensor(0.7991, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8274134397506714\n",
      "Batch: 387 , Combined Loss: tensor(0.7347, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9183453321456909\n",
      "Batch: 388 , Combined Loss: tensor(0.6251, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9528342485427856\n",
      "Batch: 389 , Combined Loss: tensor(0.5404, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7227293252944946\n",
      "Batch: 390 , Combined Loss: tensor(0.5442, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7936617136001587\n",
      "Batch: 391 , Combined Loss: tensor(0.8498, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1063261032104492\n",
      "Batch: 392 , Combined Loss: tensor(0.6252, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.555701732635498\n",
      "Batch: 393 , Combined Loss: tensor(0.7460, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1179401874542236\n",
      "Batch: 394 , Combined Loss: tensor(0.5597, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6669126749038696\n",
      "Batch: 395 , Combined Loss: tensor(0.6356, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9978781938552856\n",
      "Batch: 396 , Combined Loss: tensor(0.5315, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8525290489196777\n",
      "Batch: 397 , Combined Loss: tensor(0.6904, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9623554944992065\n",
      "Batch: 398 , Combined Loss: tensor(0.5782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.167569875717163\n",
      "Batch: 399 , Combined Loss: tensor(0.6332, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9925780296325684\n",
      "Batch: 400 , Combined Loss: tensor(0.7355, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0938355922698975\n",
      "Batch: 401 , Combined Loss: tensor(0.7290, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48600125312805176\n",
      "Batch: 402 , Combined Loss: tensor(0.5588, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9336283206939697\n",
      "Batch: 403 , Combined Loss: tensor(0.5513, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0381219387054443\n",
      "Batch: 404 , Combined Loss: tensor(0.5645, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1861953735351562\n",
      "Batch: 405 , Combined Loss: tensor(0.5963, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2237186431884766\n",
      "Batch: 406 , Combined Loss: tensor(0.7627, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0279819965362549\n",
      "Batch: 407 , Combined Loss: tensor(0.5980, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6350524425506592\n",
      "Batch: 408 , Combined Loss: tensor(0.5591, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9163322448730469\n",
      "Batch: 409 , Combined Loss: tensor(0.7092, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9850724935531616\n",
      "Batch: 410 , Combined Loss: tensor(0.5666, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7742167711257935\n",
      "Batch: 411 , Combined Loss: tensor(0.5847, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.037626028060913\n",
      "Batch: 412 , Combined Loss: tensor(0.8143, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39337682723999023\n",
      "Batch: 413 , Combined Loss: tensor(0.6322, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6648305654525757\n",
      "Batch: 414 , Combined Loss: tensor(1.1354, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42326509952545166\n",
      "Batch: 415 , Combined Loss: tensor(0.4994, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.632542610168457\n",
      "Batch: 416 , Combined Loss: tensor(0.6447, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9665454626083374\n",
      "Batch: 417 , Combined Loss: tensor(0.6880, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0578644275665283\n",
      "Batch: 418 , Combined Loss: tensor(0.5662, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8485478162765503\n",
      "Batch: 419 , Combined Loss: tensor(0.5439, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7233611345291138\n",
      "Batch: 420 , Combined Loss: tensor(0.7493, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0363917350769043\n",
      "Batch: 421 , Combined Loss: tensor(0.5838, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7041447162628174\n",
      "Batch: 422 , Combined Loss: tensor(0.5913, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9982644319534302\n",
      "Batch: 423 , Combined Loss: tensor(0.5073, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.866025447845459\n",
      "Batch: 424 , Combined Loss: tensor(0.7647, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2785841226577759\n",
      "Batch: 425 , Combined Loss: tensor(0.5688, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1700150966644287\n",
      "Batch: 426 , Combined Loss: tensor(0.7534, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0338225364685059\n",
      "Batch: 427 , Combined Loss: tensor(0.5934, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8539530038833618\n",
      "Batch: 428 , Combined Loss: tensor(0.7634, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8104225397109985\n",
      "Batch: 429 , Combined Loss: tensor(0.5789, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7742993831634521\n",
      "Batch: 430 , Combined Loss: tensor(0.5789, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9151879549026489\n",
      "Batch: 431 , Combined Loss: tensor(0.5899, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7473387718200684\n",
      "Batch: 432 , Combined Loss: tensor(0.6383, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1542692184448242\n",
      "Batch: 433 , Combined Loss: tensor(0.6515, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9755806922912598\n",
      "Batch: 434 , Combined Loss: tensor(0.6500, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5798337459564209\n",
      "Batch: 435 , Combined Loss: tensor(0.6616, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0289983749389648\n",
      "Batch: 436 , Combined Loss: tensor(0.5884, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8473328351974487\n",
      "Batch: 437 , Combined Loss: tensor(0.6155, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9987807273864746\n",
      "Batch: 438 , Combined Loss: tensor(0.7084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7109323740005493\n",
      "Batch: 439 , Combined Loss: tensor(0.7075, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9055744409561157\n",
      "Batch: 440 , Combined Loss: tensor(0.6456, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0707306861877441\n",
      "Batch: 441 , Combined Loss: tensor(0.5886, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.073620319366455\n",
      "Batch: 442 , Combined Loss: tensor(0.8066, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8124222755432129\n",
      "Batch: 443 , Combined Loss: tensor(0.5708, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8683996200561523\n",
      "Batch: 444 , Combined Loss: tensor(0.5948, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0096867084503174\n",
      "Batch: 445 , Combined Loss: tensor(0.5464, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9874074459075928\n",
      "Batch: 446 , Combined Loss: tensor(0.6779, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9724091291427612\n",
      "Batch: 447 , Combined Loss: tensor(0.5552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1174464225769043\n",
      "Batch: 448 , Combined Loss: tensor(0.6360, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8959058523178101\n",
      "Batch: 449 , Combined Loss: tensor(0.6534, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7054983377456665\n",
      "Batch: 450 , Combined Loss: tensor(0.6416, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34886956214904785\n",
      "Batch: 451 , Combined Loss: tensor(0.5814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8816801309585571\n",
      "Batch: 452 , Combined Loss: tensor(0.9811, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5355623960494995\n",
      "Batch: 453 , Combined Loss: tensor(0.6640, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0483441352844238\n",
      "Batch: 454 , Combined Loss: tensor(0.8681, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.382373571395874\n",
      "Batch: 455 , Combined Loss: tensor(0.7013, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3976132869720459\n",
      "Batch: 456 , Combined Loss: tensor(0.6297, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8958009481430054\n",
      "Batch: 457 , Combined Loss: tensor(0.6139, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0259695053100586\n",
      "Batch: 458 , Combined Loss: tensor(0.6044, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35984086990356445\n",
      "Batch: 459 , Combined Loss: tensor(0.5766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8126708269119263\n",
      "Batch: 460 , Combined Loss: tensor(0.6037, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.884835958480835\n",
      "Batch: 461 , Combined Loss: tensor(0.7327, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0053355693817139\n",
      "Batch: 462 , Combined Loss: tensor(0.5536, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0862209796905518\n",
      "Batch: 463 , Combined Loss: tensor(0.5829, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15818488597869873\n",
      "Batch: 464 , Combined Loss: tensor(0.5870, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.990729570388794\n",
      "Batch: 465 , Combined Loss: tensor(0.6661, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6393249034881592\n",
      "Batch: 466 , Combined Loss: tensor(0.5859, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31055748462677\n",
      "Batch: 467 , Combined Loss: tensor(0.6148, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9509717226028442\n",
      "Batch: 468 , Combined Loss: tensor(0.6115, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8010768890380859\n",
      "Batch: 469 , Combined Loss: tensor(0.6347, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9557968378067017\n",
      "Batch: 470 , Combined Loss: tensor(0.5868, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7909029722213745\n",
      "Batch: 471 , Combined Loss: tensor(0.5849, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03383135795593262\n",
      "Batch: 472 , Combined Loss: tensor(0.8221, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8302266597747803\n",
      "Batch: 473 , Combined Loss: tensor(0.6285, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15794432163238525\n",
      "Batch: 474 , Combined Loss: tensor(0.5524, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8066719770431519\n",
      "Batch: 475 , Combined Loss: tensor(0.5633, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.975643515586853\n",
      "Batch: 476 , Combined Loss: tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.888097882270813\n",
      "Batch: 477 , Combined Loss: tensor(0.7182, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8875945806503296\n",
      "Batch: 478 , Combined Loss: tensor(0.5981, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0439562797546387\n",
      "Batch: 479 , Combined Loss: tensor(0.5902, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7412675619125366\n",
      "Batch: 480 , Combined Loss: tensor(0.6047, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.102994441986084\n",
      "Batch: 481 , Combined Loss: tensor(0.5651, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9421606063842773\n",
      "Batch: 482 , Combined Loss: tensor(0.5468, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1579382419586182\n",
      "Batch: 483 , Combined Loss: tensor(0.6847, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9017060995101929\n",
      "Batch: 484 , Combined Loss: tensor(0.5487, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0721821784973145\n",
      "Batch: 485 , Combined Loss: tensor(0.5305, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.899624228477478\n",
      "Batch: 486 , Combined Loss: tensor(0.6366, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2604084014892578\n",
      "Batch: 487 , Combined Loss: tensor(0.5792, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6168417930603027\n",
      "Batch: 488 , Combined Loss: tensor(0.5736, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1345899105072021\n",
      "Batch: 489 , Combined Loss: tensor(0.5053, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8315976858139038\n",
      "Batch: 490 , Combined Loss: tensor(0.5565, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0547780990600586\n",
      "Batch: 491 , Combined Loss: tensor(0.7298, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8462713956832886\n",
      "Batch: 492 , Combined Loss: tensor(0.5701, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9907938241958618\n",
      "Batch: 493 , Combined Loss: tensor(0.6155, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9966769218444824\n",
      "Batch: 494 , Combined Loss: tensor(0.6012, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1105058193206787\n",
      "Batch: 495 , Combined Loss: tensor(0.7465, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9700937271118164\n",
      "Batch: 496 , Combined Loss: tensor(0.4716, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8927218914031982\n",
      "Batch: 497 , Combined Loss: tensor(0.7258, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46965646743774414\n",
      "Batch: 498 , Combined Loss: tensor(0.8621, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34303176403045654\n",
      "Batch: 499 , Combined Loss: tensor(0.5381, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7917522192001343\n",
      "Batch: 500 , Combined Loss: tensor(0.6946, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7171233892440796\n",
      "Batch: 501 , Combined Loss: tensor(0.5443, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.154738187789917\n",
      "Batch: 502 , Combined Loss: tensor(0.5611, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9782812595367432\n",
      "Batch: 503 , Combined Loss: tensor(0.4879, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8677845001220703\n",
      "Batch: 504 , Combined Loss: tensor(0.7494, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4471477270126343\n",
      "Batch: 505 , Combined Loss: tensor(0.6105, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6749213933944702\n",
      "Batch: 506 , Combined Loss: tensor(0.5386, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6087864637374878\n",
      "Batch: 507 , Combined Loss: tensor(0.6608, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5848604440689087\n",
      "Batch: 508 , Combined Loss: tensor(0.6804, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.354838490486145\n",
      "Batch: 509 , Combined Loss: tensor(0.8105, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6854519844055176\n",
      "Batch: 510 , Combined Loss: tensor(0.5915, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.049830436706543\n",
      "Batch: 511 , Combined Loss: tensor(1.0829, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4561060667037964\n",
      "Batch: 512 , Combined Loss: tensor(0.5842, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9520546197891235\n",
      "Batch: 513 , Combined Loss: tensor(0.6584, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9249531030654907\n",
      "Batch: 514 , Combined Loss: tensor(0.5322, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9079804420471191\n",
      "Batch: 515 , Combined Loss: tensor(0.5461, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37298619747161865\n",
      "Batch: 516 , Combined Loss: tensor(0.4715, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7816252708435059\n",
      "Batch: 517 , Combined Loss: tensor(0.8037, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8537135124206543\n",
      "Batch: 518 , Combined Loss: tensor(0.7417, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1159811019897461\n",
      "Batch: 519 , Combined Loss: tensor(0.6368, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8445097208023071\n",
      "Batch: 520 , Combined Loss: tensor(0.6766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9581446647644043\n",
      "Batch: 521 , Combined Loss: tensor(0.8451, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4418759346008301\n",
      "Batch: 522 , Combined Loss: tensor(0.9128, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7191779613494873\n",
      "Batch: 523 , Combined Loss: tensor(0.5996, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.28714632987976074\n",
      "Batch: 524 , Combined Loss: tensor(0.6057, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8824557065963745\n",
      "Batch: 525 , Combined Loss: tensor(0.6897, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9861893653869629\n",
      "Batch: 526 , Combined Loss: tensor(0.8098, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1749310493469238\n",
      "Batch: 527 , Combined Loss: tensor(0.5457, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.077371597290039\n",
      "Batch: 528 , Combined Loss: tensor(0.7685, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1037793159484863\n",
      "Batch: 529 , Combined Loss: tensor(0.6973, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5178810358047485\n",
      "Batch: 530 , Combined Loss: tensor(0.6979, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8894597291946411\n",
      "Batch: 531 , Combined Loss: tensor(0.5515, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.011204719543457\n",
      "Batch: 532 , Combined Loss: tensor(0.4901, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4921529293060303\n",
      "Batch: 533 , Combined Loss: tensor(0.6455, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0901086330413818\n",
      "Batch: 534 , Combined Loss: tensor(0.6256, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.879041314125061\n",
      "Batch: 535 , Combined Loss: tensor(0.7438, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0525436401367188\n",
      "Batch: 536 , Combined Loss: tensor(0.7108, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9446437358856201\n",
      "Batch: 537 , Combined Loss: tensor(0.6301, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.024975299835205078\n",
      "Batch: 538 , Combined Loss: tensor(0.5401, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.195005178451538\n",
      "Batch: 539 , Combined Loss: tensor(0.5737, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26339399814605713\n",
      "Batch: 540 , Combined Loss: tensor(0.6772, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7895342111587524\n",
      "Batch: 541 , Combined Loss: tensor(0.6690, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.946997880935669\n",
      "Batch: 542 , Combined Loss: tensor(0.6835, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9496976137161255\n",
      "Batch: 543 , Combined Loss: tensor(0.6747, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1201305389404297\n",
      "Batch: 544 , Combined Loss: tensor(0.6424, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19043326377868652\n",
      "Batch: 545 , Combined Loss: tensor(0.6031, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8553289175033569\n",
      "Batch: 546 , Combined Loss: tensor(0.6316, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9555048942565918\n",
      "Batch: 547 , Combined Loss: tensor(0.6362, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7496402263641357\n",
      "Batch: 548 , Combined Loss: tensor(0.6226, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0864553451538086\n",
      "Batch: 549 , Combined Loss: tensor(0.6121, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09121263027191162\n",
      "Batch: 550 , Combined Loss: tensor(0.6465, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8311618566513062\n",
      "Batch: 551 , Combined Loss: tensor(0.5252, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9795167446136475\n",
      "Batch: 552 , Combined Loss: tensor(0.5826, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0876743793487549\n",
      "Batch: 553 , Combined Loss: tensor(0.6846, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1020350456237793\n",
      "Batch: 554 , Combined Loss: tensor(0.7176, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6658202409744263\n",
      "Batch: 555 , Combined Loss: tensor(0.5347, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1311566829681396\n",
      "Batch: 556 , Combined Loss: tensor(0.6002, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2373597621917725\n",
      "Batch: 557 , Combined Loss: tensor(0.6004, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9836404323577881\n",
      "Batch: 558 , Combined Loss: tensor(0.5514, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1540124416351318\n",
      "Batch: 559 , Combined Loss: tensor(0.5511, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1709351539611816\n",
      "Batch: 560 , Combined Loss: tensor(0.4960, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8184181451797485\n",
      "Batch: 561 , Combined Loss: tensor(0.6205, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0818543434143066\n",
      "Batch: 562 , Combined Loss: tensor(0.5891, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9033008813858032\n",
      "Batch: 563 , Combined Loss: tensor(0.6028, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.898781418800354\n",
      "Batch: 564 , Combined Loss: tensor(0.7919, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5308728218078613\n",
      "Batch: 565 , Combined Loss: tensor(0.5625, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9229850769042969\n",
      "Batch: 566 , Combined Loss: tensor(0.5825, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9230835437774658\n",
      "Batch: 567 , Combined Loss: tensor(0.7668, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8799804449081421\n",
      "Batch: 568 , Combined Loss: tensor(0.5792, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0619165897369385\n",
      "Batch: 569 , Combined Loss: tensor(0.6070, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0750582218170166\n",
      "Batch: 570 , Combined Loss: tensor(0.5537, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0609033107757568\n",
      "Batch: 571 , Combined Loss: tensor(0.6122, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1171998977661133\n",
      "Batch: 572 , Combined Loss: tensor(0.5789, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9523099660873413\n",
      "Batch: 573 , Combined Loss: tensor(0.5093, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24173176288604736\n",
      "Batch: 574 , Combined Loss: tensor(0.5814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0556938648223877\n",
      "Batch: 575 , Combined Loss: tensor(0.5657, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9777193069458008\n",
      "Batch: 576 , Combined Loss: tensor(0.5134, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0534515380859375\n",
      "Batch: 577 , Combined Loss: tensor(0.5495, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6184020042419434\n",
      "Batch: 578 , Combined Loss: tensor(0.6953, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9176719188690186\n",
      "Batch: 579 , Combined Loss: tensor(0.6658, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2838705778121948\n",
      "Batch: 580 , Combined Loss: tensor(0.5939, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9463528394699097\n",
      "Batch: 581 , Combined Loss: tensor(0.8528, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6298693418502808\n",
      "Batch: 582 , Combined Loss: tensor(0.7496, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.119884729385376\n",
      "Batch: 583 , Combined Loss: tensor(0.6139, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1034467220306396\n",
      "Batch: 584 , Combined Loss: tensor(0.5697, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27775633335113525\n",
      "Batch: 585 , Combined Loss: tensor(0.7344, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1927754878997803\n",
      "Batch: 586 , Combined Loss: tensor(0.5407, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.26517653465271\n",
      "Batch: 587 , Combined Loss: tensor(0.7152, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9496232271194458\n",
      "Batch: 588 , Combined Loss: tensor(0.7341, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9506715536117554\n",
      "Batch: 589 , Combined Loss: tensor(0.7367, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1657767295837402\n",
      "Batch: 590 , Combined Loss: tensor(0.8844, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1596744060516357\n",
      "Batch: 591 , Combined Loss: tensor(0.6080, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31181538105010986\n",
      "Batch: 592 , Combined Loss: tensor(0.5421, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8343390226364136\n",
      "Batch: 593 , Combined Loss: tensor(0.8569, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3450719118118286\n",
      "Batch: 594 , Combined Loss: tensor(0.6711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1388709545135498\n",
      "Batch: 595 , Combined Loss: tensor(0.5434, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3290348052978516\n",
      "Batch: 596 , Combined Loss: tensor(0.7869, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15501290559768677\n",
      "Batch: 597 , Combined Loss: tensor(0.6589, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8854286670684814\n",
      "Batch: 598 , Combined Loss: tensor(0.5722, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9931584596633911\n",
      "Batch: 599 , Combined Loss: tensor(0.6118, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.154205560684204\n",
      "Batch: 600 , Combined Loss: tensor(0.5911, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0764610767364502\n",
      "Batch: 601 , Combined Loss: tensor(0.5707, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9694561958312988\n",
      "Batch: 602 , Combined Loss: tensor(0.5469, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8537062406539917\n",
      "Batch: 603 , Combined Loss: tensor(0.7960, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0984218120574951\n",
      "Batch: 604 , Combined Loss: tensor(0.6144, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7969908714294434\n",
      "Batch: 605 , Combined Loss: tensor(0.5748, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.759189248085022\n",
      "Batch: 606 , Combined Loss: tensor(0.6768, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0557465553283691\n",
      "Batch: 607 , Combined Loss: tensor(0.6362, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9521125555038452\n",
      "Batch: 608 , Combined Loss: tensor(0.7459, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5259507894515991\n",
      "Batch: 609 , Combined Loss: tensor(0.6062, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29803478717803955\n",
      "Batch: 610 , Combined Loss: tensor(0.7004, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.491388201713562\n",
      "Batch: 611 , Combined Loss: tensor(0.5731, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5998964309692383\n",
      "Batch: 612 , Combined Loss: tensor(0.5983, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2953667640686035\n",
      "Batch: 613 , Combined Loss: tensor(0.6427, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8362689018249512\n",
      "Batch: 614 , Combined Loss: tensor(0.6260, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1246273517608643\n",
      "Batch: 615 , Combined Loss: tensor(0.7096, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09414738416671753\n",
      "Batch: 616 , Combined Loss: tensor(0.7252, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8117440938949585\n",
      "Batch: 617 , Combined Loss: tensor(0.7457, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9217125177383423\n",
      "Batch: 618 , Combined Loss: tensor(0.6018, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1851167678833008\n",
      "Batch: 619 , Combined Loss: tensor(0.7846, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2905302047729492\n",
      "Batch: 620 , Combined Loss: tensor(0.6396, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5205401182174683\n",
      "Batch: 621 , Combined Loss: tensor(0.5782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8057667016983032\n",
      "Batch: 622 , Combined Loss: tensor(0.5701, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.879633903503418\n",
      "Batch: 623 , Combined Loss: tensor(0.7293, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5506092309951782\n",
      "Batch: 624 , Combined Loss: tensor(0.5998, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9755165576934814\n",
      "Batch: 625 , Combined Loss: tensor(0.5817, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8849515914916992\n",
      "Batch: 626 , Combined Loss: tensor(0.6493, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35379552841186523\n",
      "Batch: 627 , Combined Loss: tensor(0.5348, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9847666025161743\n",
      "Batch: 628 , Combined Loss: tensor(0.7243, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2370598316192627\n",
      "----------Epoch 28, Loss: 0.6460090035569687, Accuracy: 0.9754488055012374, Dice Coef: [0.9888938817955163, 0.6649671904721278, 0.6729476708787033, 0.7556240856155412], Dice Coef Necrotic: 1.027299025999126, Dice Coef Edema: 1.0398029667700417, Dice Coef Enhancing: 1.0374404441353224, Sensitivity: [0.9800079242224156, 0.7792368840292209, 0.8899875211696746, 0.8824725946521058], Specificity: [0.9670785933685606, 0.9983097429495358, 0.9818768186675346, 0.9965145017460154], Precision: [0.9980408970995055, 0.6408875710352766, 0.5706701856910692, 0.7011308627331182]\n",
      "Saving without nn.DataParallel\n",
      "Batch: 0 , Combined Loss: tensor(0.8405, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5512173175811768\n",
      "Batch: 1 , Combined Loss: tensor(0.7103, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20945072174072266\n",
      "Batch: 2 , Combined Loss: tensor(0.6044, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5271068811416626\n",
      "Batch: 3 , Combined Loss: tensor(1.0479, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8344817161560059\n",
      "Batch: 4 , Combined Loss: tensor(0.7639, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.02040410041809082\n",
      "Batch: 5 , Combined Loss: tensor(0.7449, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7846734523773193\n",
      "Batch: 6 , Combined Loss: tensor(0.5848, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5394997596740723\n",
      "Batch: 7 , Combined Loss: tensor(0.8180, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0840909481048584\n",
      "Batch: 8 , Combined Loss: tensor(0.7920, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06523847579956055\n",
      "Batch: 9 , Combined Loss: tensor(0.6790, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.021732747554779053\n",
      "Batch: 10 , Combined Loss: tensor(0.6136, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.547642707824707\n",
      "Batch: 11 , Combined Loss: tensor(0.7794, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6858303546905518\n",
      "Batch: 12 , Combined Loss: tensor(0.7007, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25895893573760986\n",
      "Batch: 13 , Combined Loss: tensor(0.6551, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9954150915145874\n",
      "Batch: 14 , Combined Loss: tensor(0.5921, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7984658479690552\n",
      "Batch: 15 , Combined Loss: tensor(0.8681, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.259493887424469\n",
      "Batch: 16 , Combined Loss: tensor(0.8242, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21601366996765137\n",
      "Batch: 17 , Combined Loss: tensor(0.5720, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7919776439666748\n",
      "Batch: 18 , Combined Loss: tensor(0.6278, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6719547510147095\n",
      "Batch: 19 , Combined Loss: tensor(0.7284, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.036002159118652344\n",
      "Batch: 20 , Combined Loss: tensor(0.5088, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7676814794540405\n",
      "Batch: 21 , Combined Loss: tensor(0.6161, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8500036001205444\n",
      "Batch: 22 , Combined Loss: tensor(0.6404, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5743341445922852\n",
      "Batch: 23 , Combined Loss: tensor(0.5794, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19025981426239014\n",
      "Batch: 24 , Combined Loss: tensor(0.6058, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8920224905014038\n",
      "Batch: 25 , Combined Loss: tensor(0.6333, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8356654644012451\n",
      "Batch: 26 , Combined Loss: tensor(0.6775, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0106360912322998\n",
      "Batch: 27 , Combined Loss: tensor(0.5693, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8885723352432251\n",
      "Batch: 28 , Combined Loss: tensor(0.5384, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9028761386871338\n",
      "Batch: 29 , Combined Loss: tensor(0.5471, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9269219636917114\n",
      "Batch: 30 , Combined Loss: tensor(0.6725, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0100083351135254\n",
      "Batch: 31 , Combined Loss: tensor(0.5556, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7582105398178101\n",
      "Batch: 32 , Combined Loss: tensor(0.5083, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9221718311309814\n",
      "Batch: 33 , Combined Loss: tensor(0.5956, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7563520669937134\n",
      "Batch: 34 , Combined Loss: tensor(0.6544, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0481972694396973\n",
      "Batch: 35 , Combined Loss: tensor(0.6328, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7762138843536377\n",
      "Batch: 36 , Combined Loss: tensor(0.6235, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.015236973762512207\n",
      "Batch: 37 , Combined Loss: tensor(0.7317, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8175554275512695\n",
      "Batch: 38 , Combined Loss: tensor(0.5871, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6596359014511108\n",
      "Batch: 39 , Combined Loss: tensor(0.6154, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0616521835327148\n",
      "Batch: 40 , Combined Loss: tensor(0.5544, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5459305047988892\n",
      "Batch: 41 , Combined Loss: tensor(0.5157, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8054249286651611\n",
      "Batch: 42 , Combined Loss: tensor(0.7341, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.657010555267334\n",
      "Batch: 43 , Combined Loss: tensor(0.6568, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7024147510528564\n",
      "Batch: 44 , Combined Loss: tensor(0.5474, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7364063262939453\n",
      "Batch: 45 , Combined Loss: tensor(0.5957, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1639750003814697\n",
      "Batch: 46 , Combined Loss: tensor(0.7089, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8883099555969238\n",
      "Batch: 47 , Combined Loss: tensor(0.5705, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0959312915802002\n",
      "Batch: 48 , Combined Loss: tensor(0.5378, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1588118076324463\n",
      "Batch: 49 , Combined Loss: tensor(0.7019, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0982615947723389\n",
      "Batch: 50 , Combined Loss: tensor(0.8435, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.265779972076416\n",
      "Batch: 51 , Combined Loss: tensor(0.7731, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1434776782989502\n",
      "Batch: 52 , Combined Loss: tensor(0.7017, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26654088497161865\n",
      "Batch: 53 , Combined Loss: tensor(0.5897, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.110551118850708\n",
      "Batch: 54 , Combined Loss: tensor(0.8213, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6085392236709595\n",
      "Batch: 55 , Combined Loss: tensor(0.6241, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5768436193466187\n",
      "Batch: 56 , Combined Loss: tensor(0.5309, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.12253999710083\n",
      "Batch: 57 , Combined Loss: tensor(0.4821, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6887166500091553\n",
      "Batch: 58 , Combined Loss: tensor(0.6081, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1142218112945557\n",
      "Batch: 59 , Combined Loss: tensor(0.5783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9752914905548096\n",
      "Batch: 60 , Combined Loss: tensor(0.7125, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9466445446014404\n",
      "Batch: 61 , Combined Loss: tensor(0.5955, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1339781284332275\n",
      "Batch: 62 , Combined Loss: tensor(0.5588, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.611636757850647\n",
      "Batch: 63 , Combined Loss: tensor(0.7269, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6081644296646118\n",
      "Batch: 64 , Combined Loss: tensor(1.3705, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5005253553390503\n",
      "Batch: 65 , Combined Loss: tensor(0.6319, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8846179246902466\n",
      "Batch: 66 , Combined Loss: tensor(0.7349, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5541237592697144\n",
      "Batch: 67 , Combined Loss: tensor(0.5904, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8835710287094116\n",
      "Batch: 68 , Combined Loss: tensor(0.6166, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7572344541549683\n",
      "Batch: 69 , Combined Loss: tensor(0.5624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0139107704162598\n",
      "Batch: 70 , Combined Loss: tensor(0.5423, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7365771532058716\n",
      "Batch: 71 , Combined Loss: tensor(0.7641, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.569127082824707\n",
      "Batch: 72 , Combined Loss: tensor(0.6008, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2071506977081299\n",
      "Batch: 73 , Combined Loss: tensor(0.5616, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9287258386611938\n",
      "Batch: 74 , Combined Loss: tensor(0.6498, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8914074897766113\n",
      "Batch: 75 , Combined Loss: tensor(0.7021, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0155761241912842\n",
      "Batch: 76 , Combined Loss: tensor(0.5993, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8681942224502563\n",
      "Batch: 77 , Combined Loss: tensor(0.6722, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9358341693878174\n",
      "Batch: 78 , Combined Loss: tensor(0.6543, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9493013620376587\n",
      "Batch: 79 , Combined Loss: tensor(0.7696, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0329815149307251\n",
      "Batch: 80 , Combined Loss: tensor(0.5337, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.026322603225708\n",
      "Batch: 81 , Combined Loss: tensor(0.6939, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5274299383163452\n",
      "Batch: 82 , Combined Loss: tensor(0.7251, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.697454571723938\n",
      "Batch: 83 , Combined Loss: tensor(0.5841, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9025613069534302\n",
      "Batch: 84 , Combined Loss: tensor(0.7269, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.923690676689148\n",
      "Batch: 85 , Combined Loss: tensor(0.6866, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4318183660507202\n",
      "Batch: 86 , Combined Loss: tensor(0.6247, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6844329833984375\n",
      "Batch: 87 , Combined Loss: tensor(0.6327, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5800837278366089\n",
      "Batch: 88 , Combined Loss: tensor(0.6097, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19995152950286865\n",
      "Batch: 89 , Combined Loss: tensor(0.5826, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8995593786239624\n",
      "Batch: 90 , Combined Loss: tensor(0.6232, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0047204494476318\n",
      "Batch: 91 , Combined Loss: tensor(0.6746, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8433535099029541\n",
      "Batch: 92 , Combined Loss: tensor(0.6153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5865463018417358\n",
      "Batch: 93 , Combined Loss: tensor(0.5757, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5797511339187622\n",
      "Batch: 94 , Combined Loss: tensor(0.5944, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.970606803894043\n",
      "Batch: 95 , Combined Loss: tensor(0.7548, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6442995071411133\n",
      "Batch: 96 , Combined Loss: tensor(0.5707, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0493087768554688\n",
      "Batch: 97 , Combined Loss: tensor(0.8162, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7321685552597046\n",
      "Batch: 98 , Combined Loss: tensor(0.5696, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.092897653579712\n",
      "Batch: 99 , Combined Loss: tensor(0.5591, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9499964714050293\n",
      "Batch: 100 , Combined Loss: tensor(0.5745, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6168255805969238\n",
      "Batch: 101 , Combined Loss: tensor(0.6222, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5971364974975586\n",
      "Batch: 102 , Combined Loss: tensor(0.7241, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2554490566253662\n",
      "Batch: 103 , Combined Loss: tensor(0.6235, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.04209303855896\n",
      "Batch: 104 , Combined Loss: tensor(0.6723, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7199479341506958\n",
      "Batch: 105 , Combined Loss: tensor(0.5945, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7585153579711914\n",
      "Batch: 106 , Combined Loss: tensor(0.7507, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8137062788009644\n",
      "Batch: 107 , Combined Loss: tensor(0.7280, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6989436149597168\n",
      "Batch: 108 , Combined Loss: tensor(0.6640, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6306720972061157\n",
      "Batch: 109 , Combined Loss: tensor(0.7728, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.044480204582214355\n",
      "Batch: 110 , Combined Loss: tensor(0.6012, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6763619184494019\n",
      "Batch: 111 , Combined Loss: tensor(0.6581, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2255769968032837\n",
      "Batch: 112 , Combined Loss: tensor(0.6198, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33352363109588623\n",
      "Batch: 113 , Combined Loss: tensor(0.9278, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.615883469581604\n",
      "Batch: 114 , Combined Loss: tensor(0.8133, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8837790489196777\n",
      "Batch: 115 , Combined Loss: tensor(0.7963, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38573360443115234\n",
      "Batch: 116 , Combined Loss: tensor(0.5894, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2386918067932129\n",
      "Batch: 117 , Combined Loss: tensor(0.7309, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9650359153747559\n",
      "Batch: 118 , Combined Loss: tensor(0.6711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9269202947616577\n",
      "Batch: 119 , Combined Loss: tensor(0.6046, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7832075357437134\n",
      "Batch: 120 , Combined Loss: tensor(0.5589, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9059021472930908\n",
      "Batch: 121 , Combined Loss: tensor(0.7057, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5783737897872925\n",
      "Batch: 122 , Combined Loss: tensor(0.5513, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9564160108566284\n",
      "Batch: 123 , Combined Loss: tensor(0.6613, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8031141757965088\n",
      "Batch: 124 , Combined Loss: tensor(0.5567, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6807574033737183\n",
      "Batch: 125 , Combined Loss: tensor(0.6004, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8394114971160889\n",
      "Batch: 126 , Combined Loss: tensor(0.5895, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7910947799682617\n",
      "Batch: 127 , Combined Loss: tensor(0.6363, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10536003112792969\n",
      "Batch: 128 , Combined Loss: tensor(0.6307, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0410358905792236\n",
      "Batch: 129 , Combined Loss: tensor(0.6435, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5570991039276123\n",
      "Batch: 130 , Combined Loss: tensor(0.6607, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.825904369354248\n",
      "Batch: 131 , Combined Loss: tensor(0.6169, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0557477474212646\n",
      "Batch: 132 , Combined Loss: tensor(0.6325, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35301053524017334\n",
      "Batch: 133 , Combined Loss: tensor(0.5240, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6894550323486328\n",
      "Batch: 134 , Combined Loss: tensor(0.6144, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0082247257232666\n",
      "Batch: 135 , Combined Loss: tensor(0.5841, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19543969631195068\n",
      "Batch: 136 , Combined Loss: tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.77451491355896\n",
      "Batch: 137 , Combined Loss: tensor(0.6716, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0746586322784424\n",
      "Batch: 138 , Combined Loss: tensor(0.6717, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0282306671142578\n",
      "Batch: 139 , Combined Loss: tensor(0.6856, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20470201969146729\n",
      "Batch: 140 , Combined Loss: tensor(0.6417, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44011783599853516\n",
      "Batch: 141 , Combined Loss: tensor(0.6388, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6131114959716797\n",
      "Batch: 142 , Combined Loss: tensor(0.7776, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3217649459838867\n",
      "Batch: 143 , Combined Loss: tensor(0.8239, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9838263988494873\n",
      "Batch: 144 , Combined Loss: tensor(0.5329, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0518085956573486\n",
      "Batch: 145 , Combined Loss: tensor(0.6846, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7981734275817871\n",
      "Batch: 146 , Combined Loss: tensor(0.5638, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.61815345287323\n",
      "Batch: 147 , Combined Loss: tensor(0.5425, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1881372928619385\n",
      "Batch: 148 , Combined Loss: tensor(0.7465, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7130848169326782\n",
      "Batch: 149 , Combined Loss: tensor(0.5770, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8952794075012207\n",
      "Batch: 150 , Combined Loss: tensor(0.6509, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9257805347442627\n",
      "Batch: 151 , Combined Loss: tensor(0.5590, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.012075424194336\n",
      "Batch: 152 , Combined Loss: tensor(0.5913, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.16307753324508667\n",
      "Batch: 153 , Combined Loss: tensor(0.5626, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39386558532714844\n",
      "Batch: 154 , Combined Loss: tensor(0.6036, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1597063541412354\n",
      "Batch: 155 , Combined Loss: tensor(0.6624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.997363805770874\n",
      "Batch: 156 , Combined Loss: tensor(0.5413, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3150355815887451\n",
      "Batch: 157 , Combined Loss: tensor(0.6716, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0013618469238281\n",
      "Batch: 158 , Combined Loss: tensor(0.5932, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.091599464416504\n",
      "Batch: 159 , Combined Loss: tensor(0.6983, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0369443893432617\n",
      "Batch: 160 , Combined Loss: tensor(0.9041, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0217666625976562\n",
      "Batch: 161 , Combined Loss: tensor(0.5839, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1274046897888184\n",
      "Batch: 162 , Combined Loss: tensor(0.8816, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.82025146484375\n",
      "Batch: 163 , Combined Loss: tensor(0.6486, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.658088207244873\n",
      "Batch: 164 , Combined Loss: tensor(0.6453, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9752808809280396\n",
      "Batch: 165 , Combined Loss: tensor(0.8312, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9655113220214844\n",
      "Batch: 166 , Combined Loss: tensor(0.6745, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8236416578292847\n",
      "Batch: 167 , Combined Loss: tensor(0.5604, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0451083183288574\n",
      "Batch: 168 , Combined Loss: tensor(0.8362, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8309671878814697\n",
      "Batch: 169 , Combined Loss: tensor(0.7397, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1338610649108887\n",
      "Batch: 170 , Combined Loss: tensor(0.5805, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.238325595855713\n",
      "Batch: 171 , Combined Loss: tensor(0.7571, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0983452796936035\n",
      "Batch: 172 , Combined Loss: tensor(0.6384, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0474402904510498\n",
      "Batch: 173 , Combined Loss: tensor(0.6009, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8560760021209717\n",
      "Batch: 174 , Combined Loss: tensor(0.6703, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6750504970550537\n",
      "Batch: 175 , Combined Loss: tensor(0.5748, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8335906267166138\n",
      "Batch: 176 , Combined Loss: tensor(0.7080, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8929615020751953\n",
      "Batch: 177 , Combined Loss: tensor(0.6109, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8967646360397339\n",
      "Batch: 178 , Combined Loss: tensor(0.6966, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8972780704498291\n",
      "Batch: 179 , Combined Loss: tensor(0.5887, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0358643531799316\n",
      "Batch: 180 , Combined Loss: tensor(0.6365, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9657537937164307\n",
      "Batch: 181 , Combined Loss: tensor(0.5503, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.033520221710205\n",
      "Batch: 182 , Combined Loss: tensor(0.6007, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8867793083190918\n",
      "Batch: 183 , Combined Loss: tensor(0.9035, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9907335042953491\n",
      "Batch: 184 , Combined Loss: tensor(0.5360, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5777562856674194\n",
      "Batch: 185 , Combined Loss: tensor(0.5992, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8496032953262329\n",
      "Batch: 186 , Combined Loss: tensor(0.7495, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5188660621643066\n",
      "Batch: 187 , Combined Loss: tensor(0.7039, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1152751445770264\n",
      "Batch: 188 , Combined Loss: tensor(0.7214, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7458268404006958\n",
      "Batch: 189 , Combined Loss: tensor(0.5940, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4054945707321167\n",
      "Batch: 190 , Combined Loss: tensor(0.7215, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8256006240844727\n",
      "Batch: 191 , Combined Loss: tensor(0.6417, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8255434036254883\n",
      "Batch: 192 , Combined Loss: tensor(0.6080, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.039304494857788\n",
      "Batch: 193 , Combined Loss: tensor(0.6029, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7361822128295898\n",
      "Batch: 194 , Combined Loss: tensor(0.5313, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6361503601074219\n",
      "Batch: 195 , Combined Loss: tensor(0.5633, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1629462242126465\n",
      "Batch: 196 , Combined Loss: tensor(0.7737, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2490160465240479\n",
      "Batch: 197 , Combined Loss: tensor(0.5793, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1878385543823242\n",
      "Batch: 198 , Combined Loss: tensor(0.5167, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32977235317230225\n",
      "Batch: 199 , Combined Loss: tensor(0.5492, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.456571340560913\n",
      "Batch: 200 , Combined Loss: tensor(0.5520, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9777712821960449\n",
      "Batch: 201 , Combined Loss: tensor(0.5663, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0555834770202637\n",
      "Batch: 202 , Combined Loss: tensor(0.6874, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1704449653625488\n",
      "Batch: 203 , Combined Loss: tensor(0.6280, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9658883810043335\n",
      "Batch: 204 , Combined Loss: tensor(0.6475, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0399749279022217\n",
      "Batch: 205 , Combined Loss: tensor(0.5990, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2900004386901855\n",
      "Batch: 206 , Combined Loss: tensor(0.5486, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1510167121887207\n",
      "Batch: 207 , Combined Loss: tensor(0.7010, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6642476320266724\n",
      "Batch: 208 , Combined Loss: tensor(0.8811, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4815077781677246\n",
      "Batch: 209 , Combined Loss: tensor(0.5907, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0349867343902588\n",
      "Batch: 210 , Combined Loss: tensor(0.7256, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9527357816696167\n",
      "Batch: 211 , Combined Loss: tensor(0.5102, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7098996639251709\n",
      "Batch: 212 , Combined Loss: tensor(0.5287, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6398570537567139\n",
      "Batch: 213 , Combined Loss: tensor(0.8153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8911629915237427\n",
      "Batch: 214 , Combined Loss: tensor(0.6201, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9472084045410156\n",
      "Batch: 215 , Combined Loss: tensor(0.5758, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1035282611846924\n",
      "Batch: 216 , Combined Loss: tensor(0.8207, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9770762920379639\n",
      "Batch: 217 , Combined Loss: tensor(0.7293, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7144511938095093\n",
      "Batch: 218 , Combined Loss: tensor(0.5712, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9254086017608643\n",
      "Batch: 219 , Combined Loss: tensor(0.6259, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0501980781555176\n",
      "Batch: 220 , Combined Loss: tensor(0.5842, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0161588191986084\n",
      "Batch: 221 , Combined Loss: tensor(0.8053, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.888609766960144\n",
      "Batch: 222 , Combined Loss: tensor(0.5429, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1658711433410645\n",
      "Batch: 223 , Combined Loss: tensor(0.5641, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.149503469467163\n",
      "Batch: 224 , Combined Loss: tensor(0.5350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9897511005401611\n",
      "Batch: 225 , Combined Loss: tensor(0.5506, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9257587194442749\n",
      "Batch: 226 , Combined Loss: tensor(0.6270, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8621865510940552\n",
      "Batch: 227 , Combined Loss: tensor(0.6648, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2668325901031494\n",
      "Batch: 228 , Combined Loss: tensor(0.6080, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8865739107131958\n",
      "Batch: 229 , Combined Loss: tensor(0.8317, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6825131177902222\n",
      "Batch: 230 , Combined Loss: tensor(0.5815, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1114132404327393\n",
      "Batch: 231 , Combined Loss: tensor(0.5963, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0203800201416016\n",
      "Batch: 232 , Combined Loss: tensor(0.5674, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.081664800643921\n",
      "Batch: 233 , Combined Loss: tensor(0.5438, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9746309518814087\n",
      "Batch: 234 , Combined Loss: tensor(0.6231, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.028404951095581\n",
      "Batch: 235 , Combined Loss: tensor(0.6128, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0387630462646484\n",
      "Batch: 236 , Combined Loss: tensor(0.5929, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.027151346206665\n",
      "Batch: 237 , Combined Loss: tensor(0.6016, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.174839735031128\n",
      "Batch: 238 , Combined Loss: tensor(0.7072, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.041116714477539\n",
      "Batch: 239 , Combined Loss: tensor(0.7643, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7412534952163696\n",
      "Batch: 240 , Combined Loss: tensor(0.6096, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.957045316696167\n",
      "Batch: 241 , Combined Loss: tensor(0.5557, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1264231204986572\n",
      "Batch: 242 , Combined Loss: tensor(0.5368, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8905037641525269\n",
      "Batch: 243 , Combined Loss: tensor(0.6838, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9461476802825928\n",
      "Batch: 244 , Combined Loss: tensor(0.5319, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8052496910095215\n",
      "Batch: 245 , Combined Loss: tensor(0.6331, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27644288539886475\n",
      "Batch: 246 , Combined Loss: tensor(0.7071, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0014803409576416\n",
      "Batch: 247 , Combined Loss: tensor(0.5956, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8627316951751709\n",
      "Batch: 248 , Combined Loss: tensor(0.6792, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9112865924835205\n",
      "Batch: 249 , Combined Loss: tensor(0.5150, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7361671924591064\n",
      "Batch: 250 , Combined Loss: tensor(0.9058, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.855134129524231\n",
      "Batch: 251 , Combined Loss: tensor(0.6352, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.131317377090454\n",
      "Batch: 252 , Combined Loss: tensor(0.6107, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1158413887023926\n",
      "Batch: 253 , Combined Loss: tensor(0.5541, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0002858638763428\n",
      "Batch: 254 , Combined Loss: tensor(0.6299, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4754389524459839\n",
      "Batch: 255 , Combined Loss: tensor(1.0346, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2520795464515686\n",
      "Batch: 256 , Combined Loss: tensor(0.7121, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22733527421951294\n",
      "Batch: 257 , Combined Loss: tensor(0.6239, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1193664073944092\n",
      "Batch: 258 , Combined Loss: tensor(0.5723, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9276481866836548\n",
      "Batch: 259 , Combined Loss: tensor(0.5925, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3455088138580322\n",
      "Batch: 260 , Combined Loss: tensor(0.5616, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9780434370040894\n",
      "Batch: 261 , Combined Loss: tensor(0.5316, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8212572336196899\n",
      "Batch: 262 , Combined Loss: tensor(0.5914, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2464840412139893\n",
      "Batch: 263 , Combined Loss: tensor(0.6955, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1096391677856445\n",
      "Batch: 264 , Combined Loss: tensor(0.7730, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7565904855728149\n",
      "Batch: 265 , Combined Loss: tensor(0.7994, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.27872830629348755\n",
      "Batch: 266 , Combined Loss: tensor(0.5702, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1142561435699463\n",
      "Batch: 267 , Combined Loss: tensor(0.5422, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.976302981376648\n",
      "Batch: 268 , Combined Loss: tensor(0.6832, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15364623069763184\n",
      "Batch: 269 , Combined Loss: tensor(0.6894, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1107027530670166\n",
      "Batch: 270 , Combined Loss: tensor(0.5630, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.77959144115448\n",
      "Batch: 271 , Combined Loss: tensor(0.4908, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8622057437896729\n",
      "Batch: 272 , Combined Loss: tensor(0.6352, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9533278942108154\n",
      "Batch: 273 , Combined Loss: tensor(0.5190, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8344802856445312\n",
      "Batch: 274 , Combined Loss: tensor(0.5955, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.751615047454834\n",
      "Batch: 275 , Combined Loss: tensor(0.6267, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9193060398101807\n",
      "Batch: 276 , Combined Loss: tensor(0.5507, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9379793405532837\n",
      "Batch: 277 , Combined Loss: tensor(0.6720, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6584690809249878\n",
      "Batch: 278 , Combined Loss: tensor(0.5766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7586473226547241\n",
      "Batch: 279 , Combined Loss: tensor(0.6395, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0638744831085205\n",
      "Batch: 280 , Combined Loss: tensor(0.6887, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5716315507888794\n",
      "Batch: 281 , Combined Loss: tensor(0.7964, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6962939500808716\n",
      "Batch: 282 , Combined Loss: tensor(0.5731, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2081489562988281\n",
      "Batch: 283 , Combined Loss: tensor(0.5929, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8408695459365845\n",
      "Batch: 284 , Combined Loss: tensor(0.8015, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8412172794342041\n",
      "Batch: 285 , Combined Loss: tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0830175876617432\n",
      "Batch: 286 , Combined Loss: tensor(0.6178, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5169380903244019\n",
      "Batch: 287 , Combined Loss: tensor(0.6400, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1173315048217773\n",
      "Batch: 288 , Combined Loss: tensor(0.5304, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9943821430206299\n",
      "Batch: 289 , Combined Loss: tensor(0.6128, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8278999328613281\n",
      "Batch: 290 , Combined Loss: tensor(0.6719, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07245934009552002\n",
      "Batch: 291 , Combined Loss: tensor(0.5539, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.989269495010376\n",
      "Batch: 292 , Combined Loss: tensor(0.6294, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0834283828735352\n",
      "Batch: 293 , Combined Loss: tensor(0.5793, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6351176500320435\n",
      "Batch: 294 , Combined Loss: tensor(0.6177, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46714019775390625\n",
      "Batch: 295 , Combined Loss: tensor(0.5997, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9373422861099243\n",
      "Batch: 296 , Combined Loss: tensor(0.6451, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8626055717468262\n",
      "Batch: 297 , Combined Loss: tensor(0.5953, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0734055042266846\n",
      "Batch: 298 , Combined Loss: tensor(0.5782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9228484630584717\n",
      "Batch: 299 , Combined Loss: tensor(0.8485, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6394873857498169\n",
      "Batch: 300 , Combined Loss: tensor(0.5718, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6824214458465576\n",
      "Batch: 301 , Combined Loss: tensor(0.5812, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8171617984771729\n",
      "Batch: 302 , Combined Loss: tensor(0.8227, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46675753593444824\n",
      "Batch: 303 , Combined Loss: tensor(0.7070, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0753955841064453\n",
      "Batch: 304 , Combined Loss: tensor(0.5949, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1717472076416016\n",
      "Batch: 305 , Combined Loss: tensor(0.9211, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6579632759094238\n",
      "Batch: 306 , Combined Loss: tensor(0.5856, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9085289239883423\n",
      "Batch: 307 , Combined Loss: tensor(0.6644, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0614075660705566\n",
      "Batch: 308 , Combined Loss: tensor(0.6991, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1478583812713623\n",
      "Batch: 309 , Combined Loss: tensor(0.5537, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.695415735244751\n",
      "Batch: 310 , Combined Loss: tensor(0.5947, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3271656036376953\n",
      "Batch: 311 , Combined Loss: tensor(0.7459, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9753397703170776\n",
      "Batch: 312 , Combined Loss: tensor(0.5986, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8814629316329956\n",
      "Batch: 313 , Combined Loss: tensor(0.5665, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.845594048500061\n",
      "Batch: 314 , Combined Loss: tensor(0.7106, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9005014896392822\n",
      "Batch: 315 , Combined Loss: tensor(0.6594, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06003129482269287\n",
      "Batch: 316 , Combined Loss: tensor(0.5289, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8303643465042114\n",
      "Batch: 317 , Combined Loss: tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7049498558044434\n",
      "Batch: 318 , Combined Loss: tensor(0.5751, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9090443849563599\n",
      "Batch: 319 , Combined Loss: tensor(0.6894, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6087558269500732\n",
      "Batch: 320 , Combined Loss: tensor(0.5594, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.722779393196106\n",
      "Batch: 321 , Combined Loss: tensor(0.7211, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5791096687316895\n",
      "Batch: 322 , Combined Loss: tensor(0.6938, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.621230959892273\n",
      "Batch: 323 , Combined Loss: tensor(0.6876, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9934288263320923\n",
      "Batch: 324 , Combined Loss: tensor(0.5219, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7750349044799805\n",
      "Batch: 325 , Combined Loss: tensor(0.5652, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8433984518051147\n",
      "Batch: 326 , Combined Loss: tensor(0.5846, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.104687213897705\n",
      "Batch: 327 , Combined Loss: tensor(0.6326, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2784197330474854\n",
      "Batch: 328 , Combined Loss: tensor(0.6075, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42158615589141846\n",
      "Batch: 329 , Combined Loss: tensor(0.6782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9449875354766846\n",
      "Batch: 330 , Combined Loss: tensor(0.7072, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9361317157745361\n",
      "Batch: 331 , Combined Loss: tensor(0.6504, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.784968376159668\n",
      "Batch: 332 , Combined Loss: tensor(0.6718, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20001327991485596\n",
      "Batch: 333 , Combined Loss: tensor(0.6354, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5705716609954834\n",
      "Batch: 334 , Combined Loss: tensor(0.6317, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8440274000167847\n",
      "Batch: 335 , Combined Loss: tensor(0.6679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6147385835647583\n",
      "Batch: 336 , Combined Loss: tensor(0.6449, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8303990364074707\n",
      "Batch: 337 , Combined Loss: tensor(0.7112, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0693762302398682\n",
      "Batch: 338 , Combined Loss: tensor(0.5688, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1444926261901855\n",
      "Batch: 339 , Combined Loss: tensor(0.6685, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.388897180557251\n",
      "Batch: 340 , Combined Loss: tensor(0.6390, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4590277671813965\n",
      "Batch: 341 , Combined Loss: tensor(0.6320, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9978421926498413\n",
      "Batch: 342 , Combined Loss: tensor(0.6115, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0618541240692139\n",
      "Batch: 343 , Combined Loss: tensor(0.6195, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8667298555374146\n",
      "Batch: 344 , Combined Loss: tensor(0.5742, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9929611682891846\n",
      "Batch: 345 , Combined Loss: tensor(0.7002, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7408634424209595\n",
      "Batch: 346 , Combined Loss: tensor(0.5558, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3970153331756592\n",
      "Batch: 347 , Combined Loss: tensor(0.6109, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0928254127502441\n",
      "Batch: 348 , Combined Loss: tensor(0.5947, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8564794063568115\n",
      "Batch: 349 , Combined Loss: tensor(0.5779, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8355616331100464\n",
      "Batch: 350 , Combined Loss: tensor(0.6598, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9954962730407715\n",
      "Batch: 351 , Combined Loss: tensor(0.6800, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3768482208251953\n",
      "Batch: 352 , Combined Loss: tensor(0.5525, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9446842670440674\n",
      "Batch: 353 , Combined Loss: tensor(0.6319, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0384521484375\n",
      "Batch: 354 , Combined Loss: tensor(0.6414, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7865521907806396\n",
      "Batch: 355 , Combined Loss: tensor(0.5985, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9698905944824219\n",
      "Batch: 356 , Combined Loss: tensor(0.6368, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9549888372421265\n",
      "Batch: 357 , Combined Loss: tensor(0.6427, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7862521409988403\n",
      "Batch: 358 , Combined Loss: tensor(0.6293, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8084861040115356\n",
      "Batch: 359 , Combined Loss: tensor(0.6483, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9235175848007202\n",
      "Batch: 360 , Combined Loss: tensor(0.5373, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.209829330444336\n",
      "Batch: 361 , Combined Loss: tensor(0.6058, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5492144823074341\n",
      "Batch: 362 , Combined Loss: tensor(0.6358, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5773782730102539\n",
      "Batch: 363 , Combined Loss: tensor(0.5831, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0590095520019531\n",
      "Batch: 364 , Combined Loss: tensor(0.5847, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1786632537841797\n",
      "Batch: 365 , Combined Loss: tensor(0.5935, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8357834815979004\n",
      "Batch: 366 , Combined Loss: tensor(0.5315, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3120746612548828\n",
      "Batch: 367 , Combined Loss: tensor(0.5654, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9063202142715454\n",
      "Batch: 368 , Combined Loss: tensor(0.6339, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0343730449676514\n",
      "Batch: 369 , Combined Loss: tensor(0.5943, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.734848141670227\n",
      "Batch: 370 , Combined Loss: tensor(0.6345, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7085306644439697\n",
      "Batch: 371 , Combined Loss: tensor(0.5560, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6079411506652832\n",
      "Batch: 372 , Combined Loss: tensor(0.5669, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1587719917297363\n",
      "Batch: 373 , Combined Loss: tensor(0.6268, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0693285465240479\n",
      "Batch: 374 , Combined Loss: tensor(0.6118, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.214754581451416\n",
      "Batch: 375 , Combined Loss: tensor(0.5503, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1443066596984863\n",
      "Batch: 376 , Combined Loss: tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18697452545166016\n",
      "Batch: 377 , Combined Loss: tensor(0.5973, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5900710821151733\n",
      "Batch: 378 , Combined Loss: tensor(0.6632, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0064828395843506\n",
      "Batch: 379 , Combined Loss: tensor(0.6504, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2730169296264648\n",
      "Batch: 380 , Combined Loss: tensor(0.6592, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22987151145935059\n",
      "Batch: 381 , Combined Loss: tensor(0.6155, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2267835140228271\n",
      "Batch: 382 , Combined Loss: tensor(0.5278, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0547184944152832\n",
      "Batch: 383 , Combined Loss: tensor(0.7689, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0122499465942383\n",
      "Batch: 384 , Combined Loss: tensor(0.6793, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7797828912734985\n",
      "Batch: 385 , Combined Loss: tensor(0.8795, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9301633834838867\n",
      "Batch: 386 , Combined Loss: tensor(0.7067, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2570691108703613\n",
      "Batch: 387 , Combined Loss: tensor(0.6484, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0737640857696533\n",
      "Batch: 388 , Combined Loss: tensor(0.5701, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5497673749923706\n",
      "Batch: 389 , Combined Loss: tensor(0.6056, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9726740121841431\n",
      "Batch: 390 , Combined Loss: tensor(0.8664, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.797577977180481\n",
      "Batch: 391 , Combined Loss: tensor(0.6195, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8621044158935547\n",
      "Batch: 392 , Combined Loss: tensor(0.6698, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8952250480651855\n",
      "Batch: 393 , Combined Loss: tensor(0.6523, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0587828159332275\n",
      "Batch: 394 , Combined Loss: tensor(0.5722, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.822846531867981\n",
      "Batch: 395 , Combined Loss: tensor(0.5387, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0117902755737305\n",
      "Batch: 396 , Combined Loss: tensor(0.6193, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0867805480957031\n",
      "Batch: 397 , Combined Loss: tensor(0.5428, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0734443664550781\n",
      "Batch: 398 , Combined Loss: tensor(0.7384, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8583730459213257\n",
      "Batch: 399 , Combined Loss: tensor(0.9234, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8791418075561523\n",
      "Batch: 400 , Combined Loss: tensor(0.5443, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8628367185592651\n",
      "Batch: 401 , Combined Loss: tensor(0.6145, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6686414480209351\n",
      "Batch: 402 , Combined Loss: tensor(0.5774, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1261322498321533\n",
      "Batch: 403 , Combined Loss: tensor(0.7273, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8356561660766602\n",
      "Batch: 404 , Combined Loss: tensor(0.5785, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9449871778488159\n",
      "Batch: 405 , Combined Loss: tensor(0.6037, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.838276743888855\n",
      "Batch: 406 , Combined Loss: tensor(0.5212, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4860684871673584\n",
      "Batch: 407 , Combined Loss: tensor(0.8393, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9379538297653198\n",
      "Batch: 408 , Combined Loss: tensor(0.6242, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7518050670623779\n",
      "Batch: 409 , Combined Loss: tensor(0.5862, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1989812850952148\n",
      "Batch: 410 , Combined Loss: tensor(0.6496, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22486352920532227\n",
      "Batch: 411 , Combined Loss: tensor(0.5897, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.385642409324646\n",
      "Batch: 412 , Combined Loss: tensor(0.5779, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.002687692642212\n",
      "Batch: 413 , Combined Loss: tensor(0.6309, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8266674280166626\n",
      "Batch: 414 , Combined Loss: tensor(0.6558, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7929314374923706\n",
      "Batch: 415 , Combined Loss: tensor(0.7381, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4853135347366333\n",
      "Batch: 416 , Combined Loss: tensor(0.6214, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9965252876281738\n",
      "Batch: 417 , Combined Loss: tensor(0.6458, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.843055009841919\n",
      "Batch: 418 , Combined Loss: tensor(0.6374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11396956443786621\n",
      "Batch: 419 , Combined Loss: tensor(0.8216, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37830233573913574\n",
      "Batch: 420 , Combined Loss: tensor(0.5746, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7637970447540283\n",
      "Batch: 421 , Combined Loss: tensor(0.6919, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9254668951034546\n",
      "Batch: 422 , Combined Loss: tensor(0.5628, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.791843056678772\n",
      "Batch: 423 , Combined Loss: tensor(0.6596, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0466349124908447\n",
      "Batch: 424 , Combined Loss: tensor(0.6155, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9855772256851196\n",
      "Batch: 425 , Combined Loss: tensor(0.5601, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9851087331771851\n",
      "Batch: 426 , Combined Loss: tensor(0.5982, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9613871574401855\n",
      "Batch: 427 , Combined Loss: tensor(0.8586, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0001838207244873\n",
      "Batch: 428 , Combined Loss: tensor(0.5521, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0403294563293457\n",
      "Batch: 429 , Combined Loss: tensor(0.5645, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3472985029220581\n",
      "Batch: 430 , Combined Loss: tensor(0.6636, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9069781303405762\n",
      "Batch: 431 , Combined Loss: tensor(0.7300, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8134281635284424\n",
      "Batch: 432 , Combined Loss: tensor(0.7280, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8476978540420532\n",
      "Batch: 433 , Combined Loss: tensor(1.0350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2816128730773926\n",
      "Batch: 434 , Combined Loss: tensor(0.5953, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8972821235656738\n",
      "Batch: 435 , Combined Loss: tensor(0.6401, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0379376411437988\n",
      "Batch: 436 , Combined Loss: tensor(0.5715, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6877446174621582\n",
      "Batch: 437 , Combined Loss: tensor(0.5921, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0943763256072998\n",
      "Batch: 438 , Combined Loss: tensor(0.7799, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9460279941558838\n",
      "Batch: 439 , Combined Loss: tensor(0.6137, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2858004570007324\n",
      "Batch: 440 , Combined Loss: tensor(0.5602, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8846644163131714\n",
      "Batch: 441 , Combined Loss: tensor(0.6494, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1799640655517578\n",
      "Batch: 442 , Combined Loss: tensor(0.6048, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5621457099914551\n",
      "Batch: 443 , Combined Loss: tensor(0.9273, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21797478199005127\n",
      "Batch: 444 , Combined Loss: tensor(1.1338, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17231237888336182\n",
      "Batch: 445 , Combined Loss: tensor(0.6815, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9513427019119263\n",
      "Batch: 446 , Combined Loss: tensor(0.8743, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.676203727722168\n",
      "Batch: 447 , Combined Loss: tensor(0.7739, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0401561260223389\n",
      "Batch: 448 , Combined Loss: tensor(0.6675, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0146934986114502\n",
      "Batch: 449 , Combined Loss: tensor(0.8826, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.05526524782180786\n",
      "Batch: 450 , Combined Loss: tensor(0.5184, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8921768665313721\n",
      "Batch: 451 , Combined Loss: tensor(0.5164, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7096008062362671\n",
      "Batch: 452 , Combined Loss: tensor(0.6564, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29387974739074707\n",
      "Batch: 453 , Combined Loss: tensor(0.8400, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.035700798034668\n",
      "Batch: 454 , Combined Loss: tensor(0.6395, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0947821140289307\n",
      "Batch: 455 , Combined Loss: tensor(0.5761, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7882661819458008\n",
      "Batch: 456 , Combined Loss: tensor(0.5080, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9344131946563721\n",
      "Batch: 457 , Combined Loss: tensor(0.6332, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.881629228591919\n",
      "Batch: 458 , Combined Loss: tensor(0.6833, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23885393142700195\n",
      "Batch: 459 , Combined Loss: tensor(0.5868, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0275371074676514\n",
      "Batch: 460 , Combined Loss: tensor(0.6032, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9693713188171387\n",
      "Batch: 461 , Combined Loss: tensor(0.6885, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6380103826522827\n",
      "Batch: 462 , Combined Loss: tensor(0.5912, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1185853481292725\n",
      "Batch: 463 , Combined Loss: tensor(0.6250, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2024767398834229\n",
      "Batch: 464 , Combined Loss: tensor(0.6845, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6488157510757446\n",
      "Batch: 465 , Combined Loss: tensor(0.6250, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.074026346206665\n",
      "Batch: 466 , Combined Loss: tensor(0.6033, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0248057842254639\n",
      "Batch: 467 , Combined Loss: tensor(0.5947, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9326760768890381\n",
      "Batch: 468 , Combined Loss: tensor(0.7029, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0524625778198242\n",
      "Batch: 469 , Combined Loss: tensor(0.5665, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7628191709518433\n",
      "Batch: 470 , Combined Loss: tensor(0.5731, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.89129638671875\n",
      "Batch: 471 , Combined Loss: tensor(0.6017, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1193034648895264\n",
      "Batch: 472 , Combined Loss: tensor(0.5021, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7342742681503296\n",
      "Batch: 473 , Combined Loss: tensor(0.6000, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9409493207931519\n",
      "Batch: 474 , Combined Loss: tensor(0.5372, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9046885967254639\n",
      "Batch: 475 , Combined Loss: tensor(0.6244, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7587504386901855\n",
      "Batch: 476 , Combined Loss: tensor(0.5642, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.034623384475708\n",
      "Batch: 477 , Combined Loss: tensor(0.5456, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7453230619430542\n",
      "Batch: 478 , Combined Loss: tensor(0.5598, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6898034811019897\n",
      "Batch: 479 , Combined Loss: tensor(1.1290, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8325729370117188\n",
      "Batch: 480 , Combined Loss: tensor(0.7203, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3233489990234375\n",
      "Batch: 481 , Combined Loss: tensor(0.6180, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2638194561004639\n",
      "Batch: 482 , Combined Loss: tensor(0.6118, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2489393949508667\n",
      "Batch: 483 , Combined Loss: tensor(0.5951, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9317312240600586\n",
      "Batch: 484 , Combined Loss: tensor(0.5697, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0390074253082275\n",
      "Batch: 485 , Combined Loss: tensor(0.6887, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.09163498878479\n",
      "Batch: 486 , Combined Loss: tensor(0.6153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6865503787994385\n",
      "Batch: 487 , Combined Loss: tensor(0.5872, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.711969256401062\n",
      "Batch: 488 , Combined Loss: tensor(0.6169, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0490620136260986\n",
      "Batch: 489 , Combined Loss: tensor(0.6580, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9298732280731201\n",
      "Batch: 490 , Combined Loss: tensor(0.6401, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.045886993408203125\n",
      "Batch: 491 , Combined Loss: tensor(0.7575, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.730076789855957\n",
      "Batch: 492 , Combined Loss: tensor(0.5742, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9978715181350708\n",
      "Batch: 493 , Combined Loss: tensor(0.8660, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8074429035186768\n",
      "Batch: 494 , Combined Loss: tensor(0.6840, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1310288906097412\n",
      "Batch: 495 , Combined Loss: tensor(0.6489, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.947478175163269\n",
      "Batch: 496 , Combined Loss: tensor(0.5481, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5015052556991577\n",
      "Batch: 497 , Combined Loss: tensor(0.6386, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.023869276046753\n",
      "Batch: 498 , Combined Loss: tensor(0.5528, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3423200845718384\n",
      "Batch: 499 , Combined Loss: tensor(0.7248, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9751166105270386\n",
      "Batch: 500 , Combined Loss: tensor(0.5847, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8881244659423828\n",
      "Batch: 501 , Combined Loss: tensor(0.5213, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8336766958236694\n",
      "Batch: 502 , Combined Loss: tensor(0.5923, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7725884914398193\n",
      "Batch: 503 , Combined Loss: tensor(0.7179, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0190482139587402\n",
      "Batch: 504 , Combined Loss: tensor(0.5710, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.001235008239746\n",
      "Batch: 505 , Combined Loss: tensor(0.6517, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.842740535736084\n",
      "Batch: 506 , Combined Loss: tensor(0.6340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0426392555236816\n",
      "Batch: 507 , Combined Loss: tensor(0.7268, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.013697862625122\n",
      "Batch: 508 , Combined Loss: tensor(0.5768, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8130398988723755\n",
      "Batch: 509 , Combined Loss: tensor(0.7120, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8337479829788208\n",
      "Batch: 510 , Combined Loss: tensor(0.7362, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0792322158813477\n",
      "Batch: 511 , Combined Loss: tensor(0.6482, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16567957401275635\n",
      "Batch: 512 , Combined Loss: tensor(0.7953, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9859540462493896\n",
      "Batch: 513 , Combined Loss: tensor(0.4817, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7674702405929565\n",
      "Batch: 514 , Combined Loss: tensor(0.5719, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35950911045074463\n",
      "Batch: 515 , Combined Loss: tensor(0.6162, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7901666164398193\n",
      "Batch: 516 , Combined Loss: tensor(0.7255, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15235447883605957\n",
      "Batch: 517 , Combined Loss: tensor(0.4742, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.548003077507019\n",
      "Batch: 518 , Combined Loss: tensor(0.6418, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1396026611328125\n",
      "Batch: 519 , Combined Loss: tensor(0.5244, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0809993743896484\n",
      "Batch: 520 , Combined Loss: tensor(0.5394, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6792007684707642\n",
      "Batch: 521 , Combined Loss: tensor(0.5459, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0502738952636719\n",
      "Batch: 522 , Combined Loss: tensor(0.5941, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8177976608276367\n",
      "Batch: 523 , Combined Loss: tensor(0.8504, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18950355052947998\n",
      "Batch: 524 , Combined Loss: tensor(0.7579, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.081225872039795\n",
      "Batch: 525 , Combined Loss: tensor(0.5177, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8561457395553589\n",
      "Batch: 526 , Combined Loss: tensor(0.6166, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0210132598876953\n",
      "Batch: 527 , Combined Loss: tensor(0.7297, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7154726982116699\n",
      "Batch: 528 , Combined Loss: tensor(0.6395, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.935418963432312\n",
      "Batch: 529 , Combined Loss: tensor(0.6349, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7826720476150513\n",
      "Batch: 530 , Combined Loss: tensor(0.7383, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.833415150642395\n",
      "Batch: 531 , Combined Loss: tensor(0.6690, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9297212362289429\n",
      "Batch: 532 , Combined Loss: tensor(0.7940, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38467931747436523\n",
      "Batch: 533 , Combined Loss: tensor(0.5842, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1893730163574219\n",
      "Batch: 534 , Combined Loss: tensor(0.6427, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5955173969268799\n",
      "Batch: 535 , Combined Loss: tensor(0.5315, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0184061527252197\n",
      "Batch: 536 , Combined Loss: tensor(0.7324, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.941785454750061\n",
      "Batch: 537 , Combined Loss: tensor(0.8530, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9753665924072266\n",
      "Batch: 538 , Combined Loss: tensor(0.5061, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.877208948135376\n",
      "Batch: 539 , Combined Loss: tensor(0.5545, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0925137996673584\n",
      "Batch: 540 , Combined Loss: tensor(0.7695, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0696101188659668\n",
      "Batch: 541 , Combined Loss: tensor(0.6776, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8091192245483398\n",
      "Batch: 542 , Combined Loss: tensor(0.5524, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0938293933868408\n",
      "Batch: 543 , Combined Loss: tensor(0.7055, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9997988939285278\n",
      "Batch: 544 , Combined Loss: tensor(0.5584, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2440571784973145\n",
      "Batch: 545 , Combined Loss: tensor(0.5650, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3977377414703369\n",
      "Batch: 546 , Combined Loss: tensor(0.7078, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0163609981536865\n",
      "Batch: 547 , Combined Loss: tensor(0.5441, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1864700317382812\n",
      "Batch: 548 , Combined Loss: tensor(0.5675, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0087864398956299\n",
      "Batch: 549 , Combined Loss: tensor(0.8319, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6803607940673828\n",
      "Batch: 550 , Combined Loss: tensor(0.5185, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7396112680435181\n",
      "Batch: 551 , Combined Loss: tensor(0.6338, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0957396030426025\n",
      "Batch: 552 , Combined Loss: tensor(0.5644, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39472496509552\n",
      "Batch: 553 , Combined Loss: tensor(0.6165, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1799707412719727\n",
      "Batch: 554 , Combined Loss: tensor(0.6334, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9035913944244385\n",
      "Batch: 555 , Combined Loss: tensor(0.5921, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8413980007171631\n",
      "Batch: 556 , Combined Loss: tensor(0.7948, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4356602430343628\n",
      "Batch: 557 , Combined Loss: tensor(0.6012, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9491914510726929\n",
      "Batch: 558 , Combined Loss: tensor(0.6714, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9714776277542114\n",
      "Batch: 559 , Combined Loss: tensor(0.7399, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.4595000743865967\n",
      "Batch: 560 , Combined Loss: tensor(0.6354, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2822721004486084\n",
      "Batch: 561 , Combined Loss: tensor(0.6821, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.00679612159729\n",
      "Batch: 562 , Combined Loss: tensor(0.6196, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8660651445388794\n",
      "Batch: 563 , Combined Loss: tensor(0.5520, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1173317432403564\n",
      "Batch: 564 , Combined Loss: tensor(0.5897, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8809853792190552\n",
      "Batch: 565 , Combined Loss: tensor(0.6369, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0643861293792725\n",
      "Batch: 566 , Combined Loss: tensor(0.6576, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.027165174484253\n",
      "Batch: 567 , Combined Loss: tensor(0.6332, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0178511142730713\n",
      "Batch: 568 , Combined Loss: tensor(0.5459, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0601041316986084\n",
      "Batch: 569 , Combined Loss: tensor(0.6427, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0330774784088135\n",
      "Batch: 570 , Combined Loss: tensor(0.7092, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0218122005462646\n",
      "Batch: 571 , Combined Loss: tensor(0.6909, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9506534337997437\n",
      "Batch: 572 , Combined Loss: tensor(0.6112, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4960404634475708\n",
      "Batch: 573 , Combined Loss: tensor(0.6162, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9813278913497925\n",
      "Batch: 574 , Combined Loss: tensor(0.5626, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8733477592468262\n",
      "Batch: 575 , Combined Loss: tensor(0.6807, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5106662511825562\n",
      "Batch: 576 , Combined Loss: tensor(0.5590, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9284870624542236\n",
      "Batch: 577 , Combined Loss: tensor(0.8105, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5449130535125732\n",
      "Batch: 578 , Combined Loss: tensor(0.7415, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3630528450012207\n",
      "Batch: 579 , Combined Loss: tensor(0.6468, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8654986619949341\n",
      "Batch: 580 , Combined Loss: tensor(0.8641, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06782996654510498\n",
      "Batch: 581 , Combined Loss: tensor(0.6838, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5373783111572266\n",
      "Batch: 582 , Combined Loss: tensor(0.5983, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8760126829147339\n",
      "Batch: 583 , Combined Loss: tensor(0.6771, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9445861577987671\n",
      "Batch: 584 , Combined Loss: tensor(0.7871, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8101013898849487\n",
      "Batch: 585 , Combined Loss: tensor(0.5378, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7249493598937988\n",
      "Batch: 586 , Combined Loss: tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5843074321746826\n",
      "Batch: 587 , Combined Loss: tensor(0.5816, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9124743938446045\n",
      "Batch: 588 , Combined Loss: tensor(0.6990, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9697680473327637\n",
      "Batch: 589 , Combined Loss: tensor(0.5863, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8350375890731812\n",
      "Batch: 590 , Combined Loss: tensor(0.5940, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6659083366394043\n",
      "Batch: 591 , Combined Loss: tensor(0.5772, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.05845046043396\n",
      "Batch: 592 , Combined Loss: tensor(0.6137, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0819063186645508\n",
      "Batch: 593 , Combined Loss: tensor(0.5682, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9987941980361938\n",
      "Batch: 594 , Combined Loss: tensor(0.6153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0540862083435059\n",
      "Batch: 595 , Combined Loss: tensor(0.5726, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0163955688476562\n",
      "Batch: 596 , Combined Loss: tensor(0.6030, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5704090595245361\n",
      "Batch: 597 , Combined Loss: tensor(0.4951, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8544273376464844\n",
      "Batch: 598 , Combined Loss: tensor(0.6955, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4766958951950073\n",
      "Batch: 599 , Combined Loss: tensor(0.5868, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.04561185836792\n",
      "Batch: 600 , Combined Loss: tensor(0.5843, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0822153091430664\n",
      "Batch: 601 , Combined Loss: tensor(0.5625, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6780743598937988\n",
      "Batch: 602 , Combined Loss: tensor(0.7134, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0977697372436523\n",
      "Batch: 603 , Combined Loss: tensor(0.9335, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.657103419303894\n",
      "Batch: 604 , Combined Loss: tensor(0.6268, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0584523677825928\n",
      "Batch: 605 , Combined Loss: tensor(0.6237, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9312652349472046\n",
      "Batch: 606 , Combined Loss: tensor(0.5715, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6894451379776001\n",
      "Batch: 607 , Combined Loss: tensor(0.9945, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.698792576789856\n",
      "Batch: 608 , Combined Loss: tensor(0.5739, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17627990245819092\n",
      "Batch: 609 , Combined Loss: tensor(0.7332, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8666063547134399\n",
      "Batch: 610 , Combined Loss: tensor(0.6523, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0306496620178223\n",
      "Batch: 611 , Combined Loss: tensor(0.6841, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49314892292022705\n",
      "Batch: 612 , Combined Loss: tensor(0.6971, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7177201509475708\n",
      "Batch: 613 , Combined Loss: tensor(0.6238, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8743119239807129\n",
      "Batch: 614 , Combined Loss: tensor(0.7578, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3867720365524292\n",
      "Batch: 615 , Combined Loss: tensor(0.5317, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0256588459014893\n",
      "Batch: 616 , Combined Loss: tensor(0.7139, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7722756862640381\n",
      "Batch: 617 , Combined Loss: tensor(0.6501, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.899588942527771\n",
      "Batch: 618 , Combined Loss: tensor(0.6041, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8550266027450562\n",
      "Batch: 619 , Combined Loss: tensor(0.5674, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9319440126419067\n",
      "Batch: 620 , Combined Loss: tensor(0.5931, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1601958274841309\n",
      "Batch: 621 , Combined Loss: tensor(0.6599, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7730039358139038\n",
      "Batch: 622 , Combined Loss: tensor(0.6104, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7264823913574219\n",
      "Batch: 623 , Combined Loss: tensor(0.5628, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8767695426940918\n",
      "Batch: 624 , Combined Loss: tensor(0.6827, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7982258796691895\n",
      "Batch: 625 , Combined Loss: tensor(0.5509, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8910679817199707\n",
      "Batch: 626 , Combined Loss: tensor(0.7133, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6612346172332764\n",
      "Batch: 627 , Combined Loss: tensor(0.7431, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.113753318786621\n",
      "Batch: 628 , Combined Loss: tensor(0.6046, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.092240810394287\n",
      "----------Epoch 29, Loss: 0.6461341892308385, Accuracy: 0.978096692853967, Dice Coef: [0.9904852414737635, 0.6668305913582057, 0.6892589409040718, 0.7629404722584232], Dice Coef Necrotic: 1.0533425903988005, Dice Coef Edema: 1.067399097102791, Dice Coef Enhancing: 1.0761069767735758, Sensitivity: [0.9831209095559174, 0.7688315773715186, 0.8816572655175942, 0.8866087363378422], Specificity: [0.9659825728314859, 0.9986348995533202, 0.9840663400477181, 0.9967392781580575], Precision: [0.9980158304561682, 0.6548230485962974, 0.5954068487077738, 0.7090979685062255]\n",
      "Batch: 0 , Combined Loss: tensor(0.7022, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8602627515792847\n",
      "Batch: 1 , Combined Loss: tensor(0.6063, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16850852966308594\n",
      "Batch: 2 , Combined Loss: tensor(0.6282, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6701239347457886\n",
      "Batch: 3 , Combined Loss: tensor(0.5894, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0314698219299316\n",
      "Batch: 4 , Combined Loss: tensor(0.7064, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.056915044784546\n",
      "Batch: 5 , Combined Loss: tensor(0.5408, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2282469272613525\n",
      "Batch: 6 , Combined Loss: tensor(0.5712, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12255847454071045\n",
      "Batch: 7 , Combined Loss: tensor(0.5634, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5427967309951782\n",
      "Batch: 8 , Combined Loss: tensor(0.6265, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0929465293884277\n",
      "Batch: 9 , Combined Loss: tensor(0.7465, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5904717445373535\n",
      "Batch: 10 , Combined Loss: tensor(0.7076, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5264889001846313\n",
      "Batch: 11 , Combined Loss: tensor(0.6354, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9332789182662964\n",
      "Batch: 12 , Combined Loss: tensor(0.5387, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.986189603805542\n",
      "Batch: 13 , Combined Loss: tensor(0.5423, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6532834768295288\n",
      "Batch: 14 , Combined Loss: tensor(0.6014, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0111103057861328\n",
      "Batch: 15 , Combined Loss: tensor(0.9209, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9142516851425171\n",
      "Batch: 16 , Combined Loss: tensor(0.6871, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30356454849243164\n",
      "Batch: 17 , Combined Loss: tensor(0.9274, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.614059567451477\n",
      "Batch: 18 , Combined Loss: tensor(0.5841, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9107879400253296\n",
      "Batch: 19 , Combined Loss: tensor(0.5782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0800917148590088\n",
      "Batch: 20 , Combined Loss: tensor(0.5823, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2052409648895264\n",
      "Batch: 21 , Combined Loss: tensor(0.6138, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.756726861000061\n",
      "Batch: 22 , Combined Loss: tensor(0.6922, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8023430109024048\n",
      "Batch: 23 , Combined Loss: tensor(0.5374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1837608814239502\n",
      "Batch: 24 , Combined Loss: tensor(0.5851, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.101574182510376\n",
      "Batch: 25 , Combined Loss: tensor(0.5556, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3345224857330322\n",
      "Batch: 26 , Combined Loss: tensor(0.6250, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0476603507995605\n",
      "Batch: 27 , Combined Loss: tensor(0.5717, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9635789394378662\n",
      "Batch: 28 , Combined Loss: tensor(0.6625, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15940821170806885\n",
      "Batch: 29 , Combined Loss: tensor(0.6622, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8051915168762207\n",
      "Batch: 30 , Combined Loss: tensor(0.6932, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1060080528259277\n",
      "Batch: 31 , Combined Loss: tensor(0.5750, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9690133333206177\n",
      "Batch: 32 , Combined Loss: tensor(0.5660, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.687712550163269\n",
      "Batch: 33 , Combined Loss: tensor(0.7309, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6849311590194702\n",
      "Batch: 34 , Combined Loss: tensor(0.5770, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8609662055969238\n",
      "Batch: 35 , Combined Loss: tensor(0.5783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.964033842086792\n",
      "Batch: 36 , Combined Loss: tensor(0.7189, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8479269742965698\n",
      "Batch: 37 , Combined Loss: tensor(0.6376, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6628832817077637\n",
      "Batch: 38 , Combined Loss: tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6234849691390991\n",
      "Batch: 39 , Combined Loss: tensor(0.7583, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3238440155982971\n",
      "Batch: 40 , Combined Loss: tensor(0.6526, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4661228656768799\n",
      "Batch: 41 , Combined Loss: tensor(0.6680, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0294666290283203\n",
      "Batch: 42 , Combined Loss: tensor(0.6438, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0639145374298096\n",
      "Batch: 43 , Combined Loss: tensor(0.5971, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11128830909729004\n",
      "Batch: 44 , Combined Loss: tensor(0.6526, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8505995273590088\n",
      "Batch: 45 , Combined Loss: tensor(0.5614, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1453282833099365\n",
      "Batch: 46 , Combined Loss: tensor(0.6546, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3582075834274292\n",
      "Batch: 47 , Combined Loss: tensor(0.6007, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7478152513504028\n",
      "Batch: 48 , Combined Loss: tensor(0.5615, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6479746103286743\n",
      "Batch: 49 , Combined Loss: tensor(0.6801, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.358737587928772\n",
      "Batch: 50 , Combined Loss: tensor(0.6371, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2997760772705078\n",
      "Batch: 51 , Combined Loss: tensor(0.5535, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4778165817260742\n",
      "Batch: 52 , Combined Loss: tensor(0.6062, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7935723066329956\n",
      "Batch: 53 , Combined Loss: tensor(0.6194, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32180118560791016\n",
      "Batch: 54 , Combined Loss: tensor(0.8333, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7208698987960815\n",
      "Batch: 55 , Combined Loss: tensor(0.7504, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30643272399902344\n",
      "Batch: 56 , Combined Loss: tensor(0.6359, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.014378368854522705\n",
      "Batch: 57 , Combined Loss: tensor(0.7173, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9788649082183838\n",
      "Batch: 58 , Combined Loss: tensor(0.5700, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7405080795288086\n",
      "Batch: 59 , Combined Loss: tensor(0.5857, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.860629677772522\n",
      "Batch: 60 , Combined Loss: tensor(0.4764, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8245422840118408\n",
      "Batch: 61 , Combined Loss: tensor(0.6156, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7875310182571411\n",
      "Batch: 62 , Combined Loss: tensor(0.5929, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8080228567123413\n",
      "Batch: 63 , Combined Loss: tensor(0.9687, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5531923770904541\n",
      "Batch: 64 , Combined Loss: tensor(0.5799, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0044856071472168\n",
      "Batch: 65 , Combined Loss: tensor(0.5794, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8642442226409912\n",
      "Batch: 66 , Combined Loss: tensor(0.6098, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7568842172622681\n",
      "Batch: 67 , Combined Loss: tensor(0.8466, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8051713705062866\n",
      "Batch: 68 , Combined Loss: tensor(0.6147, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8858367204666138\n",
      "Batch: 69 , Combined Loss: tensor(0.5635, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.766555666923523\n",
      "Batch: 70 , Combined Loss: tensor(0.5380, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8936829566955566\n",
      "Batch: 71 , Combined Loss: tensor(0.5707, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7201868295669556\n",
      "Batch: 72 , Combined Loss: tensor(0.8099, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6442153453826904\n",
      "Batch: 73 , Combined Loss: tensor(0.7276, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9241114854812622\n",
      "Batch: 74 , Combined Loss: tensor(0.6394, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10619199275970459\n",
      "Batch: 75 , Combined Loss: tensor(0.6155, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0897331237792969\n",
      "Batch: 76 , Combined Loss: tensor(0.5087, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6160093545913696\n",
      "Batch: 77 , Combined Loss: tensor(0.5899, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.778058648109436\n",
      "Batch: 78 , Combined Loss: tensor(0.6443, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.883743405342102\n",
      "Batch: 79 , Combined Loss: tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9760711193084717\n",
      "Batch: 80 , Combined Loss: tensor(0.4933, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8192867040634155\n",
      "Batch: 81 , Combined Loss: tensor(0.7594, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8434669971466064\n",
      "Batch: 82 , Combined Loss: tensor(0.5893, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0625811219215393\n",
      "Batch: 83 , Combined Loss: tensor(0.5850, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.021679401397705\n",
      "Batch: 84 , Combined Loss: tensor(0.6321, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8632749319076538\n",
      "Batch: 85 , Combined Loss: tensor(0.5251, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9400341510772705\n",
      "Batch: 86 , Combined Loss: tensor(0.5773, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9289990663528442\n",
      "Batch: 87 , Combined Loss: tensor(0.5942, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.956534743309021\n",
      "Batch: 88 , Combined Loss: tensor(0.6604, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22575795650482178\n",
      "Batch: 89 , Combined Loss: tensor(0.9811, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6867694854736328\n",
      "Batch: 90 , Combined Loss: tensor(0.5794, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0710010528564453\n",
      "Batch: 91 , Combined Loss: tensor(0.7000, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6819525957107544\n",
      "Batch: 92 , Combined Loss: tensor(0.6532, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6084814071655273\n",
      "Batch: 93 , Combined Loss: tensor(0.5748, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8288934230804443\n",
      "Batch: 94 , Combined Loss: tensor(0.6728, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9512286186218262\n",
      "Batch: 95 , Combined Loss: tensor(0.5603, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6722288131713867\n",
      "Batch: 96 , Combined Loss: tensor(0.7804, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44536924362182617\n",
      "Batch: 97 , Combined Loss: tensor(0.6167, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42231833934783936\n",
      "Batch: 98 , Combined Loss: tensor(0.6187, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5703028440475464\n",
      "Batch: 99 , Combined Loss: tensor(0.6147, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.766262412071228\n",
      "Batch: 100 , Combined Loss: tensor(0.5184, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6831986904144287\n",
      "Batch: 101 , Combined Loss: tensor(0.5560, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9746576547622681\n",
      "Batch: 102 , Combined Loss: tensor(0.7471, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7404634952545166\n",
      "Batch: 103 , Combined Loss: tensor(0.5879, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9107298851013184\n",
      "Batch: 104 , Combined Loss: tensor(0.7525, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6654473543167114\n",
      "Batch: 105 , Combined Loss: tensor(0.6167, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12818682193756104\n",
      "Batch: 106 , Combined Loss: tensor(0.6122, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0055444240570068\n",
      "Batch: 107 , Combined Loss: tensor(0.6114, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8153177499771118\n",
      "Batch: 108 , Combined Loss: tensor(0.7374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5165537595748901\n",
      "Batch: 109 , Combined Loss: tensor(0.5382, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7683897018432617\n",
      "Batch: 110 , Combined Loss: tensor(0.5710, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0209550857543945\n",
      "Batch: 111 , Combined Loss: tensor(0.5582, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0546627044677734\n",
      "Batch: 112 , Combined Loss: tensor(0.5823, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7829117774963379\n",
      "Batch: 113 , Combined Loss: tensor(0.6000, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1264452934265137\n",
      "Batch: 114 , Combined Loss: tensor(0.5360, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0250911712646484\n",
      "Batch: 115 , Combined Loss: tensor(0.6648, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0317842960357666\n",
      "Batch: 116 , Combined Loss: tensor(0.7729, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7472673654556274\n",
      "Batch: 117 , Combined Loss: tensor(0.6307, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9872723817825317\n",
      "Batch: 118 , Combined Loss: tensor(0.5641, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6694055795669556\n",
      "Batch: 119 , Combined Loss: tensor(0.6118, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5855294466018677\n",
      "Batch: 120 , Combined Loss: tensor(0.5578, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9791001081466675\n",
      "Batch: 121 , Combined Loss: tensor(0.6890, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.05812406539917\n",
      "Batch: 122 , Combined Loss: tensor(0.7950, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0361084938049316\n",
      "Batch: 123 , Combined Loss: tensor(0.6415, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.042224407196045\n",
      "Batch: 124 , Combined Loss: tensor(0.5872, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.007413625717163\n",
      "Batch: 125 , Combined Loss: tensor(0.5678, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9716609716415405\n",
      "Batch: 126 , Combined Loss: tensor(0.7262, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0120782852172852\n",
      "Batch: 127 , Combined Loss: tensor(0.6142, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7768871784210205\n",
      "Batch: 128 , Combined Loss: tensor(0.6069, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9096966981887817\n",
      "Batch: 129 , Combined Loss: tensor(0.6845, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5576741695404053\n",
      "Batch: 130 , Combined Loss: tensor(0.5680, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8135005235671997\n",
      "Batch: 131 , Combined Loss: tensor(0.6641, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3308204412460327\n",
      "Batch: 132 , Combined Loss: tensor(0.6005, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2045488357543945\n",
      "Batch: 133 , Combined Loss: tensor(0.6524, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0303127765655518\n",
      "Batch: 134 , Combined Loss: tensor(0.6284, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.997042179107666\n",
      "Batch: 135 , Combined Loss: tensor(0.5969, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0279083251953125\n",
      "Batch: 136 , Combined Loss: tensor(0.7216, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1540088653564453\n",
      "Batch: 137 , Combined Loss: tensor(0.6214, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7981739044189453\n",
      "Batch: 138 , Combined Loss: tensor(0.6965, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0809924602508545\n",
      "Batch: 139 , Combined Loss: tensor(0.5220, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0357732772827148\n",
      "Batch: 140 , Combined Loss: tensor(0.5525, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9083887338638306\n",
      "Batch: 141 , Combined Loss: tensor(0.6347, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1258704662322998\n",
      "Batch: 142 , Combined Loss: tensor(0.8785, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8519473075866699\n",
      "Batch: 143 , Combined Loss: tensor(0.6766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5730500221252441\n",
      "Batch: 144 , Combined Loss: tensor(0.6198, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.820141077041626\n",
      "Batch: 145 , Combined Loss: tensor(0.5832, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2652360200881958\n",
      "Batch: 146 , Combined Loss: tensor(0.6231, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9577846527099609\n",
      "Batch: 147 , Combined Loss: tensor(0.5972, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1551344394683838\n",
      "Batch: 148 , Combined Loss: tensor(0.5526, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8887680768966675\n",
      "Batch: 149 , Combined Loss: tensor(0.5787, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1619961261749268\n",
      "Batch: 150 , Combined Loss: tensor(0.7300, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.586145281791687\n",
      "Batch: 151 , Combined Loss: tensor(0.5962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.780093789100647\n",
      "Batch: 152 , Combined Loss: tensor(0.5104, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8118767738342285\n",
      "Batch: 153 , Combined Loss: tensor(0.9134, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5310168266296387\n",
      "Batch: 154 , Combined Loss: tensor(0.9219, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1323821544647217\n",
      "Batch: 155 , Combined Loss: tensor(0.6940, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0132203102111816\n",
      "Batch: 156 , Combined Loss: tensor(0.5681, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0735669136047363\n",
      "Batch: 157 , Combined Loss: tensor(0.6042, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7558175325393677\n",
      "Batch: 158 , Combined Loss: tensor(0.5672, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1184194087982178\n",
      "Batch: 159 , Combined Loss: tensor(0.6608, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6016231775283813\n",
      "Batch: 160 , Combined Loss: tensor(0.7548, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8624964952468872\n",
      "Batch: 161 , Combined Loss: tensor(0.5419, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.593034029006958\n",
      "Batch: 162 , Combined Loss: tensor(0.5893, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0361950397491455\n",
      "Batch: 163 , Combined Loss: tensor(0.7407, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.979137659072876\n",
      "Batch: 164 , Combined Loss: tensor(0.5871, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9361265897750854\n",
      "Batch: 165 , Combined Loss: tensor(0.5777, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8499616384506226\n",
      "Batch: 166 , Combined Loss: tensor(0.8540, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9040787220001221\n",
      "Batch: 167 , Combined Loss: tensor(0.5670, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1161930561065674\n",
      "Batch: 168 , Combined Loss: tensor(0.6514, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2010111808776855\n",
      "Batch: 169 , Combined Loss: tensor(0.5790, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9709734916687012\n",
      "Batch: 170 , Combined Loss: tensor(0.6905, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8991649150848389\n",
      "Batch: 171 , Combined Loss: tensor(0.7001, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3201940059661865\n",
      "Batch: 172 , Combined Loss: tensor(0.5429, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0262186527252197\n",
      "Batch: 173 , Combined Loss: tensor(0.5509, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9987977743148804\n",
      "Batch: 174 , Combined Loss: tensor(0.6808, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8659478425979614\n",
      "Batch: 175 , Combined Loss: tensor(0.6121, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0651874542236328\n",
      "Batch: 176 , Combined Loss: tensor(0.6898, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8552902936935425\n",
      "Batch: 177 , Combined Loss: tensor(0.6642, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8367437124252319\n",
      "Batch: 178 , Combined Loss: tensor(0.7607, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37083518505096436\n",
      "Batch: 179 , Combined Loss: tensor(0.5698, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9349902868270874\n",
      "Batch: 180 , Combined Loss: tensor(0.6889, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9916998147964478\n",
      "Batch: 181 , Combined Loss: tensor(0.6696, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0337128639221191\n",
      "Batch: 182 , Combined Loss: tensor(0.6216, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43760251998901367\n",
      "Batch: 183 , Combined Loss: tensor(0.5829, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9202812910079956\n",
      "Batch: 184 , Combined Loss: tensor(0.7010, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0800471305847168\n",
      "Batch: 185 , Combined Loss: tensor(0.6469, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8251636028289795\n",
      "Batch: 186 , Combined Loss: tensor(0.6323, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8874931335449219\n",
      "Batch: 187 , Combined Loss: tensor(0.5629, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0469098091125488\n",
      "Batch: 188 , Combined Loss: tensor(0.5816, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8898638486862183\n",
      "Batch: 189 , Combined Loss: tensor(0.5636, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0740439891815186\n",
      "Batch: 190 , Combined Loss: tensor(0.6553, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8582098484039307\n",
      "Batch: 191 , Combined Loss: tensor(0.5856, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7962837219238281\n",
      "Batch: 192 , Combined Loss: tensor(0.7500, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5754398107528687\n",
      "Batch: 193 , Combined Loss: tensor(0.5531, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9520829916000366\n",
      "Batch: 194 , Combined Loss: tensor(0.7934, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5927095413208008\n",
      "Batch: 195 , Combined Loss: tensor(0.5907, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48026347160339355\n",
      "Batch: 196 , Combined Loss: tensor(0.5459, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5987124443054199\n",
      "Batch: 197 , Combined Loss: tensor(0.5434, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7756507396697998\n",
      "Batch: 198 , Combined Loss: tensor(0.6844, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7433525323867798\n",
      "Batch: 199 , Combined Loss: tensor(0.5640, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.101058006286621\n",
      "Batch: 200 , Combined Loss: tensor(0.6730, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.25197190046310425\n",
      "Batch: 201 , Combined Loss: tensor(0.8492, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3042951822280884\n",
      "Batch: 202 , Combined Loss: tensor(0.5386, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2337629795074463\n",
      "Batch: 203 , Combined Loss: tensor(0.5268, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9889590740203857\n",
      "Batch: 204 , Combined Loss: tensor(0.5160, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.720036506652832\n",
      "Batch: 205 , Combined Loss: tensor(0.5424, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9370392560958862\n",
      "Batch: 206 , Combined Loss: tensor(0.7075, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14183318614959717\n",
      "Batch: 207 , Combined Loss: tensor(0.6559, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0135443210601807\n",
      "Batch: 208 , Combined Loss: tensor(0.5754, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8579710721969604\n",
      "Batch: 209 , Combined Loss: tensor(0.5721, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5845975875854492\n",
      "Batch: 210 , Combined Loss: tensor(0.6099, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18322694301605225\n",
      "Batch: 211 , Combined Loss: tensor(0.5935, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9028700590133667\n",
      "Batch: 212 , Combined Loss: tensor(0.7458, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8326210975646973\n",
      "Batch: 213 , Combined Loss: tensor(0.6345, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06694388389587402\n",
      "Batch: 214 , Combined Loss: tensor(0.5947, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.216411828994751\n",
      "Batch: 215 , Combined Loss: tensor(0.6045, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4862022399902344\n",
      "Batch: 216 , Combined Loss: tensor(0.6434, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.712009072303772\n",
      "Batch: 217 , Combined Loss: tensor(0.5065, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.854428768157959\n",
      "Batch: 218 , Combined Loss: tensor(0.6889, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4688868522644043\n",
      "Batch: 219 , Combined Loss: tensor(0.7891, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8313261270523071\n",
      "Batch: 220 , Combined Loss: tensor(0.7021, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9944040775299072\n",
      "Batch: 221 , Combined Loss: tensor(0.5106, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0902326107025146\n",
      "Batch: 222 , Combined Loss: tensor(0.5304, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0468688011169434\n",
      "Batch: 223 , Combined Loss: tensor(0.8869, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.184389352798462\n",
      "Batch: 224 , Combined Loss: tensor(0.5546, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6099660396575928\n",
      "Batch: 225 , Combined Loss: tensor(0.6805, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.07830810546875\n",
      "Batch: 226 , Combined Loss: tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6826049089431763\n",
      "Batch: 227 , Combined Loss: tensor(0.6915, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.011557340621948242\n",
      "Batch: 228 , Combined Loss: tensor(0.5185, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4319055676460266\n",
      "Batch: 229 , Combined Loss: tensor(0.6065, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9716910123825073\n",
      "Batch: 230 , Combined Loss: tensor(0.6137, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9751980304718018\n",
      "Batch: 231 , Combined Loss: tensor(0.6175, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0234627723693848\n",
      "Batch: 232 , Combined Loss: tensor(0.6191, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38525938987731934\n",
      "Batch: 233 , Combined Loss: tensor(0.5748, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9351214170455933\n",
      "Batch: 234 , Combined Loss: tensor(0.6374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9656155109405518\n",
      "Batch: 235 , Combined Loss: tensor(0.5506, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6342169046401978\n",
      "Batch: 236 , Combined Loss: tensor(0.5614, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0075562000274658\n",
      "Batch: 237 , Combined Loss: tensor(0.5647, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4336804151535034\n",
      "Batch: 238 , Combined Loss: tensor(0.7865, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1344809532165527\n",
      "Batch: 239 , Combined Loss: tensor(0.5957, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1450731754302979\n",
      "Batch: 240 , Combined Loss: tensor(0.6808, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.325337290763855\n",
      "Batch: 241 , Combined Loss: tensor(0.7132, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9451113939285278\n",
      "Batch: 242 , Combined Loss: tensor(0.6979, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5668251514434814\n",
      "Batch: 243 , Combined Loss: tensor(0.5954, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8613924980163574\n",
      "Batch: 244 , Combined Loss: tensor(0.8989, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0179297924041748\n",
      "Batch: 245 , Combined Loss: tensor(0.5561, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21320414543151855\n",
      "Batch: 246 , Combined Loss: tensor(0.6026, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.196408987045288\n",
      "Batch: 247 , Combined Loss: tensor(0.9624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5700796842575073\n",
      "Batch: 248 , Combined Loss: tensor(0.5891, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8837764263153076\n",
      "Batch: 249 , Combined Loss: tensor(0.6874, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5685749053955078\n",
      "Batch: 250 , Combined Loss: tensor(0.5523, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8444410562515259\n",
      "Batch: 251 , Combined Loss: tensor(0.5826, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8840721845626831\n",
      "Batch: 252 , Combined Loss: tensor(1.0560, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.6581152081489563\n",
      "Batch: 253 , Combined Loss: tensor(0.7739, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6678651571273804\n",
      "Batch: 254 , Combined Loss: tensor(0.5080, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9999635219573975\n",
      "Batch: 255 , Combined Loss: tensor(0.7352, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5100760459899902\n",
      "Batch: 256 , Combined Loss: tensor(0.5354, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.979684591293335\n",
      "Batch: 257 , Combined Loss: tensor(0.6187, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7491816282272339\n",
      "Batch: 258 , Combined Loss: tensor(0.7518, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.028552532196045\n",
      "Batch: 259 , Combined Loss: tensor(0.6498, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9514434337615967\n",
      "Batch: 260 , Combined Loss: tensor(0.8338, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5867480039596558\n",
      "Batch: 261 , Combined Loss: tensor(0.5697, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6983996629714966\n",
      "Batch: 262 , Combined Loss: tensor(0.6381, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15841853618621826\n",
      "Batch: 263 , Combined Loss: tensor(0.6030, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9609696865081787\n",
      "Batch: 264 , Combined Loss: tensor(0.6465, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9635825157165527\n",
      "Batch: 265 , Combined Loss: tensor(0.7297, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7061790227890015\n",
      "Batch: 266 , Combined Loss: tensor(0.6762, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8189222812652588\n",
      "Batch: 267 , Combined Loss: tensor(0.5583, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8358231782913208\n",
      "Batch: 268 , Combined Loss: tensor(0.6372, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0123858451843262\n",
      "Batch: 269 , Combined Loss: tensor(0.6855, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6131824254989624\n",
      "Batch: 270 , Combined Loss: tensor(0.7621, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5074828863143921\n",
      "Batch: 271 , Combined Loss: tensor(0.5759, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8601874113082886\n",
      "Batch: 272 , Combined Loss: tensor(0.5924, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3236660957336426\n",
      "Batch: 273 , Combined Loss: tensor(0.6746, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7744646072387695\n",
      "Batch: 274 , Combined Loss: tensor(0.5424, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.825840950012207\n",
      "Batch: 275 , Combined Loss: tensor(0.8185, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9500558376312256\n",
      "Batch: 276 , Combined Loss: tensor(0.7081, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1146767139434814\n",
      "Batch: 277 , Combined Loss: tensor(0.8061, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10344266891479492\n",
      "Batch: 278 , Combined Loss: tensor(0.7095, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13968610763549805\n",
      "Batch: 279 , Combined Loss: tensor(0.5612, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0168144702911377\n",
      "Batch: 280 , Combined Loss: tensor(0.6295, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8801044225692749\n",
      "Batch: 281 , Combined Loss: tensor(0.5444, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0484697818756104\n",
      "Batch: 282 , Combined Loss: tensor(0.8405, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7789441347122192\n",
      "Batch: 283 , Combined Loss: tensor(0.5554, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9960998296737671\n",
      "Batch: 284 , Combined Loss: tensor(0.7171, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8870017528533936\n",
      "Batch: 285 , Combined Loss: tensor(0.6076, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0066890716552734\n",
      "Batch: 286 , Combined Loss: tensor(0.4996, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9156297445297241\n",
      "Batch: 287 , Combined Loss: tensor(0.6794, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.410175085067749\n",
      "Batch: 288 , Combined Loss: tensor(0.5189, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8411129713058472\n",
      "Batch: 289 , Combined Loss: tensor(0.7112, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08913660049438477\n",
      "Batch: 290 , Combined Loss: tensor(0.5782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8569831848144531\n",
      "Batch: 291 , Combined Loss: tensor(0.5951, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8025707006454468\n",
      "Batch: 292 , Combined Loss: tensor(0.8330, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9207199811935425\n",
      "Batch: 293 , Combined Loss: tensor(0.8552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8979772329330444\n",
      "Batch: 294 , Combined Loss: tensor(0.6874, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0791561603546143\n",
      "Batch: 295 , Combined Loss: tensor(0.5774, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5031754970550537\n",
      "Batch: 296 , Combined Loss: tensor(0.8134, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.099484920501709\n",
      "Batch: 297 , Combined Loss: tensor(0.5622, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1244595050811768\n",
      "Batch: 298 , Combined Loss: tensor(0.6065, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9045366048812866\n",
      "Batch: 299 , Combined Loss: tensor(0.5414, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.943045973777771\n",
      "Batch: 300 , Combined Loss: tensor(0.9222, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.006734967231750488\n",
      "Batch: 301 , Combined Loss: tensor(0.6321, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5384937524795532\n",
      "Batch: 302 , Combined Loss: tensor(0.5743, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0632679462432861\n",
      "Batch: 303 , Combined Loss: tensor(0.7713, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.097100019454956\n",
      "Batch: 304 , Combined Loss: tensor(0.6565, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5835748910903931\n",
      "Batch: 305 , Combined Loss: tensor(0.5683, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6450369358062744\n",
      "Batch: 306 , Combined Loss: tensor(0.5722, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1948490142822266\n",
      "Batch: 307 , Combined Loss: tensor(0.6069, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0310020446777344\n",
      "Batch: 308 , Combined Loss: tensor(0.6767, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7595927715301514\n",
      "Batch: 309 , Combined Loss: tensor(0.5390, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9770036935806274\n",
      "Batch: 310 , Combined Loss: tensor(0.5881, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0892894268035889\n",
      "Batch: 311 , Combined Loss: tensor(0.8972, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8782607316970825\n",
      "Batch: 312 , Combined Loss: tensor(0.9342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6810081005096436\n",
      "Batch: 313 , Combined Loss: tensor(0.5465, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1917319297790527\n",
      "Batch: 314 , Combined Loss: tensor(0.6930, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19460320472717285\n",
      "Batch: 315 , Combined Loss: tensor(0.8153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9355853796005249\n",
      "Batch: 316 , Combined Loss: tensor(0.6596, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5426150560379028\n",
      "Batch: 317 , Combined Loss: tensor(0.7607, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5159008502960205\n",
      "Batch: 318 , Combined Loss: tensor(0.5502, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6354231834411621\n",
      "Batch: 319 , Combined Loss: tensor(0.6004, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1204543113708496\n",
      "Batch: 320 , Combined Loss: tensor(0.6066, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5787115097045898\n",
      "Batch: 321 , Combined Loss: tensor(0.5953, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8214149475097656\n",
      "Batch: 322 , Combined Loss: tensor(0.5379, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8531370162963867\n",
      "Batch: 323 , Combined Loss: tensor(0.6993, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0612001419067383\n",
      "Batch: 324 , Combined Loss: tensor(0.7625, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0860464572906494\n",
      "Batch: 325 , Combined Loss: tensor(0.6133, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7925686836242676\n",
      "Batch: 326 , Combined Loss: tensor(0.6450, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9043699502944946\n",
      "Batch: 327 , Combined Loss: tensor(0.5719, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7314565181732178\n",
      "Batch: 328 , Combined Loss: tensor(0.6610, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8236078023910522\n",
      "Batch: 329 , Combined Loss: tensor(0.8950, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0371952056884766\n",
      "Batch: 330 , Combined Loss: tensor(0.6112, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9743838310241699\n",
      "Batch: 331 , Combined Loss: tensor(0.6742, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0040528774261475\n",
      "Batch: 332 , Combined Loss: tensor(0.5764, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2209205627441406\n",
      "Batch: 333 , Combined Loss: tensor(0.5035, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6634997129440308\n",
      "Batch: 334 , Combined Loss: tensor(0.6623, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7792114019393921\n",
      "Batch: 335 , Combined Loss: tensor(0.5921, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7633854150772095\n",
      "Batch: 336 , Combined Loss: tensor(0.5762, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45750999450683594\n",
      "Batch: 337 , Combined Loss: tensor(0.6847, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0037269592285156\n",
      "Batch: 338 , Combined Loss: tensor(0.6027, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9728109836578369\n",
      "Batch: 339 , Combined Loss: tensor(0.5765, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0992708206176758\n",
      "Batch: 340 , Combined Loss: tensor(0.6423, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9661710262298584\n",
      "Batch: 341 , Combined Loss: tensor(0.5653, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8064603805541992\n",
      "Batch: 342 , Combined Loss: tensor(0.5366, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1632094383239746\n",
      "Batch: 343 , Combined Loss: tensor(0.6672, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8616069555282593\n",
      "Batch: 344 , Combined Loss: tensor(0.5636, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1367278099060059\n",
      "Batch: 345 , Combined Loss: tensor(0.6372, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0354273319244385\n",
      "Batch: 346 , Combined Loss: tensor(0.6021, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8584412336349487\n",
      "Batch: 347 , Combined Loss: tensor(0.5604, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9109510183334351\n",
      "Batch: 348 , Combined Loss: tensor(0.6343, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5478858947753906\n",
      "Batch: 349 , Combined Loss: tensor(0.5467, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9528809785842896\n",
      "Batch: 350 , Combined Loss: tensor(0.6384, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1274387836456299\n",
      "Batch: 351 , Combined Loss: tensor(0.6183, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0530941486358643\n",
      "Batch: 352 , Combined Loss: tensor(0.5414, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.174757719039917\n",
      "Batch: 353 , Combined Loss: tensor(0.5834, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.541452169418335\n",
      "Batch: 354 , Combined Loss: tensor(0.6815, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.003110647201538\n",
      "Batch: 355 , Combined Loss: tensor(0.6796, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1624987125396729\n",
      "Batch: 356 , Combined Loss: tensor(0.5639, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7830315828323364\n",
      "Batch: 357 , Combined Loss: tensor(0.7051, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1022846698760986\n",
      "Batch: 358 , Combined Loss: tensor(0.6636, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.56368088722229\n",
      "Batch: 359 , Combined Loss: tensor(0.6156, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.901871919631958\n",
      "Batch: 360 , Combined Loss: tensor(0.6222, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.077773094177246\n",
      "Batch: 361 , Combined Loss: tensor(0.5926, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0576099157333374\n",
      "Batch: 362 , Combined Loss: tensor(0.6986, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.4377689361572266\n",
      "Batch: 363 , Combined Loss: tensor(0.6026, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0178322792053223\n",
      "Batch: 364 , Combined Loss: tensor(0.5770, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0924224853515625\n",
      "Batch: 365 , Combined Loss: tensor(0.6768, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9710276126861572\n",
      "Batch: 366 , Combined Loss: tensor(0.6272, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8999110460281372\n",
      "Batch: 367 , Combined Loss: tensor(0.5410, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.951622486114502\n",
      "Batch: 368 , Combined Loss: tensor(0.6092, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0847485065460205\n",
      "Batch: 369 , Combined Loss: tensor(0.6284, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9582279920578003\n",
      "Batch: 370 , Combined Loss: tensor(0.7485, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0416059494018555\n",
      "Batch: 371 , Combined Loss: tensor(0.7987, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7047289609909058\n",
      "Batch: 372 , Combined Loss: tensor(0.7201, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0014221668243408\n",
      "Batch: 373 , Combined Loss: tensor(0.5877, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7297799587249756\n",
      "Batch: 374 , Combined Loss: tensor(0.6692, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0116729736328125\n",
      "Batch: 375 , Combined Loss: tensor(0.9111, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7652037143707275\n",
      "Batch: 376 , Combined Loss: tensor(0.6028, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.413252830505371\n",
      "Batch: 377 , Combined Loss: tensor(0.6139, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9457701444625854\n",
      "Batch: 378 , Combined Loss: tensor(0.6079, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0270874500274658\n",
      "Batch: 379 , Combined Loss: tensor(0.9432, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5666204690933228\n",
      "Batch: 380 , Combined Loss: tensor(0.5924, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9799245595932007\n",
      "Batch: 381 , Combined Loss: tensor(0.6459, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9086334705352783\n",
      "Batch: 382 , Combined Loss: tensor(0.7610, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2130420207977295\n",
      "Batch: 383 , Combined Loss: tensor(0.6399, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.824111819267273\n",
      "Batch: 384 , Combined Loss: tensor(0.5464, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.033501148223877\n",
      "Batch: 385 , Combined Loss: tensor(0.6286, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9968353509902954\n",
      "Batch: 386 , Combined Loss: tensor(0.6939, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7709392309188843\n",
      "Batch: 387 , Combined Loss: tensor(0.5278, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5548115968704224\n",
      "Batch: 388 , Combined Loss: tensor(0.6563, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.022146224975586\n",
      "Batch: 389 , Combined Loss: tensor(0.5404, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9806571006774902\n",
      "Batch: 390 , Combined Loss: tensor(0.6640, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2644902467727661\n",
      "Batch: 391 , Combined Loss: tensor(0.8153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5905411243438721\n",
      "Batch: 392 , Combined Loss: tensor(0.5766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1923437118530273\n",
      "Batch: 393 , Combined Loss: tensor(0.5385, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.785942554473877\n",
      "Batch: 394 , Combined Loss: tensor(0.6111, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.10108494758605957\n",
      "Batch: 395 , Combined Loss: tensor(0.7192, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2533538341522217\n",
      "Batch: 396 , Combined Loss: tensor(0.7340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9236056804656982\n",
      "Batch: 397 , Combined Loss: tensor(0.8117, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8336355686187744\n",
      "Batch: 398 , Combined Loss: tensor(0.8520, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.01664566993713379\n",
      "Batch: 399 , Combined Loss: tensor(0.5534, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9472757577896118\n",
      "Batch: 400 , Combined Loss: tensor(0.5558, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1426928043365479\n",
      "Batch: 401 , Combined Loss: tensor(0.7084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.108412265777588\n",
      "Batch: 402 , Combined Loss: tensor(0.6715, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.043360948562622\n",
      "Batch: 403 , Combined Loss: tensor(0.7031, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8302596807479858\n",
      "Batch: 404 , Combined Loss: tensor(0.5853, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3463461399078369\n",
      "Batch: 405 , Combined Loss: tensor(0.6599, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2305676937103271\n",
      "Batch: 406 , Combined Loss: tensor(0.6073, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2737185955047607\n",
      "Batch: 407 , Combined Loss: tensor(0.7303, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9697667360305786\n",
      "Batch: 408 , Combined Loss: tensor(0.5693, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7986564636230469\n",
      "Batch: 409 , Combined Loss: tensor(0.5910, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6986690759658813\n",
      "Batch: 410 , Combined Loss: tensor(0.5749, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9004063606262207\n",
      "Batch: 411 , Combined Loss: tensor(0.6856, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9662326574325562\n",
      "Batch: 412 , Combined Loss: tensor(0.5655, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6134138107299805\n",
      "Batch: 413 , Combined Loss: tensor(0.6142, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0181894302368164\n",
      "Batch: 414 , Combined Loss: tensor(0.6186, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0229525566101074\n",
      "Batch: 415 , Combined Loss: tensor(0.5182, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9601325988769531\n",
      "Batch: 416 , Combined Loss: tensor(0.5338, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0662310123443604\n",
      "Batch: 417 , Combined Loss: tensor(0.4980, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5173919200897217\n",
      "Batch: 418 , Combined Loss: tensor(0.6073, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6353880167007446\n",
      "Batch: 419 , Combined Loss: tensor(0.8262, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8071991205215454\n",
      "Batch: 420 , Combined Loss: tensor(0.8695, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5665757656097412\n",
      "Batch: 421 , Combined Loss: tensor(0.6212, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8218523263931274\n",
      "Batch: 422 , Combined Loss: tensor(0.5816, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3379721641540527\n",
      "Batch: 423 , Combined Loss: tensor(0.5380, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1016716957092285\n",
      "Batch: 424 , Combined Loss: tensor(0.7703, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8034141063690186\n",
      "Batch: 425 , Combined Loss: tensor(0.6238, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.307615041732788\n",
      "Batch: 426 , Combined Loss: tensor(0.6118, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0962755680084229\n",
      "Batch: 427 , Combined Loss: tensor(0.5447, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.206981897354126\n",
      "Batch: 428 , Combined Loss: tensor(0.7207, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5658175945281982\n",
      "Batch: 429 , Combined Loss: tensor(0.5604, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0417075157165527\n",
      "Batch: 430 , Combined Loss: tensor(0.6114, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.099787712097168\n",
      "Batch: 431 , Combined Loss: tensor(0.8173, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4098728895187378\n",
      "Batch: 432 , Combined Loss: tensor(0.6977, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9779171943664551\n",
      "Batch: 433 , Combined Loss: tensor(0.5701, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.069262981414795\n",
      "Batch: 434 , Combined Loss: tensor(0.6007, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6647311449050903\n",
      "Batch: 435 , Combined Loss: tensor(0.6425, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0939054489135742\n",
      "Batch: 436 , Combined Loss: tensor(0.5710, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1802875995635986\n",
      "Batch: 437 , Combined Loss: tensor(0.6295, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0439300537109375\n",
      "Batch: 438 , Combined Loss: tensor(0.6514, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1103401184082031\n",
      "Batch: 439 , Combined Loss: tensor(0.5756, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.042212724685669\n",
      "Batch: 440 , Combined Loss: tensor(0.6329, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6228039264678955\n",
      "Batch: 441 , Combined Loss: tensor(0.7571, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7237544059753418\n",
      "Batch: 442 , Combined Loss: tensor(0.5570, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7545607089996338\n",
      "Batch: 443 , Combined Loss: tensor(0.5771, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9517272710800171\n",
      "Batch: 444 , Combined Loss: tensor(0.6735, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0597338676452637\n",
      "Batch: 445 , Combined Loss: tensor(0.7281, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1746277809143066\n",
      "Batch: 446 , Combined Loss: tensor(0.7019, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1318979263305664\n",
      "Batch: 447 , Combined Loss: tensor(0.7032, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0645122528076172\n",
      "Batch: 448 , Combined Loss: tensor(0.5493, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9017761945724487\n",
      "Batch: 449 , Combined Loss: tensor(0.5678, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2096929550170898\n",
      "Batch: 450 , Combined Loss: tensor(0.6287, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8755384683609009\n",
      "Batch: 451 , Combined Loss: tensor(0.6204, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0122144222259521\n",
      "Batch: 452 , Combined Loss: tensor(0.5859, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0907886028289795\n",
      "Batch: 453 , Combined Loss: tensor(0.5953, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.012364387512207\n",
      "Batch: 454 , Combined Loss: tensor(0.5629, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5026111602783203\n",
      "Batch: 455 , Combined Loss: tensor(0.6257, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1182410717010498\n",
      "Batch: 456 , Combined Loss: tensor(0.6410, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0840702056884766\n",
      "Batch: 457 , Combined Loss: tensor(0.6121, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.209625482559204\n",
      "Batch: 458 , Combined Loss: tensor(0.6153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1718058586120605\n",
      "Batch: 459 , Combined Loss: tensor(0.9340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4376957416534424\n",
      "Batch: 460 , Combined Loss: tensor(0.5795, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1252803802490234\n",
      "Batch: 461 , Combined Loss: tensor(0.5931, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8875956535339355\n",
      "Batch: 462 , Combined Loss: tensor(0.7310, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1143724918365479\n",
      "Batch: 463 , Combined Loss: tensor(0.6445, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1028873920440674\n",
      "Batch: 464 , Combined Loss: tensor(0.6587, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.153242588043213\n",
      "Batch: 465 , Combined Loss: tensor(0.5840, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7324905395507812\n",
      "Batch: 466 , Combined Loss: tensor(0.6678, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6327732801437378\n",
      "Batch: 467 , Combined Loss: tensor(0.6068, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2411837577819824\n",
      "Batch: 468 , Combined Loss: tensor(0.7420, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8556145429611206\n",
      "Batch: 469 , Combined Loss: tensor(0.6294, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8801388740539551\n",
      "Batch: 470 , Combined Loss: tensor(0.6974, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1749324798583984\n",
      "Batch: 471 , Combined Loss: tensor(0.6372, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9960888624191284\n",
      "Batch: 472 , Combined Loss: tensor(0.5963, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9702659845352173\n",
      "Batch: 473 , Combined Loss: tensor(0.6831, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8369234800338745\n",
      "Batch: 474 , Combined Loss: tensor(0.6328, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0564422607421875\n",
      "Batch: 475 , Combined Loss: tensor(0.5302, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4143866300582886\n",
      "Batch: 476 , Combined Loss: tensor(0.6708, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7736573219299316\n",
      "Batch: 477 , Combined Loss: tensor(0.7151, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9632976055145264\n",
      "Batch: 478 , Combined Loss: tensor(0.7850, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1030504703521729\n",
      "Batch: 479 , Combined Loss: tensor(0.5943, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9850916862487793\n",
      "Batch: 480 , Combined Loss: tensor(0.7679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5900299549102783\n",
      "Batch: 481 , Combined Loss: tensor(0.6698, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6342352628707886\n",
      "Batch: 482 , Combined Loss: tensor(0.6601, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6674469709396362\n",
      "Batch: 483 , Combined Loss: tensor(0.6347, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7067474126815796\n",
      "Batch: 484 , Combined Loss: tensor(0.6952, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25780200958251953\n",
      "Batch: 485 , Combined Loss: tensor(0.5593, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.758068323135376\n",
      "Batch: 486 , Combined Loss: tensor(0.9347, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8033965826034546\n",
      "Batch: 487 , Combined Loss: tensor(0.5650, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9743635654449463\n",
      "Batch: 488 , Combined Loss: tensor(0.6144, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6514557600021362\n",
      "Batch: 489 , Combined Loss: tensor(0.5585, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6331055164337158\n",
      "Batch: 490 , Combined Loss: tensor(0.6581, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1470520496368408\n",
      "Batch: 491 , Combined Loss: tensor(0.6427, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5071046352386475\n",
      "Batch: 492 , Combined Loss: tensor(0.6420, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5268927812576294\n",
      "Batch: 493 , Combined Loss: tensor(0.5506, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0474095344543457\n",
      "Batch: 494 , Combined Loss: tensor(0.6557, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9958546161651611\n",
      "Batch: 495 , Combined Loss: tensor(0.7677, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03918564319610596\n",
      "Batch: 496 , Combined Loss: tensor(0.6711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.900118350982666\n",
      "Batch: 497 , Combined Loss: tensor(0.6210, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23135650157928467\n",
      "Batch: 498 , Combined Loss: tensor(0.7803, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.37306153774261475\n",
      "Batch: 499 , Combined Loss: tensor(0.5518, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3038980960845947\n",
      "Batch: 500 , Combined Loss: tensor(0.7967, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7536275386810303\n",
      "Batch: 501 , Combined Loss: tensor(0.6012, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8649476766586304\n",
      "Batch: 502 , Combined Loss: tensor(0.6560, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.703407883644104\n",
      "Batch: 503 , Combined Loss: tensor(0.5470, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9914224147796631\n",
      "Batch: 504 , Combined Loss: tensor(0.6088, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8969557285308838\n",
      "Batch: 505 , Combined Loss: tensor(0.6050, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0396449565887451\n",
      "Batch: 506 , Combined Loss: tensor(0.5846, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3702036142349243\n",
      "Batch: 507 , Combined Loss: tensor(0.6887, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43449831008911133\n",
      "Batch: 508 , Combined Loss: tensor(0.6107, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0591602325439453\n",
      "Batch: 509 , Combined Loss: tensor(0.6078, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0488576889038086\n",
      "Batch: 510 , Combined Loss: tensor(0.6502, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9003658294677734\n",
      "Batch: 511 , Combined Loss: tensor(0.6925, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.667067289352417\n",
      "Batch: 512 , Combined Loss: tensor(0.8216, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47434401512145996\n",
      "Batch: 513 , Combined Loss: tensor(0.5877, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5593891143798828\n",
      "Batch: 514 , Combined Loss: tensor(0.6418, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7849549055099487\n",
      "Batch: 515 , Combined Loss: tensor(0.5281, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8257191181182861\n",
      "Batch: 516 , Combined Loss: tensor(0.6072, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12238550186157227\n",
      "Batch: 517 , Combined Loss: tensor(0.6733, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5246310234069824\n",
      "Batch: 518 , Combined Loss: tensor(0.5615, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9536153078079224\n",
      "Batch: 519 , Combined Loss: tensor(0.5854, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6651461124420166\n",
      "Batch: 520 , Combined Loss: tensor(0.6034, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7896709442138672\n",
      "Batch: 521 , Combined Loss: tensor(0.7108, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7680208683013916\n",
      "Batch: 522 , Combined Loss: tensor(0.6473, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9449412822723389\n",
      "Batch: 523 , Combined Loss: tensor(0.4652, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5921066999435425\n",
      "Batch: 524 , Combined Loss: tensor(0.6476, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6190260648727417\n",
      "Batch: 525 , Combined Loss: tensor(0.7879, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6916203498840332\n",
      "Batch: 526 , Combined Loss: tensor(0.5521, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6830674409866333\n",
      "Batch: 527 , Combined Loss: tensor(0.6801, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9461621046066284\n",
      "Batch: 528 , Combined Loss: tensor(0.6027, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0858218669891357\n",
      "Batch: 529 , Combined Loss: tensor(0.6473, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.066051959991455\n",
      "Batch: 530 , Combined Loss: tensor(0.7119, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1647157669067383\n",
      "Batch: 531 , Combined Loss: tensor(0.5692, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1926932334899902\n",
      "Batch: 532 , Combined Loss: tensor(0.5450, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9547643661499023\n",
      "Batch: 533 , Combined Loss: tensor(0.5843, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8844795227050781\n",
      "Batch: 534 , Combined Loss: tensor(0.6153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0375993251800537\n",
      "Batch: 535 , Combined Loss: tensor(0.7620, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5552934408187866\n",
      "Batch: 536 , Combined Loss: tensor(0.8030, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8300784826278687\n",
      "Batch: 537 , Combined Loss: tensor(0.7730, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5936692953109741\n",
      "Batch: 538 , Combined Loss: tensor(0.5603, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9807270765304565\n",
      "Batch: 539 , Combined Loss: tensor(0.6253, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1355705261230469\n",
      "Batch: 540 , Combined Loss: tensor(0.7829, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0010340213775635\n",
      "Batch: 541 , Combined Loss: tensor(0.6423, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7583532333374023\n",
      "Batch: 542 , Combined Loss: tensor(0.6469, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.218616247177124\n",
      "Batch: 543 , Combined Loss: tensor(0.7937, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6056171655654907\n",
      "Batch: 544 , Combined Loss: tensor(0.7392, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5971786975860596\n",
      "Batch: 545 , Combined Loss: tensor(0.6100, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.000079870223999\n",
      "Batch: 546 , Combined Loss: tensor(0.5227, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1893138885498047\n",
      "Batch: 547 , Combined Loss: tensor(0.6978, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.046144962310791\n",
      "Batch: 548 , Combined Loss: tensor(0.6637, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42152321338653564\n",
      "Batch: 549 , Combined Loss: tensor(0.6196, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7320691347122192\n",
      "Batch: 550 , Combined Loss: tensor(0.7306, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8749566078186035\n",
      "Batch: 551 , Combined Loss: tensor(0.6324, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.846127986907959\n",
      "Batch: 552 , Combined Loss: tensor(0.6505, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1155905723571777\n",
      "Batch: 553 , Combined Loss: tensor(0.5510, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.426310658454895\n",
      "Batch: 554 , Combined Loss: tensor(0.6349, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6331355571746826\n",
      "Batch: 555 , Combined Loss: tensor(0.5584, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5030386447906494\n",
      "Batch: 556 , Combined Loss: tensor(0.6157, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7789671421051025\n",
      "Batch: 557 , Combined Loss: tensor(0.6171, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5107558965682983\n",
      "Batch: 558 , Combined Loss: tensor(0.5306, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8991644382476807\n",
      "Batch: 559 , Combined Loss: tensor(0.6582, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8954693078994751\n",
      "Batch: 560 , Combined Loss: tensor(0.6823, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9505724906921387\n",
      "Batch: 561 , Combined Loss: tensor(0.5443, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7631982564926147\n",
      "Batch: 562 , Combined Loss: tensor(0.7573, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41543030738830566\n",
      "Batch: 563 , Combined Loss: tensor(0.8115, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9507240056991577\n",
      "Batch: 564 , Combined Loss: tensor(0.8040, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8142012357711792\n",
      "Batch: 565 , Combined Loss: tensor(0.8752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32449543476104736\n",
      "Batch: 566 , Combined Loss: tensor(0.5476, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7152613401412964\n",
      "Batch: 567 , Combined Loss: tensor(0.5566, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7837721109390259\n",
      "Batch: 568 , Combined Loss: tensor(0.9025, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2983170747756958\n",
      "Batch: 569 , Combined Loss: tensor(0.5819, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9327192306518555\n",
      "Batch: 570 , Combined Loss: tensor(0.5795, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1136486530303955\n",
      "Batch: 571 , Combined Loss: tensor(0.5231, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8237701654434204\n",
      "Batch: 572 , Combined Loss: tensor(0.7487, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8822532892227173\n",
      "Batch: 573 , Combined Loss: tensor(0.6312, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8417102098464966\n",
      "Batch: 574 , Combined Loss: tensor(0.6074, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6939672231674194\n",
      "Batch: 575 , Combined Loss: tensor(0.6410, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0425660610198975\n",
      "Batch: 576 , Combined Loss: tensor(0.5711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9874089956283569\n",
      "Batch: 577 , Combined Loss: tensor(0.5110, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.035475492477417\n",
      "Batch: 578 , Combined Loss: tensor(0.5434, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8482757806777954\n",
      "Batch: 579 , Combined Loss: tensor(0.5256, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6204465627670288\n",
      "Batch: 580 , Combined Loss: tensor(0.6920, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9210625886917114\n",
      "Batch: 581 , Combined Loss: tensor(0.5741, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.929205060005188\n",
      "Batch: 582 , Combined Loss: tensor(0.6264, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1724076271057129\n",
      "Batch: 583 , Combined Loss: tensor(0.5746, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7723191976547241\n",
      "Batch: 584 , Combined Loss: tensor(0.5830, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8644595146179199\n",
      "Batch: 585 , Combined Loss: tensor(0.7026, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0181784629821777\n",
      "Batch: 586 , Combined Loss: tensor(0.5184, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8752454519271851\n",
      "Batch: 587 , Combined Loss: tensor(0.5609, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.326650857925415\n",
      "Batch: 588 , Combined Loss: tensor(0.5949, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42851996421813965\n",
      "Batch: 589 , Combined Loss: tensor(0.5676, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2678184509277344\n",
      "Batch: 590 , Combined Loss: tensor(0.5584, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2032477855682373\n",
      "Batch: 591 , Combined Loss: tensor(0.6494, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8070138692855835\n",
      "Batch: 592 , Combined Loss: tensor(0.5342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.697361946105957\n",
      "Batch: 593 , Combined Loss: tensor(0.5027, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9482096433639526\n",
      "Batch: 594 , Combined Loss: tensor(0.6104, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1707780361175537\n",
      "Batch: 595 , Combined Loss: tensor(0.6433, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8306001424789429\n",
      "Batch: 596 , Combined Loss: tensor(0.5733, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5954129695892334\n",
      "Batch: 597 , Combined Loss: tensor(0.7028, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2215373516082764\n",
      "Batch: 598 , Combined Loss: tensor(0.5512, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1505787372589111\n",
      "Batch: 599 , Combined Loss: tensor(0.6730, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1175601482391357\n",
      "Batch: 600 , Combined Loss: tensor(0.7259, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0293028354644775\n",
      "Batch: 601 , Combined Loss: tensor(0.7392, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8028244972229004\n",
      "Batch: 602 , Combined Loss: tensor(0.5501, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49417734146118164\n",
      "Batch: 603 , Combined Loss: tensor(0.6674, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0001730918884277\n",
      "Batch: 604 , Combined Loss: tensor(0.5663, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8090289831161499\n",
      "Batch: 605 , Combined Loss: tensor(0.5825, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.118506908416748\n",
      "Batch: 606 , Combined Loss: tensor(0.5191, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7916015386581421\n",
      "Batch: 607 , Combined Loss: tensor(0.6467, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39702069759368896\n",
      "Batch: 608 , Combined Loss: tensor(0.6302, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9918444156646729\n",
      "Batch: 609 , Combined Loss: tensor(0.6863, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7473632097244263\n",
      "Batch: 610 , Combined Loss: tensor(0.7466, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6795598268508911\n",
      "Batch: 611 , Combined Loss: tensor(1.2474, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8938649892807007\n",
      "Batch: 612 , Combined Loss: tensor(0.4691, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8056951761245728\n",
      "Batch: 613 , Combined Loss: tensor(0.5232, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1293861865997314\n",
      "Batch: 614 , Combined Loss: tensor(0.7473, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9084982872009277\n",
      "Batch: 615 , Combined Loss: tensor(0.6782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8710927963256836\n",
      "Batch: 616 , Combined Loss: tensor(0.5859, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.064742088317871\n",
      "Batch: 617 , Combined Loss: tensor(0.5724, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1132571697235107\n",
      "Batch: 618 , Combined Loss: tensor(0.5305, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7376127243041992\n",
      "Batch: 619 , Combined Loss: tensor(0.5974, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6354625225067139\n",
      "Batch: 620 , Combined Loss: tensor(0.6881, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6410077810287476\n",
      "Batch: 621 , Combined Loss: tensor(0.7892, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20187592506408691\n",
      "Batch: 622 , Combined Loss: tensor(0.6714, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0320937633514404\n",
      "Batch: 623 , Combined Loss: tensor(0.5634, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9760078191757202\n",
      "Batch: 624 , Combined Loss: tensor(0.6491, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8361592292785645\n",
      "Batch: 625 , Combined Loss: tensor(0.5938, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8390294313430786\n",
      "Batch: 626 , Combined Loss: tensor(0.6227, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0331919193267822\n",
      "Batch: 627 , Combined Loss: tensor(0.6566, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7622442245483398\n",
      "Batch: 628 , Combined Loss: tensor(0.7189, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1242883205413818\n",
      "----------Epoch 30, Loss: 0.6427525361505335, Accuracy: 0.9779131234355496, Dice Coef: [0.9904780256160681, 0.6557897485664648, 0.6888279345462881, 0.7618897325901923], Dice Coef Necrotic: 1.044885814976974, Dice Coef Edema: 1.0599430258262277, Dice Coef Enhancing: 1.072982922597499, Sensitivity: [0.9831400021839597, 0.7678978026546397, 0.880607458053598, 0.8776170842598277], Specificity: [0.9654971604695949, 0.9980080882960928, 0.9845244652326611, 0.9967696382434644], Precision: [0.997982756890629, 0.6442497482019257, 0.5969343002045687, 0.7119400822205857]\n",
      "-----------Validation Epoch 30, Loss: 0.6467494056859148, Accuracy: 0.9717329139009528, Dice Coef: [0.9872509809808994, 0.6621737630983078, 0.6634401896062794, 0.706475764240296], Dice Coef Necrotic: 0.17478308685013924, Dice Coef Edema: 0.1749678117230221, Dice Coef Enhancing: 0.17715491349824108, Sensitivity: [0.9790871531591503, 0.7114881947636604, 0.7865737579899643, 0.8305513637328367], Specificity: [0.9176109764519909, 0.9983221653404586, 0.9829971418468231, 0.9934944149551042], Precision: [0.9959479160265091, 0.6777574376997735, 0.61127509200655, 0.6922450292206138]\n",
      "Saving without nn.DataParallel\n",
      "Batch: 0 , Combined Loss: tensor(0.9324, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6555646657943726\n",
      "Batch: 1 , Combined Loss: tensor(0.6920, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0167067050933838\n",
      "Batch: 2 , Combined Loss: tensor(0.5915, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6227600574493408\n",
      "Batch: 3 , Combined Loss: tensor(0.6175, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1338984966278076\n",
      "Batch: 4 , Combined Loss: tensor(0.6594, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32178592681884766\n",
      "Batch: 5 , Combined Loss: tensor(0.7017, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8009576797485352\n",
      "Batch: 6 , Combined Loss: tensor(0.6372, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.100135326385498\n",
      "Batch: 7 , Combined Loss: tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0632421970367432\n",
      "Batch: 8 , Combined Loss: tensor(0.5952, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1220252513885498\n",
      "Batch: 9 , Combined Loss: tensor(0.5518, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8835333585739136\n",
      "Batch: 10 , Combined Loss: tensor(0.5586, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0353455543518066\n",
      "Batch: 11 , Combined Loss: tensor(0.6080, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9585959911346436\n",
      "Batch: 12 , Combined Loss: tensor(0.5932, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6290363073348999\n",
      "Batch: 13 , Combined Loss: tensor(0.6347, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8654193878173828\n",
      "Batch: 14 , Combined Loss: tensor(0.5699, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2060754299163818\n",
      "Batch: 15 , Combined Loss: tensor(0.6166, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3672847747802734\n",
      "Batch: 16 , Combined Loss: tensor(0.6020, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8341630697250366\n",
      "Batch: 17 , Combined Loss: tensor(0.5371, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2094414234161377\n",
      "Batch: 18 , Combined Loss: tensor(0.6304, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0159451961517334\n",
      "Batch: 19 , Combined Loss: tensor(0.6272, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0781660079956055\n",
      "Batch: 20 , Combined Loss: tensor(0.5046, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7814937829971313\n",
      "Batch: 21 , Combined Loss: tensor(0.8064, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.859205961227417\n",
      "Batch: 22 , Combined Loss: tensor(0.7452, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9051741361618042\n",
      "Batch: 23 , Combined Loss: tensor(0.5876, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1999411582946777\n",
      "Batch: 24 , Combined Loss: tensor(0.6493, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2109105587005615\n",
      "Batch: 25 , Combined Loss: tensor(0.6404, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0498864650726318\n",
      "Batch: 26 , Combined Loss: tensor(0.6993, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0104296207427979\n",
      "Batch: 27 , Combined Loss: tensor(0.6573, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36582911014556885\n",
      "Batch: 28 , Combined Loss: tensor(0.7338, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.324748158454895\n",
      "Batch: 29 , Combined Loss: tensor(1.0150, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.653448224067688\n",
      "Batch: 30 , Combined Loss: tensor(0.6201, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6265490055084229\n",
      "Batch: 31 , Combined Loss: tensor(0.5990, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9533766508102417\n",
      "Batch: 32 , Combined Loss: tensor(0.8122, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38910841941833496\n",
      "Batch: 33 , Combined Loss: tensor(0.6138, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8223713636398315\n",
      "Batch: 34 , Combined Loss: tensor(0.5594, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6346637010574341\n",
      "Batch: 35 , Combined Loss: tensor(0.6540, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8229962587356567\n",
      "Batch: 36 , Combined Loss: tensor(0.7188, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.152862310409546\n",
      "Batch: 37 , Combined Loss: tensor(0.5541, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0787262916564941\n",
      "Batch: 38 , Combined Loss: tensor(0.6948, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7927347421646118\n",
      "Batch: 39 , Combined Loss: tensor(0.5683, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7586907148361206\n",
      "Batch: 40 , Combined Loss: tensor(0.5896, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6359905004501343\n",
      "Batch: 41 , Combined Loss: tensor(0.5728, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2982889413833618\n",
      "Batch: 42 , Combined Loss: tensor(0.6671, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1367814540863037\n",
      "Batch: 43 , Combined Loss: tensor(0.6278, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.831360936164856\n",
      "Batch: 44 , Combined Loss: tensor(0.6704, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0943522453308105\n",
      "Batch: 45 , Combined Loss: tensor(0.6276, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8849654197692871\n",
      "Batch: 46 , Combined Loss: tensor(0.5922, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5975699424743652\n",
      "Batch: 47 , Combined Loss: tensor(0.7073, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7959367036819458\n",
      "Batch: 48 , Combined Loss: tensor(0.6132, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0645170211791992\n",
      "Batch: 49 , Combined Loss: tensor(0.6987, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6769567728042603\n",
      "Batch: 50 , Combined Loss: tensor(0.5631, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1308200359344482\n",
      "Batch: 51 , Combined Loss: tensor(0.5570, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8323596715927124\n",
      "Batch: 52 , Combined Loss: tensor(0.5693, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33000099658966064\n",
      "Batch: 53 , Combined Loss: tensor(0.5942, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9713255167007446\n",
      "Batch: 54 , Combined Loss: tensor(0.6202, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0082142353057861\n",
      "Batch: 55 , Combined Loss: tensor(0.6248, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0832042694091797\n",
      "Batch: 56 , Combined Loss: tensor(0.6455, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8154072761535645\n",
      "Batch: 57 , Combined Loss: tensor(0.6323, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35417330265045166\n",
      "Batch: 58 , Combined Loss: tensor(0.5780, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1393797397613525\n",
      "Batch: 59 , Combined Loss: tensor(0.7813, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.720120906829834\n",
      "Batch: 60 , Combined Loss: tensor(0.6107, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9191995859146118\n",
      "Batch: 61 , Combined Loss: tensor(0.7167, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0726027488708496\n",
      "Batch: 62 , Combined Loss: tensor(0.5194, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6872690916061401\n",
      "Batch: 63 , Combined Loss: tensor(0.6078, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.50154709815979\n",
      "Batch: 64 , Combined Loss: tensor(0.5489, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.932748556137085\n",
      "Batch: 65 , Combined Loss: tensor(0.5721, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8336050510406494\n",
      "Batch: 66 , Combined Loss: tensor(0.7201, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1654763221740723\n",
      "Batch: 67 , Combined Loss: tensor(0.6627, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9687185287475586\n",
      "Batch: 68 , Combined Loss: tensor(0.6425, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0565667152404785\n",
      "Batch: 69 , Combined Loss: tensor(0.5922, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8319776058197021\n",
      "Batch: 70 , Combined Loss: tensor(0.7221, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7494775056838989\n",
      "Batch: 71 , Combined Loss: tensor(0.5670, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5809565782546997\n",
      "Batch: 72 , Combined Loss: tensor(0.7978, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.4893674850463867\n",
      "Batch: 73 , Combined Loss: tensor(0.7120, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4798409938812256\n",
      "Batch: 74 , Combined Loss: tensor(0.6639, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7227033376693726\n",
      "Batch: 75 , Combined Loss: tensor(0.5897, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0685431957244873\n",
      "Batch: 76 , Combined Loss: tensor(0.5882, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5916448831558228\n",
      "Batch: 77 , Combined Loss: tensor(0.5903, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5772863626480103\n",
      "Batch: 78 , Combined Loss: tensor(0.6245, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0305497646331787\n",
      "Batch: 79 , Combined Loss: tensor(1.0241, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2795383930206299\n",
      "Batch: 80 , Combined Loss: tensor(0.6463, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7865196466445923\n",
      "Batch: 81 , Combined Loss: tensor(0.7178, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6058444976806641\n",
      "Batch: 82 , Combined Loss: tensor(0.8238, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6338098049163818\n",
      "Batch: 83 , Combined Loss: tensor(0.6158, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7931417226791382\n",
      "Batch: 84 , Combined Loss: tensor(0.5909, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9928009510040283\n",
      "Batch: 85 , Combined Loss: tensor(0.5673, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9129937887191772\n",
      "Batch: 86 , Combined Loss: tensor(0.6635, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7422020435333252\n",
      "Batch: 87 , Combined Loss: tensor(0.4738, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44219720363616943\n",
      "Batch: 88 , Combined Loss: tensor(0.6602, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5719209909439087\n",
      "Batch: 89 , Combined Loss: tensor(0.6452, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.720718264579773\n",
      "Batch: 90 , Combined Loss: tensor(0.5930, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8062242269515991\n",
      "Batch: 91 , Combined Loss: tensor(0.6103, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5685276985168457\n",
      "Batch: 92 , Combined Loss: tensor(0.6174, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2494480013847351\n",
      "Batch: 93 , Combined Loss: tensor(0.5172, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8329054117202759\n",
      "Batch: 94 , Combined Loss: tensor(0.6225, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8591281175613403\n",
      "Batch: 95 , Combined Loss: tensor(0.5146, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6865373849868774\n",
      "Batch: 96 , Combined Loss: tensor(0.6456, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.817197322845459\n",
      "Batch: 97 , Combined Loss: tensor(0.6140, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.021204948425293\n",
      "Batch: 98 , Combined Loss: tensor(0.6859, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8371376991271973\n",
      "Batch: 99 , Combined Loss: tensor(0.6167, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9146665334701538\n",
      "Batch: 100 , Combined Loss: tensor(0.6372, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4423556327819824\n",
      "Batch: 101 , Combined Loss: tensor(0.6922, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6044487953186035\n",
      "Batch: 102 , Combined Loss: tensor(0.5604, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0687010288238525\n",
      "Batch: 103 , Combined Loss: tensor(0.6075, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.603591799736023\n",
      "Batch: 104 , Combined Loss: tensor(0.6575, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9594736099243164\n",
      "Batch: 105 , Combined Loss: tensor(0.5783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6261420249938965\n",
      "Batch: 106 , Combined Loss: tensor(0.7531, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21806848049163818\n",
      "Batch: 107 , Combined Loss: tensor(0.6241, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19273245334625244\n",
      "Batch: 108 , Combined Loss: tensor(0.5895, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4753354787826538\n",
      "Batch: 109 , Combined Loss: tensor(0.5788, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2298346757888794\n",
      "Batch: 110 , Combined Loss: tensor(0.8214, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5464391708374023\n",
      "Batch: 111 , Combined Loss: tensor(0.5419, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8410183191299438\n",
      "Batch: 112 , Combined Loss: tensor(0.7881, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48070061206817627\n",
      "Batch: 113 , Combined Loss: tensor(0.5349, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.150470495223999\n",
      "Batch: 114 , Combined Loss: tensor(0.5892, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8634766340255737\n",
      "Batch: 115 , Combined Loss: tensor(0.7374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1051323413848877\n",
      "Batch: 116 , Combined Loss: tensor(0.5346, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6841698884963989\n",
      "Batch: 117 , Combined Loss: tensor(0.5817, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7755519151687622\n",
      "Batch: 118 , Combined Loss: tensor(0.5809, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0711448192596436\n",
      "Batch: 119 , Combined Loss: tensor(0.5644, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1409518718719482\n",
      "Batch: 120 , Combined Loss: tensor(0.5387, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1572327613830566\n",
      "Batch: 121 , Combined Loss: tensor(0.5331, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.4179580211639404\n",
      "Batch: 122 , Combined Loss: tensor(0.8847, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0947396755218506\n",
      "Batch: 123 , Combined Loss: tensor(0.6321, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9302682876586914\n",
      "Batch: 124 , Combined Loss: tensor(0.6235, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7315011024475098\n",
      "Batch: 125 , Combined Loss: tensor(0.5396, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.074676513671875\n",
      "Batch: 126 , Combined Loss: tensor(0.5537, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.024409532546997\n",
      "Batch: 127 , Combined Loss: tensor(0.5305, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2380611896514893\n",
      "Batch: 128 , Combined Loss: tensor(0.6587, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29611706733703613\n",
      "Batch: 129 , Combined Loss: tensor(0.5171, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9444446563720703\n",
      "Batch: 130 , Combined Loss: tensor(0.6856, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5419481992721558\n",
      "Batch: 131 , Combined Loss: tensor(0.6650, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9907773733139038\n",
      "Batch: 132 , Combined Loss: tensor(1.0244, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5318715572357178\n",
      "Batch: 133 , Combined Loss: tensor(0.5913, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1048636436462402\n",
      "Batch: 134 , Combined Loss: tensor(0.7887, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6264761686325073\n",
      "Batch: 135 , Combined Loss: tensor(0.7000, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.044182300567627\n",
      "Batch: 136 , Combined Loss: tensor(0.5652, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0120904445648193\n",
      "Batch: 137 , Combined Loss: tensor(0.7536, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.02721339464187622\n",
      "Batch: 138 , Combined Loss: tensor(0.8421, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9093754291534424\n",
      "Batch: 139 , Combined Loss: tensor(0.5924, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6317766904830933\n",
      "Batch: 140 , Combined Loss: tensor(0.5431, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5188627243041992\n",
      "Batch: 141 , Combined Loss: tensor(0.5692, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0034844875335693\n",
      "Batch: 142 , Combined Loss: tensor(0.6895, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0851500034332275\n",
      "Batch: 143 , Combined Loss: tensor(0.6690, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4724849462509155\n",
      "Batch: 144 , Combined Loss: tensor(0.6550, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9875047206878662\n",
      "Batch: 145 , Combined Loss: tensor(0.5134, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9240237474441528\n",
      "Batch: 146 , Combined Loss: tensor(0.5959, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5931156873703003\n",
      "Batch: 147 , Combined Loss: tensor(0.5903, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0256917476654053\n",
      "Batch: 148 , Combined Loss: tensor(0.5986, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0833957195281982\n",
      "Batch: 149 , Combined Loss: tensor(0.5630, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.957787275314331\n",
      "Batch: 150 , Combined Loss: tensor(1.0301, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8122578859329224\n",
      "Batch: 151 , Combined Loss: tensor(0.6269, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0136096477508545\n",
      "Batch: 152 , Combined Loss: tensor(0.8109, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.011993646621704\n",
      "Batch: 153 , Combined Loss: tensor(0.7651, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6660302877426147\n",
      "Batch: 154 , Combined Loss: tensor(0.5767, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9098924398422241\n",
      "Batch: 155 , Combined Loss: tensor(0.5265, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5127195119857788\n",
      "Batch: 156 , Combined Loss: tensor(0.6305, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7283004522323608\n",
      "Batch: 157 , Combined Loss: tensor(0.5725, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0415115356445312\n",
      "Batch: 158 , Combined Loss: tensor(0.6521, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0661227703094482\n",
      "Batch: 159 , Combined Loss: tensor(0.5874, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0734837055206299\n",
      "Batch: 160 , Combined Loss: tensor(0.5340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8967568874359131\n",
      "Batch: 161 , Combined Loss: tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8096762895584106\n",
      "Batch: 162 , Combined Loss: tensor(0.5375, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9013539552688599\n",
      "Batch: 163 , Combined Loss: tensor(0.7486, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7025364637374878\n",
      "Batch: 164 , Combined Loss: tensor(0.5719, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23490941524505615\n",
      "Batch: 165 , Combined Loss: tensor(0.6155, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.917360782623291\n",
      "Batch: 166 , Combined Loss: tensor(0.5679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8853031396865845\n",
      "Batch: 167 , Combined Loss: tensor(0.5697, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7006295919418335\n",
      "Batch: 168 , Combined Loss: tensor(0.6068, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7140653133392334\n",
      "Batch: 169 , Combined Loss: tensor(0.7121, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5686072111129761\n",
      "Batch: 170 , Combined Loss: tensor(0.5924, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7386573553085327\n",
      "Batch: 171 , Combined Loss: tensor(0.6881, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9034593105316162\n",
      "Batch: 172 , Combined Loss: tensor(0.5994, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.854302167892456\n",
      "Batch: 173 , Combined Loss: tensor(0.5676, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9832470417022705\n",
      "Batch: 174 , Combined Loss: tensor(0.5614, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6508766412734985\n",
      "Batch: 175 , Combined Loss: tensor(0.5564, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47141122817993164\n",
      "Batch: 176 , Combined Loss: tensor(0.8052, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8311301469802856\n",
      "Batch: 177 , Combined Loss: tensor(0.6047, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1338186264038086\n",
      "Batch: 178 , Combined Loss: tensor(0.6696, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.127272367477417\n",
      "Batch: 179 , Combined Loss: tensor(0.6162, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9088965654373169\n",
      "Batch: 180 , Combined Loss: tensor(0.6940, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9852105379104614\n",
      "Batch: 181 , Combined Loss: tensor(0.5351, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.026003360748291\n",
      "Batch: 182 , Combined Loss: tensor(0.5368, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0165071487426758\n",
      "Batch: 183 , Combined Loss: tensor(0.5667, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37510883808135986\n",
      "Batch: 184 , Combined Loss: tensor(0.6497, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7304264307022095\n",
      "Batch: 185 , Combined Loss: tensor(0.5968, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0895709991455078\n",
      "Batch: 186 , Combined Loss: tensor(0.6180, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04229474067687988\n",
      "Batch: 187 , Combined Loss: tensor(0.5987, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6633507013320923\n",
      "Batch: 188 , Combined Loss: tensor(0.9004, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.624190092086792\n",
      "Batch: 189 , Combined Loss: tensor(0.8576, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5262734889984131\n",
      "Batch: 190 , Combined Loss: tensor(0.4754, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7724541425704956\n",
      "Batch: 191 , Combined Loss: tensor(0.7079, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9943077564239502\n",
      "Batch: 192 , Combined Loss: tensor(0.6931, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5331460237503052\n",
      "Batch: 193 , Combined Loss: tensor(0.5526, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7640019655227661\n",
      "Batch: 194 , Combined Loss: tensor(0.7675, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0805644989013672\n",
      "Batch: 195 , Combined Loss: tensor(0.7539, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9270401000976562\n",
      "Batch: 196 , Combined Loss: tensor(0.6417, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1280152797698975\n",
      "Batch: 197 , Combined Loss: tensor(0.5911, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5634433031082153\n",
      "Batch: 198 , Combined Loss: tensor(0.6197, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1156260967254639\n",
      "Batch: 199 , Combined Loss: tensor(0.7357, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7047914266586304\n",
      "Batch: 200 , Combined Loss: tensor(0.6874, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14314234256744385\n",
      "Batch: 201 , Combined Loss: tensor(0.7181, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1130180358886719\n",
      "Batch: 202 , Combined Loss: tensor(0.5121, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.018451452255249\n",
      "Batch: 203 , Combined Loss: tensor(0.5238, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0071659088134766\n",
      "Batch: 204 , Combined Loss: tensor(0.6003, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2205021381378174\n",
      "Batch: 205 , Combined Loss: tensor(0.6907, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8115912675857544\n",
      "Batch: 206 , Combined Loss: tensor(0.7000, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9237844944000244\n",
      "Batch: 207 , Combined Loss: tensor(0.5720, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9897099733352661\n",
      "Batch: 208 , Combined Loss: tensor(0.7063, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2999460697174072\n",
      "Batch: 209 , Combined Loss: tensor(0.6268, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1103665828704834\n",
      "Batch: 210 , Combined Loss: tensor(0.6268, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9215716123580933\n",
      "Batch: 211 , Combined Loss: tensor(0.6450, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.36717677116394043\n",
      "Batch: 212 , Combined Loss: tensor(0.6893, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8332395553588867\n",
      "Batch: 213 , Combined Loss: tensor(0.5732, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0365018844604492\n",
      "Batch: 214 , Combined Loss: tensor(0.7945, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9666392803192139\n",
      "Batch: 215 , Combined Loss: tensor(0.5182, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9681375026702881\n",
      "Batch: 216 , Combined Loss: tensor(0.5741, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1345057487487793\n",
      "Batch: 217 , Combined Loss: tensor(0.6782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8153880834579468\n",
      "Batch: 218 , Combined Loss: tensor(0.5504, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.665824294090271\n",
      "Batch: 219 , Combined Loss: tensor(0.5723, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0312273502349854\n",
      "Batch: 220 , Combined Loss: tensor(0.6564, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8729081153869629\n",
      "Batch: 221 , Combined Loss: tensor(0.6276, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2767736911773682\n",
      "Batch: 222 , Combined Loss: tensor(0.6853, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3262209892272949\n",
      "Batch: 223 , Combined Loss: tensor(0.5775, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9620473384857178\n",
      "Batch: 224 , Combined Loss: tensor(0.5332, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1057307720184326\n",
      "Batch: 225 , Combined Loss: tensor(0.5772, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0440881252288818\n",
      "Batch: 226 , Combined Loss: tensor(0.5914, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7811810970306396\n",
      "Batch: 227 , Combined Loss: tensor(0.5808, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2449538707733154\n",
      "Batch: 228 , Combined Loss: tensor(0.8202, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5338478088378906\n",
      "Batch: 229 , Combined Loss: tensor(0.5469, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0781772136688232\n",
      "Batch: 230 , Combined Loss: tensor(0.5071, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5515420436859131\n",
      "Batch: 231 , Combined Loss: tensor(0.6616, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8662693500518799\n",
      "Batch: 232 , Combined Loss: tensor(0.6671, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8169174194335938\n",
      "Batch: 233 , Combined Loss: tensor(0.6145, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.140949010848999\n",
      "Batch: 234 , Combined Loss: tensor(0.5192, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.901342511177063\n",
      "Batch: 235 , Combined Loss: tensor(0.5867, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0911641120910645\n",
      "Batch: 236 , Combined Loss: tensor(0.6285, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1070401668548584\n",
      "Batch: 237 , Combined Loss: tensor(0.5482, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7913706302642822\n",
      "Batch: 238 , Combined Loss: tensor(0.5509, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.092844009399414\n",
      "Batch: 239 , Combined Loss: tensor(0.6218, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23093461990356445\n",
      "Batch: 240 , Combined Loss: tensor(0.6256, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0663399696350098\n",
      "Batch: 241 , Combined Loss: tensor(0.5411, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0342662334442139\n",
      "Batch: 242 , Combined Loss: tensor(0.6285, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5461385250091553\n",
      "Batch: 243 , Combined Loss: tensor(0.5657, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0052471160888672\n",
      "Batch: 244 , Combined Loss: tensor(0.7891, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.52945876121521\n",
      "Batch: 245 , Combined Loss: tensor(0.6063, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0110630989074707\n",
      "Batch: 246 , Combined Loss: tensor(0.6227, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2053813934326172\n",
      "Batch: 247 , Combined Loss: tensor(0.5697, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8153258562088013\n",
      "Batch: 248 , Combined Loss: tensor(0.5738, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.081456184387207\n",
      "Batch: 249 , Combined Loss: tensor(0.6387, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.000748872756958\n",
      "Batch: 250 , Combined Loss: tensor(0.5117, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8619890213012695\n",
      "Batch: 251 , Combined Loss: tensor(0.5493, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0283503532409668\n",
      "Batch: 252 , Combined Loss: tensor(0.6026, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.074951410293579\n",
      "Batch: 253 , Combined Loss: tensor(0.9844, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9636785984039307\n",
      "Batch: 254 , Combined Loss: tensor(0.9624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7822600603103638\n",
      "Batch: 255 , Combined Loss: tensor(0.5136, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3699384927749634\n",
      "Batch: 256 , Combined Loss: tensor(0.7485, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0798892974853516\n",
      "Batch: 257 , Combined Loss: tensor(0.5246, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.105483055114746\n",
      "Batch: 258 , Combined Loss: tensor(0.6297, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0815935134887695\n",
      "Batch: 259 , Combined Loss: tensor(0.6595, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0048589706420898\n",
      "Batch: 260 , Combined Loss: tensor(0.6571, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7249819040298462\n",
      "Batch: 261 , Combined Loss: tensor(0.6105, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.16682112216949463\n",
      "Batch: 262 , Combined Loss: tensor(0.9037, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8118234872817993\n",
      "Batch: 263 , Combined Loss: tensor(0.5618, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1042547225952148\n",
      "Batch: 264 , Combined Loss: tensor(0.5835, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9500495195388794\n",
      "Batch: 265 , Combined Loss: tensor(0.5317, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8377739191055298\n",
      "Batch: 266 , Combined Loss: tensor(0.8975, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.011081576347351074\n",
      "Batch: 267 , Combined Loss: tensor(0.5691, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8387829065322876\n",
      "Batch: 268 , Combined Loss: tensor(0.6706, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.019465446472168\n",
      "Batch: 269 , Combined Loss: tensor(0.6940, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6976925134658813\n",
      "Batch: 270 , Combined Loss: tensor(0.8551, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1998717784881592\n",
      "Batch: 271 , Combined Loss: tensor(0.7588, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9204744100570679\n",
      "Batch: 272 , Combined Loss: tensor(0.6892, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1012670993804932\n",
      "Batch: 273 , Combined Loss: tensor(0.6296, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7253408432006836\n",
      "Batch: 274 , Combined Loss: tensor(0.6744, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1688458919525146\n",
      "Batch: 275 , Combined Loss: tensor(0.5549, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9970587491989136\n",
      "Batch: 276 , Combined Loss: tensor(0.5923, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8303250074386597\n",
      "Batch: 277 , Combined Loss: tensor(0.5533, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.823807954788208\n",
      "Batch: 278 , Combined Loss: tensor(0.6119, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1008414626121521\n",
      "Batch: 279 , Combined Loss: tensor(0.7641, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7921137809753418\n",
      "Batch: 280 , Combined Loss: tensor(0.6063, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3722844123840332\n",
      "Batch: 281 , Combined Loss: tensor(0.7251, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43095362186431885\n",
      "Batch: 282 , Combined Loss: tensor(0.6370, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8184447288513184\n",
      "Batch: 283 , Combined Loss: tensor(0.6121, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.03676438331604\n",
      "Batch: 284 , Combined Loss: tensor(0.6353, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6781914234161377\n",
      "Batch: 285 , Combined Loss: tensor(0.5641, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1287484169006348\n",
      "Batch: 286 , Combined Loss: tensor(0.6864, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8229224681854248\n",
      "Batch: 287 , Combined Loss: tensor(0.6827, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7467149496078491\n",
      "Batch: 288 , Combined Loss: tensor(0.5435, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7555931806564331\n",
      "Batch: 289 , Combined Loss: tensor(0.7641, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.009814739227295\n",
      "Batch: 290 , Combined Loss: tensor(0.5337, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8926123380661011\n",
      "Batch: 291 , Combined Loss: tensor(0.6170, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9435163736343384\n",
      "Batch: 292 , Combined Loss: tensor(0.7463, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6222249269485474\n",
      "Batch: 293 , Combined Loss: tensor(0.5446, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6897870302200317\n",
      "Batch: 294 , Combined Loss: tensor(0.6934, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6692395210266113\n",
      "Batch: 295 , Combined Loss: tensor(0.6464, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6789810657501221\n",
      "Batch: 296 , Combined Loss: tensor(0.5512, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48247385025024414\n",
      "Batch: 297 , Combined Loss: tensor(0.6108, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3272005319595337\n",
      "Batch: 298 , Combined Loss: tensor(0.6276, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7504422664642334\n",
      "Batch: 299 , Combined Loss: tensor(0.6803, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4671231508255005\n",
      "Batch: 300 , Combined Loss: tensor(0.6306, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3723320960998535\n",
      "Batch: 301 , Combined Loss: tensor(0.7426, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34187161922454834\n",
      "Batch: 302 , Combined Loss: tensor(0.6573, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8234752416610718\n",
      "Batch: 303 , Combined Loss: tensor(0.6958, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6404726505279541\n",
      "Batch: 304 , Combined Loss: tensor(0.6024, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.974581241607666\n",
      "Batch: 305 , Combined Loss: tensor(0.6305, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.005112886428833\n",
      "Batch: 306 , Combined Loss: tensor(0.6633, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0005643367767334\n",
      "Batch: 307 , Combined Loss: tensor(0.6005, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7463831901550293\n",
      "Batch: 308 , Combined Loss: tensor(0.5614, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.728509783744812\n",
      "Batch: 309 , Combined Loss: tensor(0.6323, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3176349401473999\n",
      "Batch: 310 , Combined Loss: tensor(0.6177, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.633947491645813\n",
      "Batch: 311 , Combined Loss: tensor(0.7094, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9347231388092041\n",
      "Batch: 312 , Combined Loss: tensor(0.8093, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9768409729003906\n",
      "Batch: 313 , Combined Loss: tensor(0.5675, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.836564302444458\n",
      "Batch: 314 , Combined Loss: tensor(0.8437, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4294896125793457\n",
      "Batch: 315 , Combined Loss: tensor(0.6489, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7074042558670044\n",
      "Batch: 316 , Combined Loss: tensor(0.6527, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2217346429824829\n",
      "Batch: 317 , Combined Loss: tensor(0.6444, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0472326278686523\n",
      "Batch: 318 , Combined Loss: tensor(0.5924, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0800433158874512\n",
      "Batch: 319 , Combined Loss: tensor(0.8875, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3510863780975342\n",
      "Batch: 320 , Combined Loss: tensor(0.6191, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0097391605377197\n",
      "Batch: 321 , Combined Loss: tensor(1.0675, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1666320562362671\n",
      "Batch: 322 , Combined Loss: tensor(0.6233, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6349256038665771\n",
      "Batch: 323 , Combined Loss: tensor(0.8178, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7823383808135986\n",
      "Batch: 324 , Combined Loss: tensor(0.9101, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.870110034942627\n",
      "Batch: 325 , Combined Loss: tensor(0.7332, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7235599756240845\n",
      "Batch: 326 , Combined Loss: tensor(0.9044, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12185430526733398\n",
      "Batch: 327 , Combined Loss: tensor(0.7516, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6710795164108276\n",
      "Batch: 328 , Combined Loss: tensor(0.7629, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9416369199752808\n",
      "Batch: 329 , Combined Loss: tensor(0.6416, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6769475936889648\n",
      "Batch: 330 , Combined Loss: tensor(0.5883, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5900144577026367\n",
      "Batch: 331 , Combined Loss: tensor(0.7237, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.028400182723999\n",
      "Batch: 332 , Combined Loss: tensor(0.6264, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1019282341003418\n",
      "Batch: 333 , Combined Loss: tensor(0.6366, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7035706043243408\n",
      "Batch: 334 , Combined Loss: tensor(0.6631, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9319690465927124\n",
      "Batch: 335 , Combined Loss: tensor(0.6093, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6359239816665649\n",
      "Batch: 336 , Combined Loss: tensor(0.5797, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8109791278839111\n",
      "Batch: 337 , Combined Loss: tensor(0.6108, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6682162284851074\n",
      "Batch: 338 , Combined Loss: tensor(0.6218, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.610864520072937\n",
      "Batch: 339 , Combined Loss: tensor(0.6313, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9017561674118042\n",
      "Batch: 340 , Combined Loss: tensor(0.5853, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2688779830932617\n",
      "Batch: 341 , Combined Loss: tensor(0.6117, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12910878658294678\n",
      "Batch: 342 , Combined Loss: tensor(0.7090, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48347222805023193\n",
      "Batch: 343 , Combined Loss: tensor(0.6188, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4448636770248413\n",
      "Batch: 344 , Combined Loss: tensor(0.6450, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.905893087387085\n",
      "Batch: 345 , Combined Loss: tensor(0.6697, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8051793575286865\n",
      "Batch: 346 , Combined Loss: tensor(0.5595, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8497998714447021\n",
      "Batch: 347 , Combined Loss: tensor(0.6162, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7149927616119385\n",
      "Batch: 348 , Combined Loss: tensor(0.6116, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.179964542388916\n",
      "Batch: 349 , Combined Loss: tensor(0.6587, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5847704410552979\n",
      "Batch: 350 , Combined Loss: tensor(0.6412, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0276813507080078\n",
      "Batch: 351 , Combined Loss: tensor(0.7980, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7025730609893799\n",
      "Batch: 352 , Combined Loss: tensor(0.5683, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7900028228759766\n",
      "Batch: 353 , Combined Loss: tensor(0.6227, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7515525817871094\n",
      "Batch: 354 , Combined Loss: tensor(0.5994, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5486736297607422\n",
      "Batch: 355 , Combined Loss: tensor(0.5438, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5662410259246826\n",
      "Batch: 356 , Combined Loss: tensor(0.7053, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39025652408599854\n",
      "Batch: 357 , Combined Loss: tensor(0.5816, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8497052192687988\n",
      "Batch: 358 , Combined Loss: tensor(0.7199, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7877187728881836\n",
      "Batch: 359 , Combined Loss: tensor(0.5967, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1252925395965576\n",
      "Batch: 360 , Combined Loss: tensor(0.6785, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3559771776199341\n",
      "Batch: 361 , Combined Loss: tensor(0.6598, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7510145902633667\n",
      "Batch: 362 , Combined Loss: tensor(0.5662, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9266179800033569\n",
      "Batch: 363 , Combined Loss: tensor(0.6093, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0230135917663574\n",
      "Batch: 364 , Combined Loss: tensor(0.6973, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9413975477218628\n",
      "Batch: 365 , Combined Loss: tensor(0.6185, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8891191482543945\n",
      "Batch: 366 , Combined Loss: tensor(0.5518, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9862498044967651\n",
      "Batch: 367 , Combined Loss: tensor(0.5229, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.750016450881958\n",
      "Batch: 368 , Combined Loss: tensor(0.6901, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8875274658203125\n",
      "Batch: 369 , Combined Loss: tensor(0.5444, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3673027753829956\n",
      "Batch: 370 , Combined Loss: tensor(0.5947, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8468233346939087\n",
      "Batch: 371 , Combined Loss: tensor(0.6414, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.713039755821228\n",
      "Batch: 372 , Combined Loss: tensor(0.8625, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.751596212387085\n",
      "Batch: 373 , Combined Loss: tensor(0.6666, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9758238792419434\n",
      "Batch: 374 , Combined Loss: tensor(0.5784, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.66504967212677\n",
      "Batch: 375 , Combined Loss: tensor(0.6077, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.202536940574646\n",
      "Batch: 376 , Combined Loss: tensor(0.5864, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8429991006851196\n",
      "Batch: 377 , Combined Loss: tensor(0.5652, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6923662424087524\n",
      "Batch: 378 , Combined Loss: tensor(0.6501, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.03942513465881348\n",
      "Batch: 379 , Combined Loss: tensor(0.5693, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8098998069763184\n",
      "Batch: 380 , Combined Loss: tensor(0.5631, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0605344772338867\n",
      "Batch: 381 , Combined Loss: tensor(0.6025, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.739094614982605\n",
      "Batch: 382 , Combined Loss: tensor(0.5090, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8596528768539429\n",
      "Batch: 383 , Combined Loss: tensor(0.6755, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6250828504562378\n",
      "Batch: 384 , Combined Loss: tensor(0.7073, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8775060176849365\n",
      "Batch: 385 , Combined Loss: tensor(0.8545, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6880275011062622\n",
      "Batch: 386 , Combined Loss: tensor(0.7031, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7865360975265503\n",
      "Batch: 387 , Combined Loss: tensor(0.6043, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.542998194694519\n",
      "Batch: 388 , Combined Loss: tensor(0.6587, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6255090236663818\n",
      "Batch: 389 , Combined Loss: tensor(0.6398, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9460668563842773\n",
      "Batch: 390 , Combined Loss: tensor(0.5080, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9499285221099854\n",
      "Batch: 391 , Combined Loss: tensor(0.6176, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7092152833938599\n",
      "Batch: 392 , Combined Loss: tensor(0.6004, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.02152681350708\n",
      "Batch: 393 , Combined Loss: tensor(0.7861, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5872045755386353\n",
      "Batch: 394 , Combined Loss: tensor(0.5995, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8439954519271851\n",
      "Batch: 395 , Combined Loss: tensor(0.6810, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5043618679046631\n",
      "Batch: 396 , Combined Loss: tensor(0.5383, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9586325883865356\n",
      "Batch: 397 , Combined Loss: tensor(0.6692, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4177849292755127\n",
      "Batch: 398 , Combined Loss: tensor(0.5888, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20075058937072754\n",
      "Batch: 399 , Combined Loss: tensor(0.6519, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0775301456451416\n",
      "Batch: 400 , Combined Loss: tensor(0.5343, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1194818019866943\n",
      "Batch: 401 , Combined Loss: tensor(0.5995, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0264809131622314\n",
      "Batch: 402 , Combined Loss: tensor(0.7450, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6508524417877197\n",
      "Batch: 403 , Combined Loss: tensor(0.6203, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7493647336959839\n",
      "Batch: 404 , Combined Loss: tensor(0.6357, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3769901990890503\n",
      "Batch: 405 , Combined Loss: tensor(0.7168, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8305703401565552\n",
      "Batch: 406 , Combined Loss: tensor(0.6034, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9995080232620239\n",
      "Batch: 407 , Combined Loss: tensor(0.6007, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0242822170257568\n",
      "Batch: 408 , Combined Loss: tensor(0.7161, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.014643907546997\n",
      "Batch: 409 , Combined Loss: tensor(0.9101, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7366914749145508\n",
      "Batch: 410 , Combined Loss: tensor(0.6492, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7068288326263428\n",
      "Batch: 411 , Combined Loss: tensor(0.5998, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8179757595062256\n",
      "Batch: 412 , Combined Loss: tensor(0.5564, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9003732204437256\n",
      "Batch: 413 , Combined Loss: tensor(0.8952, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.862411379814148\n",
      "Batch: 414 , Combined Loss: tensor(0.6263, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1931769847869873\n",
      "Batch: 415 , Combined Loss: tensor(0.6193, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.742260217666626\n",
      "Batch: 416 , Combined Loss: tensor(0.5859, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.123380184173584\n",
      "Batch: 417 , Combined Loss: tensor(0.6036, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.046255350112915\n",
      "Batch: 418 , Combined Loss: tensor(0.5761, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6548494100570679\n",
      "Batch: 419 , Combined Loss: tensor(0.6878, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0428922176361084\n",
      "Batch: 420 , Combined Loss: tensor(0.5915, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7350354194641113\n",
      "Batch: 421 , Combined Loss: tensor(0.6806, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1412606239318848\n",
      "Batch: 422 , Combined Loss: tensor(0.5153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7751388549804688\n",
      "Batch: 423 , Combined Loss: tensor(0.7374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8023518323898315\n",
      "Batch: 424 , Combined Loss: tensor(0.5488, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6593583822250366\n",
      "Batch: 425 , Combined Loss: tensor(0.5525, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0481019020080566\n",
      "Batch: 426 , Combined Loss: tensor(0.5408, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.777122974395752\n",
      "Batch: 427 , Combined Loss: tensor(0.9140, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7597059011459351\n",
      "Batch: 428 , Combined Loss: tensor(0.5838, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2106997966766357\n",
      "Batch: 429 , Combined Loss: tensor(0.7434, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8758693933486938\n",
      "Batch: 430 , Combined Loss: tensor(0.6567, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0765647888183594\n",
      "Batch: 431 , Combined Loss: tensor(0.7757, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.187921404838562\n",
      "Batch: 432 , Combined Loss: tensor(0.6295, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9002763032913208\n",
      "Batch: 433 , Combined Loss: tensor(0.5722, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44542717933654785\n",
      "Batch: 434 , Combined Loss: tensor(0.6822, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1050801277160645\n",
      "Batch: 435 , Combined Loss: tensor(0.5793, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.295581340789795\n",
      "Batch: 436 , Combined Loss: tensor(0.5842, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9434232711791992\n",
      "Batch: 437 , Combined Loss: tensor(0.7796, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0587921142578125\n",
      "Batch: 438 , Combined Loss: tensor(0.5772, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3864402770996094\n",
      "Batch: 439 , Combined Loss: tensor(0.5920, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33191609382629395\n",
      "Batch: 440 , Combined Loss: tensor(0.5614, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9814929962158203\n",
      "Batch: 441 , Combined Loss: tensor(0.6787, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2572877407073975\n",
      "Batch: 442 , Combined Loss: tensor(0.6338, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.41574347019195557\n",
      "Batch: 443 , Combined Loss: tensor(0.5893, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8602573871612549\n",
      "Batch: 444 , Combined Loss: tensor(0.5923, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7742122411727905\n",
      "Batch: 445 , Combined Loss: tensor(0.8318, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43146371841430664\n",
      "Batch: 446 , Combined Loss: tensor(0.6214, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1306660175323486\n",
      "Batch: 447 , Combined Loss: tensor(0.5354, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.171675443649292\n",
      "Batch: 448 , Combined Loss: tensor(0.6566, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19034624099731445\n",
      "Batch: 449 , Combined Loss: tensor(0.6316, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15638911724090576\n",
      "Batch: 450 , Combined Loss: tensor(0.5650, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2163119316101074\n",
      "Batch: 451 , Combined Loss: tensor(0.7486, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.37148821353912354\n",
      "Batch: 452 , Combined Loss: tensor(0.5730, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0792381763458252\n",
      "Batch: 453 , Combined Loss: tensor(0.5853, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0086894035339355\n",
      "Batch: 454 , Combined Loss: tensor(0.5691, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9350969791412354\n",
      "Batch: 455 , Combined Loss: tensor(0.7222, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8026160001754761\n",
      "Batch: 456 , Combined Loss: tensor(0.6218, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.007188081741333\n",
      "Batch: 457 , Combined Loss: tensor(0.5973, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0706911087036133\n",
      "Batch: 458 , Combined Loss: tensor(0.5860, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0136935710906982\n",
      "Batch: 459 , Combined Loss: tensor(0.7877, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1378076076507568\n",
      "Batch: 460 , Combined Loss: tensor(0.5782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2309341430664062\n",
      "Batch: 461 , Combined Loss: tensor(0.6254, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1032726764678955\n",
      "Batch: 462 , Combined Loss: tensor(0.6610, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.666405439376831\n",
      "Batch: 463 , Combined Loss: tensor(0.6090, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.94034743309021\n",
      "Batch: 464 , Combined Loss: tensor(0.5967, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1104376316070557\n",
      "Batch: 465 , Combined Loss: tensor(0.8300, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7839388847351074\n",
      "Batch: 466 , Combined Loss: tensor(0.6004, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0423855781555176\n",
      "Batch: 467 , Combined Loss: tensor(0.5814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0755314826965332\n",
      "Batch: 468 , Combined Loss: tensor(0.5790, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0383789539337158\n",
      "Batch: 469 , Combined Loss: tensor(0.6002, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9933184385299683\n",
      "Batch: 470 , Combined Loss: tensor(0.6961, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2080345153808594\n",
      "Batch: 471 , Combined Loss: tensor(0.5780, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5154091119766235\n",
      "Batch: 472 , Combined Loss: tensor(0.6060, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9903271198272705\n",
      "Batch: 473 , Combined Loss: tensor(0.6121, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7883857488632202\n",
      "Batch: 474 , Combined Loss: tensor(0.6499, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7362905740737915\n",
      "Batch: 475 , Combined Loss: tensor(0.7264, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25265300273895264\n",
      "Batch: 476 , Combined Loss: tensor(0.5334, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0683138370513916\n",
      "Batch: 477 , Combined Loss: tensor(0.5890, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0028512477874756\n",
      "Batch: 478 , Combined Loss: tensor(0.6391, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.204115867614746\n",
      "Batch: 479 , Combined Loss: tensor(0.5924, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.878645658493042\n",
      "Batch: 480 , Combined Loss: tensor(0.6883, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.387204647064209\n",
      "Batch: 481 , Combined Loss: tensor(0.6018, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1280944347381592\n",
      "Batch: 482 , Combined Loss: tensor(0.5323, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0004804134368896\n",
      "Batch: 483 , Combined Loss: tensor(0.5717, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3093855381011963\n",
      "Batch: 484 , Combined Loss: tensor(0.5201, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5072282552719116\n",
      "Batch: 485 , Combined Loss: tensor(0.6550, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48595738410949707\n",
      "Batch: 486 , Combined Loss: tensor(0.5787, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40764081478118896\n",
      "Batch: 487 , Combined Loss: tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1048080921173096\n",
      "Batch: 488 , Combined Loss: tensor(0.6351, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0775609016418457\n",
      "Batch: 489 , Combined Loss: tensor(0.6489, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.158431053161621\n",
      "Batch: 490 , Combined Loss: tensor(0.5798, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9542768001556396\n",
      "Batch: 491 , Combined Loss: tensor(0.7288, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.772629976272583\n",
      "Batch: 492 , Combined Loss: tensor(0.6504, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9884061813354492\n",
      "Batch: 493 , Combined Loss: tensor(0.7397, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17406249046325684\n",
      "Batch: 494 , Combined Loss: tensor(0.5189, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1991932392120361\n",
      "Batch: 495 , Combined Loss: tensor(0.6067, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6802648305892944\n",
      "Batch: 496 , Combined Loss: tensor(0.5264, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.017643690109253\n",
      "Batch: 497 , Combined Loss: tensor(0.6000, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9613723754882812\n",
      "Batch: 498 , Combined Loss: tensor(0.7323, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9795570373535156\n",
      "Batch: 499 , Combined Loss: tensor(0.7114, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0279021263122559\n",
      "Batch: 500 , Combined Loss: tensor(0.5764, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1070818901062012\n",
      "Batch: 501 , Combined Loss: tensor(0.5942, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.043769121170044\n",
      "Batch: 502 , Combined Loss: tensor(0.5915, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.097599983215332\n",
      "Batch: 503 , Combined Loss: tensor(0.6134, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1322145462036133\n",
      "Batch: 504 , Combined Loss: tensor(0.9386, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9295972585678101\n",
      "Batch: 505 , Combined Loss: tensor(0.6802, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9430590867996216\n",
      "Batch: 506 , Combined Loss: tensor(0.6861, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9403045177459717\n",
      "Batch: 507 , Combined Loss: tensor(0.6087, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.761246919631958\n",
      "Batch: 508 , Combined Loss: tensor(0.6301, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8909777402877808\n",
      "Batch: 509 , Combined Loss: tensor(0.7577, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9761828184127808\n",
      "Batch: 510 , Combined Loss: tensor(0.5141, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0661640167236328\n",
      "Batch: 511 , Combined Loss: tensor(0.7229, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.303286075592041\n",
      "Batch: 512 , Combined Loss: tensor(0.8754, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6972649097442627\n",
      "Batch: 513 , Combined Loss: tensor(0.9216, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4972503185272217\n",
      "Batch: 514 , Combined Loss: tensor(0.6912, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3076218366622925\n",
      "Batch: 515 , Combined Loss: tensor(0.6441, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7993993759155273\n",
      "Batch: 516 , Combined Loss: tensor(0.6962, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9548656940460205\n",
      "Batch: 517 , Combined Loss: tensor(0.6576, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9439282417297363\n",
      "Batch: 518 , Combined Loss: tensor(0.6198, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.054600477218628\n",
      "Batch: 519 , Combined Loss: tensor(0.6875, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44566142559051514\n",
      "Batch: 520 , Combined Loss: tensor(0.6509, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08871150016784668\n",
      "Batch: 521 , Combined Loss: tensor(0.6184, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7488210201263428\n",
      "Batch: 522 , Combined Loss: tensor(0.6715, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8102599382400513\n",
      "Batch: 523 , Combined Loss: tensor(0.5979, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7117536067962646\n",
      "Batch: 524 , Combined Loss: tensor(0.6297, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5741416215896606\n",
      "Batch: 525 , Combined Loss: tensor(0.6475, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8635170459747314\n",
      "Batch: 526 , Combined Loss: tensor(0.7174, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9948431253433228\n",
      "Batch: 527 , Combined Loss: tensor(0.6226, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9445171356201172\n",
      "Batch: 528 , Combined Loss: tensor(0.6625, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9834878444671631\n",
      "Batch: 529 , Combined Loss: tensor(0.5827, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14081907272338867\n",
      "Batch: 530 , Combined Loss: tensor(0.6913, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.99516761302948\n",
      "Batch: 531 , Combined Loss: tensor(0.6023, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8743733167648315\n",
      "Batch: 532 , Combined Loss: tensor(0.5289, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8029149770736694\n",
      "Batch: 533 , Combined Loss: tensor(0.4946, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5405547618865967\n",
      "Batch: 534 , Combined Loss: tensor(0.5966, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9398589134216309\n",
      "Batch: 535 , Combined Loss: tensor(0.5672, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6218305826187134\n",
      "Batch: 536 , Combined Loss: tensor(0.6715, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5248181819915771\n",
      "Batch: 537 , Combined Loss: tensor(0.6043, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1045351028442383\n",
      "Batch: 538 , Combined Loss: tensor(0.6687, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5690667629241943\n",
      "Batch: 539 , Combined Loss: tensor(0.6915, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8987128734588623\n",
      "Batch: 540 , Combined Loss: tensor(0.5484, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29087889194488525\n",
      "Batch: 541 , Combined Loss: tensor(0.7587, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12846708297729492\n",
      "Batch: 542 , Combined Loss: tensor(0.6360, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7622007131576538\n",
      "Batch: 543 , Combined Loss: tensor(0.8222, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6495969295501709\n",
      "Batch: 544 , Combined Loss: tensor(0.7906, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7926123142242432\n",
      "Batch: 545 , Combined Loss: tensor(0.6414, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0257318019866943\n",
      "Batch: 546 , Combined Loss: tensor(0.6051, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6540824174880981\n",
      "Batch: 547 , Combined Loss: tensor(0.6387, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0290234088897705\n",
      "Batch: 548 , Combined Loss: tensor(0.5780, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7913608551025391\n",
      "Batch: 549 , Combined Loss: tensor(0.6186, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.960186243057251\n",
      "Batch: 550 , Combined Loss: tensor(0.6096, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25191962718963623\n",
      "Batch: 551 , Combined Loss: tensor(0.5972, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8122973442077637\n",
      "Batch: 552 , Combined Loss: tensor(0.6185, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0977540016174316\n",
      "Batch: 553 , Combined Loss: tensor(0.5717, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7722300291061401\n",
      "Batch: 554 , Combined Loss: tensor(0.5232, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6601477861404419\n",
      "Batch: 555 , Combined Loss: tensor(0.7692, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7448692321777344\n",
      "Batch: 556 , Combined Loss: tensor(0.6779, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.68128502368927\n",
      "Batch: 557 , Combined Loss: tensor(0.6175, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9745125770568848\n",
      "Batch: 558 , Combined Loss: tensor(0.5837, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0046045780181885\n",
      "Batch: 559 , Combined Loss: tensor(0.6111, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6875271797180176\n",
      "Batch: 560 , Combined Loss: tensor(0.5860, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9392379522323608\n",
      "Batch: 561 , Combined Loss: tensor(0.6304, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7735979557037354\n",
      "Batch: 562 , Combined Loss: tensor(0.6871, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0475482940673828\n",
      "Batch: 563 , Combined Loss: tensor(0.5753, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9804413318634033\n",
      "Batch: 564 , Combined Loss: tensor(1.0023, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7952286005020142\n",
      "Batch: 565 , Combined Loss: tensor(0.6476, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9263869524002075\n",
      "Batch: 566 , Combined Loss: tensor(0.7183, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5992562770843506\n",
      "Batch: 567 , Combined Loss: tensor(0.6663, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.466518759727478\n",
      "Batch: 568 , Combined Loss: tensor(0.6469, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9492365121841431\n",
      "Batch: 569 , Combined Loss: tensor(0.5586, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2599983215332031\n",
      "Batch: 570 , Combined Loss: tensor(1.0259, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6749329566955566\n",
      "Batch: 571 , Combined Loss: tensor(0.7085, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8053336143493652\n",
      "Batch: 572 , Combined Loss: tensor(0.6375, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9964061975479126\n",
      "Batch: 573 , Combined Loss: tensor(0.6502, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6999157667160034\n",
      "Batch: 574 , Combined Loss: tensor(0.6995, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9350091218948364\n",
      "Batch: 575 , Combined Loss: tensor(0.6216, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7304079532623291\n",
      "Batch: 576 , Combined Loss: tensor(0.8444, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5298314094543457\n",
      "Batch: 577 , Combined Loss: tensor(0.7388, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0098633766174316\n",
      "Batch: 578 , Combined Loss: tensor(0.5255, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8591111898422241\n",
      "Batch: 579 , Combined Loss: tensor(0.7248, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30036628246307373\n",
      "Batch: 580 , Combined Loss: tensor(0.6202, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4610483646392822\n",
      "Batch: 581 , Combined Loss: tensor(0.6810, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8173837661743164\n",
      "Batch: 582 , Combined Loss: tensor(0.6232, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7272324562072754\n",
      "Batch: 583 , Combined Loss: tensor(0.5348, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2440884113311768\n",
      "Batch: 584 , Combined Loss: tensor(0.8711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7919199466705322\n",
      "Batch: 585 , Combined Loss: tensor(0.6728, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7717325687408447\n",
      "Batch: 586 , Combined Loss: tensor(0.6899, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1048123836517334\n",
      "Batch: 587 , Combined Loss: tensor(0.6084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6062042713165283\n",
      "Batch: 588 , Combined Loss: tensor(0.5734, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0282764434814453\n",
      "Batch: 589 , Combined Loss: tensor(0.5569, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1106386184692383\n",
      "Batch: 590 , Combined Loss: tensor(0.8284, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8447574377059937\n",
      "Batch: 591 , Combined Loss: tensor(0.7258, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9698411226272583\n",
      "Batch: 592 , Combined Loss: tensor(0.5875, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44545257091522217\n",
      "Batch: 593 , Combined Loss: tensor(0.6905, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0653822422027588\n",
      "Batch: 594 , Combined Loss: tensor(0.6377, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.903710126876831\n",
      "Batch: 595 , Combined Loss: tensor(0.5878, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5723710060119629\n",
      "Batch: 596 , Combined Loss: tensor(0.7598, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.956708550453186\n",
      "Batch: 597 , Combined Loss: tensor(0.5679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39909470081329346\n",
      "Batch: 598 , Combined Loss: tensor(0.5884, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39699530601501465\n",
      "Batch: 599 , Combined Loss: tensor(0.5839, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9324278831481934\n",
      "Batch: 600 , Combined Loss: tensor(0.5994, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8765273094177246\n",
      "Batch: 601 , Combined Loss: tensor(0.6912, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5440912246704102\n",
      "Batch: 602 , Combined Loss: tensor(0.8202, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7176936864852905\n",
      "Batch: 603 , Combined Loss: tensor(0.6022, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9647359848022461\n",
      "Batch: 604 , Combined Loss: tensor(0.5503, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47932326793670654\n",
      "Batch: 605 , Combined Loss: tensor(0.5659, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8430153131484985\n",
      "Batch: 606 , Combined Loss: tensor(0.6184, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.952800989151001\n",
      "Batch: 607 , Combined Loss: tensor(0.6396, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44357264041900635\n",
      "Batch: 608 , Combined Loss: tensor(0.6830, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.10281336307525635\n",
      "Batch: 609 , Combined Loss: tensor(0.5608, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6111496686935425\n",
      "Batch: 610 , Combined Loss: tensor(0.5999, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7311594486236572\n",
      "Batch: 611 , Combined Loss: tensor(0.5699, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7888482809066772\n",
      "Batch: 612 , Combined Loss: tensor(0.6999, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8895488977432251\n",
      "Batch: 613 , Combined Loss: tensor(0.5877, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8958172798156738\n",
      "Batch: 614 , Combined Loss: tensor(0.7675, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1474859714508057\n",
      "Batch: 615 , Combined Loss: tensor(0.6247, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0254058837890625\n",
      "Batch: 616 , Combined Loss: tensor(0.7769, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.136033296585083\n",
      "Batch: 617 , Combined Loss: tensor(0.6375, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9130733013153076\n",
      "Batch: 618 , Combined Loss: tensor(0.7884, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7745944261550903\n",
      "Batch: 619 , Combined Loss: tensor(0.5635, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4762934446334839\n",
      "Batch: 620 , Combined Loss: tensor(0.5455, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6120285987854004\n",
      "Batch: 621 , Combined Loss: tensor(0.5966, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1440868377685547\n",
      "Batch: 622 , Combined Loss: tensor(0.6207, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0401322841644287\n",
      "Batch: 623 , Combined Loss: tensor(0.6896, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5384256839752197\n",
      "Batch: 624 , Combined Loss: tensor(0.5851, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.943079948425293\n",
      "Batch: 625 , Combined Loss: tensor(0.5969, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.132073163986206\n",
      "Batch: 626 , Combined Loss: tensor(0.5434, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21053051948547363\n",
      "Batch: 627 , Combined Loss: tensor(0.6767, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5687177181243896\n",
      "Batch: 628 , Combined Loss: tensor(0.6849, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8721551895141602\n",
      "----------Epoch 31, Loss: 0.6442680275497072, Accuracy: 0.976431766261357, Dice Coef: [0.9898984907920486, 0.6556079165326515, 0.6680879368239385, 0.7658415807956398], Dice Coef Necrotic: 1.0449651164987834, Dice Coef Edema: 1.0579910532678225, Dice Coef Enhancing: 1.0759658034231137, Sensitivity: [0.9818128333182706, 0.7916566397449141, 0.8678301461455553, 0.8834646229761014], Specificity: [0.9692698557918894, 0.9978764847465843, 0.9829649931865201, 0.9967502981945517], Precision: [0.9981664087510829, 0.6206311715066097, 0.5727287831105522, 0.712696191389854]\n",
      "Batch: 0 , Combined Loss: tensor(0.5732, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23338639736175537\n",
      "Batch: 1 , Combined Loss: tensor(0.5807, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6266852617263794\n",
      "Batch: 2 , Combined Loss: tensor(0.6479, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8948397636413574\n",
      "Batch: 3 , Combined Loss: tensor(0.5801, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5697427988052368\n",
      "Batch: 4 , Combined Loss: tensor(0.6091, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.855608344078064\n",
      "Batch: 5 , Combined Loss: tensor(0.5717, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8397177457809448\n",
      "Batch: 6 , Combined Loss: tensor(0.6462, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9329392910003662\n",
      "Batch: 7 , Combined Loss: tensor(0.6505, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7750353813171387\n",
      "Batch: 8 , Combined Loss: tensor(0.6496, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8442162275314331\n",
      "Batch: 9 , Combined Loss: tensor(0.5226, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7262790203094482\n",
      "Batch: 10 , Combined Loss: tensor(0.4725, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5160479545593262\n",
      "Batch: 11 , Combined Loss: tensor(0.6564, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9653451442718506\n",
      "Batch: 12 , Combined Loss: tensor(0.7053, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8252136707305908\n",
      "Batch: 13 , Combined Loss: tensor(0.5520, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6639015674591064\n",
      "Batch: 14 , Combined Loss: tensor(0.6443, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8130166530609131\n",
      "Batch: 15 , Combined Loss: tensor(0.7103, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.016483068466186523\n",
      "Batch: 16 , Combined Loss: tensor(0.7888, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08675718307495117\n",
      "Batch: 17 , Combined Loss: tensor(0.6175, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0036470890045166\n",
      "Batch: 18 , Combined Loss: tensor(0.6117, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4080989360809326\n",
      "Batch: 19 , Combined Loss: tensor(0.6142, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.727269172668457\n",
      "Batch: 20 , Combined Loss: tensor(0.6077, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7905346155166626\n",
      "Batch: 21 , Combined Loss: tensor(0.5566, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9991357326507568\n",
      "Batch: 22 , Combined Loss: tensor(0.6593, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6005141735076904\n",
      "Batch: 23 , Combined Loss: tensor(0.5882, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.003521203994751\n",
      "Batch: 24 , Combined Loss: tensor(0.5520, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9753175973892212\n",
      "Batch: 25 , Combined Loss: tensor(0.5968, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7059741020202637\n",
      "Batch: 26 , Combined Loss: tensor(0.5713, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5281946659088135\n",
      "Batch: 27 , Combined Loss: tensor(0.7844, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0120127201080322\n",
      "Batch: 28 , Combined Loss: tensor(0.6727, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9993927478790283\n",
      "Batch: 29 , Combined Loss: tensor(0.5797, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9538818597793579\n",
      "Batch: 30 , Combined Loss: tensor(0.7804, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0392301082611084\n",
      "Batch: 31 , Combined Loss: tensor(0.5152, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49866366386413574\n",
      "Batch: 32 , Combined Loss: tensor(0.7170, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34594714641571045\n",
      "Batch: 33 , Combined Loss: tensor(0.6207, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20072877407073975\n",
      "Batch: 34 , Combined Loss: tensor(0.6773, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5946033000946045\n",
      "Batch: 35 , Combined Loss: tensor(0.5946, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0284698009490967\n",
      "Batch: 36 , Combined Loss: tensor(0.5320, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0980582237243652\n",
      "Batch: 37 , Combined Loss: tensor(0.5217, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6624195575714111\n",
      "Batch: 38 , Combined Loss: tensor(0.5716, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3478848934173584\n",
      "Batch: 39 , Combined Loss: tensor(0.5391, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7930819988250732\n",
      "Batch: 40 , Combined Loss: tensor(0.5830, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8042745590209961\n",
      "Batch: 41 , Combined Loss: tensor(0.5211, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1505773067474365\n",
      "Batch: 42 , Combined Loss: tensor(0.5757, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.216228723526001\n",
      "Batch: 43 , Combined Loss: tensor(0.7631, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0348682403564453\n",
      "Batch: 44 , Combined Loss: tensor(0.7008, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8152793645858765\n",
      "Batch: 45 , Combined Loss: tensor(0.6762, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7301015853881836\n",
      "Batch: 46 , Combined Loss: tensor(0.6086, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8395371437072754\n",
      "Batch: 47 , Combined Loss: tensor(0.5697, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9639389514923096\n",
      "Batch: 48 , Combined Loss: tensor(0.6508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7703732252120972\n",
      "Batch: 49 , Combined Loss: tensor(0.6300, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2742269039154053\n",
      "Batch: 50 , Combined Loss: tensor(0.6243, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.178889513015747\n",
      "Batch: 51 , Combined Loss: tensor(0.5665, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0251832008361816\n",
      "Batch: 52 , Combined Loss: tensor(0.5773, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8733807802200317\n",
      "Batch: 53 , Combined Loss: tensor(0.6001, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1143734455108643\n",
      "Batch: 54 , Combined Loss: tensor(0.7905, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9687843322753906\n",
      "Batch: 55 , Combined Loss: tensor(0.5265, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6047207117080688\n",
      "Batch: 56 , Combined Loss: tensor(0.5110, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.84398353099823\n",
      "Batch: 57 , Combined Loss: tensor(0.6110, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6745573282241821\n",
      "Batch: 58 , Combined Loss: tensor(0.6927, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7281535863876343\n",
      "Batch: 59 , Combined Loss: tensor(0.5829, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.924310564994812\n",
      "Batch: 60 , Combined Loss: tensor(0.5561, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7735176086425781\n",
      "Batch: 61 , Combined Loss: tensor(0.6031, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6826174259185791\n",
      "Batch: 62 , Combined Loss: tensor(0.6170, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6255431175231934\n",
      "Batch: 63 , Combined Loss: tensor(0.5539, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2563364505767822\n",
      "Batch: 64 , Combined Loss: tensor(0.5843, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9131525754928589\n",
      "Batch: 65 , Combined Loss: tensor(0.7221, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4348713159561157\n",
      "Batch: 66 , Combined Loss: tensor(0.6799, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.4165747165679932\n",
      "Batch: 67 , Combined Loss: tensor(0.5417, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9413242340087891\n",
      "Batch: 68 , Combined Loss: tensor(0.6916, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.010122716426849365\n",
      "Batch: 69 , Combined Loss: tensor(0.6238, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0680298805236816\n",
      "Batch: 70 , Combined Loss: tensor(0.6434, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3153262138366699\n",
      "Batch: 71 , Combined Loss: tensor(0.5562, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9335761070251465\n",
      "Batch: 72 , Combined Loss: tensor(0.6407, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7413703203201294\n",
      "Batch: 73 , Combined Loss: tensor(0.5727, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.046952724456787\n",
      "Batch: 74 , Combined Loss: tensor(0.5960, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8291170597076416\n",
      "Batch: 75 , Combined Loss: tensor(0.4943, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8278422355651855\n",
      "Batch: 76 , Combined Loss: tensor(0.7033, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0308325290679932\n",
      "Batch: 77 , Combined Loss: tensor(0.5817, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.007810056209564209\n",
      "Batch: 78 , Combined Loss: tensor(0.8220, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5576767921447754\n",
      "Batch: 79 , Combined Loss: tensor(0.5963, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0229556560516357\n",
      "Batch: 80 , Combined Loss: tensor(0.5978, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.815301775932312\n",
      "Batch: 81 , Combined Loss: tensor(0.6287, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0299623012542725\n",
      "Batch: 82 , Combined Loss: tensor(0.5842, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8802515268325806\n",
      "Batch: 83 , Combined Loss: tensor(0.5740, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8481974601745605\n",
      "Batch: 84 , Combined Loss: tensor(0.6464, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8611226081848145\n",
      "Batch: 85 , Combined Loss: tensor(0.5770, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7819250822067261\n",
      "Batch: 86 , Combined Loss: tensor(0.8806, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6637898683547974\n",
      "Batch: 87 , Combined Loss: tensor(0.6225, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8338531255722046\n",
      "Batch: 88 , Combined Loss: tensor(0.5810, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0403468608856201\n",
      "Batch: 89 , Combined Loss: tensor(0.6249, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.013723611831665\n",
      "Batch: 90 , Combined Loss: tensor(0.6769, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9089628458023071\n",
      "Batch: 91 , Combined Loss: tensor(0.8390, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.890937328338623\n",
      "Batch: 92 , Combined Loss: tensor(0.5815, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7566810846328735\n",
      "Batch: 93 , Combined Loss: tensor(0.6639, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0519914627075195\n",
      "Batch: 94 , Combined Loss: tensor(0.6333, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9116714000701904\n",
      "Batch: 95 , Combined Loss: tensor(0.6055, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5121208429336548\n",
      "Batch: 96 , Combined Loss: tensor(0.6077, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12199091911315918\n",
      "Batch: 97 , Combined Loss: tensor(0.5684, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0330476760864258\n",
      "Batch: 98 , Combined Loss: tensor(0.6518, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9624111652374268\n",
      "Batch: 99 , Combined Loss: tensor(0.5551, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1536321640014648\n",
      "Batch: 100 , Combined Loss: tensor(0.6928, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9053701162338257\n",
      "Batch: 101 , Combined Loss: tensor(0.5035, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.866804838180542\n",
      "Batch: 102 , Combined Loss: tensor(0.6779, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.866202712059021\n",
      "Batch: 103 , Combined Loss: tensor(0.6305, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8549984693527222\n",
      "Batch: 104 , Combined Loss: tensor(0.5652, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7109510898590088\n",
      "Batch: 105 , Combined Loss: tensor(0.9725, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.875098466873169\n",
      "Batch: 106 , Combined Loss: tensor(0.7992, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.774032473564148\n",
      "Batch: 107 , Combined Loss: tensor(0.6433, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0654940605163574\n",
      "Batch: 108 , Combined Loss: tensor(0.8853, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.035040438175201416\n",
      "Batch: 109 , Combined Loss: tensor(0.5814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.094580888748169\n",
      "Batch: 110 , Combined Loss: tensor(0.6267, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3209027051925659\n",
      "Batch: 111 , Combined Loss: tensor(0.6350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1019794940948486\n",
      "Batch: 112 , Combined Loss: tensor(0.5736, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19253242015838623\n",
      "Batch: 113 , Combined Loss: tensor(0.7477, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9824024438858032\n",
      "Batch: 114 , Combined Loss: tensor(0.5056, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0100138187408447\n",
      "Batch: 115 , Combined Loss: tensor(0.5530, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6016371250152588\n",
      "Batch: 116 , Combined Loss: tensor(0.6674, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8880883455276489\n",
      "Batch: 117 , Combined Loss: tensor(0.5442, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8032494783401489\n",
      "Batch: 118 , Combined Loss: tensor(0.6282, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9531644582748413\n",
      "Batch: 119 , Combined Loss: tensor(0.8744, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5731654167175293\n",
      "Batch: 120 , Combined Loss: tensor(0.5471, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9390027523040771\n",
      "Batch: 121 , Combined Loss: tensor(0.5710, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1823053359985352\n",
      "Batch: 122 , Combined Loss: tensor(0.6270, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12305545806884766\n",
      "Batch: 123 , Combined Loss: tensor(0.6753, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0729880332946777\n",
      "Batch: 124 , Combined Loss: tensor(0.5192, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8796354532241821\n",
      "Batch: 125 , Combined Loss: tensor(0.5868, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.005605697631836\n",
      "Batch: 126 , Combined Loss: tensor(0.5490, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1896255016326904\n",
      "Batch: 127 , Combined Loss: tensor(0.6749, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0470635890960693\n",
      "Batch: 128 , Combined Loss: tensor(0.5510, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8036327362060547\n",
      "Batch: 129 , Combined Loss: tensor(0.6288, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0524559020996094\n",
      "Batch: 130 , Combined Loss: tensor(0.5550, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7944501638412476\n",
      "Batch: 131 , Combined Loss: tensor(0.5866, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9449645280838013\n",
      "Batch: 132 , Combined Loss: tensor(0.5036, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8726052045822144\n",
      "Batch: 133 , Combined Loss: tensor(0.6578, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8754110336303711\n",
      "Batch: 134 , Combined Loss: tensor(0.6445, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.363513708114624\n",
      "Batch: 135 , Combined Loss: tensor(0.5168, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.619214653968811\n",
      "Batch: 136 , Combined Loss: tensor(0.7860, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7339584827423096\n",
      "Batch: 137 , Combined Loss: tensor(0.5783, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.996218204498291\n",
      "Batch: 138 , Combined Loss: tensor(0.5752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9738589525222778\n",
      "Batch: 139 , Combined Loss: tensor(0.5398, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9279665946960449\n",
      "Batch: 140 , Combined Loss: tensor(0.5883, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7460076808929443\n",
      "Batch: 141 , Combined Loss: tensor(0.5302, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4497493505477905\n",
      "Batch: 142 , Combined Loss: tensor(0.5502, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9355734586715698\n",
      "Batch: 143 , Combined Loss: tensor(0.6539, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.590636134147644\n",
      "Batch: 144 , Combined Loss: tensor(0.6446, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5428756475448608\n",
      "Batch: 145 , Combined Loss: tensor(0.5072, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8885328769683838\n",
      "Batch: 146 , Combined Loss: tensor(0.5539, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8735557794570923\n",
      "Batch: 147 , Combined Loss: tensor(0.5786, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1112172603607178\n",
      "Batch: 148 , Combined Loss: tensor(0.5832, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5061633586883545\n",
      "Batch: 149 , Combined Loss: tensor(0.6197, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0577104091644287\n",
      "Batch: 150 , Combined Loss: tensor(0.6095, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9140094518661499\n",
      "Batch: 151 , Combined Loss: tensor(0.7295, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8285132646560669\n",
      "Batch: 152 , Combined Loss: tensor(0.5570, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9909260272979736\n",
      "Batch: 153 , Combined Loss: tensor(0.5792, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0592372417449951\n",
      "Batch: 154 , Combined Loss: tensor(0.5786, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.261883020401001\n",
      "Batch: 155 , Combined Loss: tensor(0.6627, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1686859130859375\n",
      "Batch: 156 , Combined Loss: tensor(0.6752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9590197801589966\n",
      "Batch: 157 , Combined Loss: tensor(0.5639, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.070969581604004\n",
      "Batch: 158 , Combined Loss: tensor(0.5553, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.798474907875061\n",
      "Batch: 159 , Combined Loss: tensor(0.6535, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4101914167404175\n",
      "Batch: 160 , Combined Loss: tensor(0.5633, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8982206583023071\n",
      "Batch: 161 , Combined Loss: tensor(0.6037, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7396103143692017\n",
      "Batch: 162 , Combined Loss: tensor(0.6728, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7523022890090942\n",
      "Batch: 163 , Combined Loss: tensor(0.5819, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0014629364013672\n",
      "Batch: 164 , Combined Loss: tensor(0.6519, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0073423385620117\n",
      "Batch: 165 , Combined Loss: tensor(0.5161, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7887849807739258\n",
      "Batch: 166 , Combined Loss: tensor(0.6484, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.868679404258728\n",
      "Batch: 167 , Combined Loss: tensor(0.6125, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9492542743682861\n",
      "Batch: 168 , Combined Loss: tensor(0.8004, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38548195362091064\n",
      "Batch: 169 , Combined Loss: tensor(0.6189, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0958349704742432\n",
      "Batch: 170 , Combined Loss: tensor(0.5866, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2550170421600342\n",
      "Batch: 171 , Combined Loss: tensor(0.6708, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9610985517501831\n",
      "Batch: 172 , Combined Loss: tensor(0.7597, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.681942343711853\n",
      "Batch: 173 , Combined Loss: tensor(0.5757, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.004220724105835\n",
      "Batch: 174 , Combined Loss: tensor(0.8063, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9055696725845337\n",
      "Batch: 175 , Combined Loss: tensor(0.6097, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.21762001514434814\n",
      "Batch: 176 , Combined Loss: tensor(0.7681, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9807915687561035\n",
      "Batch: 177 , Combined Loss: tensor(0.5442, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5184248685836792\n",
      "Batch: 178 , Combined Loss: tensor(0.5462, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0787272453308105\n",
      "Batch: 179 , Combined Loss: tensor(0.5623, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.816352367401123\n",
      "Batch: 180 , Combined Loss: tensor(0.7164, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1557915210723877\n",
      "Batch: 181 , Combined Loss: tensor(0.5365, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9728090763092041\n",
      "Batch: 182 , Combined Loss: tensor(0.5958, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9321731328964233\n",
      "Batch: 183 , Combined Loss: tensor(0.6508, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6131542921066284\n",
      "Batch: 184 , Combined Loss: tensor(0.7153, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8138325214385986\n",
      "Batch: 185 , Combined Loss: tensor(0.6169, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0166196823120117\n",
      "Batch: 186 , Combined Loss: tensor(0.5338, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8756166696548462\n",
      "Batch: 187 , Combined Loss: tensor(0.5311, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8433301448822021\n",
      "Batch: 188 , Combined Loss: tensor(0.5217, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7158403396606445\n",
      "Batch: 189 , Combined Loss: tensor(0.8305, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8718274831771851\n",
      "Batch: 190 , Combined Loss: tensor(0.8643, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.091109037399292\n",
      "Batch: 191 , Combined Loss: tensor(0.6823, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0103795528411865\n",
      "Batch: 192 , Combined Loss: tensor(0.6020, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0396974086761475\n",
      "Batch: 193 , Combined Loss: tensor(0.7782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6120854616165161\n",
      "Batch: 194 , Combined Loss: tensor(0.7411, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9836616516113281\n",
      "Batch: 195 , Combined Loss: tensor(0.6240, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3647521734237671\n",
      "Batch: 196 , Combined Loss: tensor(0.5644, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1074204444885254\n",
      "Batch: 197 , Combined Loss: tensor(0.5129, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7701681852340698\n",
      "Batch: 198 , Combined Loss: tensor(0.5889, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0289137363433838\n",
      "Batch: 199 , Combined Loss: tensor(0.5402, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5393824577331543\n",
      "Batch: 200 , Combined Loss: tensor(0.6897, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9534749984741211\n",
      "Batch: 201 , Combined Loss: tensor(0.7025, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7980377674102783\n",
      "Batch: 202 , Combined Loss: tensor(0.5574, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7648684978485107\n",
      "Batch: 203 , Combined Loss: tensor(0.5134, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.904744029045105\n",
      "Batch: 204 , Combined Loss: tensor(0.7157, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.84953773021698\n",
      "Batch: 205 , Combined Loss: tensor(0.8162, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3898940086364746\n",
      "Batch: 206 , Combined Loss: tensor(0.6079, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8033232688903809\n",
      "Batch: 207 , Combined Loss: tensor(0.7030, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7381268739700317\n",
      "Batch: 208 , Combined Loss: tensor(0.6469, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.715752124786377\n",
      "Batch: 209 , Combined Loss: tensor(0.5621, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1586904525756836\n",
      "Batch: 210 , Combined Loss: tensor(0.6073, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0133898258209229\n",
      "Batch: 211 , Combined Loss: tensor(0.7182, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9441670179367065\n",
      "Batch: 212 , Combined Loss: tensor(0.6831, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7649394273757935\n",
      "Batch: 213 , Combined Loss: tensor(0.5346, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3089059591293335\n",
      "Batch: 214 , Combined Loss: tensor(0.6388, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25921523571014404\n",
      "Batch: 215 , Combined Loss: tensor(0.7914, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5361553430557251\n",
      "Batch: 216 , Combined Loss: tensor(0.5616, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2861086130142212\n",
      "Batch: 217 , Combined Loss: tensor(0.7166, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28774333000183105\n",
      "Batch: 218 , Combined Loss: tensor(0.6180, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5500166416168213\n",
      "Batch: 219 , Combined Loss: tensor(0.5941, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11162519454956055\n",
      "Batch: 220 , Combined Loss: tensor(0.5317, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9139667749404907\n",
      "Batch: 221 , Combined Loss: tensor(0.5784, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20738446712493896\n",
      "Batch: 222 , Combined Loss: tensor(0.8023, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6592788696289062\n",
      "Batch: 223 , Combined Loss: tensor(0.6252, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.030054926872253418\n",
      "Batch: 224 , Combined Loss: tensor(0.6735, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0859918594360352\n",
      "Batch: 225 , Combined Loss: tensor(0.7930, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.633592963218689\n",
      "Batch: 226 , Combined Loss: tensor(0.5630, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0895915031433105\n",
      "Batch: 227 , Combined Loss: tensor(0.5416, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.982829213142395\n",
      "Batch: 228 , Combined Loss: tensor(0.7137, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7476369142532349\n",
      "Batch: 229 , Combined Loss: tensor(0.5471, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5765465497970581\n",
      "Batch: 230 , Combined Loss: tensor(0.6212, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4098557233810425\n",
      "Batch: 231 , Combined Loss: tensor(0.6093, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9443060159683228\n",
      "Batch: 232 , Combined Loss: tensor(0.6419, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2691142559051514\n",
      "Batch: 233 , Combined Loss: tensor(0.6230, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1284196376800537\n",
      "Batch: 234 , Combined Loss: tensor(0.6111, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8702625036239624\n",
      "Batch: 235 , Combined Loss: tensor(0.7770, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9869409799575806\n",
      "Batch: 236 , Combined Loss: tensor(0.6995, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0300359725952148\n",
      "Batch: 237 , Combined Loss: tensor(0.5740, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5937801599502563\n",
      "Batch: 238 , Combined Loss: tensor(0.6346, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5397541522979736\n",
      "Batch: 239 , Combined Loss: tensor(0.6193, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7155439853668213\n",
      "Batch: 240 , Combined Loss: tensor(0.5997, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.701209545135498\n",
      "Batch: 241 , Combined Loss: tensor(0.5487, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8637995719909668\n",
      "Batch: 242 , Combined Loss: tensor(0.6337, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0286026000976562\n",
      "Batch: 243 , Combined Loss: tensor(0.8130, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7945269346237183\n",
      "Batch: 244 , Combined Loss: tensor(0.7249, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5642317533493042\n",
      "Batch: 245 , Combined Loss: tensor(0.6480, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7299449443817139\n",
      "Batch: 246 , Combined Loss: tensor(0.5416, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9806374311447144\n",
      "Batch: 247 , Combined Loss: tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0709457397460938\n",
      "Batch: 248 , Combined Loss: tensor(0.5693, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3677070140838623\n",
      "Batch: 249 , Combined Loss: tensor(0.5991, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9732534885406494\n",
      "Batch: 250 , Combined Loss: tensor(0.6254, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1280617713928223\n",
      "Batch: 251 , Combined Loss: tensor(0.5498, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0439717769622803\n",
      "Batch: 252 , Combined Loss: tensor(0.5318, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0779669284820557\n",
      "Batch: 253 , Combined Loss: tensor(0.5269, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.008542537689209\n",
      "Batch: 254 , Combined Loss: tensor(0.5973, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9429740905761719\n",
      "Batch: 255 , Combined Loss: tensor(0.6181, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.04206293821334839\n",
      "Batch: 256 , Combined Loss: tensor(0.5946, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.829875111579895\n",
      "Batch: 257 , Combined Loss: tensor(0.6387, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4720062017440796\n",
      "Batch: 258 , Combined Loss: tensor(0.6031, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6262582540512085\n",
      "Batch: 259 , Combined Loss: tensor(0.6089, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.682317852973938\n",
      "Batch: 260 , Combined Loss: tensor(0.6502, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07192754745483398\n",
      "Batch: 261 , Combined Loss: tensor(0.5855, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8813570737838745\n",
      "Batch: 262 , Combined Loss: tensor(0.5868, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.198906421661377\n",
      "Batch: 263 , Combined Loss: tensor(0.5255, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6115254163742065\n",
      "Batch: 264 , Combined Loss: tensor(0.5544, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1739177703857422\n",
      "Batch: 265 , Combined Loss: tensor(0.8034, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.923012375831604\n",
      "Batch: 266 , Combined Loss: tensor(0.6056, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.13811707496643066\n",
      "Batch: 267 , Combined Loss: tensor(0.6580, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15712928771972656\n",
      "Batch: 268 , Combined Loss: tensor(0.5790, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9490988254547119\n",
      "Batch: 269 , Combined Loss: tensor(0.8714, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8875366449356079\n",
      "Batch: 270 , Combined Loss: tensor(0.5651, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7847636938095093\n",
      "Batch: 271 , Combined Loss: tensor(0.5230, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0714352130889893\n",
      "Batch: 272 , Combined Loss: tensor(0.5810, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.848064661026001\n",
      "Batch: 273 , Combined Loss: tensor(0.6351, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8105299472808838\n",
      "Batch: 274 , Combined Loss: tensor(0.8583, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6329625844955444\n",
      "Batch: 275 , Combined Loss: tensor(0.5456, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0304179191589355\n",
      "Batch: 276 , Combined Loss: tensor(0.5466, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8369303941726685\n",
      "Batch: 277 , Combined Loss: tensor(0.5710, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9461069107055664\n",
      "Batch: 278 , Combined Loss: tensor(0.6652, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.037218689918518066\n",
      "Batch: 279 , Combined Loss: tensor(0.6613, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9007667303085327\n",
      "Batch: 280 , Combined Loss: tensor(0.7403, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7782421112060547\n",
      "Batch: 281 , Combined Loss: tensor(0.5372, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5393990278244019\n",
      "Batch: 282 , Combined Loss: tensor(0.6627, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5963040590286255\n",
      "Batch: 283 , Combined Loss: tensor(0.8312, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.11669564247131348\n",
      "Batch: 284 , Combined Loss: tensor(0.5630, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9779672622680664\n",
      "Batch: 285 , Combined Loss: tensor(0.6480, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8517159223556519\n",
      "Batch: 286 , Combined Loss: tensor(0.5135, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5452816486358643\n",
      "Batch: 287 , Combined Loss: tensor(0.6322, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0200397968292236\n",
      "Batch: 288 , Combined Loss: tensor(0.5682, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9552359580993652\n",
      "Batch: 289 , Combined Loss: tensor(0.5790, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40722763538360596\n",
      "Batch: 290 , Combined Loss: tensor(0.6224, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2072843313217163\n",
      "Batch: 291 , Combined Loss: tensor(0.5724, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6125595569610596\n",
      "Batch: 292 , Combined Loss: tensor(0.5743, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.599361777305603\n",
      "Batch: 293 , Combined Loss: tensor(0.6061, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9827454090118408\n",
      "Batch: 294 , Combined Loss: tensor(0.5337, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1618998050689697\n",
      "Batch: 295 , Combined Loss: tensor(0.5846, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.811596155166626\n",
      "Batch: 296 , Combined Loss: tensor(0.8872, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0239272117614746\n",
      "Batch: 297 , Combined Loss: tensor(0.5529, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8400528430938721\n",
      "Batch: 298 , Combined Loss: tensor(0.6744, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23604071140289307\n",
      "Batch: 299 , Combined Loss: tensor(0.5522, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9951210021972656\n",
      "Batch: 300 , Combined Loss: tensor(0.5639, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12295758724212646\n",
      "Batch: 301 , Combined Loss: tensor(0.6179, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1277446746826172\n",
      "Batch: 302 , Combined Loss: tensor(0.6132, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7871869802474976\n",
      "Batch: 303 , Combined Loss: tensor(0.5750, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1627230644226074\n",
      "Batch: 304 , Combined Loss: tensor(0.6256, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9432666301727295\n",
      "Batch: 305 , Combined Loss: tensor(0.5481, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.009988784790039\n",
      "Batch: 306 , Combined Loss: tensor(1.0655, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3986856937408447\n",
      "Batch: 307 , Combined Loss: tensor(0.6892, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6017450094223022\n",
      "Batch: 308 , Combined Loss: tensor(0.6093, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0019810199737549\n",
      "Batch: 309 , Combined Loss: tensor(0.6212, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0766186714172363\n",
      "Batch: 310 , Combined Loss: tensor(0.5592, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9899293184280396\n",
      "Batch: 311 , Combined Loss: tensor(0.7421, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6063547134399414\n",
      "Batch: 312 , Combined Loss: tensor(0.6953, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.056513965129852295\n",
      "Batch: 313 , Combined Loss: tensor(0.5399, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1022357940673828\n",
      "Batch: 314 , Combined Loss: tensor(0.6299, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6894183158874512\n",
      "Batch: 315 , Combined Loss: tensor(0.5703, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0409531593322754\n",
      "Batch: 316 , Combined Loss: tensor(0.5018, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.914749264717102\n",
      "Batch: 317 , Combined Loss: tensor(0.5230, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.066274881362915\n",
      "Batch: 318 , Combined Loss: tensor(0.4916, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9940923452377319\n",
      "Batch: 319 , Combined Loss: tensor(0.7780, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24124634265899658\n",
      "Batch: 320 , Combined Loss: tensor(0.5266, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8159239292144775\n",
      "Batch: 321 , Combined Loss: tensor(0.6403, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9721636772155762\n",
      "Batch: 322 , Combined Loss: tensor(0.7681, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.065307378768921\n",
      "Batch: 323 , Combined Loss: tensor(0.6422, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1060807704925537\n",
      "Batch: 324 , Combined Loss: tensor(0.5160, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7024281024932861\n",
      "Batch: 325 , Combined Loss: tensor(0.5812, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0464794635772705\n",
      "Batch: 326 , Combined Loss: tensor(0.5757, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1455891132354736\n",
      "Batch: 327 , Combined Loss: tensor(0.9770, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5886005163192749\n",
      "Batch: 328 , Combined Loss: tensor(0.7072, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1010388731956482\n",
      "Batch: 329 , Combined Loss: tensor(0.5327, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7806997299194336\n",
      "Batch: 330 , Combined Loss: tensor(0.6063, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0672850608825684\n",
      "Batch: 331 , Combined Loss: tensor(0.5321, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.727684497833252\n",
      "Batch: 332 , Combined Loss: tensor(0.5369, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9393763542175293\n",
      "Batch: 333 , Combined Loss: tensor(0.5937, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8636012077331543\n",
      "Batch: 334 , Combined Loss: tensor(0.6448, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28158342838287354\n",
      "Batch: 335 , Combined Loss: tensor(0.5653, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2313709259033203\n",
      "Batch: 336 , Combined Loss: tensor(0.7234, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9845035076141357\n",
      "Batch: 337 , Combined Loss: tensor(0.8559, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6428699493408203\n",
      "Batch: 338 , Combined Loss: tensor(0.7199, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0059516429901123\n",
      "Batch: 339 , Combined Loss: tensor(0.5160, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1142911911010742\n",
      "Batch: 340 , Combined Loss: tensor(0.6563, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8980865478515625\n",
      "Batch: 341 , Combined Loss: tensor(0.7374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2532625198364258\n",
      "Batch: 342 , Combined Loss: tensor(0.7109, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9198317527770996\n",
      "Batch: 343 , Combined Loss: tensor(0.7812, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06538087129592896\n",
      "Batch: 344 , Combined Loss: tensor(0.5879, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7517292499542236\n",
      "Batch: 345 , Combined Loss: tensor(0.5805, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.019550085067749\n",
      "Batch: 346 , Combined Loss: tensor(0.6667, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.866073727607727\n",
      "Batch: 347 , Combined Loss: tensor(0.5584, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1529943943023682\n",
      "Batch: 348 , Combined Loss: tensor(0.5601, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0772249698638916\n",
      "Batch: 349 , Combined Loss: tensor(0.6263, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.877871036529541\n",
      "Batch: 350 , Combined Loss: tensor(0.4826, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8555855751037598\n",
      "Batch: 351 , Combined Loss: tensor(0.7085, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9293713569641113\n",
      "Batch: 352 , Combined Loss: tensor(0.6299, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.864840030670166\n",
      "Batch: 353 , Combined Loss: tensor(0.7375, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8520298004150391\n",
      "Batch: 354 , Combined Loss: tensor(0.5599, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7780481576919556\n",
      "Batch: 355 , Combined Loss: tensor(0.8735, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7146631479263306\n",
      "Batch: 356 , Combined Loss: tensor(0.6266, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1973369121551514\n",
      "Batch: 357 , Combined Loss: tensor(0.5844, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9945241212844849\n",
      "Batch: 358 , Combined Loss: tensor(0.6196, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0393157005310059\n",
      "Batch: 359 , Combined Loss: tensor(0.5719, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9083660840988159\n",
      "Batch: 360 , Combined Loss: tensor(0.7271, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7577720880508423\n",
      "Batch: 361 , Combined Loss: tensor(0.7442, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1007311344146729\n",
      "Batch: 362 , Combined Loss: tensor(0.8016, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8190715312957764\n",
      "Batch: 363 , Combined Loss: tensor(0.9372, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8240885734558105\n",
      "Batch: 364 , Combined Loss: tensor(0.5060, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1521127223968506\n",
      "Batch: 365 , Combined Loss: tensor(0.5294, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0981051921844482\n",
      "Batch: 366 , Combined Loss: tensor(0.5070, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1747145652770996\n",
      "Batch: 367 , Combined Loss: tensor(0.6393, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9957606792449951\n",
      "Batch: 368 , Combined Loss: tensor(0.9236, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3988229036331177\n",
      "Batch: 369 , Combined Loss: tensor(0.5859, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9597830772399902\n",
      "Batch: 370 , Combined Loss: tensor(0.8263, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.005845069885254\n",
      "Batch: 371 , Combined Loss: tensor(0.5619, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1164608001708984\n",
      "Batch: 372 , Combined Loss: tensor(0.8242, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2284879684448242\n",
      "Batch: 373 , Combined Loss: tensor(0.7667, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9824957847595215\n",
      "Batch: 374 , Combined Loss: tensor(0.5865, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0369412899017334\n",
      "Batch: 375 , Combined Loss: tensor(0.7838, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0780699253082275\n",
      "Batch: 376 , Combined Loss: tensor(0.6319, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3566255569458008\n",
      "Batch: 377 , Combined Loss: tensor(0.4747, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6674346923828125\n",
      "Batch: 378 , Combined Loss: tensor(0.6392, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1198744773864746\n",
      "Batch: 379 , Combined Loss: tensor(0.7858, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0810909271240234\n",
      "Batch: 380 , Combined Loss: tensor(0.6321, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8320349454879761\n",
      "Batch: 381 , Combined Loss: tensor(0.6901, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32252681255340576\n",
      "Batch: 382 , Combined Loss: tensor(0.5463, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0758764743804932\n",
      "Batch: 383 , Combined Loss: tensor(0.5483, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0549139976501465\n",
      "Batch: 384 , Combined Loss: tensor(0.5735, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8787436485290527\n",
      "Batch: 385 , Combined Loss: tensor(0.5149, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0042946338653564\n",
      "Batch: 386 , Combined Loss: tensor(0.5572, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.270972728729248\n",
      "Batch: 387 , Combined Loss: tensor(0.8197, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0863656997680664\n",
      "Batch: 388 , Combined Loss: tensor(0.5357, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0035438537597656\n",
      "Batch: 389 , Combined Loss: tensor(0.6583, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6390351057052612\n",
      "Batch: 390 , Combined Loss: tensor(0.4630, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9139919281005859\n",
      "Batch: 391 , Combined Loss: tensor(0.6729, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.339666485786438\n",
      "Batch: 392 , Combined Loss: tensor(0.8180, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.065150260925293\n",
      "Batch: 393 , Combined Loss: tensor(0.5514, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0775039196014404\n",
      "Batch: 394 , Combined Loss: tensor(0.6372, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.063690185546875\n",
      "Batch: 395 , Combined Loss: tensor(0.7106, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9845395088195801\n",
      "Batch: 396 , Combined Loss: tensor(0.6337, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.158789873123169\n",
      "Batch: 397 , Combined Loss: tensor(0.7592, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4159914255142212\n",
      "Batch: 398 , Combined Loss: tensor(0.5473, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.07338547706604\n",
      "Batch: 399 , Combined Loss: tensor(0.6481, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7299594879150391\n",
      "Batch: 400 , Combined Loss: tensor(0.7327, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0631663799285889\n",
      "Batch: 401 , Combined Loss: tensor(0.5760, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6855361461639404\n",
      "Batch: 402 , Combined Loss: tensor(0.5519, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1279942989349365\n",
      "Batch: 403 , Combined Loss: tensor(0.5716, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8520348072052002\n",
      "Batch: 404 , Combined Loss: tensor(0.5454, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.029921054840088\n",
      "Batch: 405 , Combined Loss: tensor(0.5257, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8468475341796875\n",
      "Batch: 406 , Combined Loss: tensor(0.7835, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6095927953720093\n",
      "Batch: 407 , Combined Loss: tensor(0.6839, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9436089992523193\n",
      "Batch: 408 , Combined Loss: tensor(0.6268, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8646007776260376\n",
      "Batch: 409 , Combined Loss: tensor(0.5688, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7887110710144043\n",
      "Batch: 410 , Combined Loss: tensor(0.7226, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8092690706253052\n",
      "Batch: 411 , Combined Loss: tensor(0.6537, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9153133630752563\n",
      "Batch: 412 , Combined Loss: tensor(0.6181, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6913156509399414\n",
      "Batch: 413 , Combined Loss: tensor(0.5905, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0455334186553955\n",
      "Batch: 414 , Combined Loss: tensor(0.6509, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8675216436386108\n",
      "Batch: 415 , Combined Loss: tensor(0.7694, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.14916658401489258\n",
      "Batch: 416 , Combined Loss: tensor(0.5421, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26624131202697754\n",
      "Batch: 417 , Combined Loss: tensor(0.5552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9485272169113159\n",
      "Batch: 418 , Combined Loss: tensor(0.8059, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4833005666732788\n",
      "Batch: 419 , Combined Loss: tensor(0.6594, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6950204372406006\n",
      "Batch: 420 , Combined Loss: tensor(0.7937, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23883092403411865\n",
      "Batch: 421 , Combined Loss: tensor(0.5574, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8315889835357666\n",
      "Batch: 422 , Combined Loss: tensor(0.4981, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8028714656829834\n",
      "Batch: 423 , Combined Loss: tensor(0.5134, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9588789939880371\n",
      "Batch: 424 , Combined Loss: tensor(0.5622, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12655603885650635\n",
      "Batch: 425 , Combined Loss: tensor(0.5925, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0623784065246582\n",
      "Batch: 426 , Combined Loss: tensor(0.5442, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8721778392791748\n",
      "Batch: 427 , Combined Loss: tensor(0.5777, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2006014585494995\n",
      "Batch: 428 , Combined Loss: tensor(0.6515, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1906949281692505\n",
      "Batch: 429 , Combined Loss: tensor(0.6791, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8720788955688477\n",
      "Batch: 430 , Combined Loss: tensor(0.6805, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1674201488494873\n",
      "Batch: 431 , Combined Loss: tensor(1.0603, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.18648672103881836\n",
      "Batch: 432 , Combined Loss: tensor(0.6692, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34433889389038086\n",
      "Batch: 433 , Combined Loss: tensor(0.5552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8719123601913452\n",
      "Batch: 434 , Combined Loss: tensor(0.5380, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6949213743209839\n",
      "Batch: 435 , Combined Loss: tensor(0.5867, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0843863487243652\n",
      "Batch: 436 , Combined Loss: tensor(0.5870, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5165915489196777\n",
      "Batch: 437 , Combined Loss: tensor(0.5823, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7217681407928467\n",
      "Batch: 438 , Combined Loss: tensor(0.6190, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4117579460144043\n",
      "Batch: 439 , Combined Loss: tensor(0.7917, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26519858837127686\n",
      "Batch: 440 , Combined Loss: tensor(0.5361, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6702054738998413\n",
      "Batch: 441 , Combined Loss: tensor(0.6131, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.491019606590271\n",
      "Batch: 442 , Combined Loss: tensor(0.5364, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8810328245162964\n",
      "Batch: 443 , Combined Loss: tensor(0.6163, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.931721568107605\n",
      "Batch: 444 , Combined Loss: tensor(0.7289, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.848791241645813\n",
      "Batch: 445 , Combined Loss: tensor(0.5580, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7982094287872314\n",
      "Batch: 446 , Combined Loss: tensor(0.5711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9752222299575806\n",
      "Batch: 447 , Combined Loss: tensor(0.6115, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8523497581481934\n",
      "Batch: 448 , Combined Loss: tensor(0.6813, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09369468688964844\n",
      "Batch: 449 , Combined Loss: tensor(0.6182, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07847011089324951\n",
      "Batch: 450 , Combined Loss: tensor(0.6607, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9531233310699463\n",
      "Batch: 451 , Combined Loss: tensor(0.6132, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0359878540039062\n",
      "Batch: 452 , Combined Loss: tensor(0.5620, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3043299913406372\n",
      "Batch: 453 , Combined Loss: tensor(0.7040, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5584838390350342\n",
      "Batch: 454 , Combined Loss: tensor(0.7415, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6200637817382812\n",
      "Batch: 455 , Combined Loss: tensor(0.6068, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8221404552459717\n",
      "Batch: 456 , Combined Loss: tensor(0.5270, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7579317092895508\n",
      "Batch: 457 , Combined Loss: tensor(0.5565, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5916280746459961\n",
      "Batch: 458 , Combined Loss: tensor(0.6209, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.141970694065094\n",
      "Batch: 459 , Combined Loss: tensor(0.5446, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0624992847442627\n",
      "Batch: 460 , Combined Loss: tensor(0.5608, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.005425214767456\n",
      "Batch: 461 , Combined Loss: tensor(0.6978, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.32099878787994385\n",
      "Batch: 462 , Combined Loss: tensor(0.6802, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9496170282363892\n",
      "Batch: 463 , Combined Loss: tensor(0.6663, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28279435634613037\n",
      "Batch: 464 , Combined Loss: tensor(0.6172, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7606062889099121\n",
      "Batch: 465 , Combined Loss: tensor(0.9319, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5325080156326294\n",
      "Batch: 466 , Combined Loss: tensor(0.6219, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.055837631225586\n",
      "Batch: 467 , Combined Loss: tensor(0.6125, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9740725755691528\n",
      "Batch: 468 , Combined Loss: tensor(1.0989, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8447264432907104\n",
      "Batch: 469 , Combined Loss: tensor(0.7211, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8652969598770142\n",
      "Batch: 470 , Combined Loss: tensor(0.5891, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5229805707931519\n",
      "Batch: 471 , Combined Loss: tensor(0.5046, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0956575870513916\n",
      "Batch: 472 , Combined Loss: tensor(0.5245, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0492262840270996\n",
      "Batch: 473 , Combined Loss: tensor(0.5806, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.853378415107727\n",
      "Batch: 474 , Combined Loss: tensor(0.5217, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9517865180969238\n",
      "Batch: 475 , Combined Loss: tensor(0.6318, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9113256931304932\n",
      "Batch: 476 , Combined Loss: tensor(0.6203, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1045668125152588\n",
      "Batch: 477 , Combined Loss: tensor(0.6211, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0656561851501465\n",
      "Batch: 478 , Combined Loss: tensor(0.5972, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2394925355911255\n",
      "Batch: 479 , Combined Loss: tensor(0.6384, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5846072435379028\n",
      "Batch: 480 , Combined Loss: tensor(0.5166, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5812307596206665\n",
      "Batch: 481 , Combined Loss: tensor(0.5833, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6871956586837769\n",
      "Batch: 482 , Combined Loss: tensor(0.8012, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8400266170501709\n",
      "Batch: 483 , Combined Loss: tensor(0.5650, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.111959457397461\n",
      "Batch: 484 , Combined Loss: tensor(0.5449, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9370707273483276\n",
      "Batch: 485 , Combined Loss: tensor(0.6711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.22072243690490723\n",
      "Batch: 486 , Combined Loss: tensor(0.7092, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9635230302810669\n",
      "Batch: 487 , Combined Loss: tensor(0.7142, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0429203510284424\n",
      "Batch: 488 , Combined Loss: tensor(0.6275, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9193377494812012\n",
      "Batch: 489 , Combined Loss: tensor(0.5864, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2146282196044922\n",
      "Batch: 490 , Combined Loss: tensor(0.6859, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6650365591049194\n",
      "Batch: 491 , Combined Loss: tensor(0.5380, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7183438539505005\n",
      "Batch: 492 , Combined Loss: tensor(0.6557, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2684215307235718\n",
      "Batch: 493 , Combined Loss: tensor(0.5739, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9280253648757935\n",
      "Batch: 494 , Combined Loss: tensor(0.5699, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7128926515579224\n",
      "Batch: 495 , Combined Loss: tensor(0.5749, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2659482955932617\n",
      "Batch: 496 , Combined Loss: tensor(0.6476, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0594756603240967\n",
      "Batch: 497 , Combined Loss: tensor(0.6012, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0831410884857178\n",
      "Batch: 498 , Combined Loss: tensor(0.6277, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8820347785949707\n",
      "Batch: 499 , Combined Loss: tensor(0.5652, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7014975547790527\n",
      "Batch: 500 , Combined Loss: tensor(0.7546, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1437463760375977\n",
      "Batch: 501 , Combined Loss: tensor(0.8035, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6752053499221802\n",
      "Batch: 502 , Combined Loss: tensor(0.6102, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7567586898803711\n",
      "Batch: 503 , Combined Loss: tensor(0.5301, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1783976554870605\n",
      "Batch: 504 , Combined Loss: tensor(0.5312, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34784531593322754\n",
      "Batch: 505 , Combined Loss: tensor(0.5899, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0733869075775146\n",
      "Batch: 506 , Combined Loss: tensor(0.5603, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7716253995895386\n",
      "Batch: 507 , Combined Loss: tensor(0.6827, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0387651920318604\n",
      "Batch: 508 , Combined Loss: tensor(0.6003, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34489238262176514\n",
      "Batch: 509 , Combined Loss: tensor(0.5116, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.503305196762085\n",
      "Batch: 510 , Combined Loss: tensor(0.6726, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.059807777404785156\n",
      "Batch: 511 , Combined Loss: tensor(0.6136, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0653738975524902\n",
      "Batch: 512 , Combined Loss: tensor(0.5511, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1564345359802246\n",
      "Batch: 513 , Combined Loss: tensor(0.5602, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0327036380767822\n",
      "Batch: 514 , Combined Loss: tensor(0.5532, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8865004777908325\n",
      "Batch: 515 , Combined Loss: tensor(0.7538, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1218783855438232\n",
      "Batch: 516 , Combined Loss: tensor(1.1417, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7391844987869263\n",
      "Batch: 517 , Combined Loss: tensor(1.1887, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2393639087677002\n",
      "Batch: 518 , Combined Loss: tensor(0.5852, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7095400094985962\n",
      "Batch: 519 , Combined Loss: tensor(0.5946, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1565942764282227\n",
      "Batch: 520 , Combined Loss: tensor(0.5800, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8816362619400024\n",
      "Batch: 521 , Combined Loss: tensor(0.7115, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0519042015075684\n",
      "Batch: 522 , Combined Loss: tensor(0.4940, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8690776824951172\n",
      "Batch: 523 , Combined Loss: tensor(0.7155, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.768943190574646\n",
      "Batch: 524 , Combined Loss: tensor(0.6433, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7499415874481201\n",
      "Batch: 525 , Combined Loss: tensor(0.5346, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1580774784088135\n",
      "Batch: 526 , Combined Loss: tensor(0.7089, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7936608791351318\n",
      "Batch: 527 , Combined Loss: tensor(1.6477, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49584877490997314\n",
      "Batch: 528 , Combined Loss: tensor(0.5532, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7493427991867065\n",
      "Batch: 529 , Combined Loss: tensor(0.7030, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.973641037940979\n",
      "Batch: 530 , Combined Loss: tensor(0.5257, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.288766860961914\n",
      "Batch: 531 , Combined Loss: tensor(0.7074, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0721793174743652\n",
      "Batch: 532 , Combined Loss: tensor(0.6816, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9793462753295898\n",
      "Batch: 533 , Combined Loss: tensor(0.5077, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2829375267028809\n",
      "Batch: 534 , Combined Loss: tensor(0.7113, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1279256343841553\n",
      "Batch: 535 , Combined Loss: tensor(0.6260, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8487907648086548\n",
      "Batch: 536 , Combined Loss: tensor(0.6237, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0067214965820312\n",
      "Batch: 537 , Combined Loss: tensor(0.5244, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.602586030960083\n",
      "Batch: 538 , Combined Loss: tensor(0.7140, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0220427513122559\n",
      "Batch: 539 , Combined Loss: tensor(0.5778, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0673792362213135\n",
      "Batch: 540 , Combined Loss: tensor(0.6965, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0232553482055664\n",
      "Batch: 541 , Combined Loss: tensor(0.5654, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0620906352996826\n",
      "Batch: 542 , Combined Loss: tensor(0.6973, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9953768253326416\n",
      "Batch: 543 , Combined Loss: tensor(0.6606, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8660975694656372\n",
      "Batch: 544 , Combined Loss: tensor(0.7061, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0659840106964111\n",
      "Batch: 545 , Combined Loss: tensor(0.5766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8068960905075073\n",
      "Batch: 546 , Combined Loss: tensor(0.6272, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0061869621276855\n",
      "Batch: 547 , Combined Loss: tensor(0.5785, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1428685188293457\n",
      "Batch: 548 , Combined Loss: tensor(0.5472, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8792036771774292\n",
      "Batch: 549 , Combined Loss: tensor(0.8327, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8812141418457031\n",
      "Batch: 550 , Combined Loss: tensor(0.6381, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.216219186782837\n",
      "Batch: 551 , Combined Loss: tensor(0.5578, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7946946620941162\n",
      "Batch: 552 , Combined Loss: tensor(0.5477, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1006035804748535\n",
      "Batch: 553 , Combined Loss: tensor(0.8666, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6371214389801025\n",
      "Batch: 554 , Combined Loss: tensor(0.5751, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.241684913635254\n",
      "Batch: 555 , Combined Loss: tensor(0.5981, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0554580688476562\n",
      "Batch: 556 , Combined Loss: tensor(0.8180, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.746679425239563\n",
      "Batch: 557 , Combined Loss: tensor(0.6270, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.210463285446167\n",
      "Batch: 558 , Combined Loss: tensor(0.7165, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9707885980606079\n",
      "Batch: 559 , Combined Loss: tensor(0.5032, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0300331115722656\n",
      "Batch: 560 , Combined Loss: tensor(0.6407, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7753115892410278\n",
      "Batch: 561 , Combined Loss: tensor(0.5698, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3547595739364624\n",
      "Batch: 562 , Combined Loss: tensor(0.6602, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4902064800262451\n",
      "Batch: 563 , Combined Loss: tensor(0.5861, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.078399896621704\n",
      "Batch: 564 , Combined Loss: tensor(0.7432, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8856989145278931\n",
      "Batch: 565 , Combined Loss: tensor(0.9039, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8010984659194946\n",
      "Batch: 566 , Combined Loss: tensor(0.7048, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0333600044250488\n",
      "Batch: 567 , Combined Loss: tensor(0.5603, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1765410900115967\n",
      "Batch: 568 , Combined Loss: tensor(0.8189, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1066174507141113\n",
      "Batch: 569 , Combined Loss: tensor(0.5920, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.933749794960022\n",
      "Batch: 570 , Combined Loss: tensor(0.6676, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8536972999572754\n",
      "Batch: 571 , Combined Loss: tensor(1.0249, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6241474151611328\n",
      "Batch: 572 , Combined Loss: tensor(0.6166, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3740675449371338\n",
      "Batch: 573 , Combined Loss: tensor(0.5311, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9165751934051514\n",
      "Batch: 574 , Combined Loss: tensor(0.5542, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.960559606552124\n",
      "Batch: 575 , Combined Loss: tensor(0.5316, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8646252155303955\n",
      "Batch: 576 , Combined Loss: tensor(0.6561, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8986959457397461\n",
      "Batch: 577 , Combined Loss: tensor(0.5678, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23350656032562256\n",
      "Batch: 578 , Combined Loss: tensor(0.5599, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0023267269134521\n",
      "Batch: 579 , Combined Loss: tensor(0.6254, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6688873767852783\n",
      "Batch: 580 , Combined Loss: tensor(0.8025, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2255401611328125\n",
      "Batch: 581 , Combined Loss: tensor(0.6066, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8754839897155762\n",
      "Batch: 582 , Combined Loss: tensor(0.5370, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.09248828887939453\n",
      "Batch: 583 , Combined Loss: tensor(0.7544, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7181832790374756\n",
      "Batch: 584 , Combined Loss: tensor(0.5551, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9336291551589966\n",
      "Batch: 585 , Combined Loss: tensor(0.7938, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7274022102355957\n",
      "Batch: 586 , Combined Loss: tensor(0.6617, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9933860301971436\n",
      "Batch: 587 , Combined Loss: tensor(0.6127, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7936166524887085\n",
      "Batch: 588 , Combined Loss: tensor(0.7922, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4201200008392334\n",
      "Batch: 589 , Combined Loss: tensor(0.7072, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1033449172973633\n",
      "Batch: 590 , Combined Loss: tensor(0.5531, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1645629405975342\n",
      "Batch: 591 , Combined Loss: tensor(0.6066, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.078758955001831\n",
      "Batch: 592 , Combined Loss: tensor(0.5623, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.28171849250793457\n",
      "Batch: 593 , Combined Loss: tensor(0.6308, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1100373268127441\n",
      "Batch: 594 , Combined Loss: tensor(0.6535, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8591029644012451\n",
      "Batch: 595 , Combined Loss: tensor(0.7351, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45742976665496826\n",
      "Batch: 596 , Combined Loss: tensor(0.5565, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1116292476654053\n",
      "Batch: 597 , Combined Loss: tensor(0.6419, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7499368190765381\n",
      "Batch: 598 , Combined Loss: tensor(0.6777, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9640347957611084\n",
      "Batch: 599 , Combined Loss: tensor(0.5405, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.898167610168457\n",
      "Batch: 600 , Combined Loss: tensor(0.6097, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9619002342224121\n",
      "Batch: 601 , Combined Loss: tensor(0.5708, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8874859809875488\n",
      "Batch: 602 , Combined Loss: tensor(0.6593, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39850473403930664\n",
      "Batch: 603 , Combined Loss: tensor(0.7440, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6205464601516724\n",
      "Batch: 604 , Combined Loss: tensor(0.6527, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0434038639068604\n",
      "Batch: 605 , Combined Loss: tensor(0.5815, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8091583251953125\n",
      "Batch: 606 , Combined Loss: tensor(0.6494, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3711963891983032\n",
      "Batch: 607 , Combined Loss: tensor(0.4543, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8026502132415771\n",
      "Batch: 608 , Combined Loss: tensor(0.6768, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0440044403076172\n",
      "Batch: 609 , Combined Loss: tensor(0.8440, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5596191883087158\n",
      "Batch: 610 , Combined Loss: tensor(0.7557, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.91450035572052\n",
      "Batch: 611 , Combined Loss: tensor(0.6230, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42991602420806885\n",
      "Batch: 612 , Combined Loss: tensor(0.7944, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5433562994003296\n",
      "Batch: 613 , Combined Loss: tensor(0.6805, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7991180419921875\n",
      "Batch: 614 , Combined Loss: tensor(0.6205, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.128594160079956\n",
      "Batch: 615 , Combined Loss: tensor(0.6714, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6033605337142944\n",
      "Batch: 616 , Combined Loss: tensor(1.0455, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8706493377685547\n",
      "Batch: 617 , Combined Loss: tensor(0.6187, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9220626354217529\n",
      "Batch: 618 , Combined Loss: tensor(0.7291, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0990419387817383\n",
      "Batch: 619 , Combined Loss: tensor(0.8841, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3593834638595581\n",
      "Batch: 620 , Combined Loss: tensor(0.6373, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0644676685333252\n",
      "Batch: 621 , Combined Loss: tensor(0.7509, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8091738224029541\n",
      "Batch: 622 , Combined Loss: tensor(0.5851, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9671611785888672\n",
      "Batch: 623 , Combined Loss: tensor(0.6680, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9897983074188232\n",
      "Batch: 624 , Combined Loss: tensor(0.7336, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0241527557373047\n",
      "Batch: 625 , Combined Loss: tensor(0.6979, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5197889804840088\n",
      "Batch: 626 , Combined Loss: tensor(0.6573, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7485287189483643\n",
      "Batch: 627 , Combined Loss: tensor(0.7344, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24068200588226318\n",
      "Batch: 628 , Combined Loss: tensor(0.5782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0281834602355957\n",
      "----------Epoch 32, Loss: 0.6375552559410635, Accuracy: 0.9771256621198549, Dice Coef: [0.9899042016561536, 0.6779728631520753, 0.6796795723259553, 0.7796177795883272], Dice Coef Necrotic: 1.0243852678824403, Dice Coef Edema: 1.038719299477105, Dice Coef Enhancing: 1.0437754801839723, Sensitivity: [0.9818642121430232, 0.7613061473679703, 0.8920775268386771, 0.8796055176205021], Specificity: [0.9675907144864906, 0.9987557294448343, 0.9822998324524617, 0.9972458315009343], Precision: [0.998142684491526, 0.6671373308285059, 0.5789021182345052, 0.7339496523553108]\n",
      "Saving without nn.DataParallel\n",
      "Batch: 0 , Combined Loss: tensor(0.6278, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0306570529937744\n",
      "Batch: 1 , Combined Loss: tensor(0.5179, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9464101791381836\n",
      "Batch: 2 , Combined Loss: tensor(0.6331, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4290320873260498\n",
      "Batch: 3 , Combined Loss: tensor(0.6502, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.666972279548645\n",
      "Batch: 4 , Combined Loss: tensor(0.5618, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21917814016342163\n",
      "Batch: 5 , Combined Loss: tensor(0.5947, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.107236623764038\n",
      "Batch: 6 , Combined Loss: tensor(0.7982, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1612896919250488\n",
      "Batch: 7 , Combined Loss: tensor(0.5617, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.047536849975586\n",
      "Batch: 8 , Combined Loss: tensor(0.5694, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.80686354637146\n",
      "Batch: 9 , Combined Loss: tensor(0.5857, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9349720478057861\n",
      "Batch: 10 , Combined Loss: tensor(0.9270, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5137954950332642\n",
      "Batch: 11 , Combined Loss: tensor(0.5345, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7221968173980713\n",
      "Batch: 12 , Combined Loss: tensor(0.9034, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5999925136566162\n",
      "Batch: 13 , Combined Loss: tensor(0.6517, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.13985157012939453\n",
      "Batch: 14 , Combined Loss: tensor(0.7150, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9976519346237183\n",
      "Batch: 15 , Combined Loss: tensor(0.6238, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09654819965362549\n",
      "Batch: 16 , Combined Loss: tensor(0.5900, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8268886804580688\n",
      "Batch: 17 , Combined Loss: tensor(0.5637, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7002673149108887\n",
      "Batch: 18 , Combined Loss: tensor(0.6113, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.602357029914856\n",
      "Batch: 19 , Combined Loss: tensor(0.5461, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5618349313735962\n",
      "Batch: 20 , Combined Loss: tensor(0.7204, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4663541316986084\n",
      "Batch: 21 , Combined Loss: tensor(0.6087, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48394978046417236\n",
      "Batch: 22 , Combined Loss: tensor(0.5352, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9525187015533447\n",
      "Batch: 23 , Combined Loss: tensor(0.7096, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13606464862823486\n",
      "Batch: 24 , Combined Loss: tensor(0.8205, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7383949756622314\n",
      "Batch: 25 , Combined Loss: tensor(0.5892, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8197571039199829\n",
      "Batch: 26 , Combined Loss: tensor(0.5446, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0636284351348877\n",
      "Batch: 27 , Combined Loss: tensor(0.5498, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9702125787734985\n",
      "Batch: 28 , Combined Loss: tensor(0.5645, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7386752367019653\n",
      "Batch: 29 , Combined Loss: tensor(0.5788, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8959423303604126\n",
      "Batch: 30 , Combined Loss: tensor(0.5628, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0575392246246338\n",
      "Batch: 31 , Combined Loss: tensor(0.5233, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0682215690612793\n",
      "Batch: 32 , Combined Loss: tensor(0.6269, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8853778839111328\n",
      "Batch: 33 , Combined Loss: tensor(0.5123, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8282655477523804\n",
      "Batch: 34 , Combined Loss: tensor(0.6318, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8308409452438354\n",
      "Batch: 35 , Combined Loss: tensor(0.7084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.007136583328247\n",
      "Batch: 36 , Combined Loss: tensor(0.6475, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3350510597229004\n",
      "Batch: 37 , Combined Loss: tensor(0.5732, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49291086196899414\n",
      "Batch: 38 , Combined Loss: tensor(0.5397, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.1524619460105896\n",
      "Batch: 39 , Combined Loss: tensor(0.6532, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31981778144836426\n",
      "Batch: 40 , Combined Loss: tensor(0.6517, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8618420362472534\n",
      "Batch: 41 , Combined Loss: tensor(0.6352, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7060163021087646\n",
      "Batch: 42 , Combined Loss: tensor(0.7064, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1978365182876587\n",
      "Batch: 43 , Combined Loss: tensor(0.6180, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4087862968444824\n",
      "Batch: 44 , Combined Loss: tensor(0.6156, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7319433689117432\n",
      "Batch: 45 , Combined Loss: tensor(0.5689, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.708713173866272\n",
      "Batch: 46 , Combined Loss: tensor(0.6416, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6947391033172607\n",
      "Batch: 47 , Combined Loss: tensor(0.7299, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6883156299591064\n",
      "Batch: 48 , Combined Loss: tensor(0.5657, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7534657716751099\n",
      "Batch: 49 , Combined Loss: tensor(0.7218, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.044873952865600586\n",
      "Batch: 50 , Combined Loss: tensor(0.5663, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.820263147354126\n",
      "Batch: 51 , Combined Loss: tensor(0.5854, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0654680728912354\n",
      "Batch: 52 , Combined Loss: tensor(0.6708, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5127307176589966\n",
      "Batch: 53 , Combined Loss: tensor(0.6899, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6870640516281128\n",
      "Batch: 54 , Combined Loss: tensor(0.5476, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8118568658828735\n",
      "Batch: 55 , Combined Loss: tensor(0.5225, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2561776638031006\n",
      "Batch: 56 , Combined Loss: tensor(0.5352, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.061448574066162\n",
      "Batch: 57 , Combined Loss: tensor(0.6095, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9771275520324707\n",
      "Batch: 58 , Combined Loss: tensor(0.6721, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7519568204879761\n",
      "Batch: 59 , Combined Loss: tensor(0.7607, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48906373977661133\n",
      "Batch: 60 , Combined Loss: tensor(0.6392, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8202383518218994\n",
      "Batch: 61 , Combined Loss: tensor(0.6694, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5298957824707031\n",
      "Batch: 62 , Combined Loss: tensor(0.7753, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35028088092803955\n",
      "Batch: 63 , Combined Loss: tensor(0.6312, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9627702236175537\n",
      "Batch: 64 , Combined Loss: tensor(0.6331, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.116990327835083\n",
      "Batch: 65 , Combined Loss: tensor(0.5781, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.891609787940979\n",
      "Batch: 66 , Combined Loss: tensor(0.7237, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2323591709136963\n",
      "Batch: 67 , Combined Loss: tensor(0.5928, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.813740611076355\n",
      "Batch: 68 , Combined Loss: tensor(0.7534, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9857121706008911\n",
      "Batch: 69 , Combined Loss: tensor(0.6115, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0808799266815186\n",
      "Batch: 70 , Combined Loss: tensor(0.5559, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.140866994857788\n",
      "Batch: 71 , Combined Loss: tensor(0.6172, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3766392469406128\n",
      "Batch: 72 , Combined Loss: tensor(0.6061, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0598106384277344\n",
      "Batch: 73 , Combined Loss: tensor(0.5313, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1139874458312988\n",
      "Batch: 74 , Combined Loss: tensor(0.6347, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8676420450210571\n",
      "Batch: 75 , Combined Loss: tensor(0.6640, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8856170177459717\n",
      "Batch: 76 , Combined Loss: tensor(0.7482, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5715148448944092\n",
      "Batch: 77 , Combined Loss: tensor(0.5352, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5239880084991455\n",
      "Batch: 78 , Combined Loss: tensor(0.5647, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0107760429382324\n",
      "Batch: 79 , Combined Loss: tensor(0.6596, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6975040435791016\n",
      "Batch: 80 , Combined Loss: tensor(0.6722, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9397376775741577\n",
      "Batch: 81 , Combined Loss: tensor(0.5574, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9894295930862427\n",
      "Batch: 82 , Combined Loss: tensor(0.5786, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8981698751449585\n",
      "Batch: 83 , Combined Loss: tensor(0.6173, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8303347826004028\n",
      "Batch: 84 , Combined Loss: tensor(0.6404, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46333229541778564\n",
      "Batch: 85 , Combined Loss: tensor(0.5090, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47924816608428955\n",
      "Batch: 86 , Combined Loss: tensor(0.6841, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0380334854125977\n",
      "Batch: 87 , Combined Loss: tensor(0.5701, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9574650526046753\n",
      "Batch: 88 , Combined Loss: tensor(0.5515, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0064048767089844\n",
      "Batch: 89 , Combined Loss: tensor(0.5275, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.071817398071289\n",
      "Batch: 90 , Combined Loss: tensor(0.6848, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.901309609413147\n",
      "Batch: 91 , Combined Loss: tensor(0.5870, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7298671007156372\n",
      "Batch: 92 , Combined Loss: tensor(0.5109, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9136589765548706\n",
      "Batch: 93 , Combined Loss: tensor(0.7029, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9339586496353149\n",
      "Batch: 94 , Combined Loss: tensor(0.5862, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9415938854217529\n",
      "Batch: 95 , Combined Loss: tensor(0.7409, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.538954496383667\n",
      "Batch: 96 , Combined Loss: tensor(0.6091, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0654017925262451\n",
      "Batch: 97 , Combined Loss: tensor(0.5769, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.15561926364898682\n",
      "Batch: 98 , Combined Loss: tensor(0.6084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.015733540058135986\n",
      "Batch: 99 , Combined Loss: tensor(0.6367, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9922033548355103\n",
      "Batch: 100 , Combined Loss: tensor(0.6434, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.897736668586731\n",
      "Batch: 101 , Combined Loss: tensor(0.5591, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4678990840911865\n",
      "Batch: 102 , Combined Loss: tensor(0.6088, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6203194856643677\n",
      "Batch: 103 , Combined Loss: tensor(0.5771, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8523294925689697\n",
      "Batch: 104 , Combined Loss: tensor(0.5190, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9350910186767578\n",
      "Batch: 105 , Combined Loss: tensor(0.5730, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5145039558410645\n",
      "Batch: 106 , Combined Loss: tensor(0.7169, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9870339632034302\n",
      "Batch: 107 , Combined Loss: tensor(0.6184, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13119375705718994\n",
      "Batch: 108 , Combined Loss: tensor(0.5581, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0325021743774414\n",
      "Batch: 109 , Combined Loss: tensor(0.6730, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9841171503067017\n",
      "Batch: 110 , Combined Loss: tensor(0.6919, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7593443393707275\n",
      "Batch: 111 , Combined Loss: tensor(0.5841, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0301704406738281\n",
      "Batch: 112 , Combined Loss: tensor(0.5514, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3120917081832886\n",
      "Batch: 113 , Combined Loss: tensor(0.5473, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6522418260574341\n",
      "Batch: 114 , Combined Loss: tensor(0.6568, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8592813014984131\n",
      "Batch: 115 , Combined Loss: tensor(0.6021, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9745979309082031\n",
      "Batch: 116 , Combined Loss: tensor(0.9465, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7684810161590576\n",
      "Batch: 117 , Combined Loss: tensor(0.7231, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0580801963806152\n",
      "Batch: 118 , Combined Loss: tensor(0.7023, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9222499132156372\n",
      "Batch: 119 , Combined Loss: tensor(0.6281, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45646464824676514\n",
      "Batch: 120 , Combined Loss: tensor(0.7353, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9583213329315186\n",
      "Batch: 121 , Combined Loss: tensor(0.6243, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8145084381103516\n",
      "Batch: 122 , Combined Loss: tensor(0.5244, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0499234199523926\n",
      "Batch: 123 , Combined Loss: tensor(0.7034, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0682404041290283\n",
      "Batch: 124 , Combined Loss: tensor(0.6911, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7738465070724487\n",
      "Batch: 125 , Combined Loss: tensor(0.6250, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7254446744918823\n",
      "Batch: 126 , Combined Loss: tensor(0.6910, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1002109050750732\n",
      "Batch: 127 , Combined Loss: tensor(0.6288, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.122938632965088\n",
      "Batch: 128 , Combined Loss: tensor(0.5821, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5721324682235718\n",
      "Batch: 129 , Combined Loss: tensor(0.6911, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.027522087097168\n",
      "Batch: 130 , Combined Loss: tensor(0.5418, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9636379480361938\n",
      "Batch: 131 , Combined Loss: tensor(0.5473, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9523066282272339\n",
      "Batch: 132 , Combined Loss: tensor(0.6530, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6637852191925049\n",
      "Batch: 133 , Combined Loss: tensor(0.6006, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.984245777130127\n",
      "Batch: 134 , Combined Loss: tensor(0.7462, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9464757442474365\n",
      "Batch: 135 , Combined Loss: tensor(0.6773, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0387306213378906\n",
      "Batch: 136 , Combined Loss: tensor(0.5444, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0199086666107178\n",
      "Batch: 137 , Combined Loss: tensor(0.7044, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9987157583236694\n",
      "Batch: 138 , Combined Loss: tensor(0.7207, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0192303657531738\n",
      "Batch: 139 , Combined Loss: tensor(0.6584, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.35922181606292725\n",
      "Batch: 140 , Combined Loss: tensor(0.5967, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0944900512695312\n",
      "Batch: 141 , Combined Loss: tensor(0.5417, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19829142093658447\n",
      "Batch: 142 , Combined Loss: tensor(0.6680, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9294389486312866\n",
      "Batch: 143 , Combined Loss: tensor(0.5550, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7374556064605713\n",
      "Batch: 144 , Combined Loss: tensor(0.6827, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1724863052368164\n",
      "Batch: 145 , Combined Loss: tensor(0.5130, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29666125774383545\n",
      "Batch: 146 , Combined Loss: tensor(0.4929, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9812692403793335\n",
      "Batch: 147 , Combined Loss: tensor(0.5777, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9575842618942261\n",
      "Batch: 148 , Combined Loss: tensor(0.7159, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8206304311752319\n",
      "Batch: 149 , Combined Loss: tensor(0.5945, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4241821765899658\n",
      "Batch: 150 , Combined Loss: tensor(0.5137, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8157438039779663\n",
      "Batch: 151 , Combined Loss: tensor(0.5881, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1237921714782715\n",
      "Batch: 152 , Combined Loss: tensor(0.5291, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1946673393249512\n",
      "Batch: 153 , Combined Loss: tensor(0.8220, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2975892424583435\n",
      "Batch: 154 , Combined Loss: tensor(0.6392, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7055320739746094\n",
      "Batch: 155 , Combined Loss: tensor(0.6081, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8344452381134033\n",
      "Batch: 156 , Combined Loss: tensor(0.6785, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1314418315887451\n",
      "Batch: 157 , Combined Loss: tensor(0.5798, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.076573133468628\n",
      "Batch: 158 , Combined Loss: tensor(0.4428, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6254693269729614\n",
      "Batch: 159 , Combined Loss: tensor(0.5854, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6650015115737915\n",
      "Batch: 160 , Combined Loss: tensor(0.6405, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.927318811416626\n",
      "Batch: 161 , Combined Loss: tensor(0.6295, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9240283966064453\n",
      "Batch: 162 , Combined Loss: tensor(0.6429, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9727919101715088\n",
      "Batch: 163 , Combined Loss: tensor(0.7381, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7956366539001465\n",
      "Batch: 164 , Combined Loss: tensor(0.5307, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.284088134765625\n",
      "Batch: 165 , Combined Loss: tensor(0.6200, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1249456405639648\n",
      "Batch: 166 , Combined Loss: tensor(0.7484, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5050172805786133\n",
      "Batch: 167 , Combined Loss: tensor(0.8284, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4313812255859375\n",
      "Batch: 168 , Combined Loss: tensor(0.5887, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9122300148010254\n",
      "Batch: 169 , Combined Loss: tensor(0.4940, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8225375413894653\n",
      "Batch: 170 , Combined Loss: tensor(0.6636, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06420731544494629\n",
      "Batch: 171 , Combined Loss: tensor(0.5780, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.649635910987854\n",
      "Batch: 172 , Combined Loss: tensor(0.6283, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.381272554397583\n",
      "Batch: 173 , Combined Loss: tensor(0.5565, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1531894207000732\n",
      "Batch: 174 , Combined Loss: tensor(0.7918, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8426395654678345\n",
      "Batch: 175 , Combined Loss: tensor(0.6039, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9550098180770874\n",
      "Batch: 176 , Combined Loss: tensor(0.5641, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9835776090621948\n",
      "Batch: 177 , Combined Loss: tensor(0.5517, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.192190408706665\n",
      "Batch: 178 , Combined Loss: tensor(0.6293, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2110373973846436\n",
      "Batch: 179 , Combined Loss: tensor(0.8610, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7661298513412476\n",
      "Batch: 180 , Combined Loss: tensor(0.6319, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7404232025146484\n",
      "Batch: 181 , Combined Loss: tensor(0.4814, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.807185173034668\n",
      "Batch: 182 , Combined Loss: tensor(0.7707, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0287363529205322\n",
      "Batch: 183 , Combined Loss: tensor(0.7308, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45153844356536865\n",
      "Batch: 184 , Combined Loss: tensor(0.5055, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7919702529907227\n",
      "Batch: 185 , Combined Loss: tensor(0.5483, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0186054706573486\n",
      "Batch: 186 , Combined Loss: tensor(0.5971, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1216623783111572\n",
      "Batch: 187 , Combined Loss: tensor(0.6565, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.588543176651001\n",
      "Batch: 188 , Combined Loss: tensor(0.6002, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9299279451370239\n",
      "Batch: 189 , Combined Loss: tensor(0.8075, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8616737127304077\n",
      "Batch: 190 , Combined Loss: tensor(0.5411, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8786309957504272\n",
      "Batch: 191 , Combined Loss: tensor(0.7295, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.088219404220581\n",
      "Batch: 192 , Combined Loss: tensor(0.6065, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0418250560760498\n",
      "Batch: 193 , Combined Loss: tensor(0.5397, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0152826309204102\n",
      "Batch: 194 , Combined Loss: tensor(0.5432, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6744061708450317\n",
      "Batch: 195 , Combined Loss: tensor(0.4910, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9015839099884033\n",
      "Batch: 196 , Combined Loss: tensor(0.6829, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8077124357223511\n",
      "Batch: 197 , Combined Loss: tensor(0.7740, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5256420373916626\n",
      "Batch: 198 , Combined Loss: tensor(0.5628, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.330517053604126\n",
      "Batch: 199 , Combined Loss: tensor(0.5263, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7886695861816406\n",
      "Batch: 200 , Combined Loss: tensor(0.6877, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33985447883605957\n",
      "Batch: 201 , Combined Loss: tensor(0.5786, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1318883895874023\n",
      "Batch: 202 , Combined Loss: tensor(0.5983, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.869192361831665\n",
      "Batch: 203 , Combined Loss: tensor(0.6723, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.947820782661438\n",
      "Batch: 204 , Combined Loss: tensor(0.4729, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9215525388717651\n",
      "Batch: 205 , Combined Loss: tensor(0.6227, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.564378023147583\n",
      "Batch: 206 , Combined Loss: tensor(0.6745, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0197243690490723\n",
      "Batch: 207 , Combined Loss: tensor(0.4632, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8519890308380127\n",
      "Batch: 208 , Combined Loss: tensor(0.6079, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.000603199005127\n",
      "Batch: 209 , Combined Loss: tensor(0.5437, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1227812767028809\n",
      "Batch: 210 , Combined Loss: tensor(0.6236, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5310815572738647\n",
      "Batch: 211 , Combined Loss: tensor(1.1199, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4828096628189087\n",
      "Batch: 212 , Combined Loss: tensor(0.7113, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6772565841674805\n",
      "Batch: 213 , Combined Loss: tensor(0.8621, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0794813632965088\n",
      "Batch: 214 , Combined Loss: tensor(0.5742, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0160787105560303\n",
      "Batch: 215 , Combined Loss: tensor(0.6580, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9356709718704224\n",
      "Batch: 216 , Combined Loss: tensor(0.5370, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4956468343734741\n",
      "Batch: 217 , Combined Loss: tensor(0.5808, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9261164665222168\n",
      "Batch: 218 , Combined Loss: tensor(0.6117, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.094883680343628\n",
      "Batch: 219 , Combined Loss: tensor(0.5414, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8728048801422119\n",
      "Batch: 220 , Combined Loss: tensor(0.5068, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9308773279190063\n",
      "Batch: 221 , Combined Loss: tensor(0.6421, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5790954828262329\n",
      "Batch: 222 , Combined Loss: tensor(0.6676, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7451143264770508\n",
      "Batch: 223 , Combined Loss: tensor(0.6288, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9028561115264893\n",
      "Batch: 224 , Combined Loss: tensor(0.5511, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9249272346496582\n",
      "Batch: 225 , Combined Loss: tensor(0.6087, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7550245523452759\n",
      "Batch: 226 , Combined Loss: tensor(0.6326, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0561306476593018\n",
      "Batch: 227 , Combined Loss: tensor(0.5310, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1660902500152588\n",
      "Batch: 228 , Combined Loss: tensor(0.5872, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0849573612213135\n",
      "Batch: 229 , Combined Loss: tensor(0.7425, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7450227737426758\n",
      "Batch: 230 , Combined Loss: tensor(0.5594, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7803385257720947\n",
      "Batch: 231 , Combined Loss: tensor(0.6219, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8972427845001221\n",
      "Batch: 232 , Combined Loss: tensor(0.6843, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9564052820205688\n",
      "Batch: 233 , Combined Loss: tensor(0.6440, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.127636194229126\n",
      "Batch: 234 , Combined Loss: tensor(0.6453, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0072150230407715\n",
      "Batch: 235 , Combined Loss: tensor(0.6282, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9731205701828003\n",
      "Batch: 236 , Combined Loss: tensor(0.9704, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.843315839767456\n",
      "Batch: 237 , Combined Loss: tensor(0.7005, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8872189521789551\n",
      "Batch: 238 , Combined Loss: tensor(0.6381, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7292243242263794\n",
      "Batch: 239 , Combined Loss: tensor(0.6774, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0777263641357422\n",
      "Batch: 240 , Combined Loss: tensor(0.5723, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8769111633300781\n",
      "Batch: 241 , Combined Loss: tensor(0.7446, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.978005051612854\n",
      "Batch: 242 , Combined Loss: tensor(0.5854, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1086883544921875\n",
      "Batch: 243 , Combined Loss: tensor(0.5637, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6734974384307861\n",
      "Batch: 244 , Combined Loss: tensor(0.6114, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7813974618911743\n",
      "Batch: 245 , Combined Loss: tensor(0.7462, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6899005174636841\n",
      "Batch: 246 , Combined Loss: tensor(0.6920, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8808858394622803\n",
      "Batch: 247 , Combined Loss: tensor(0.6167, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1683337688446045\n",
      "Batch: 248 , Combined Loss: tensor(0.6360, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8403421640396118\n",
      "Batch: 249 , Combined Loss: tensor(0.6816, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0917341709136963\n",
      "Batch: 250 , Combined Loss: tensor(0.6201, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.240851879119873\n",
      "Batch: 251 , Combined Loss: tensor(0.6945, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.036064863204956\n",
      "Batch: 252 , Combined Loss: tensor(0.5739, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2099790573120117\n",
      "Batch: 253 , Combined Loss: tensor(0.7463, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8105266094207764\n",
      "Batch: 254 , Combined Loss: tensor(0.6555, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0055022239685059\n",
      "Batch: 255 , Combined Loss: tensor(0.5813, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9483588933944702\n",
      "Batch: 256 , Combined Loss: tensor(0.5674, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7302207946777344\n",
      "Batch: 257 , Combined Loss: tensor(0.8084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.741426944732666\n",
      "Batch: 258 , Combined Loss: tensor(0.7445, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6402269601821899\n",
      "Batch: 259 , Combined Loss: tensor(0.5501, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2357414960861206\n",
      "Batch: 260 , Combined Loss: tensor(0.6143, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8637408018112183\n",
      "Batch: 261 , Combined Loss: tensor(0.5640, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2656471729278564\n",
      "Batch: 262 , Combined Loss: tensor(0.5574, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8750823736190796\n",
      "Batch: 263 , Combined Loss: tensor(0.4933, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9573506116867065\n",
      "Batch: 264 , Combined Loss: tensor(0.5694, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4070923328399658\n",
      "Batch: 265 , Combined Loss: tensor(0.4857, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7572356462478638\n",
      "Batch: 266 , Combined Loss: tensor(0.7286, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0483531951904297\n",
      "Batch: 267 , Combined Loss: tensor(0.5476, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8950945138931274\n",
      "Batch: 268 , Combined Loss: tensor(0.6995, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9668200016021729\n",
      "Batch: 269 , Combined Loss: tensor(0.4727, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8540463447570801\n",
      "Batch: 270 , Combined Loss: tensor(0.8162, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9180655479431152\n",
      "Batch: 271 , Combined Loss: tensor(0.4889, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0161347389221191\n",
      "Batch: 272 , Combined Loss: tensor(0.5832, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7384209632873535\n",
      "Batch: 273 , Combined Loss: tensor(0.8322, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.39612114429473877\n",
      "Batch: 274 , Combined Loss: tensor(0.7200, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8539925813674927\n",
      "Batch: 275 , Combined Loss: tensor(0.6955, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8692317008972168\n",
      "Batch: 276 , Combined Loss: tensor(0.5848, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.21836847066879272\n",
      "Batch: 277 , Combined Loss: tensor(0.6013, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24979567527770996\n",
      "Batch: 278 , Combined Loss: tensor(0.5548, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0246095657348633\n",
      "Batch: 279 , Combined Loss: tensor(0.5651, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.773179292678833\n",
      "Batch: 280 , Combined Loss: tensor(0.5365, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8225932121276855\n",
      "Batch: 281 , Combined Loss: tensor(0.5090, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.875177264213562\n",
      "Batch: 282 , Combined Loss: tensor(0.6615, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9604600667953491\n",
      "Batch: 283 , Combined Loss: tensor(0.5594, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0445187091827393\n",
      "Batch: 284 , Combined Loss: tensor(0.6834, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5494320392608643\n",
      "Batch: 285 , Combined Loss: tensor(0.5422, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1679291725158691\n",
      "Batch: 286 , Combined Loss: tensor(0.5095, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9882205724716187\n",
      "Batch: 287 , Combined Loss: tensor(0.6164, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0449678897857666\n",
      "Batch: 288 , Combined Loss: tensor(0.6567, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8358460664749146\n",
      "Batch: 289 , Combined Loss: tensor(0.7028, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9704842567443848\n",
      "Batch: 290 , Combined Loss: tensor(0.7705, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7017700672149658\n",
      "Batch: 291 , Combined Loss: tensor(0.5598, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9723424911499023\n",
      "Batch: 292 , Combined Loss: tensor(0.7571, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.801451563835144\n",
      "Batch: 293 , Combined Loss: tensor(0.5689, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9752411842346191\n",
      "Batch: 294 , Combined Loss: tensor(0.5919, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.224891185760498\n",
      "Batch: 295 , Combined Loss: tensor(0.5748, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9484816789627075\n",
      "Batch: 296 , Combined Loss: tensor(0.5706, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9247455596923828\n",
      "Batch: 297 , Combined Loss: tensor(0.8100, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6216778755187988\n",
      "Batch: 298 , Combined Loss: tensor(0.7494, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7041312456130981\n",
      "Batch: 299 , Combined Loss: tensor(0.7699, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4801841974258423\n",
      "Batch: 300 , Combined Loss: tensor(0.5353, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1390271186828613\n",
      "Batch: 301 , Combined Loss: tensor(0.6920, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8378806114196777\n",
      "Batch: 302 , Combined Loss: tensor(0.5755, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.025634765625\n",
      "Batch: 303 , Combined Loss: tensor(0.7352, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9961791038513184\n",
      "Batch: 304 , Combined Loss: tensor(0.5782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.814681887626648\n",
      "Batch: 305 , Combined Loss: tensor(0.8066, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8185240030288696\n",
      "Batch: 306 , Combined Loss: tensor(0.5644, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.823296070098877\n",
      "Batch: 307 , Combined Loss: tensor(0.5276, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9365065097808838\n",
      "Batch: 308 , Combined Loss: tensor(0.5603, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9885603189468384\n",
      "Batch: 309 , Combined Loss: tensor(0.5909, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07141876220703125\n",
      "Batch: 310 , Combined Loss: tensor(0.5139, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7911533117294312\n",
      "Batch: 311 , Combined Loss: tensor(0.5810, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7546632289886475\n",
      "Batch: 312 , Combined Loss: tensor(0.6348, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0184824466705322\n",
      "Batch: 313 , Combined Loss: tensor(0.5679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2062978744506836\n",
      "Batch: 314 , Combined Loss: tensor(0.5424, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0370457172393799\n",
      "Batch: 315 , Combined Loss: tensor(0.5241, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8071045875549316\n",
      "Batch: 316 , Combined Loss: tensor(0.6211, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2507359981536865\n",
      "Batch: 317 , Combined Loss: tensor(0.6518, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0318388938903809\n",
      "Batch: 318 , Combined Loss: tensor(0.5266, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0102863311767578\n",
      "Batch: 319 , Combined Loss: tensor(0.6300, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8480855226516724\n",
      "Batch: 320 , Combined Loss: tensor(0.6147, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8074983358383179\n",
      "Batch: 321 , Combined Loss: tensor(0.7361, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1402113437652588\n",
      "Batch: 322 , Combined Loss: tensor(0.5919, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9454061985015869\n",
      "Batch: 323 , Combined Loss: tensor(0.6347, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9180350303649902\n",
      "Batch: 324 , Combined Loss: tensor(0.6934, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9103593826293945\n",
      "Batch: 325 , Combined Loss: tensor(0.5787, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9258157014846802\n",
      "Batch: 326 , Combined Loss: tensor(0.6874, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.049487590789795\n",
      "Batch: 327 , Combined Loss: tensor(0.6185, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.054065465927124\n",
      "Batch: 328 , Combined Loss: tensor(0.5837, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2390096187591553\n",
      "Batch: 329 , Combined Loss: tensor(0.5849, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.084315538406372\n",
      "Batch: 330 , Combined Loss: tensor(0.7275, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.029571533203125\n",
      "Batch: 331 , Combined Loss: tensor(0.5709, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.24090540409088135\n",
      "Batch: 332 , Combined Loss: tensor(0.6402, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.826583743095398\n",
      "Batch: 333 , Combined Loss: tensor(0.5925, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6120907068252563\n",
      "Batch: 334 , Combined Loss: tensor(0.7575, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.920738935470581\n",
      "Batch: 335 , Combined Loss: tensor(0.5663, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.092703104019165\n",
      "Batch: 336 , Combined Loss: tensor(0.5978, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.985611081123352\n",
      "Batch: 337 , Combined Loss: tensor(0.5346, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.831157922744751\n",
      "Batch: 338 , Combined Loss: tensor(0.5578, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.29272663593292236\n",
      "Batch: 339 , Combined Loss: tensor(0.6765, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9829733371734619\n",
      "Batch: 340 , Combined Loss: tensor(0.5812, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.148350715637207\n",
      "Batch: 341 , Combined Loss: tensor(0.6116, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1227855682373047\n",
      "Batch: 342 , Combined Loss: tensor(0.6641, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8005064725875854\n",
      "Batch: 343 , Combined Loss: tensor(0.5161, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8681623935699463\n",
      "Batch: 344 , Combined Loss: tensor(0.5578, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1571722030639648\n",
      "Batch: 345 , Combined Loss: tensor(0.6186, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0745062828063965\n",
      "Batch: 346 , Combined Loss: tensor(0.7302, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6344599723815918\n",
      "Batch: 347 , Combined Loss: tensor(0.5759, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.068788766860962\n",
      "Batch: 348 , Combined Loss: tensor(0.6204, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5955049991607666\n",
      "Batch: 349 , Combined Loss: tensor(0.5064, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7724946737289429\n",
      "Batch: 350 , Combined Loss: tensor(0.5610, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9736877679824829\n",
      "Batch: 351 , Combined Loss: tensor(0.6988, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4070931673049927\n",
      "Batch: 352 , Combined Loss: tensor(0.5760, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2347092628479004\n",
      "Batch: 353 , Combined Loss: tensor(0.6382, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2935391664505005\n",
      "Batch: 354 , Combined Loss: tensor(0.8626, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20621860027313232\n",
      "Batch: 355 , Combined Loss: tensor(0.5925, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8482704162597656\n",
      "Batch: 356 , Combined Loss: tensor(0.5484, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8987261056900024\n",
      "Batch: 357 , Combined Loss: tensor(0.6585, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9475222826004028\n",
      "Batch: 358 , Combined Loss: tensor(0.6017, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0035667419433594\n",
      "Batch: 359 , Combined Loss: tensor(0.6767, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0476117134094238\n",
      "Batch: 360 , Combined Loss: tensor(0.6303, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6463807821273804\n",
      "Batch: 361 , Combined Loss: tensor(0.5638, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.050790548324585\n",
      "Batch: 362 , Combined Loss: tensor(0.6027, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.33904457092285156\n",
      "Batch: 363 , Combined Loss: tensor(0.7280, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1584441661834717\n",
      "Batch: 364 , Combined Loss: tensor(0.6166, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8681497573852539\n",
      "Batch: 365 , Combined Loss: tensor(0.5504, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9896119832992554\n",
      "Batch: 366 , Combined Loss: tensor(0.5460, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8531094789505005\n",
      "Batch: 367 , Combined Loss: tensor(0.6529, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0362555980682373\n",
      "Batch: 368 , Combined Loss: tensor(0.5864, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9795006513595581\n",
      "Batch: 369 , Combined Loss: tensor(0.5594, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0576510429382324\n",
      "Batch: 370 , Combined Loss: tensor(0.5372, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.136408805847168\n",
      "Batch: 371 , Combined Loss: tensor(0.6033, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9249327182769775\n",
      "Batch: 372 , Combined Loss: tensor(0.6205, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1424789428710938\n",
      "Batch: 373 , Combined Loss: tensor(0.5787, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9435803890228271\n",
      "Batch: 374 , Combined Loss: tensor(0.5193, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2145075798034668\n",
      "Batch: 375 , Combined Loss: tensor(0.6299, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.144970178604126\n",
      "Batch: 376 , Combined Loss: tensor(0.6120, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.081739902496338\n",
      "Batch: 377 , Combined Loss: tensor(0.5537, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9280540943145752\n",
      "Batch: 378 , Combined Loss: tensor(0.5059, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7918440103530884\n",
      "Batch: 379 , Combined Loss: tensor(0.6569, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7102645635604858\n",
      "Batch: 380 , Combined Loss: tensor(0.6537, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.847419261932373\n",
      "Batch: 381 , Combined Loss: tensor(0.7704, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8856121301651001\n",
      "Batch: 382 , Combined Loss: tensor(0.5946, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4846888780593872\n",
      "Batch: 383 , Combined Loss: tensor(0.5890, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.119330883026123\n",
      "Batch: 384 , Combined Loss: tensor(0.6809, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0075693130493164\n",
      "Batch: 385 , Combined Loss: tensor(0.5763, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7723851203918457\n",
      "Batch: 386 , Combined Loss: tensor(0.5694, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0711450576782227\n",
      "Batch: 387 , Combined Loss: tensor(0.6575, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9047634601593018\n",
      "Batch: 388 , Combined Loss: tensor(0.6330, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1083416938781738\n",
      "Batch: 389 , Combined Loss: tensor(0.5650, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8879214525222778\n",
      "Batch: 390 , Combined Loss: tensor(0.5663, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2124117612838745\n",
      "Batch: 391 , Combined Loss: tensor(0.5337, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8239003419876099\n",
      "Batch: 392 , Combined Loss: tensor(0.5436, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7407652139663696\n",
      "Batch: 393 , Combined Loss: tensor(0.7190, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7956068515777588\n",
      "Batch: 394 , Combined Loss: tensor(0.6524, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7792474031448364\n",
      "Batch: 395 , Combined Loss: tensor(0.5686, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9928101301193237\n",
      "Batch: 396 , Combined Loss: tensor(0.5840, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6958225965499878\n",
      "Batch: 397 , Combined Loss: tensor(0.5411, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6912297010421753\n",
      "Batch: 398 , Combined Loss: tensor(0.6005, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1854181289672852\n",
      "Batch: 399 , Combined Loss: tensor(0.5662, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1218347549438477\n",
      "Batch: 400 , Combined Loss: tensor(0.5348, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7513043880462646\n",
      "Batch: 401 , Combined Loss: tensor(0.5853, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8418301343917847\n",
      "Batch: 402 , Combined Loss: tensor(0.7205, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9241935014724731\n",
      "Batch: 403 , Combined Loss: tensor(0.8680, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8282839059829712\n",
      "Batch: 404 , Combined Loss: tensor(0.5023, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6584516763687134\n",
      "Batch: 405 , Combined Loss: tensor(0.6475, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9792214632034302\n",
      "Batch: 406 , Combined Loss: tensor(0.5912, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7368969917297363\n",
      "Batch: 407 , Combined Loss: tensor(0.5023, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9249821901321411\n",
      "Batch: 408 , Combined Loss: tensor(0.6912, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0641908645629883\n",
      "Batch: 409 , Combined Loss: tensor(0.5627, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8634039163589478\n",
      "Batch: 410 , Combined Loss: tensor(0.6362, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7733349800109863\n",
      "Batch: 411 , Combined Loss: tensor(0.6689, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9478844404220581\n",
      "Batch: 412 , Combined Loss: tensor(1.0540, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.2162880301475525\n",
      "Batch: 413 , Combined Loss: tensor(0.5133, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7546786069869995\n",
      "Batch: 414 , Combined Loss: tensor(0.6463, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.070322036743164\n",
      "Batch: 415 , Combined Loss: tensor(0.5423, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0858840942382812\n",
      "Batch: 416 , Combined Loss: tensor(0.6380, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0935473442077637\n",
      "Batch: 417 , Combined Loss: tensor(0.5730, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2563707828521729\n",
      "Batch: 418 , Combined Loss: tensor(0.5314, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9883805513381958\n",
      "Batch: 419 , Combined Loss: tensor(0.5471, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9567934274673462\n",
      "Batch: 420 , Combined Loss: tensor(0.5855, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20340609550476074\n",
      "Batch: 421 , Combined Loss: tensor(0.5261, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.233647108078003\n",
      "Batch: 422 , Combined Loss: tensor(0.6206, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8778625726699829\n",
      "Batch: 423 , Combined Loss: tensor(0.7710, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9468499422073364\n",
      "Batch: 424 , Combined Loss: tensor(0.8003, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9607553482055664\n",
      "Batch: 425 , Combined Loss: tensor(0.5770, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7202417850494385\n",
      "Batch: 426 , Combined Loss: tensor(0.5918, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6804491281509399\n",
      "Batch: 427 , Combined Loss: tensor(0.6181, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9814375638961792\n",
      "Batch: 428 , Combined Loss: tensor(0.5350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0334508419036865\n",
      "Batch: 429 , Combined Loss: tensor(0.6284, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7616389989852905\n",
      "Batch: 430 , Combined Loss: tensor(0.6537, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7075142860412598\n",
      "Batch: 431 , Combined Loss: tensor(0.6127, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9052907228469849\n",
      "Batch: 432 , Combined Loss: tensor(0.5421, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.875151515007019\n",
      "Batch: 433 , Combined Loss: tensor(0.6008, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9567351341247559\n",
      "Batch: 434 , Combined Loss: tensor(0.9160, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44981837272644043\n",
      "Batch: 435 , Combined Loss: tensor(0.6769, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0373811721801758\n",
      "Batch: 436 , Combined Loss: tensor(0.7383, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8124021291732788\n",
      "Batch: 437 , Combined Loss: tensor(0.5595, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0622751712799072\n",
      "Batch: 438 , Combined Loss: tensor(0.6498, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9999680519104004\n",
      "Batch: 439 , Combined Loss: tensor(0.5654, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1181871891021729\n",
      "Batch: 440 , Combined Loss: tensor(0.8193, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6207607984542847\n",
      "Batch: 441 , Combined Loss: tensor(0.6450, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9047400951385498\n",
      "Batch: 442 , Combined Loss: tensor(0.5315, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0855636596679688\n",
      "Batch: 443 , Combined Loss: tensor(0.5322, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0336248874664307\n",
      "Batch: 444 , Combined Loss: tensor(0.5481, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9158068895339966\n",
      "Batch: 445 , Combined Loss: tensor(0.6999, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.895384669303894\n",
      "Batch: 446 , Combined Loss: tensor(0.6791, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.27996182441711426\n",
      "Batch: 447 , Combined Loss: tensor(0.6511, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9975014925003052\n",
      "Batch: 448 , Combined Loss: tensor(0.6171, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7794543504714966\n",
      "Batch: 449 , Combined Loss: tensor(0.6114, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1166260242462158\n",
      "Batch: 450 , Combined Loss: tensor(0.6425, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9252474308013916\n",
      "Batch: 451 , Combined Loss: tensor(0.8653, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.109400987625122\n",
      "Batch: 452 , Combined Loss: tensor(0.5515, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6725133657455444\n",
      "Batch: 453 , Combined Loss: tensor(0.6279, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5030261278152466\n",
      "Batch: 454 , Combined Loss: tensor(0.5958, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2121622562408447\n",
      "Batch: 455 , Combined Loss: tensor(0.9806, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7974874973297119\n",
      "Batch: 456 , Combined Loss: tensor(0.4708, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9059593677520752\n",
      "Batch: 457 , Combined Loss: tensor(0.7724, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14547908306121826\n",
      "Batch: 458 , Combined Loss: tensor(0.8315, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8877356052398682\n",
      "Batch: 459 , Combined Loss: tensor(0.7264, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9203928709030151\n",
      "Batch: 460 , Combined Loss: tensor(1.0010, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4704979658126831\n",
      "Batch: 461 , Combined Loss: tensor(0.5492, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1125445365905762\n",
      "Batch: 462 , Combined Loss: tensor(0.5504, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8968708515167236\n",
      "Batch: 463 , Combined Loss: tensor(0.6493, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.928641676902771\n",
      "Batch: 464 , Combined Loss: tensor(0.8587, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0079684257507324\n",
      "Batch: 465 , Combined Loss: tensor(0.6033, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.122279167175293\n",
      "Batch: 466 , Combined Loss: tensor(0.8442, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8900104761123657\n",
      "Batch: 467 , Combined Loss: tensor(0.6797, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7550554275512695\n",
      "Batch: 468 , Combined Loss: tensor(0.7458, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2004258632659912\n",
      "Batch: 469 , Combined Loss: tensor(0.5622, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.040546178817749\n",
      "Batch: 470 , Combined Loss: tensor(0.5570, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0425758361816406\n",
      "Batch: 471 , Combined Loss: tensor(0.5267, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7099461555480957\n",
      "Batch: 472 , Combined Loss: tensor(0.5538, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3153872489929199\n",
      "Batch: 473 , Combined Loss: tensor(0.5356, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.090435266494751\n",
      "Batch: 474 , Combined Loss: tensor(0.7293, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2079942226409912\n",
      "Batch: 475 , Combined Loss: tensor(0.6509, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25803685188293457\n",
      "Batch: 476 , Combined Loss: tensor(0.7442, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0182394981384277\n",
      "Batch: 477 , Combined Loss: tensor(0.5182, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1197841167449951\n",
      "Batch: 478 , Combined Loss: tensor(0.5574, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.26034045219421387\n",
      "Batch: 479 , Combined Loss: tensor(0.7074, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7671011686325073\n",
      "Batch: 480 , Combined Loss: tensor(0.6323, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5995219945907593\n",
      "Batch: 481 , Combined Loss: tensor(0.5792, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6955970525741577\n",
      "Batch: 482 , Combined Loss: tensor(0.6027, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0902507305145264\n",
      "Batch: 483 , Combined Loss: tensor(0.7997, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0328397750854492\n",
      "Batch: 484 , Combined Loss: tensor(0.6298, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6717455387115479\n",
      "Batch: 485 , Combined Loss: tensor(0.6049, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6876195669174194\n",
      "Batch: 486 , Combined Loss: tensor(0.5523, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8455148935317993\n",
      "Batch: 487 , Combined Loss: tensor(0.7737, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7017897367477417\n",
      "Batch: 488 , Combined Loss: tensor(0.7576, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8727031946182251\n",
      "Batch: 489 , Combined Loss: tensor(0.6342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6513700485229492\n",
      "Batch: 490 , Combined Loss: tensor(0.9646, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.902256965637207\n",
      "Batch: 491 , Combined Loss: tensor(0.6467, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0553948879241943\n",
      "Batch: 492 , Combined Loss: tensor(0.6932, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9016003608703613\n",
      "Batch: 493 , Combined Loss: tensor(0.5757, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9487026929855347\n",
      "Batch: 494 , Combined Loss: tensor(0.8866, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.23717963695526123\n",
      "Batch: 495 , Combined Loss: tensor(0.6239, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9976370334625244\n",
      "Batch: 496 , Combined Loss: tensor(0.6207, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9286437034606934\n",
      "Batch: 497 , Combined Loss: tensor(0.5333, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.972297191619873\n",
      "Batch: 498 , Combined Loss: tensor(0.5146, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.841218113899231\n",
      "Batch: 499 , Combined Loss: tensor(0.5678, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8592933416366577\n",
      "Batch: 500 , Combined Loss: tensor(0.5900, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8700569868087769\n",
      "Batch: 501 , Combined Loss: tensor(0.5582, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.024824619293213\n",
      "Batch: 502 , Combined Loss: tensor(0.6976, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8962172269821167\n",
      "Batch: 503 , Combined Loss: tensor(0.8893, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.19748365879058838\n",
      "Batch: 504 , Combined Loss: tensor(0.6010, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0502712726593018\n",
      "Batch: 505 , Combined Loss: tensor(0.6005, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40885961055755615\n",
      "Batch: 506 , Combined Loss: tensor(0.5340, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8896751403808594\n",
      "Batch: 507 , Combined Loss: tensor(0.5663, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9141536951065063\n",
      "Batch: 508 , Combined Loss: tensor(0.5700, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.090505838394165\n",
      "Batch: 509 , Combined Loss: tensor(0.8688, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.03719252347946167\n",
      "Batch: 510 , Combined Loss: tensor(0.6043, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0539348125457764\n",
      "Batch: 511 , Combined Loss: tensor(0.6014, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6277446746826172\n",
      "Batch: 512 , Combined Loss: tensor(0.6698, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9363391399383545\n",
      "Batch: 513 , Combined Loss: tensor(0.6871, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8605033159255981\n",
      "Batch: 514 , Combined Loss: tensor(0.5391, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4976705312728882\n",
      "Batch: 515 , Combined Loss: tensor(0.6056, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0743560791015625\n",
      "Batch: 516 , Combined Loss: tensor(0.7038, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9375560283660889\n",
      "Batch: 517 , Combined Loss: tensor(0.6206, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9965218305587769\n",
      "Batch: 518 , Combined Loss: tensor(0.5504, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1813833713531494\n",
      "Batch: 519 , Combined Loss: tensor(0.6268, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9766135215759277\n",
      "Batch: 520 , Combined Loss: tensor(0.6342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45155441761016846\n",
      "Batch: 521 , Combined Loss: tensor(0.7555, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4787508249282837\n",
      "Batch: 522 , Combined Loss: tensor(0.5679, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0021998882293701\n",
      "Batch: 523 , Combined Loss: tensor(0.6143, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0525195598602295\n",
      "Batch: 524 , Combined Loss: tensor(0.5304, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.211700201034546\n",
      "Batch: 525 , Combined Loss: tensor(0.5785, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.958760142326355\n",
      "Batch: 526 , Combined Loss: tensor(0.5523, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1122076511383057\n",
      "Batch: 527 , Combined Loss: tensor(0.6293, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8736259937286377\n",
      "Batch: 528 , Combined Loss: tensor(0.6734, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5743488073348999\n",
      "Batch: 529 , Combined Loss: tensor(0.7226, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6631461381912231\n",
      "Batch: 530 , Combined Loss: tensor(0.5123, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.522858738899231\n",
      "Batch: 531 , Combined Loss: tensor(0.7922, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6352906227111816\n",
      "Batch: 532 , Combined Loss: tensor(0.6209, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.249659776687622\n",
      "Batch: 533 , Combined Loss: tensor(0.6674, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6052916049957275\n",
      "Batch: 534 , Combined Loss: tensor(0.7284, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5435053110122681\n",
      "Batch: 535 , Combined Loss: tensor(0.8360, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9189271926879883\n",
      "Batch: 536 , Combined Loss: tensor(0.5837, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23298144340515137\n",
      "Batch: 537 , Combined Loss: tensor(0.5883, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6817152500152588\n",
      "Batch: 538 , Combined Loss: tensor(0.7032, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5001916885375977\n",
      "Batch: 539 , Combined Loss: tensor(0.6652, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3853719234466553\n",
      "Batch: 540 , Combined Loss: tensor(0.6187, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0547735691070557\n",
      "Batch: 541 , Combined Loss: tensor(0.6219, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08539938926696777\n",
      "Batch: 542 , Combined Loss: tensor(0.5432, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.4114999771118164\n",
      "Batch: 543 , Combined Loss: tensor(0.5620, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4787447452545166\n",
      "Batch: 544 , Combined Loss: tensor(0.8559, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0354783535003662\n",
      "Batch: 545 , Combined Loss: tensor(0.7063, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0113060474395752\n",
      "Batch: 546 , Combined Loss: tensor(0.6375, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1027729511260986\n",
      "Batch: 547 , Combined Loss: tensor(0.5975, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0491912364959717\n",
      "Batch: 548 , Combined Loss: tensor(0.8582, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08186471462249756\n",
      "Batch: 549 , Combined Loss: tensor(0.5618, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0942881107330322\n",
      "Batch: 550 , Combined Loss: tensor(0.5523, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6743819713592529\n",
      "Batch: 551 , Combined Loss: tensor(0.5750, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9036303758621216\n",
      "Batch: 552 , Combined Loss: tensor(0.8371, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3814373016357422\n",
      "Batch: 553 , Combined Loss: tensor(0.5644, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.836167573928833\n",
      "Batch: 554 , Combined Loss: tensor(0.5557, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8158396482467651\n",
      "Batch: 555 , Combined Loss: tensor(0.5402, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8861485719680786\n",
      "Batch: 556 , Combined Loss: tensor(0.6721, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.11082816123962402\n",
      "Batch: 557 , Combined Loss: tensor(0.6385, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7540404796600342\n",
      "Batch: 558 , Combined Loss: tensor(0.6491, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0345053672790527\n",
      "Batch: 559 , Combined Loss: tensor(0.6096, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9977166652679443\n",
      "Batch: 560 , Combined Loss: tensor(0.6552, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.13102972507476807\n",
      "Batch: 561 , Combined Loss: tensor(0.6790, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1282093524932861\n",
      "Batch: 562 , Combined Loss: tensor(0.6874, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7413876056671143\n",
      "Batch: 563 , Combined Loss: tensor(0.5070, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8944449424743652\n",
      "Batch: 564 , Combined Loss: tensor(0.6110, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5629985332489014\n",
      "Batch: 565 , Combined Loss: tensor(0.5264, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8892799615859985\n",
      "Batch: 566 , Combined Loss: tensor(0.7534, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.409753680229187\n",
      "Batch: 567 , Combined Loss: tensor(0.5002, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7327420711517334\n",
      "Batch: 568 , Combined Loss: tensor(0.8149, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5723564624786377\n",
      "Batch: 569 , Combined Loss: tensor(0.5684, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1063671112060547\n",
      "Batch: 570 , Combined Loss: tensor(0.7084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7032496929168701\n",
      "Batch: 571 , Combined Loss: tensor(0.6422, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0893142223358154\n",
      "Batch: 572 , Combined Loss: tensor(0.5642, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.663528323173523\n",
      "Batch: 573 , Combined Loss: tensor(0.6334, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3090038299560547\n",
      "Batch: 574 , Combined Loss: tensor(0.6064, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8994014263153076\n",
      "Batch: 575 , Combined Loss: tensor(0.8808, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7189031839370728\n",
      "Batch: 576 , Combined Loss: tensor(0.5057, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.040501356124878\n",
      "Batch: 577 , Combined Loss: tensor(0.5504, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0745055675506592\n",
      "Batch: 578 , Combined Loss: tensor(0.7711, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8030623197555542\n",
      "Batch: 579 , Combined Loss: tensor(0.5806, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0995256900787354\n",
      "Batch: 580 , Combined Loss: tensor(0.5305, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5668188333511353\n",
      "Batch: 581 , Combined Loss: tensor(0.5957, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9544823169708252\n",
      "Batch: 582 , Combined Loss: tensor(0.4907, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5429596900939941\n",
      "Batch: 583 , Combined Loss: tensor(0.5342, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6802492141723633\n",
      "Batch: 584 , Combined Loss: tensor(0.5831, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.881971001625061\n",
      "Batch: 585 , Combined Loss: tensor(0.6133, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12178421020507812\n",
      "Batch: 586 , Combined Loss: tensor(0.7424, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.799075722694397\n",
      "Batch: 587 , Combined Loss: tensor(0.5119, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3612140417098999\n",
      "Batch: 588 , Combined Loss: tensor(0.5998, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6049710512161255\n",
      "Batch: 589 , Combined Loss: tensor(0.6186, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43969011306762695\n",
      "Batch: 590 , Combined Loss: tensor(1.2119, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2026979923248291\n",
      "Batch: 591 , Combined Loss: tensor(0.6399, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.02564781904220581\n",
      "Batch: 592 , Combined Loss: tensor(0.5477, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4939589500427246\n",
      "Batch: 593 , Combined Loss: tensor(0.6879, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.22597622871398926\n",
      "Batch: 594 , Combined Loss: tensor(0.7231, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.853024959564209\n",
      "Batch: 595 , Combined Loss: tensor(0.5732, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3783383369445801\n",
      "Batch: 596 , Combined Loss: tensor(0.6593, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1312875747680664\n",
      "Batch: 597 , Combined Loss: tensor(0.6068, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9818280935287476\n",
      "Batch: 598 , Combined Loss: tensor(0.5652, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.842915415763855\n",
      "Batch: 599 , Combined Loss: tensor(0.5981, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6294620037078857\n",
      "Batch: 600 , Combined Loss: tensor(0.7240, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.790835976600647\n",
      "Batch: 601 , Combined Loss: tensor(0.9393, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.006082534790039\n",
      "Batch: 602 , Combined Loss: tensor(0.5616, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0466337203979492\n",
      "Batch: 603 , Combined Loss: tensor(0.5933, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7121903896331787\n",
      "Batch: 604 , Combined Loss: tensor(0.6935, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.34289348125457764\n",
      "Batch: 605 , Combined Loss: tensor(1.3626, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4962151050567627\n",
      "Batch: 606 , Combined Loss: tensor(0.5540, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9339706897735596\n",
      "Batch: 607 , Combined Loss: tensor(0.8129, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.790026068687439\n",
      "Batch: 608 , Combined Loss: tensor(0.5524, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.074293613433838\n",
      "Batch: 609 , Combined Loss: tensor(0.5857, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9016896486282349\n",
      "Batch: 610 , Combined Loss: tensor(0.5497, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8606464862823486\n",
      "Batch: 611 , Combined Loss: tensor(0.5698, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0074431896209717\n",
      "Batch: 612 , Combined Loss: tensor(0.5910, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.035374402999878\n",
      "Batch: 613 , Combined Loss: tensor(0.5587, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9739474058151245\n",
      "Batch: 614 , Combined Loss: tensor(0.5559, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2112135887145996\n",
      "Batch: 615 , Combined Loss: tensor(0.6073, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.161055326461792\n",
      "Batch: 616 , Combined Loss: tensor(0.5473, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5808112621307373\n",
      "Batch: 617 , Combined Loss: tensor(0.5499, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8759275674819946\n",
      "Batch: 618 , Combined Loss: tensor(0.6277, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0431592464447021\n",
      "Batch: 619 , Combined Loss: tensor(0.6119, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31142914295196533\n",
      "Batch: 620 , Combined Loss: tensor(0.5913, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.189298152923584\n",
      "Batch: 621 , Combined Loss: tensor(0.5877, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5449521541595459\n",
      "Batch: 622 , Combined Loss: tensor(0.6441, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0443356037139893\n",
      "Batch: 623 , Combined Loss: tensor(0.5793, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0741088390350342\n",
      "Batch: 624 , Combined Loss: tensor(0.5683, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7679357528686523\n",
      "Batch: 625 , Combined Loss: tensor(1.1254, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.595702052116394\n",
      "Batch: 626 , Combined Loss: tensor(0.7479, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3594413995742798\n",
      "Batch: 627 , Combined Loss: tensor(0.6952, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1526834964752197\n",
      "Batch: 628 , Combined Loss: tensor(0.5626, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0564322471618652\n",
      "----------Epoch 33, Loss: 0.6321755366219246, Accuracy: 0.9786733193693176, Dice Coef: [0.9906281802347241, 0.68476238449358, 0.6909173896147286, 0.7759509799425707], Dice Coef Necrotic: 1.0136734094752509, Dice Coef Edema: 1.0331904372467797, Dice Coef Enhancing: 1.0323212719193129, Sensitivity: [0.9834184688301268, 0.7733212316413195, 0.8906850926637271, 0.874184950285951], Specificity: [0.9661243285966034, 0.9988703120304405, 0.9838754343304232, 0.9972939244893473], Precision: [0.997995925347642, 0.6696326361487165, 0.5925710638573003, 0.7351625021930195]\n",
      "Saving without nn.DataParallel\n",
      "Batch: 0 , Combined Loss: tensor(0.5761, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.06324243545532227\n",
      "Batch: 1 , Combined Loss: tensor(0.6077, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.373555064201355\n",
      "Batch: 2 , Combined Loss: tensor(0.6367, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9628890752792358\n",
      "Batch: 3 , Combined Loss: tensor(0.5611, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5041435956954956\n",
      "Batch: 4 , Combined Loss: tensor(0.6489, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0486202239990234\n",
      "Batch: 5 , Combined Loss: tensor(0.5357, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0079126358032227\n",
      "Batch: 6 , Combined Loss: tensor(0.5352, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.356691837310791\n",
      "Batch: 7 , Combined Loss: tensor(0.6438, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.099905252456665\n",
      "Batch: 8 , Combined Loss: tensor(0.6905, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0012977123260498\n",
      "Batch: 9 , Combined Loss: tensor(0.6080, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1754605770111084\n",
      "Batch: 10 , Combined Loss: tensor(0.6429, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9910929203033447\n",
      "Batch: 11 , Combined Loss: tensor(0.7329, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.067694902420044\n",
      "Batch: 12 , Combined Loss: tensor(0.4937, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7062925100326538\n",
      "Batch: 13 , Combined Loss: tensor(0.6020, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9356000423431396\n",
      "Batch: 14 , Combined Loss: tensor(0.6053, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7369276285171509\n",
      "Batch: 15 , Combined Loss: tensor(0.5637, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0083026885986328\n",
      "Batch: 16 , Combined Loss: tensor(0.5140, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9915027618408203\n",
      "Batch: 17 , Combined Loss: tensor(0.6249, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9176782369613647\n",
      "Batch: 18 , Combined Loss: tensor(0.6321, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9164062738418579\n",
      "Batch: 19 , Combined Loss: tensor(0.6425, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5462430715560913\n",
      "Batch: 20 , Combined Loss: tensor(0.5196, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2530333995819092\n",
      "Batch: 21 , Combined Loss: tensor(0.5856, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9520599842071533\n",
      "Batch: 22 , Combined Loss: tensor(0.6113, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9413149356842041\n",
      "Batch: 23 , Combined Loss: tensor(0.6335, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9227434396743774\n",
      "Batch: 24 , Combined Loss: tensor(0.6395, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9233860969543457\n",
      "Batch: 25 , Combined Loss: tensor(0.5363, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1518735885620117\n",
      "Batch: 26 , Combined Loss: tensor(0.6249, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8931704759597778\n",
      "Batch: 27 , Combined Loss: tensor(0.5036, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8178073167800903\n",
      "Batch: 28 , Combined Loss: tensor(0.8121, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0031054019927979\n",
      "Batch: 29 , Combined Loss: tensor(0.6002, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1280207633972168\n",
      "Batch: 30 , Combined Loss: tensor(0.5861, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.133732557296753\n",
      "Batch: 31 , Combined Loss: tensor(0.6673, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.035043716430664\n",
      "Batch: 32 , Combined Loss: tensor(0.5686, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.720878005027771\n",
      "Batch: 33 , Combined Loss: tensor(0.6452, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9005221128463745\n",
      "Batch: 34 , Combined Loss: tensor(0.7018, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.068213701248169\n",
      "Batch: 35 , Combined Loss: tensor(0.6732, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8460686206817627\n",
      "Batch: 36 , Combined Loss: tensor(0.6652, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0321898460388184\n",
      "Batch: 37 , Combined Loss: tensor(0.5478, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3001277446746826\n",
      "Batch: 38 , Combined Loss: tensor(0.5706, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0794098377227783\n",
      "Batch: 39 , Combined Loss: tensor(0.5089, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.662338376045227\n",
      "Batch: 40 , Combined Loss: tensor(0.7609, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8666858673095703\n",
      "Batch: 41 , Combined Loss: tensor(0.6737, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.065039873123169\n",
      "Batch: 42 , Combined Loss: tensor(1.3116, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4498797655105591\n",
      "Batch: 43 , Combined Loss: tensor(0.5369, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.966101884841919\n",
      "Batch: 44 , Combined Loss: tensor(0.6060, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.092336654663086\n",
      "Batch: 45 , Combined Loss: tensor(0.5521, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1681947708129883\n",
      "Batch: 46 , Combined Loss: tensor(0.8181, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0668628215789795\n",
      "Batch: 47 , Combined Loss: tensor(0.6567, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1398117542266846\n",
      "Batch: 48 , Combined Loss: tensor(0.6317, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0483534336090088\n",
      "Batch: 49 , Combined Loss: tensor(0.5766, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0616331100463867\n",
      "Batch: 50 , Combined Loss: tensor(0.9745, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7998685836791992\n",
      "Batch: 51 , Combined Loss: tensor(0.6515, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.038508415222168\n",
      "Batch: 52 , Combined Loss: tensor(0.7984, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.631069540977478\n",
      "Batch: 53 , Combined Loss: tensor(0.5698, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0990450382232666\n",
      "Batch: 54 , Combined Loss: tensor(0.6025, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5971907377243042\n",
      "Batch: 55 , Combined Loss: tensor(0.7149, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.152980089187622\n",
      "Batch: 56 , Combined Loss: tensor(0.6145, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0045533180236816\n",
      "Batch: 57 , Combined Loss: tensor(0.6067, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0719974040985107\n",
      "Batch: 58 , Combined Loss: tensor(0.5863, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0696051120758057\n",
      "Batch: 59 , Combined Loss: tensor(0.6854, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9092544317245483\n",
      "Batch: 60 , Combined Loss: tensor(0.6950, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9744948148727417\n",
      "Batch: 61 , Combined Loss: tensor(0.6365, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8135232925415039\n",
      "Batch: 62 , Combined Loss: tensor(0.5251, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2140491008758545\n",
      "Batch: 63 , Combined Loss: tensor(0.5233, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0812175273895264\n",
      "Batch: 64 , Combined Loss: tensor(0.6203, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1255664825439453\n",
      "Batch: 65 , Combined Loss: tensor(0.6755, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1239490509033203\n",
      "Batch: 66 , Combined Loss: tensor(0.6120, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3185181617736816\n",
      "Batch: 67 , Combined Loss: tensor(0.6573, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0042319297790527\n",
      "Batch: 68 , Combined Loss: tensor(0.7412, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7156420946121216\n",
      "Batch: 69 , Combined Loss: tensor(0.5319, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0945429801940918\n",
      "Batch: 70 , Combined Loss: tensor(0.5887, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.102996587753296\n",
      "Batch: 71 , Combined Loss: tensor(0.6188, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.157827377319336\n",
      "Batch: 72 , Combined Loss: tensor(0.5086, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0188331604003906\n",
      "Batch: 73 , Combined Loss: tensor(0.5446, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9146268367767334\n",
      "Batch: 74 , Combined Loss: tensor(0.7620, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0518591403961182\n",
      "Batch: 75 , Combined Loss: tensor(0.7493, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1630020141601562\n",
      "Batch: 76 , Combined Loss: tensor(0.5481, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7330467700958252\n",
      "Batch: 77 , Combined Loss: tensor(0.7422, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8368867635726929\n",
      "Batch: 78 , Combined Loss: tensor(0.5465, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9966813325881958\n",
      "Batch: 79 , Combined Loss: tensor(0.5467, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9628698825836182\n",
      "Batch: 80 , Combined Loss: tensor(0.7071, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1971678733825684\n",
      "Batch: 81 , Combined Loss: tensor(0.6607, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4550992250442505\n",
      "Batch: 82 , Combined Loss: tensor(0.5628, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0009820461273193\n",
      "Batch: 83 , Combined Loss: tensor(0.4920, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9664452075958252\n",
      "Batch: 84 , Combined Loss: tensor(0.5250, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.150338888168335\n",
      "Batch: 85 , Combined Loss: tensor(0.5693, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0740656852722168\n",
      "Batch: 86 , Combined Loss: tensor(0.8867, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2379164695739746\n",
      "Batch: 87 , Combined Loss: tensor(0.6894, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0602045059204102\n",
      "Batch: 88 , Combined Loss: tensor(0.8207, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.919094443321228\n",
      "Batch: 89 , Combined Loss: tensor(0.6148, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9452099800109863\n",
      "Batch: 90 , Combined Loss: tensor(0.8106, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8442169427871704\n",
      "Batch: 91 , Combined Loss: tensor(0.5431, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2922475337982178\n",
      "Batch: 92 , Combined Loss: tensor(0.6241, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8016124963760376\n",
      "Batch: 93 , Combined Loss: tensor(0.5380, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0540375709533691\n",
      "Batch: 94 , Combined Loss: tensor(0.6296, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7373747825622559\n",
      "Batch: 95 , Combined Loss: tensor(0.5827, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1476051807403564\n",
      "Batch: 96 , Combined Loss: tensor(0.5877, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.260765552520752\n",
      "Batch: 97 , Combined Loss: tensor(0.6186, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1305849552154541\n",
      "Batch: 98 , Combined Loss: tensor(0.5855, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.882080078125\n",
      "Batch: 99 , Combined Loss: tensor(0.5275, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4406231641769409\n",
      "Batch: 100 , Combined Loss: tensor(0.5386, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0352137088775635\n",
      "Batch: 101 , Combined Loss: tensor(0.6061, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7560641765594482\n",
      "Batch: 102 , Combined Loss: tensor(0.5261, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5067766904830933\n",
      "Batch: 103 , Combined Loss: tensor(0.6089, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5990866422653198\n",
      "Batch: 104 , Combined Loss: tensor(0.5788, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9044804573059082\n",
      "Batch: 105 , Combined Loss: tensor(0.5824, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1773200035095215\n",
      "Batch: 106 , Combined Loss: tensor(0.5447, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6989561319351196\n",
      "Batch: 107 , Combined Loss: tensor(0.5714, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1142652034759521\n",
      "Batch: 108 , Combined Loss: tensor(0.6870, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0320491790771484\n",
      "Batch: 109 , Combined Loss: tensor(0.6193, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6783885955810547\n",
      "Batch: 110 , Combined Loss: tensor(0.6581, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.039247989654541\n",
      "Batch: 111 , Combined Loss: tensor(0.5421, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5965083837509155\n",
      "Batch: 112 , Combined Loss: tensor(0.6206, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.955302357673645\n",
      "Batch: 113 , Combined Loss: tensor(0.5624, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0156311988830566\n",
      "Batch: 114 , Combined Loss: tensor(0.5924, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0191004276275635\n",
      "Batch: 115 , Combined Loss: tensor(0.6001, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6468856334686279\n",
      "Batch: 116 , Combined Loss: tensor(0.6971, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1302440166473389\n",
      "Batch: 117 , Combined Loss: tensor(0.5752, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9131232500076294\n",
      "Batch: 118 , Combined Loss: tensor(0.5574, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9428563117980957\n",
      "Batch: 119 , Combined Loss: tensor(0.7394, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7162526845932007\n",
      "Batch: 120 , Combined Loss: tensor(0.5698, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7403818368911743\n",
      "Batch: 121 , Combined Loss: tensor(0.8963, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5179497003555298\n",
      "Batch: 122 , Combined Loss: tensor(0.5187, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0866897106170654\n",
      "Batch: 123 , Combined Loss: tensor(0.6751, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0057601928710938\n",
      "Batch: 124 , Combined Loss: tensor(0.5419, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1167163848876953\n",
      "Batch: 125 , Combined Loss: tensor(0.5603, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9547082185745239\n",
      "Batch: 126 , Combined Loss: tensor(0.6804, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7836928367614746\n",
      "Batch: 127 , Combined Loss: tensor(0.5677, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3219977617263794\n",
      "Batch: 128 , Combined Loss: tensor(0.5427, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0529649257659912\n",
      "Batch: 129 , Combined Loss: tensor(0.8491, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0070643424987793\n",
      "Batch: 130 , Combined Loss: tensor(0.7146, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0332233905792236\n",
      "Batch: 131 , Combined Loss: tensor(0.6973, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6569315195083618\n",
      "Batch: 132 , Combined Loss: tensor(0.4943, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7753376960754395\n",
      "Batch: 133 , Combined Loss: tensor(0.6424, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0357882976531982\n",
      "Batch: 134 , Combined Loss: tensor(0.6884, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8879358768463135\n",
      "Batch: 135 , Combined Loss: tensor(0.5877, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9145375490188599\n",
      "Batch: 136 , Combined Loss: tensor(0.6550, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0210039615631104\n",
      "Batch: 137 , Combined Loss: tensor(0.5595, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9988412857055664\n",
      "Batch: 138 , Combined Loss: tensor(0.6274, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9446371793746948\n",
      "Batch: 139 , Combined Loss: tensor(0.6068, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.950519323348999\n",
      "Batch: 140 , Combined Loss: tensor(0.7971, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.07739925384521484\n",
      "Batch: 141 , Combined Loss: tensor(0.5365, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7031310796737671\n",
      "Batch: 142 , Combined Loss: tensor(0.6776, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.25285303592681885\n",
      "Batch: 143 , Combined Loss: tensor(0.7776, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8168909549713135\n",
      "Batch: 144 , Combined Loss: tensor(0.6318, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7848285436630249\n",
      "Batch: 145 , Combined Loss: tensor(0.6379, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.13044387102127075\n",
      "Batch: 146 , Combined Loss: tensor(0.6437, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9744645357131958\n",
      "Batch: 147 , Combined Loss: tensor(0.5596, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20556223392486572\n",
      "Batch: 148 , Combined Loss: tensor(0.7234, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.30365312099456787\n",
      "Batch: 149 , Combined Loss: tensor(0.7001, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8610807657241821\n",
      "Batch: 150 , Combined Loss: tensor(0.5966, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2578631639480591\n",
      "Batch: 151 , Combined Loss: tensor(0.6561, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0696959495544434\n",
      "Batch: 152 , Combined Loss: tensor(0.5571, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0172436237335205\n",
      "Batch: 153 , Combined Loss: tensor(1.0282, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4797121286392212\n",
      "Batch: 154 , Combined Loss: tensor(0.7501, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7023235559463501\n",
      "Batch: 155 , Combined Loss: tensor(0.6366, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9320800304412842\n",
      "Batch: 156 , Combined Loss: tensor(0.5739, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.098938226699829\n",
      "Batch: 157 , Combined Loss: tensor(0.7076, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9213072061538696\n",
      "Batch: 158 , Combined Loss: tensor(0.5800, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1837077140808105\n",
      "Batch: 159 , Combined Loss: tensor(0.5276, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8145531415939331\n",
      "Batch: 160 , Combined Loss: tensor(0.6990, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.682722806930542\n",
      "Batch: 161 , Combined Loss: tensor(0.6220, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8276244401931763\n",
      "Batch: 162 , Combined Loss: tensor(0.6935, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5144891738891602\n",
      "Batch: 163 , Combined Loss: tensor(0.6967, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2161788940429688\n",
      "Batch: 164 , Combined Loss: tensor(0.6224, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.46491527557373047\n",
      "Batch: 165 , Combined Loss: tensor(0.5438, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.724353551864624\n",
      "Batch: 166 , Combined Loss: tensor(0.6870, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9918301105499268\n",
      "Batch: 167 , Combined Loss: tensor(0.5857, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6976443529129028\n",
      "Batch: 168 , Combined Loss: tensor(0.6274, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2984992265701294\n",
      "Batch: 169 , Combined Loss: tensor(0.5867, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.075685977935791\n",
      "Batch: 170 , Combined Loss: tensor(0.6181, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.856492280960083\n",
      "Batch: 171 , Combined Loss: tensor(0.6594, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0085816383361816\n",
      "Batch: 172 , Combined Loss: tensor(0.5920, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8652507066726685\n",
      "Batch: 173 , Combined Loss: tensor(0.5688, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5350440740585327\n",
      "Batch: 174 , Combined Loss: tensor(0.7842, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49938857555389404\n",
      "Batch: 175 , Combined Loss: tensor(0.6530, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1896524429321289\n",
      "Batch: 176 , Combined Loss: tensor(0.6088, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7594007253646851\n",
      "Batch: 177 , Combined Loss: tensor(0.5427, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6276782751083374\n",
      "Batch: 178 , Combined Loss: tensor(0.6973, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0314395427703857\n",
      "Batch: 179 , Combined Loss: tensor(0.4988, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8036375045776367\n",
      "Batch: 180 , Combined Loss: tensor(0.5062, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9799313545227051\n",
      "Batch: 181 , Combined Loss: tensor(0.5864, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2494058609008789\n",
      "Batch: 182 , Combined Loss: tensor(0.5893, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8968517780303955\n",
      "Batch: 183 , Combined Loss: tensor(0.5955, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.20828759670257568\n",
      "Batch: 184 , Combined Loss: tensor(0.6510, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.955561637878418\n",
      "Batch: 185 , Combined Loss: tensor(0.6019, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6385688781738281\n",
      "Batch: 186 , Combined Loss: tensor(0.7844, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6750937700271606\n",
      "Batch: 187 , Combined Loss: tensor(0.5836, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.17100763320922852\n",
      "Batch: 188 , Combined Loss: tensor(0.8245, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6963789463043213\n",
      "Batch: 189 , Combined Loss: tensor(0.5905, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8563117980957031\n",
      "Batch: 190 , Combined Loss: tensor(0.6703, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9531005620956421\n",
      "Batch: 191 , Combined Loss: tensor(0.5708, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.050731897354126\n",
      "Batch: 192 , Combined Loss: tensor(0.6666, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8590917587280273\n",
      "Batch: 193 , Combined Loss: tensor(0.6718, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0055201053619385\n",
      "Batch: 194 , Combined Loss: tensor(0.7351, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7215700149536133\n",
      "Batch: 195 , Combined Loss: tensor(0.6249, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7461647987365723\n",
      "Batch: 196 , Combined Loss: tensor(0.7024, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.31245678663253784\n",
      "Batch: 197 , Combined Loss: tensor(0.6206, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45301735401153564\n",
      "Batch: 198 , Combined Loss: tensor(0.5246, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7183496952056885\n",
      "Batch: 199 , Combined Loss: tensor(0.6313, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.23934507369995117\n",
      "Batch: 200 , Combined Loss: tensor(0.6939, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.1029198169708252\n",
      "Batch: 201 , Combined Loss: tensor(0.6358, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8891515731811523\n",
      "Batch: 202 , Combined Loss: tensor(0.5579, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9635093212127686\n",
      "Batch: 203 , Combined Loss: tensor(0.5694, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5988612174987793\n",
      "Batch: 204 , Combined Loss: tensor(0.5605, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8890841007232666\n",
      "Batch: 205 , Combined Loss: tensor(0.4633, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.761909008026123\n",
      "Batch: 206 , Combined Loss: tensor(0.6544, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.0594179630279541\n",
      "Batch: 207 , Combined Loss: tensor(0.5772, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9214658737182617\n",
      "Batch: 208 , Combined Loss: tensor(0.5534, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.044874906539917\n",
      "Batch: 209 , Combined Loss: tensor(0.6569, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.09076899290084839\n",
      "Batch: 210 , Combined Loss: tensor(0.6578, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8785660266876221\n",
      "Batch: 211 , Combined Loss: tensor(0.6721, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.98958420753479\n",
      "Batch: 212 , Combined Loss: tensor(0.5234, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9190099239349365\n",
      "Batch: 213 , Combined Loss: tensor(0.5078, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6064499616622925\n",
      "Batch: 214 , Combined Loss: tensor(0.6259, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7515555620193481\n",
      "Batch: 215 , Combined Loss: tensor(0.6627, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6357792615890503\n",
      "Batch: 216 , Combined Loss: tensor(0.5083, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0932037830352783\n",
      "Batch: 217 , Combined Loss: tensor(0.6098, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0841078758239746\n",
      "Batch: 218 , Combined Loss: tensor(0.8199, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6360887289047241\n",
      "Batch: 219 , Combined Loss: tensor(0.6269, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9004384279251099\n",
      "Batch: 220 , Combined Loss: tensor(0.6892, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6254466772079468\n",
      "Batch: 221 , Combined Loss: tensor(0.5279, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7687579393386841\n",
      "Batch: 222 , Combined Loss: tensor(0.6748, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8927936553955078\n",
      "Batch: 223 , Combined Loss: tensor(0.5364, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1643495559692383\n",
      "Batch: 224 , Combined Loss: tensor(0.7044, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0927073955535889\n",
      "Batch: 225 , Combined Loss: tensor(0.5135, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0085961818695068\n",
      "Batch: 226 , Combined Loss: tensor(0.5476, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9598941802978516\n",
      "Batch: 227 , Combined Loss: tensor(0.4851, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.921588659286499\n",
      "Batch: 228 , Combined Loss: tensor(0.5428, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.102367877960205\n",
      "Batch: 229 , Combined Loss: tensor(0.7044, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9981429576873779\n",
      "Batch: 230 , Combined Loss: tensor(0.5576, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0612850189208984\n",
      "Batch: 231 , Combined Loss: tensor(0.5129, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8364245891571045\n",
      "Batch: 232 , Combined Loss: tensor(0.6419, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8831477165222168\n",
      "Batch: 233 , Combined Loss: tensor(0.5141, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9858790636062622\n",
      "Batch: 234 , Combined Loss: tensor(0.4882, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7241034507751465\n",
      "Batch: 235 , Combined Loss: tensor(0.5718, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.006638765335083\n",
      "Batch: 236 , Combined Loss: tensor(0.5728, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0031559467315674\n",
      "Batch: 237 , Combined Loss: tensor(0.5909, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1800506114959717\n",
      "Batch: 238 , Combined Loss: tensor(0.6862, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8829153776168823\n",
      "Batch: 239 , Combined Loss: tensor(0.5998, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8075480461120605\n",
      "Batch: 240 , Combined Loss: tensor(0.7048, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9512777328491211\n",
      "Batch: 241 , Combined Loss: tensor(0.6462, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.053711175918579\n",
      "Batch: 242 , Combined Loss: tensor(0.6863, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6577519178390503\n",
      "Batch: 243 , Combined Loss: tensor(0.5893, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8505983352661133\n",
      "Batch: 244 , Combined Loss: tensor(0.6719, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1285297870635986\n",
      "Batch: 245 , Combined Loss: tensor(0.6035, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6801142692565918\n",
      "Batch: 246 , Combined Loss: tensor(0.5763, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9787721633911133\n",
      "Batch: 247 , Combined Loss: tensor(0.5190, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1336205005645752\n",
      "Batch: 248 , Combined Loss: tensor(0.5494, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9561265707015991\n",
      "Batch: 249 , Combined Loss: tensor(0.6828, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8679163455963135\n",
      "Batch: 250 , Combined Loss: tensor(0.6404, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0064446926116943\n",
      "Batch: 251 , Combined Loss: tensor(0.8546, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0963852405548096\n",
      "Batch: 252 , Combined Loss: tensor(0.5525, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1822528839111328\n",
      "Batch: 253 , Combined Loss: tensor(0.4847, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9827631711959839\n",
      "Batch: 254 , Combined Loss: tensor(0.5488, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8068716526031494\n",
      "Batch: 255 , Combined Loss: tensor(0.6447, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.44852137565612793\n",
      "Batch: 256 , Combined Loss: tensor(0.5349, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.38442885875701904\n",
      "Batch: 257 , Combined Loss: tensor(0.8710, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12169766426086426\n",
      "Batch: 258 , Combined Loss: tensor(0.5150, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9393709897994995\n",
      "Batch: 259 , Combined Loss: tensor(0.6722, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0300500392913818\n",
      "Batch: 260 , Combined Loss: tensor(0.6758, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8026981353759766\n",
      "Batch: 261 , Combined Loss: tensor(0.6252, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9798398017883301\n",
      "Batch: 262 , Combined Loss: tensor(0.6350, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.681289792060852\n",
      "Batch: 263 , Combined Loss: tensor(0.7529, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5044040679931641\n",
      "Batch: 264 , Combined Loss: tensor(0.6633, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0020251274108887\n",
      "Batch: 265 , Combined Loss: tensor(0.5539, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2427916526794434\n",
      "Batch: 266 , Combined Loss: tensor(0.6435, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5825315713882446\n",
      "Batch: 267 , Combined Loss: tensor(0.5086, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9904793500900269\n",
      "Batch: 268 , Combined Loss: tensor(0.7609, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.01265287399292\n",
      "Batch: 269 , Combined Loss: tensor(0.5551, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2893608808517456\n",
      "Batch: 270 , Combined Loss: tensor(0.5712, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2538869380950928\n",
      "Batch: 271 , Combined Loss: tensor(0.6031, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4398322105407715\n",
      "Batch: 272 , Combined Loss: tensor(0.6139, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9191607236862183\n",
      "Batch: 273 , Combined Loss: tensor(0.6891, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3712434768676758\n",
      "Batch: 274 , Combined Loss: tensor(0.8220, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8012312650680542\n",
      "Batch: 275 , Combined Loss: tensor(0.5234, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.3662056922912598\n",
      "Batch: 276 , Combined Loss: tensor(0.5104, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.068608283996582\n",
      "Batch: 277 , Combined Loss: tensor(0.6828, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7064176797866821\n",
      "Batch: 278 , Combined Loss: tensor(0.5305, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1692125797271729\n",
      "Batch: 279 , Combined Loss: tensor(1.0374, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7260140180587769\n",
      "Batch: 280 , Combined Loss: tensor(0.5794, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7100772857666016\n",
      "Batch: 281 , Combined Loss: tensor(0.5555, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7307231426239014\n",
      "Batch: 282 , Combined Loss: tensor(0.6782, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.48812711238861084\n",
      "Batch: 283 , Combined Loss: tensor(0.6325, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7515134811401367\n",
      "Batch: 284 , Combined Loss: tensor(0.5506, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7791084051132202\n",
      "Batch: 285 , Combined Loss: tensor(0.9989, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9337574243545532\n",
      "Batch: 286 , Combined Loss: tensor(0.5308, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9500818252563477\n",
      "Batch: 287 , Combined Loss: tensor(0.5857, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2230775356292725\n",
      "Batch: 288 , Combined Loss: tensor(0.7246, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8115757703781128\n",
      "Batch: 289 , Combined Loss: tensor(0.6302, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4954735040664673\n",
      "Batch: 290 , Combined Loss: tensor(0.6013, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.087836503982544\n",
      "Batch: 291 , Combined Loss: tensor(0.6741, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.869346022605896\n",
      "Batch: 292 , Combined Loss: tensor(0.9532, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8043595552444458\n",
      "Batch: 293 , Combined Loss: tensor(0.5839, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8292204141616821\n",
      "Batch: 294 , Combined Loss: tensor(0.5592, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8687005043029785\n",
      "Batch: 295 , Combined Loss: tensor(0.6844, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9634305238723755\n",
      "Batch: 296 , Combined Loss: tensor(0.5625, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8272751569747925\n",
      "Batch: 297 , Combined Loss: tensor(0.6957, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9888448715209961\n",
      "Batch: 298 , Combined Loss: tensor(0.4939, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8460497856140137\n",
      "Batch: 299 , Combined Loss: tensor(0.5731, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1250572204589844\n",
      "Batch: 300 , Combined Loss: tensor(0.7066, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0248701572418213\n",
      "Batch: 301 , Combined Loss: tensor(0.6092, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9532772302627563\n",
      "Batch: 302 , Combined Loss: tensor(0.6513, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7066986560821533\n",
      "Batch: 303 , Combined Loss: tensor(0.7217, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9338334798812866\n",
      "Batch: 304 , Combined Loss: tensor(0.5937, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1915578842163086\n",
      "Batch: 305 , Combined Loss: tensor(0.7435, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6006019115447998\n",
      "Batch: 306 , Combined Loss: tensor(0.8181, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0709054470062256\n",
      "Batch: 307 , Combined Loss: tensor(0.8923, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.19017374515533447\n",
      "Batch: 308 , Combined Loss: tensor(0.6084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7864822149276733\n",
      "Batch: 309 , Combined Loss: tensor(0.6220, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9698079824447632\n",
      "Batch: 310 , Combined Loss: tensor(0.6336, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8613277673721313\n",
      "Batch: 311 , Combined Loss: tensor(0.5642, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8097879886627197\n",
      "Batch: 312 , Combined Loss: tensor(0.5830, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.706391453742981\n",
      "Batch: 313 , Combined Loss: tensor(0.6474, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2302207946777344\n",
      "Batch: 314 , Combined Loss: tensor(0.6049, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.037405014038086\n",
      "Batch: 315 , Combined Loss: tensor(0.6627, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0726971626281738\n",
      "Batch: 316 , Combined Loss: tensor(0.6233, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.013035774230957\n",
      "Batch: 317 , Combined Loss: tensor(0.5445, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7437371015548706\n",
      "Batch: 318 , Combined Loss: tensor(0.5506, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9197797775268555\n",
      "Batch: 319 , Combined Loss: tensor(0.6107, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.906704306602478\n",
      "Batch: 320 , Combined Loss: tensor(0.5270, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.000152826309204\n",
      "Batch: 321 , Combined Loss: tensor(1.2904, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4759988784790039\n",
      "Batch: 322 , Combined Loss: tensor(1.0256, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9463256597518921\n",
      "Batch: 323 , Combined Loss: tensor(0.8811, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8540308475494385\n",
      "Batch: 324 , Combined Loss: tensor(0.7385, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7229814529418945\n",
      "Batch: 325 , Combined Loss: tensor(0.5938, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5800000429153442\n",
      "Batch: 326 , Combined Loss: tensor(0.6641, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9719992876052856\n",
      "Batch: 327 , Combined Loss: tensor(0.7062, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6529422998428345\n",
      "Batch: 328 , Combined Loss: tensor(0.5988, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9963247776031494\n",
      "Batch: 329 , Combined Loss: tensor(0.6493, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.119992971420288\n",
      "Batch: 330 , Combined Loss: tensor(0.5385, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.829208254814148\n",
      "Batch: 331 , Combined Loss: tensor(0.7738, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8005610704421997\n",
      "Batch: 332 , Combined Loss: tensor(0.6740, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7086187601089478\n",
      "Batch: 333 , Combined Loss: tensor(0.5599, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7911008596420288\n",
      "Batch: 334 , Combined Loss: tensor(0.8088, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7225505113601685\n",
      "Batch: 335 , Combined Loss: tensor(0.5673, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0892133712768555\n",
      "Batch: 336 , Combined Loss: tensor(0.6543, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8710747957229614\n",
      "Batch: 337 , Combined Loss: tensor(0.5908, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9656517505645752\n",
      "Batch: 338 , Combined Loss: tensor(0.7317, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9791831970214844\n",
      "Batch: 339 , Combined Loss: tensor(0.6399, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9051550626754761\n",
      "Batch: 340 , Combined Loss: tensor(0.7051, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0537757873535156\n",
      "Batch: 341 , Combined Loss: tensor(0.6454, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7709739208221436\n",
      "Batch: 342 , Combined Loss: tensor(0.5494, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5269663333892822\n",
      "Batch: 343 , Combined Loss: tensor(0.8016, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7096697092056274\n",
      "Batch: 344 , Combined Loss: tensor(0.4960, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.544554591178894\n",
      "Batch: 345 , Combined Loss: tensor(0.6661, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8063756227493286\n",
      "Batch: 346 , Combined Loss: tensor(0.5283, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.206636667251587\n",
      "Batch: 347 , Combined Loss: tensor(0.5939, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8368077278137207\n",
      "Batch: 348 , Combined Loss: tensor(0.8162, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9669989347457886\n",
      "Batch: 349 , Combined Loss: tensor(0.8002, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0249085426330566\n",
      "Batch: 350 , Combined Loss: tensor(0.6018, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0045757293701172\n",
      "Batch: 351 , Combined Loss: tensor(0.6212, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.195967435836792\n",
      "Batch: 352 , Combined Loss: tensor(0.6479, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.095278024673462\n",
      "Batch: 353 , Combined Loss: tensor(0.6488, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0146641731262207\n",
      "Batch: 354 , Combined Loss: tensor(0.6272, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0333174467086792\n",
      "Batch: 355 , Combined Loss: tensor(0.6792, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0110743045806885\n",
      "Batch: 356 , Combined Loss: tensor(0.5577, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3907850980758667\n",
      "Batch: 357 , Combined Loss: tensor(0.6233, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8032441139221191\n",
      "Batch: 358 , Combined Loss: tensor(0.5968, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9002379179000854\n",
      "Batch: 359 , Combined Loss: tensor(0.8013, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0046226978302002\n",
      "Batch: 360 , Combined Loss: tensor(0.7808, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.058760762214660645\n",
      "Batch: 361 , Combined Loss: tensor(0.5809, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9891254901885986\n",
      "Batch: 362 , Combined Loss: tensor(0.5314, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.00178861618042\n",
      "Batch: 363 , Combined Loss: tensor(0.6272, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0416455268859863\n",
      "Batch: 364 , Combined Loss: tensor(0.5634, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.14528942108154297\n",
      "Batch: 365 , Combined Loss: tensor(0.5949, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8466447591781616\n",
      "Batch: 366 , Combined Loss: tensor(0.7120, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9319720268249512\n",
      "Batch: 367 , Combined Loss: tensor(0.5685, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7914812564849854\n",
      "Batch: 368 , Combined Loss: tensor(0.5329, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7608736753463745\n",
      "Batch: 369 , Combined Loss: tensor(0.6112, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6803549528121948\n",
      "Batch: 370 , Combined Loss: tensor(0.6084, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.775847315788269\n",
      "Batch: 371 , Combined Loss: tensor(0.8227, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7519352436065674\n",
      "Batch: 372 , Combined Loss: tensor(0.6640, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.39593803882598877\n",
      "Batch: 373 , Combined Loss: tensor(0.6595, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.2214066982269287\n",
      "Batch: 374 , Combined Loss: tensor(0.7385, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.49417638778686523\n",
      "Batch: 375 , Combined Loss: tensor(0.6409, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0462994575500488\n",
      "Batch: 376 , Combined Loss: tensor(0.6269, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0181827545166016\n",
      "Batch: 377 , Combined Loss: tensor(0.6694, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9057590961456299\n",
      "Batch: 378 , Combined Loss: tensor(0.6016, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8934465646743774\n",
      "Batch: 379 , Combined Loss: tensor(0.6534, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8394858837127686\n",
      "Batch: 380 , Combined Loss: tensor(0.5928, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8230834007263184\n",
      "Batch: 381 , Combined Loss: tensor(0.6579, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7435111999511719\n",
      "Batch: 382 , Combined Loss: tensor(0.6291, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9865738153457642\n",
      "Batch: 383 , Combined Loss: tensor(0.6072, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5824143886566162\n",
      "Batch: 384 , Combined Loss: tensor(0.6805, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.26287680864334106\n",
      "Batch: 385 , Combined Loss: tensor(0.6658, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6674809455871582\n",
      "Batch: 386 , Combined Loss: tensor(0.6663, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.26415419578552246\n",
      "Batch: 387 , Combined Loss: tensor(0.5780, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.2631765604019165\n",
      "Batch: 388 , Combined Loss: tensor(0.6979, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.43527543544769287\n",
      "Batch: 389 , Combined Loss: tensor(0.7903, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6026087999343872\n",
      "Batch: 390 , Combined Loss: tensor(0.7457, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.3204500675201416\n",
      "Batch: 391 , Combined Loss: tensor(0.7082, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.45083165168762207\n",
      "Batch: 392 , Combined Loss: tensor(0.5700, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5587248802185059\n",
      "Batch: 393 , Combined Loss: tensor(0.7066, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0247633457183838\n",
      "Batch: 394 , Combined Loss: tensor(0.5501, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8370081186294556\n",
      "Batch: 395 , Combined Loss: tensor(0.6159, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9608999490737915\n",
      "Batch: 396 , Combined Loss: tensor(0.5933, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5060899257659912\n",
      "Batch: 397 , Combined Loss: tensor(0.5918, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8982281684875488\n",
      "Batch: 398 , Combined Loss: tensor(0.6821, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4383152723312378\n",
      "Batch: 399 , Combined Loss: tensor(0.6062, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8919832706451416\n",
      "Batch: 400 , Combined Loss: tensor(0.5391, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6105614900588989\n",
      "Batch: 401 , Combined Loss: tensor(0.9044, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.12167811393737793\n",
      "Batch: 402 , Combined Loss: tensor(0.7036, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.15812289714813232\n",
      "Batch: 403 , Combined Loss: tensor(0.5707, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5427960157394409\n",
      "Batch: 404 , Combined Loss: tensor(0.6520, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7781436443328857\n",
      "Batch: 405 , Combined Loss: tensor(0.6169, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0023777484893799\n",
      "Batch: 406 , Combined Loss: tensor(0.6070, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7346259355545044\n",
      "Batch: 407 , Combined Loss: tensor(0.5595, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9778211116790771\n",
      "Batch: 408 , Combined Loss: tensor(0.6381, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.42308568954467773\n",
      "Batch: 409 , Combined Loss: tensor(0.7951, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.796086311340332\n",
      "Batch: 410 , Combined Loss: tensor(0.6568, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9582796096801758\n",
      "Batch: 411 , Combined Loss: tensor(0.6699, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9303630590438843\n",
      "Batch: 412 , Combined Loss: tensor(0.5306, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7670227289199829\n",
      "Batch: 413 , Combined Loss: tensor(0.5859, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1685662269592285\n",
      "Batch: 414 , Combined Loss: tensor(0.6204, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0127801895141602\n",
      "Batch: 415 , Combined Loss: tensor(0.5894, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6263717412948608\n",
      "Batch: 416 , Combined Loss: tensor(0.5829, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.46793168783187866\n",
      "Batch: 417 , Combined Loss: tensor(0.6087, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9374912977218628\n",
      "Batch: 418 , Combined Loss: tensor(0.6141, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4469491243362427\n",
      "Batch: 419 , Combined Loss: tensor(0.7006, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4942983388900757\n",
      "Batch: 420 , Combined Loss: tensor(0.6528, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8723964691162109\n",
      "Batch: 421 , Combined Loss: tensor(0.5983, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.88420569896698\n",
      "Batch: 422 , Combined Loss: tensor(0.6455, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.12325102090835571\n",
      "Batch: 423 , Combined Loss: tensor(0.6588, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8495298624038696\n",
      "Batch: 424 , Combined Loss: tensor(0.6634, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.47637975215911865\n",
      "Batch: 425 , Combined Loss: tensor(0.5672, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0014293193817139\n",
      "Batch: 426 , Combined Loss: tensor(0.5908, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.31459617614746094\n",
      "Batch: 427 , Combined Loss: tensor(0.6894, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.05383002758026123\n",
      "Batch: 428 , Combined Loss: tensor(0.5700, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.015699386596679688\n",
      "Batch: 429 , Combined Loss: tensor(0.5362, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5661143064498901\n",
      "Batch: 430 , Combined Loss: tensor(0.5626, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9850363731384277\n",
      "Batch: 431 , Combined Loss: tensor(0.7436, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.010651350021362305\n",
      "Batch: 432 , Combined Loss: tensor(0.5937, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.011972606182098389\n",
      "Batch: 433 , Combined Loss: tensor(0.6144, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.945754885673523\n",
      "Batch: 434 , Combined Loss: tensor(0.6180, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7334398031234741\n",
      "Batch: 435 , Combined Loss: tensor(0.5787, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7955466508865356\n",
      "Batch: 436 , Combined Loss: tensor(0.6057, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9737111330032349\n",
      "Batch: 437 , Combined Loss: tensor(0.6313, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.180103600025177\n",
      "Batch: 438 , Combined Loss: tensor(0.6041, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.4058887958526611\n",
      "Batch: 439 , Combined Loss: tensor(0.6450, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4983440637588501\n",
      "Batch: 440 , Combined Loss: tensor(0.6412, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6668170690536499\n",
      "Batch: 441 , Combined Loss: tensor(0.6026, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.956499457359314\n",
      "Batch: 442 , Combined Loss: tensor(0.5854, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9298590421676636\n",
      "Batch: 443 , Combined Loss: tensor(0.7197, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4079326391220093\n",
      "Batch: 444 , Combined Loss: tensor(0.6992, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8068773746490479\n",
      "Batch: 445 , Combined Loss: tensor(0.6019, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9591765403747559\n",
      "Batch: 446 , Combined Loss: tensor(0.7518, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5674349069595337\n",
      "Batch: 447 , Combined Loss: tensor(0.6459, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.08480370044708252\n",
      "Batch: 448 , Combined Loss: tensor(0.7614, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9116923809051514\n",
      "Batch: 449 , Combined Loss: tensor(0.7038, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.40688276290893555\n",
      "Batch: 450 , Combined Loss: tensor(0.5101, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9779621362686157\n",
      "Batch: 451 , Combined Loss: tensor(0.6314, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7833914756774902\n",
      "Batch: 452 , Combined Loss: tensor(0.7432, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.3692985773086548\n",
      "Batch: 453 , Combined Loss: tensor(0.6314, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0830562114715576\n",
      "Batch: 454 , Combined Loss: tensor(0.5233, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4265272617340088\n",
      "Batch: 455 , Combined Loss: tensor(0.6398, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0562431812286377\n",
      "Batch: 456 , Combined Loss: tensor(0.5600, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0927624702453613\n",
      "Batch: 457 , Combined Loss: tensor(0.9524, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.06274008750915527\n",
      "Batch: 458 , Combined Loss: tensor(0.5722, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9151836633682251\n",
      "Batch: 459 , Combined Loss: tensor(0.5512, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.618895411491394\n",
      "Batch: 460 , Combined Loss: tensor(0.6741, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.127737283706665\n",
      "Batch: 461 , Combined Loss: tensor(0.5674, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1313910484313965\n",
      "Batch: 462 , Combined Loss: tensor(0.6543, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.29679536819458\n",
      "Batch: 463 , Combined Loss: tensor(0.6904, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0951833724975586\n",
      "Batch: 464 , Combined Loss: tensor(0.5914, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5113447308540344\n",
      "Batch: 465 , Combined Loss: tensor(0.7329, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.5377941131591797\n",
      "Batch: 466 , Combined Loss: tensor(0.7695, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.17675095796585083\n",
      "Batch: 467 , Combined Loss: tensor(0.6655, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9631834030151367\n",
      "Batch: 468 , Combined Loss: tensor(0.7310, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8429857492446899\n",
      "Batch: 469 , Combined Loss: tensor(0.7038, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1098346710205078\n",
      "Batch: 470 , Combined Loss: tensor(0.5838, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9392268657684326\n",
      "Batch: 471 , Combined Loss: tensor(0.5825, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1184515953063965\n",
      "Batch: 472 , Combined Loss: tensor(0.7066, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8210065364837646\n",
      "Batch: 473 , Combined Loss: tensor(1.0732, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.5494649410247803\n",
      "Batch: 474 , Combined Loss: tensor(0.5757, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.4708130359649658\n",
      "Batch: 475 , Combined Loss: tensor(0.6158, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0861611366271973\n",
      "Batch: 476 , Combined Loss: tensor(0.5263, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8042161464691162\n",
      "Batch: 477 , Combined Loss: tensor(0.6419, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.0007988810539245605\n",
      "Batch: 478 , Combined Loss: tensor(0.7673, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1194918155670166\n",
      "Batch: 479 , Combined Loss: tensor(0.5755, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0696794986724854\n",
      "Batch: 480 , Combined Loss: tensor(0.5775, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8990950584411621\n",
      "Batch: 481 , Combined Loss: tensor(0.5474, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7424700260162354\n",
      "Batch: 482 , Combined Loss: tensor(0.6516, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0436220169067383\n",
      "Batch: 483 , Combined Loss: tensor(0.6435, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.0589885711669922\n",
      "Batch: 484 , Combined Loss: tensor(0.7160, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7441954612731934\n",
      "Batch: 485 , Combined Loss: tensor(0.5343, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.6222034692764282\n",
      "Batch: 486 , Combined Loss: tensor(0.6042, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8946205377578735\n",
      "Batch: 487 , Combined Loss: tensor(0.6251, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -1.1127681732177734\n",
      "Batch: 488 , Combined Loss: tensor(0.6587, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8181719779968262\n",
      "Batch: 489 , Combined Loss: tensor(0.6108, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: 0.07876765727996826\n",
      "Batch: 490 , Combined Loss: tensor(0.7712, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.8654187917709351\n",
      "Batch: 491 , Combined Loss: tensor(0.4534, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.7355959415435791\n",
      "Batch: 492 , Combined Loss: tensor(0.5453, device='cuda:0', grad_fn=<MeanBackward0>) , Dice Loss: -0.9519118070602417\n"
     ]
    }
   ],
   "source": [
    "!python main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7659393d-f209-4595-b5fe-8ccbda0732f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  unrar\n",
      "0 upgraded, 1 newly installed, 0 to remove and 3 not upgraded.\n",
      "Need to get 113 kB of archives.\n",
      "After this operation, 406 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 unrar amd64 1:5.6.6-2build1 [113 kB]\n",
      "Fetched 113 kB in 0s (276 kB/s) \u001B[0m\u001B[33m\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "\n",
      "\u001B7\u001B[0;23r\u001B8\u001B[1ASelecting previously unselected package unrar.\n",
      "(Reading database ... 64485 files and directories currently installed.)\n",
      "Preparing to unpack .../unrar_1%3a5.6.6-2build1_amd64.deb ...\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [  0%]\u001B[49m\u001B[39m [..........................................................] \u001B8\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 20%]\u001B[49m\u001B[39m [###########...............................................] \u001B8Unpacking unrar (1:5.6.6-2build1) ...\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 40%]\u001B[49m\u001B[39m [#######################...................................] \u001B8Setting up unrar (1:5.6.6-2build1) ...\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 60%]\u001B[49m\u001B[39m [##################################........................] \u001B8update-alternatives: using /usr/bin/unrar-nonfree to provide /usr/bin/unrar (unrar) in auto mode\n",
      "\u001B7\u001B[24;0f\u001B[42m\u001B[30mProgress: [ 80%]\u001B[49m\u001B[39m [##############################################............] \u001B8Processing triggers for man-db (2.9.1-1) ...\n",
      "\n",
      "\u001B7\u001B[0;24r\u001B8\u001B[1A\u001B[J"
     ]
    }
   ],
   "source": [
    "!sudo apt install unrar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c23669-7782-4bcb-96d8-d91d7eb4095e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unrar x ./data.rar ./"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
